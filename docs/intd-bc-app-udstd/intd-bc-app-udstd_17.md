© 作者，独家授权给 APress Media，LLC，属于 Springer Nature 2022J. T. George 引介区块链应用[`doi.org/10.1007/978-1-4842-7480-4_17`](https://doi.org/10.1007/978-1-4842-7480-4_17)

# 17. AI 和区块链监控自主车辆管理项目

约瑟夫·泰奇尔·乔治^(1  )(1)意大利罗马

自主车辆管理系统是本章的主题。这涉及在分布式环境中操作车辆或系统。*人工智能*和消息交换（区块链）在这种情况下都存在。同时，当涉及自主车辆管理时，我们必须防止灾难性崩溃。

## 17.1 区块链与人工智能之间的联系

区块链和人工智能是目前两个最受欢迎的技术发展方向。尽管它们的发展伙伴和实现方式大相径庭，但科学家们一直在讨论和研究这两种技术的整合。按照定义，区块链是用于存储加密数据的分布式、去中心化、不可变的账本。而人工智能，则是根据获得的信息进行分析和判断的引擎或“大脑”^(1)。

人工智能和区块链处于一种相互支持和相互受益的位置。因为这两种技术可能以各种方式影响数据，将它们结合起来在逻辑上是合理的，并且可能将数据的利用推向新的高度。同时，将机器学习和人工智能纳入区块链，反之亦然，可以改进区块链的基本架构，同时增强人工智能的能力。区块链还可以使人工智能更加逻辑和可理解，使开发人员能够跟踪和理解为什么做出深度学习选择。区块链及其分类帐可以跟踪所有数据和因素，这些数据和因素涉及到一个深度学习结论（见图 17-1）¹。![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig1_HTML.jpg](img/520777_1_En_17_Fig1_HTML.jpg)

图 17-1

区块链和人工智能

此外，人工智能可以比人类甚至传统技术更有效地提高区块链的效率。仅仅看一下目前如何在传统计算机上操作区块链就可以证明这一点，即使是完成基本活动也需要大量的计算能力^(2)。

### 17.1.1 应用中的人工智能和区块链

最近，路上的汽车数量正在增加。因此，预防交通事故是社会面临的一个问题。例如，机器学习（ML）技术在提高道路安全管理系统的整体性能方面特别有用。区块链使用共识方法和智能合约来管理节点之间的通信，无需第三方中介。同时，人工智能有潜力提供智能的、具有人类思维能力的决策机器人²。

基本上，当我们应用区块链和人工智能进行应用开发时，我们需要考虑以下两个方面：

+   **数据的货币化**。通过共识算法和智能合约，区块链在没有第三方或中介机构参与的情况下管理节点之间的通信。此外，区块链技术促进了网络上信息的共享，这是分散、安全、持久、匿名和可信的。²

+   **使用 AI 进行决策**。人工智能（AI）如机器学习（ML）算法对提升整体车辆安全管理系统的性能非常有帮助。²

### 17.1.2 AI 在实时智能和决策机器中的角色

AI 技术使机器能够自主思考，无需人类参与。AI 方法在通过已置于车辆驾驶舱内的 IoT 设备分析收集的数据时非常谨慎。对于车辆的实时决策操作，多种机器学习技术都非常重要。

系统根据系统的训练评估驾驶员的不适或不舒适状态。首先，系统与驾驶员进行沟通。之后，如果检测到车辆的不适身体表达，它会向预先编程的网络发送报告。本章介绍了如何在车辆系统管理中实施 AI^(3)。

## 17.2 区块链用于信息共享与交换

区块链对跨 IoT 设备端点共享和传输数据至关重要。它使用 BC 管理各个网络控制位置、系统和服务器之间的无线通信网络。BC 是 IoT 的支柱技术，用于收集数据并将其分发到端点或最终节点。众所周知，BC 在共享信息时为 IoT 节点和利益相关者提供了可追溯性、信任、隐私、安全性和透明度。

区块链允许提供商和互联网公司共享数据，并根据客户隐私数据批准互操作性。它还分享数据共享记录，以授权数据访问。数据可追溯性也很重要，以保证数据交换合法、受控、可审计和受监管³。

信息应该通过这个区块链系统以信任、安全和透明的方式在端点之间进行通信。为了实现数据访问权限，区块链共享数据共享记录。车辆驾驶员有自己的私人访问控制机制，并有能力分享或出售他们的数据，如图 17-2 所示。这里，承运人或通信服务提供商（CSP）提供诸如（1）不发送私人数据、（2）确认信息可以验证和修改以及（3）可追溯且防篡改信息等好处³。![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig2_HTML.jpg](img/520777_1_En_17_Fig2_HTML.jpg)

图 17-2

通过区块链技术在车辆管理系统中进行数据传输

注

在本章中，我们创建了一个项目（自动车辆管理），结合了人工智能和区块链技术。目标是专注于人工智能，因为前一章已经大量讨论了区块链技术。这是人工智能、区块链和物联网等最流行技术的结合体。在西方国家有许多例子，这两种技术都被应用于应用程序开发。

在所有西方国家，自动驾驶车辆现在是移动性发展的主要轴线之一。欧洲委员会致力于支持任何能够帮助实现其智能和可持续移动性计划中先前确立的可持续性和安全目标的连接和自动化移动解决方案。

城市有轨电车和火车，目前已具备自动驾驶能力，用于公共交通。未来几年内，我们可能会看到配备数字共享汽车系统的自动出租车在限定区域运营。在私人交通方面，实现完全无人驾驶汽车的目标仍然遥远，特别是在拥堵区域。然而，在接下来的几年里，市场上将会有越来越多配备先进自动驾驶功能的汽车可供购买。几个城市可能会提供基础设施，以开发环境数字系统，使得一些自动驾驶功能在未来十年内得以部署。即使变革将会逐步进行，让我们期待一条全新的道路。

当前，自动驾驶是汽车界面临的最大挑战之一。开发具备人工智能能力，能够在没有人类干预的情况下驾驶并在几千分之一秒内做出基本决策的汽车，并非易事。在公开道路上测试阶段，涉及自动驾驶汽车的事故并不少见，但逐步推进，我们正迎来越来越先进的车型，能够不需要人类干预。

自动驾驶车辆管理的优势包括：

+   **多任务处理：** 驾驶者可以专注于完全不同的活动。

+   **安全性：** 传感器和预测算法将使自动驾驶汽车能够评估并在某些情况下预测风险。通过安全驾驶，道路事故的数量将会减少。

+   **效率：** 可以避免急刹车和突然加速，从而优化燃料消耗。

+   **减少交通堵塞：** 一旦上路，车辆将会持续相互通信，交换位置、行驶速度和其他有用的、符合交通规则的信息。

+   **无人例外：** 残疾人也可以使用自动驾驶汽车。事实上，他们不需要特殊的身体技能。只需向无人驾驶驾驶员指示目的地就可以了。

计算机现在在我们的文化中发挥着关键作用。这些系统如今被用于各种领域的各种应用，从医学到航空电子，还包括相对较新的新兴技术，称为人工智能。

由于这些技术被应用于新的领域，因此“计算机系统”的概念必须重新定义。大多数这些系统必须在严格的时间表内完成任务，否则可能会发生灾难性后果，包括广泛的破坏、伤害，甚至死亡。

当系统必须遵守严格的时间框架时，我们将其称为*关键系统*。当系统的失败可能是灾难性的，给环境、基础设施或个人造成严重伤害时，我们将其称为*安全关键系统*。

在某些情况下，这些系统是在物理环境中使用的。自动驾驶汽车就是这样一个系统的例子：它由一个执行完成给定任务所需的计算的计算机系统和一个与环境进行交互的物理组件组成，从而改变环境和平台的状态。

由于这些系统如此广泛，但如果它们出现故障会如此危险，因此在设计和开发过程中满足和确保它们（通常）超高可靠性标准至关重要。一个系统的可靠性是衡量其“可信度”或其提供准确服务的能力的一个标准。

故障是造成所提供服务中断的事件。一个关键系统的*可靠性*被描述为一组理论和实践指标。让我们更仔细地看看最重要的指标。

## 17.3 可靠性与安全

关键系统的*可依赖性* 描述为一组*定量* 指标。以下是其中几个较为重要的指标：

+   *可用性* 是一个度量指标，用于比较正确与错误服务的频率。

![../images/520777_1_En_17_Chapter/520777_1_En_17_Figa_HTML.jpg](img/520777_1_En_17_Figa_HTML.jpg)

+   *可靠性* 指系统提供一致服务的能力。

+   *安全性* 定义为故障发生时无灾难性影响。

    由于安全标准要求有可量化的度量，系统的安全性通常通过整合额外的指标如平均到下一次灾难性故障时间来描述。

![../images/520777_1_En_17_Chapter/520777_1_En_17_Figb_HTML.jpg](img/520777_1_En_17_Figb_HTML.jpg)

+   *可维护性* 指在系统失败后维护和恢复系统的能力。此因素对可用性有影响。

+   *覆盖率* 是系统容错措施在预防、避免或纠正问题方面的效能度量。

*风险* 是威胁系统可靠性的事件：是导致系统提供错误服务的“事件”。威胁可以采取各种形式，源自不正确的规范或需求的不正确执行，或灾难。

关于系统可靠性，我们希望确保服务始终正确。当服务从准确转变为错误时发生故障。减少从适当服务阶段到错误服务阶段的可能转变要求项目部署，同时构建关键系统。 (见图 17-3.)![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig3_HTML.jpg](img/520777_1_En_17_Fig3_HTML.jpg)

图 17-3

正确与错误服务

在评估安全关键系统的可靠性时，我们应区分良性和灾难性故障。对于良性故障，系统可能无法提供最佳服务，但仍将保持安全。在这些系统和人员在密切接触的情况下，不安全的服务可能会产生灾难性后果，如环境损害，系统基础设施的干扰，甚至致命事故。以自动驾驶汽车为例。考虑这样一个情景，汽车在“正常”情况下行驶时，前方出现了障碍物。

尽管急刹车和随后的乘车中断是一个失败的状态，但因为没有人受伤，它被认为是一种良性的失败。除此之外，当车辆加速驶向障碍物（最终与之碰撞）的情况被视为危险故障，因为乘员可能会受重伤。（见图 17-4。）![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig4_HTML.jpg](img/520777_1_En_17_Fig4_HTML.jpg)

图 17-4

状态

我们希望发现所有可能的故障，以评估安全关键系统的可靠性。研究人员使用了备受学术界和政策制定者青睐的故障错误失败链，以实现他们的目标：

+   故障是一个带有裁定或推测原因的错误。

+   错误：系统的一部分条件可能导致失败。

+   失败：当错误进入服务接口，导致整个系统服务中断的情况。（见图 17-5。）

![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig5_HTML.jpg](img/520777_1_En_17_Fig5_HTML.jpg)

图 17-5

故障，错误和失败

当错误发展到无法纠正的地步时，系统的可靠性取决于四种旨在预防或减轻潜在故障影响的方法的集合：

+   **防止故障发生：**预防故障发生或引入的方法。

+   **容错：**允许缺陷被容忍的方法。即使发生故障，系统仍能正常提供服务。

+   **故障消除：**降低系统缺陷的数量或严重程度。

+   **故障预测：**使用统计方法估计当前缺陷数量、未来发生和潜在影响。验证程序用于评估采取的措施是否符合系统的可靠性标准。

系统需求确认是一种必须在整个开发阶段遵循的方法，包括在设计过程开始时。对于系统开发过程的每个阶段，都有多种验证技术可供选择：

+   **数值建模：**使用简单的数值模型对系统能力进行建模的方法，具有简单的分析解决方案。换句话说，可以使用定量分析函数来表达系统的变化。这些模型包括顺序模型和基于状态的模型。

+   **模拟：**在模拟环境中，可以对系统可靠性进行经验估计。这种方法允许您测试某种容错机制是否能在不损害实际系统的情况下运行。

+   **测量：**一旦系统的原型准备就绪，可以监视其运行并产生相关指标。

注意，这些技术并不是相互排斥的，在验证过程中应考虑所有这些技术。

如前所述，验证必须在项目的整个生命周期中进行，从建模阶段开始，直至实施后继续进行。在某些时期，本书描述的一些方法更为合适：

+   **规格：** 通过可靠性标准的描述来实现有效性，这可以使用数值技术来验证。要确定系统组件的故障标准，可以使用组合设计等方法。故障被认为是相互独立的。

+   **设计：** 在设计阶段使用基于状态的模型来表示系统的状态空间是合适的。马尔可夫链和彼得里网是这些模型的例子。

+   **实施：** 当项目进行到一定程度时，可能可以构建一个原型模型，该模型可以进行密切监控，以查看提高系统可靠性的容错方法的有效性。

+   **运行：** 在安装后，可以在真实环境中测试系统。

## 17.4 跟踪系统

监测系统是一种技术，涉及观察系统在其环境中运行，并收集有关其特征的数据和证据。目前，这被视为评估系统可靠性的一种有效方式，并且已经提出了许多这样做的技术。我们在本章中使用了这些书中提出的方法。

这种方法旨在持续监控系统在其最终环境中的情况，确保观察到的行为和性能符合特定需求。需要对监控活动中获取的数据进行验证：

+   **离线：** 在系统运行时，数据被收集并保存在某个地方，然后在之后进行评估。

+   **在线**（或实时）：数据在获取时进行评估。在制定监控策略时必须考虑所有这些因素：

    +   确定系统的重要事件、指标和必须评估以确定系统可靠性的特性。

    +   数据标记以增加原始测量的信息。

    +   数据收集和传输到分析节点进行处理。

    +   基于感兴趣的度量标准进行数据过滤和分类，在监控过程的描述中整个系统被称为目标系统。当跟踪活动与特定的硬件或软件或系统的一部分相关联时，使用一个针对的组件或最终应用程序。专业人士和学者们一致认为，这两种截然相反的技术是有效的：

    +   在黑盒设置中的分析。

    +   在白盒设置中的分析。

你选择的策略取决于你对目标系统的控制程度，特别是其内部实现。

当实现未知时，可以使用黑盒方法，例如当监视操作的能力由第三方系统执行时。在定义了一个工作负载之后，将任务提供给系统，然后注意其输出。（见图 17-6。）![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig6_HTML.jpg](img/520777_1_En_17_Fig6_HTML.jpg)

图 17-6

目标系统输出处理

如果目标系统的内部特征已知且易于获取，可以通过直接连接探针到计算机并在其运行时查看系统的中间输出来研究目标机器的“内部”。由于这些探针直接连接到系统的内部组件，它们可以提供比简单观察系统输出更多的信息。

一方面，这种技术提供了更多关于系统行为的信息，但在监控和系统探查方面也需要更多的注意。特别是，必须遵循这两个原则：

+   **选择的代表性：** 为了执行成功的监控活动，探针应能够获取足够数量的相关事实。

+   **无侵入性：** 探测不能改变系统的行为；否则获取的数据将毫无用处。![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig7_HTML.jpg](img/520777_1_En_17_Fig7_HTML.jpg)

    图 17-7

    探针

在监控系统的设计和开发中需要额外的理念，特别是关于探测的执行方式。我们可以具体区分以下内容。

硬件监控、软件监控和混合监控都是选择。由于其明显的最小侵入性，专用于跟踪的硬件通道是观察系统的最佳方法。然而，随着系统变得更加复杂，安装硬件探针变得越来越困难，甚至极为困难。（见图 17-7。）

软件探针比硬件探针更强大，因为它们可以访问更多相关数据并能建立特定输出产生的上下文。数据提取和测量指令可以包含在过程中，操作系统中，或者可以创建一个新的探针过程。在混合技术中，设备/软件探针可以同时使用，特别侧重于减少每种技术的缺点。

## 17.5 这项工作的动机与目标

由驾驶汽车的*神经网络*与提供容错机制以防止灾难性故障的系统监督者对抗，关于自动驾驶汽车可能对未来系统进步的影响，它们是当前和最有前景的安全关键技术之一。

这种类型的技术通常具有非常高的容量需求，难以验证。此外，软件架构的性质，涉及人工智能和非人工智能软件相互作用，使验证变得更加困难。

本研究的目标是提供一种实验技术，用于评估这种复杂系统的可靠性，重点是什么指标对这些过程是可接受的，以及什么因素影响了分析过程。为了举例说明本书提供的原则，进行了一项在现实模拟环境中进行的实验活动。

你无法访问系统监督员或经过训练的神经网络。该网络是从头开始开发的，项目包括创建基本的系统监督员。

需要注意的是，这项工作的目标不是提供对论点的完整处理；相反，它是为了开始对这些概念和困难进行探索的阶段，这将需要在未来的设计中进行进一步的验证和研究。

## 17.6 汽车应用

十年来的流行趋势之一是自动驾驶汽车。通过使用机器学习技术实际训练过的人工智能已经表明了计算机可以驾驶汽车。然而，如果这些系统失败，个人可能会受伤或丧生。与此同时，证明所需的超高可靠性规格正在变得困难。本章将审查当今自动驾驶车辆安全面临的现代问题。

### 17.6.1 自主汽车作为网络物理系统

车辆自动驾驶的能力需要使用适当的技术和软件。因此，自动驾驶车辆被归类为*网络物理系统*（CPSs），这些系统的故障可能会产生灾难性的影响，将它们归类为重要系统。

该系统从各种传感器收集数据以感知和绘制本地环境。以下是一些最重要的传感器及其功能：

+   **高精度 GPS 传感器：** 这些传感器对于监测汽车和周围物体的状态随时间的变化非常有用。

+   **摄像头：** 通常使用人脸识别软件和摄像头来处理记录的图像。

+   **激光雷达和雷达：** 激光雷达是传统雷达演变的下一步。从这些传感器收集的信息用于绘制周围环境并检测车辆附近的障碍物和物体。

这些传感器的结果被整合并发送到汽车的控制系统中。图 17-8 描述了软件架构的简化版本。![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig8_HTML.jpg](img/520777_1_En_17_Fig8_HTML.jpg)

图 17-8

系统的软件架构在高层次上进行了抽象。

传感器数据是管理系统的输入，分为两部分。一个输入直接从传感器收集数据，处理数据以创建一个占用栅格，以映射附近的区域，并生成一个物理模型，以便按照适当的路径到达最终阶段而不会崩溃。另一个输入从传感器收集数据，处理数据以创建一个占用栅格，以映射附近的区域，并生成一个系统的物理模型，以便在没有碰撞的情况下获得正确的路径到达最终阶段。

汽车的活动包括加速、制动和转向。由于其工作的重要性，需要一个系统监督员。该系统负责检测潜在的硬件故障或错误的过程控制输出，并在必要时执行正确的操作。

系统管理员是这些系统的关键部分，并防止了故障。 毫无疑问，数据分析时可以进行某些检查，但最终决定权在于系统的监视器，而低估其重要性可能会产生灾难性结果，例如 2018 年亚利桑那州的一起悲剧，当时一名女士在一次试验中被一辆自动驾驶汽车撞死。¹

额外的调查发现，车辆的雷达和激光雷达传感器在碰撞前大约六秒就检测到了受害者，并且需要四秒的时间来推断道路上有障碍物需要紧急停车。然而，在进行“更平稳的行驶”测试期间，这个安全检查器被停用，导致了悲剧发生。^(4)

这些系统的高复杂性引起了专家们之间的争议，包括需要为研究和测试其安全性开发一种新视角，以及需要提高对安全性的认识。

## 17.7 安全和自控车辆

自动化程度可根据 SAE International 提出的建议分为六个等级，从 0 到 5 不等，用于对自动驾驶汽车的自主性进行分类。 0 级意味着没有自主性：汽车仅由人操作；5 级表示不需要人类参与，并且车辆必须能够在道路上安全驾驶，同时避免可能严重伤害人员的灾难性故障。 对于在开放道路上使用的汽车，可靠性标准越高，其自主性就越高。⁴

证明设备的可靠性本身就是一项困难的工作，但对于像这样具有超高可靠性的系统来说，情况变得更加困难。 除了手头的问题之外，展示自动驾驶汽车的可靠性还面临着两个额外的挑战：如何高效而安全地测试系统，以及神经网络的存在，因此很难解释为什么在给定输入 x 的情况下产生了输出 y。¹

几项研究表明，道路测试汽车是不可能的。其中一项名为兰德研究，考虑了使用传统统计推断来展示自动驾驶车辆准确性需要驾驶多少英里，估计如果自动驾驶车辆的致命率比人类低 20 个百分点，将需要超过五个世纪，“一天 24 小时 7 天，一年 24/7 驾驶 100 辆无人驾驶汽车的车队。”¹

对于安全关键系统的超高可靠性标准的确认是安全文献中一个众所周知的话题，而自动驾驶汽车尚未加入其中。事实上，兰德研究只是描述利特伍德和斯特里吉尼在 1993 年的论文中描述的问题的一个例子，在该论文中，相同的思想被检验和扩展用于任何超高可靠性系统。¹

兰德研究方法的根本缺陷在于，未来失败的频率不能仅仅基于观察到的失败预期。这种方法无效，不仅因为其不可能性的数量性发现，而且因为观察到的频率失效为零将导致乐观（可能危险的）预测。幸运的是，正如赵等人展示的那样，这个困境是可以解决的。¹

验证自动驾驶车辆的可靠性标准本身就是一个艰巨的挑战。这些汽车由神经网络控制，使得事情变得更加困难。

机器学习领域近年来受到了越来越多的关注，从而产生了重要的科学进展。由于这些进展，自动驾驶汽车似乎成为现实，因为人工智能已经通过其能力取得了令人惊讶的成果，大型企业如亚马逊和阿里巴巴正在更多地投资于人工智能相关的研究。由于这一新的人工智能研究浪潮，人们与计算机的互动方式正在发生巨大变化，神经网络已经产生了令人惊讶的结果。

尽管神经网络表现出了潜力，并且似乎是达到自动驾驶等目标的唯一方法，但已经多次证明，当输入偏斜时，网络的预测可能变得多么奇怪，以及当输入偏斜时置信水平可以有多高。对于这种类型的软件缺乏既定的标准和认证，以及完全理解神经网络的需求，引发了对这些系统依赖性的担忧。随着先进的人工智能企业游说加强限制，对这个问题的认识正在增加。

## 17.8 控制器：检查者的问题

控制系统与系统管理员之间的连接是车辆运动的核心。控制系统，通常被称为*主要因素*，是进行系统主要计算的软件，这些计算是车辆运行所必需的。为了避免在这种情况下发生灾难性故障，需要采取容错措施，例如系统管理员。由于这些系统对高可靠性的需求，因此需要这种类型的架构，以尝试覆盖所有可能的故障。（见图 17-9。）![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig9_HTML.jpg](img/520777_1_En_17_Fig9_HTML.jpg)

图 17-9

这张图描述了系统的安全状态。

安全状态是指控制系统生成的输出不会导致车辆崩溃的状态。 系统安全程度可以表示为控制器和监督器故障区域的并集，其中有一个重叠区域，监督器对系统性能真正有害。

考虑一辆自动驾驶汽车在道路上行驶时遇到意外的绊倒障碍物。 如果主要识别障碍物正确，它应该采取自保措施以防止进入警报模式。

如果控制器无法检测到障碍物或检测到障碍物但继续油门，那么判定控制器已经失效，故障特征开始发挥作用，控制器从安全状态切换到警报状态。 现在，系统管理员有责任采取补救措施将系统置于故障安全模式。 由于两个元素的故障，管理员错误一定会迫使系统失败，导致故障状态。

*聚类算法*，一种独特的表格布置方式，允许可视化分类系统的性能，可以用于显示系统监督员的可能行动。 这是通过将世界分为两类：正类和负类来实现的。

假设我们正在试图区分羊群中的白羊和黑羊。 正类将是黑羊的类。 被识别为黑羊的黑羊称为真正的+Ve。 白羊构成-Ve 类，每只白羊都是真正的-Ve。 当白羊或黑羊被错误分类时，称为假阳性或假阴性¹。 实际值和预期值是这种形式的列联表的两个维度，如图 17-10 所示。![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig10_HTML.jpg](img/520777_1_En_17_Fig10_HTML.jpg)

图 17-10

迷惑矩阵表

我们需要指定在自动驾驶汽车领域中什么构成良好和不良分类。请记住，控制器的“故障”被定义为从安全位置转换到警报状态，其中监管者可以在不崩溃的情况下管理生态系统，而在此状态下，系统最终会崩溃而无法由管理员控制。

因此，+ve 类代表最终会导致控制器故障的事件集，而负类代表控制器成功控制的事件集。我们将对管理员的选择进行测试，以区分安全和警报状态。为了实现这一点，我们使用了以下正负预测的定义：![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig11_HTML.jpg](img/520777_1_En_17_Fig11_HTML.jpg)

图 17-11

系统状态空间中以图形方式表示真实和错误的预测。系统的当前状态由点表示。蓝点表示没有引发警报，而红点表示监视器触发了警报。

+   **真阳性（TP）：** 由于控制器故障，系统进入了警报模式，控制器正确识别并停止了警报。

+   **真阴性（TN）：** 系统工作良好，控制器未发出警报。

+   **假阳性（FB）：** 尽管系统是安全的，但监控信号却发出了警报。

+   **假阴性（FN）：** 系统处于高度警戒状态，控制器无法识别威胁。

这些原始数字只是更复杂和更有价值的测量的起点，通常以率的形式给出，并使用统计定律进行链接，使它们在已知正确和错误预测的数量的情况下成为统计上可比较且易于计算。这些是这些指标的一些实例：

+   **敏感性（真正率）：** 计算被准确识别为真正阳性的真正阳性的百分比。

![../images/520777_1_En_17_Chapter/520777_1_En_17_Figc_HTML.jpg](img/520777_1_En_17_Figc_HTML.jpg)

+   **特异性（真阴性率）：** 评估准确分类为真阴性的真负值的百分比的指标。

![../images/520777_1_En_17_Chapter/520777_1_En_17_Figd_HTML.jpg](img/520777_1_En_17_Figd_HTML.jpg)

+   ***错误拒绝率*** **（也称为假阴性率）：** 被错误预测为负的真正阳性的百分比。

![../images/520777_1_En_17_Chapter/520777_1_En_17_Fige_HTML.jpg](img/520777_1_En_17_Fige_HTML.jpg)

+   ***错误接收率：*** 通过错误接收率（假阳性率）测量了被错误预测为正的真实负值的分数。

![../images/520777_1_En_17_Chapter/520777_1_En_17_Figf_HTML.jpg](img/520777_1_En_17_Figf_HTML.jpg)

这四个率也可以耦合以提供多种其他指标，表明模型的预测性能。

这里是一些更常用的度量指标：

+   *准确度* 是衡量预测中系统错误的度量标准。这种预测与其“实际”值之间的差异是由于精度不足引起的。

![../images/520777_1_En_17_Chapter/520777_1_En_17_Figg_HTML.jpg](img/520777_1_En_17_Figg_HTML.jpg)

+   *精确度* 是用于描述预测中的随机错误的模型的统计变化的度量。

![../images/520777_1_En_17_Chapter/520777_1_En_17_Figh_HTML.jpg](img/520777_1_En_17_Figh_HTML.jpg)

+   *Fβ-分数* 是测试可靠性的综合精度和敏感性度量。其范围从 0（最差值）到 1（最佳值），与真正阳性直接相关。

![../images/520777_1_En_17_Chapter/520777_1_En_17_Figi_HTML.jpg](img/520777_1_En_17_Figi_HTML.jpg)**马修相关系数**是考虑混淆矩阵中的每个单元格的整体预测质量的指标。该指标范围从 1（最差值）到 1（最高值），允许更全面地评估模型的正确性。![../images/520777_1_En_17_Chapter/520777_1_En_17_Figj_HTML.jpg](img/520777_1_En_17_Figj_HTML.jpg)

*ROC5 曲线图*是二元分类器效果的图形表示，其中 x 轴表示假阳率，y 轴表示真阳率，并且通过 y = x 线将图形分割。

此行以上的值表示“优秀”的预测，而此行以下的值表示“低于随机”的预测，而此行上的值表示任意的猜测。

所有这些指标都可以计算并相互连接，如果知道正面和负面期望的实际数量，则分析的视角转换就变得简单。我们想要展示的是，通过利用这种技术，我们可以估计计算复杂额外指标所需的所有数量，如威胁评分和虚假发现率，这些指标依赖于评估的需求。

这只是与计算机系统的不对称容错架构相关的安全扩展，其中一个主要组件执行主要计算，而一个主要检查器检测（和纠正）任何主要缺陷。确定这些较简单系统的可靠性的挑战在出版物中得到了深入研究。

在 2010 年由 Popov 和 Strigini 发表的一篇论文中，证明了系统在给定输入（或输入集合）上失败的机会与主要检查器的覆盖范围和次要检查器的覆盖范围密切相关。

我们希望在自动驾驶汽车的情况下，主要覆盖尽可能多的地面。 这是通过对驾驶汽车的神经网络进行广泛培训来实现的。 只要网络“完全训练”，控制系统必须能够处理大部分潜在危险事件。 有可能在某个时候，控制器学会处理系统监督者的“警戒状态”，从而减少监督者对软件安全性的总体贡献。（见图 17-12。）![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig12_HTML.png](img/520777_1_En_17_Fig12_HTML.png)

图 17-12

控制器现在捕获过去所有被监视器覆盖的状态，以及以前仅被监视器覆盖的多个状态

另一种情况是，在训练过程中，由控制器覆盖的故障区域的一部分变得暴露出来。 这可能导致某些以前安全的条件现在不再安全。

因为系统监督者的覆盖范围不能改变而不修改其实施，所以过渡到这些状态之一将不可避免地导致失败。（见图 17-13。）![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig13_HTML.png](img/520777_1_En_17_Fig13_HTML.png)

图 17-13

尽管在训练中先前覆盖的一些状态现在不再覆盖，但控制器现在捕获了监视器过去覆盖的所有状态

谈到自动驾驶汽车，我们希望主体尽可能覆盖尽可能多的地面。 这是通过对将控制车辆的神经网络进行严格培训来实现的。 只要网络“完全受教育”，管理系统就应该能够处理大部分潜在有害事件。

在以下部分中，介绍并讨论了对这些元素进行实验性方法的创建和执行。

## 17.9 系统分析方法

### 17.9.1 初步回合与介绍

该研究的目标是为监测在受控环境中控制系统与系统管理员交互时出现的与新兴相关特征提供初步测试方法。一个抗病毒程序的软件设计被简化为仅两个组件：

+   **一个控制器：** 一个经过强化学习方法训练过的神经网络，用于控制汽车。

+   **一个安全监督员：** 使用来自激光雷达传感器的数据确定车辆是否以过快的速度接近物体，并在必要时施加紧急制动的系统监督员子模块。

本研究的目标是从一个受控的、模拟的环境中重新审视问题，并评估其可行性。由于系统由两个构成系统——控制和监测——组成，我们相信基于从系统相互作用中产生的新兴行为的观点可能会提高评估的标准。

本节介绍和探讨了一种研究自动驾驶车辆安全水平随时间变化的策略，其中包括观察神经网络运算器的新兴行为，并在虚拟环境中安全评估它。

建议的框架专注于调查由这两个构成网络的相互作用产生的新兴现象。

我们专注于监视器的有效性如何随着神经网络的学习而变化，以及培训技术对监视器效能的影响。

通过在数据集上训练神经网络来增强它们的能力是它们最吸引人的元素之一。培训的一个步骤涉及在 n 个阶段收集数据并修订预测函数的权重。

函数的权重表示训练阶段后网络的状态。神经网络应该在足够的迭代之后产生满意的结果。随着所需迭代次数的增加，任务变得更加困难。驾驶汽车是一项困难的任务，保存每个周期的权重是不可能的。

因此，我们将神经网络 N 的断点定义为 N 的通用迭代。假设 N 已经完成了一千次迭代的训练。如果我们通常每 100 次迭代保存一次权重，我们将会有十个检查点：

Checkpoint1 < checkpoint2 < : : : < checkpoint10

其中 checkpoint1 表示第 100 次迭代时的通道权重，checkpoint2 表示第 200 次迭代时网络的权重，依此类推。

看一下正在道路上测试的自动驾驶汽车。它的目标是在尽可能长的时间内保持不撞车。随着汽车在旅途中前进，周围的世界将发生变化。在特定系统状态下，例如当有人突然横穿马路时，后续事故的几率可能会显著增加。只有当控制器的行动导致撞到行人时，我们才会认为它是失败的。如果行人被真实识别并且汽车在试图避免时撞到其他东西，则相同的逻辑适用。

控制器采取的任何可能导致崩溃的行动都被视为失败。当发生潜在的损坏事件时，例如当看到事故的可能性比正常情况更高时，如果其试图阻止即将发生的失败的尝试失败，则控制器注定失败。在这个阶段，我们不区分增加事故几率的气候变化（例如，乘客在街上漫步）和控制器的有害行为。

传感器的任务是在控制器失败时运行安全性以防止系统故障。

如果控制器失败，监控必须不仅识别其是否成功，还必须运行一个安全程序，以确保整个系统不会失败。我们相信在这个分析的初始阶段，监控的行为一定是安全的。也就是说：

+   如果控制器完成了安全程序中的所有阶段，网络将处于安全状态。

+   以下情况之一可能导致安全监控失败：

    +   尚未找到阻塞。

    +   障碍物已被识别，但程序的执行未完成。如果管理员和安全监控同时崩溃，导致失败，则我们评估系统已失败。

我们可以根据这个概念将系统状态分为三组：

+   **安全状态:** 控制器不需要监视器帮助的状态。

+   **警报状态:** 需要监视器干预的情况。如果即将发生的事故被正确检测到（并防止发生），则会重新进入安全状态空间。

+   **故障状态:** 发生事故的区域。重要的是要记住监视器无法识别每一种情况。有些事件是无法避免的，也没有监控可以拯救系统，导致从安全状态直接转变为故障状态。（参见图 17-14。）

![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig14_HTML.jpg](img/520777_1_En_17_Fig14_HTML.jpg)

图 17-14

系统的相空间如图所示。

重要的是发现系统失败的可能性，并找出如何减少它。同时，我们想要看到安全监视器的功效随着控制器学习而随时间演变。

这不仅有助于确保网络在学习过程中改进，还有助于控制器在获得经验时更好地了解监视器的使用。因为在相同的确切情况下评估同一系统的几个检查点，以发现操作员的行为随时间如何变化，这对实验活动是必要的。

不仅需要多个检查点来确保连接的发展，还需要跟踪监视器效果随时间的变化。此外，正如您将在下一节中看到的，如果在相同情况下测试来自同一系统的多个检查点，它可以获取相关指标，并比较两个检查点在相同情况下的行为。

在分析开始之前，必须确定几个场景。场景是汽车将被测试的起始条件的集合（例如，汽车的生成位置，随机数生成器中使用的种子等）。给定示例的困难程度由 pedix h 表示。这样做的理由是我们希望在相同的初始设置下测试汽车，除了一个方面之外，以便我们可以更多地了解是什么导致系统更频繁地失败。随着时间的推移，h 变化应该变得更加复杂，但仍然保持现实。场景 S 可能会通过增加场景中的汽车数量或模拟气候变化来修改。

结合这两个版本，应该产生一个更严格的 scenario1 版本。重要的是要记住，这些场景在建立后不应该被修改，因为它们将被用于测试所有的检查点。这里收集的信息将有助于确定什么因素使某些系统比其他系统更难。

## 17.10 实验方法

这个探索性研究的方法分为三个阶段：

+   **第一阶段：** 鉴于神经网络的 c 个检查点和 nh 种情况，操作员在所有情况下进行评估，并记录其运行。

+   **第二阶段：** 安全监视器连接到系统后，将通过重复执行第一阶段的测试来验证其。

+   **第三阶段：** 使用各种技术对网络进行重新训练，以增强其效率，从上一个检查点开始。之后，将在所有指定的情况下评估更新的控制器和安全监视器。

我们有兴趣在第一阶段确定神经网络和监视器的质量。这分为两个阶段完成。第一阶段测试控制器的 m 个检查点在所有情况下。我们主要想看到在这个阶段控制器的可靠性如何相对于这些检查点而变化。

重复性问题是评估神经网络最困难的方面之一。如果初始情况相同，同一个神经网络在多次运行中以相同的方式行事是相当不可能的。

由于这种网络特性，有可能在其中一个场景运行中指示的故障模式永远不会再次发生，或者其所需的时间会不合理地长。由于难以预见所有可能的故障场景，我们认为这种情况方法可能有助于解决这个问题，通过创建更具挑战性的操作条件，在其中可以检查导致崩溃的变量。

为了解决可重复性问题，为运行的每个测试场景建立了一个黑盒子。该方法跟踪操作员的行动，以便可以进一步查看特定的运行情况，以发现控制器出了什么问题。然后可以利用这些数据来找出控制器在检查点 j 处保护哪些危险情况，以及当网络在检查点 --:j + x 处进行审查时，这些情况是否仍然受到保护。

### 17.10.1 控制器测试

控制器在每种情况下都是独立评估的，在每个难度级别下，直到发生崩溃。仍然可以想象到可能不会记录任何故障。可接受的行为标准超出了本研究的范围，尽管它们仍然是学术界的一个争议点；然而，正如前一节所述，这个问题可能会得到解决。

在方法开发阶段发生的一些困难促使决定隔离控制器进行测试。主要的挑战是一致性和非侵入性。如前所述，神经网络的可重复性问题通过创建一个黑盒子来处理，该黑盒子保存了有关每一帧汽车状态的信息。由于监视器强制实施的安全制动几乎肯定会改变模拟器的环境条件，在模拟器运行期间我们无法计算控制器性能指标，因此我们无法同时测试整个系统（控制器和监视器）。

将控制器隔离测试有助于解决这些困难，并作为第二步的热身。在每种复杂情况下测试控制器后，必须至少计算以下内容：![../images/520777_1_En_17_Chapter/520777_1_En_17_Figk_HTML.jpg](img/520777_1_En_17_Figk_HTML.jpg)

评估系统可靠性函数 R(t)最重要的指标之一是故障中位时间，这在模拟条件下很容易计算，并用于确定指数函数的速率。 另一方面，汽车部门的统计数据通常以行驶距离表示，例如平均故障距离、每公里碰撞发生率等。 如果参数和模拟硬件足够强大，可以在定义的时间步长内进行计算，那么使用这种方法来改变数据的观点非常简单。

我们预计以下不等式将持续到神经网络完全训练为止：Ri(t) 6 Rj(t)，其中 I 和 j 是两个检查点，I j。 这可以通过前面描述的数据收集方法轻松确认。![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig15_HTML.jpg](img/520777_1_En_17_Fig15_HTML.jpg)

图 17-15

可靠函数确定系统在时间 t 继续工作的可能性。 我们预计，经验丰富的驾驶员能够完成比训练不足的网络更长的行程。

+   如果测试用的模拟器允许，还应记录其他信息，以提高对控制器行为的了解，例如：

    +   汽车的瞬时速度和加速度矢量。

    +   汽车碰撞的对象（另一辆车，行人）。

+   设置一个或多个目标目标，并跟踪车辆是否达到目标。

+   如果在时间 t 发生碰撞，则确定时间 t-x 的环境条件。 这些数字对区分“安全”和“灾难性”故障至关重要。 例如，如果以不到 10 公里/小时的速度撞击围栏，可能被认为是比以相同速度撞击人的事故更轻微的事故。

因为经过训练的驾驶员比新手造成的事故要少，我们预期控制器学习后可靠功能会增加，从而提高 MTBF。

如果黑匣子利用更好的数据，也有可能跟踪汽车行为的变化，与情况和难度水平相关。例如，如果我们将情况中的汽车数量加倍，那么与其他障碍物相撞的次数几乎肯定会增加。如果是这种情况，就应该更深入地研究模拟，以便将培训策略集中在特定方向上，因为这可能导致控制器在试图避开其他汽车时撞上墙壁。

### 17.10.2 监控或观察测试

在操作员的行程已经记录之后，监控测试可以开始。在这个阶段，我们不仅要评估安全监控在防止崩溃方面的表现如何，还要寻找哪些情况对监控来说“困难”，哪些情况对控制器来说“容易”的证据。

因为控制器现在包含了屏幕先前披露的所有故障，并且其新行为带来的风险对监视器来说太大，以至于监视器无法检测到因特网骨干线路成熟时即将发生的故障，因此其行为可能会演变到监视器不再能够检测到的程度。

另一方面，相反的方式也是可行的选择。例如，在早期的时代，控制器可能会“疯狂”地驾驶，做出许多突然的、高角度的转向，并以高速行驶。由于控制器的行为是意外的，监视器将更难预测未来的状态。随着学习的进行，网络会运行得更加平稳，使监视器更容易看到潜在的事故。

主要问题是，随着网络学习，监视器的有效性可能会降低，导致一个完全无用的组件，甚至可能对系统的性能有害：操作者可能足够强大，以覆盖先前检查点处屏幕覆盖的所有损坏，从而导致无用的组件。如果我们相信监视器的活动是完全安全的，那么系统的整体安全性可能不会受到威胁，但是安全监视器的安全性将导致更少的顺利出行。

监视器通过重复在控制器测试阶段生成的运行来进行测试。起始条件必须相同，并且它们必须保留在上一个阶段的黑盒中。现在，控制器之前的运行将被重复，监视器连接到系统，并记录整个运行期间引发的警告，以及它是否能够避免先前的崩溃。

在调查的这一阶段，主要问题是非侵入性。我们不能仅通过添加安全监视器并观察事物如何进行来考虑重新运行模拟，原因如上所述。如果触发了警报，安全监视器将覆盖控制器的操作，改变运行的下一部分。理论上，如果您能区分出虚假和真实的阳性，这不是问题。然而，如果没有开发软件传感器来监视和映射环境，我们将无法预测技术错误将是什么。

因为这是一个安全监视器，即使虚假阳性非常低，也会出现假阳性，因此这种方法无法解决问题。

目标是在操作过程中跟踪发生的警告，同时避免启动安全程序。因为我们将重复从第 1 阶段开始的运行，所以我们将能够确定在崩溃之前发生警报状态转换的确切时间 t。由于我们知道 t，因此在 t 之前的所有警报都是假阳性或错误报告，根据这一信息。可以通过在此时间点之后允许监视器启动安全程序来近似覆盖范围。

如前一章所述，我们使用混淆矩阵来显示模型的预测值与真实值的比较，以了解其在分类任务中的表现如何。然而，要在实时关键系统中测量所有这些值是困难的，如果不是不可能的话。当操作员避免了碰撞，但监视器没有发出警报时，尤其难以理解。

这使得计算真负例的数量变得异常困难，因为在大多数情况下，只有在操作员审查每个单独的运行时，这种情况才能被识别出来，从而为真负例等指标带来了一定程度的主观性。

例如，安全监视器的输入由一系列定时输入组成，这些输入可以被视为系统运行时环境的发展。因此，无法预测是否会发出另一个状态警报或安全警报，因为我们不知道最终导致崩溃的输入收集何时开始。

因为监视器需要一定数量的真负例，所以可以计算的度量和比率受到限制。同时，安全监视器在每个帧中对系统的状态进行分类，收集激光雷达数据，评估它，并决定是否需要安全制动器。由于系统的实时性质，我们可以将监视器未发出警报的任何帧都视为真负例。我们可以使用这种方法计算统计分类模型中所有广泛使用的度量标准。

我们必须结合真假的正负号，例如精确度和准确性，以获得巨大的好处，因为真负例的数量很可能远远大于其他度量标准，其原因如前所述。由于假阳性率被说明为 FP/FP+TN，因此在第一个显著数字之前有大量零的数字结果。此外，为了给出对假阳性的可理解的速率度量，计算了会话中行驶的距离上的假阳性的数量。

如前所述，确定了正确和错误操作员预测的比率，并且可以用于比较检查点：

+   漏报率和感知度

+   特异性和后果

+   正确性

+   精确

+   马修连接因子

+   每米误报率百分比

+   精确召回曲线降低

选择准确性和可靠性的 ISO 标准。准确性的概念已被预测准确性的概念所取代，其中准确性被解释为随机错误的混合需要大量精度和准确性的表示。评估混淆矩阵最有用的度量标准是马修相关系数，其计算方法为所有预测的总和，并且发现比 F 分数提供更准确的总体数据。

我们选择不使用 Fi，因为它在一般情况下与不平衡的数据集的功能不佳，导致结论要么过于乐观，要么取决于数据量。我们选择使用 MCC 作为监视器性能的度量标准，因为真阴性的数量很大，而且我们对监视器的整体效用很感兴趣。

每米的误报率被用来预测如果控制器和安全措施都启用并共同操作，系统将如何运行，并量化后者故障安全刹车的影响。ROC2 曲线是分类器工具诊断能力的图形表示，可能提供了传感器有效性的快速视觉表示，但这种方法不可行。x 轴由 PR 决定，而 y 轴由 TPR 决定。

由于我们数据集的显著不平衡，图表在左侧将被压扁，假定假负例的数量可能低于 10^-2，基于如何对真阴性进行分类。因此，根据每个难度下获得的数据，我们使用高度精确的裁剪来生成图形平均值，通过定义以召回为 x 轴，准确率为 y 轴的曲线生成。

我们无法构建一个测试集来评估监视器，在改变选择是否刹车并呈现整个曲线的截止值时，因为监视器仅根据激光雷达传感器提供的数据实时定义状态是安全还是危险的。因此，对每个复杂度的过去数据进行了计算，并显示了这些值，以探索难度与监视器效能之间的联系，裁剪到包含预期值的区域。

在测试监视器时，最好使其经受考验以收集额外的数据并建立数据之间的联系。这个元素与上述难度水平无关，因为它是与环境有关的任何东西，它可以提供关于监视器何时工作良好何时不工作的证据，并且更多涉及高级别的故障注入。

安全监控设置的修改方式大多由其实现方式定义，开发团队负责选择包含哪些问题以及包含多少个问题。减少传感器读取的数据量或者向观察中添加噪音是两个简单的选择。这一阶段将教会你如何更改软件的内部设置，以获得“理想”的版本，该版本将在整个控制器重新训练过程中使用。

### 17.10.3 控制器重新训练

在这一点上，我们已经收集了监视器和控制器行动的信息。每当神经网络从最新的检查点中保存时，我们将调查这些值根据所使用的学习技术而异的程度。

我们正在研究一个由使用强化学习技术训练过的神经网络构建而成的控制器，正如本章开头所述。在这些方法中，奖励函数被用来告知网络它的工作是好还是坏，并且它会被计算每一次预测步骤。

训练函数需要基本参数，并且在每个算法迭代中重新评估：

+   网络的响应。

+   系统在执行动作时的当前状态。

+   以特定方式完成任务而给予的奖励。

在这个阶段，我们将研究不同的神经网络训练技术如何影响系统的整体行为，重点放在安全监控的效果上。

为了开始我们对这个问题的调查，我们确定了四种技术以及在训练完成后的预期后果。这些结果是“预测的”，因为我们不知道网络对训练方法的修改会如何反应，或者观察到的行为是否与预测的行为相同。

使用这种技术创建的策略主要取决于奖励函数和通道的行为：

+   S1) 当汽车撞到任何东西时，奖励函数更加惩罚，但只要车不停止行驶，刹车就会得到更多的奖励。

+   S2) 安全监控与系统相连，如果触发了警报，监控的响应优先于网络的（安全制动器）。

+   S3) 如果监控引发警报，则网络的活动会被监控的活动替代。为了像监控一样行动，网络会获得良好的奖励。

+   S4) 如果触发了警报，则训练阶段终止，网络会获得较差的奖励。

如果我们使用 S1，我们估计控制器的中位故障时间/距离会减少。对于碰撞提供更高的负激励，对于刹车提供更低的正奖励（如果汽车不停止行驶）应该鼓励汽车选择刹车而不是转向（可能会导致新的危险情况），从而增加故障之间的时间和行驶距离。

S2 的目标是“训练”网络，如果监控引发警报，则刹车。因此，以前由监控覆盖的战斗状态可能会变成安全状态。

S3 在许多方面类似于 S2。为像监控一样行为提供正激励有望加快学习速度。

S4 是迄今为止最有前景的方法，它有潜力提供最有趣的结果。当安全监控发出警报时，无论是真实的还是误报，都会产生负面奖励和训练步骤的变化，这应该迫使网络完全避免监控介入的情况。从本质上讲，我们预计安全组件的效果会显著降低。

当四个控制器已经得到足够的教育时，新设备被测试，就像在第 1 阶段一样。对控制器和监控器进行了相同的测量估计，并将结果与实际检查点进行了比较。

## 17.11 方法实施和结果

本章回顾了所使用的工具、软件架构和技术实现，以及在分析过程中收集的数据。一个 DDPG 代理器 1 被教会在城市环境中驾驶。在训练过程中，记录了网络状态的检查点以进行比较。为了对 AV 行为提供独特的视角，这些网络检查点在有和没有简单安全监控的情况下进行了测试。

## [工具和软件](https://wiki.example.org/tools_and_software)

### [CARLA 模拟器](https://wiki.example.org/carla_simulator)

CARLA^([5)](https://wiki.example.org/carla_simulator)，由巴塞罗那大学研究人员创建的开源模拟器，用于构建一个具有准确物理模拟和数据传感器的现实环境。该模拟器的目标是提供一个环境，使得 AI 代理能够在其中接受驾驶训练，并且能够高度控制模拟设置以及真实传感器的模拟，这些传感器可以被修改以改善或降低数据质量或插入错误。

CARLA 设计为在客户端-服务器环境中工作。服务器本质上是使用 Unreal Engine 4 创建的一个游戏。C++的速度对服务器的功能至关重要：不仅必须模拟环境（包括行人/车辆的移动、气候建模等），而且还必须处理与系统连接的传感器所需的所有数据。

CARLA 现在已经更新到版本 0.9.7，每个版本的发布都带来了重大改进，进一步吸引了专家们的关注，因为它的真实性。不幸的是，当我们的研究开始时，CARLA 0.9 刚刚发布，我们需要的工具还没有在网上提供。

首先使用 0.8.4 版本是因为已经完成了之前稳定版本 CARLA 的工作量。

在 0.9 版本之前，对模拟参数和收集数据的控制有限制。这并不妨碍我们的研究，但它确实在某种程度上限制了有关周围环境和系统的有用信息。一些这些缺陷仍然存在于之前的模拟器版本中，但在从 0.8 版本升级到 0.9 版本后，大部分已经修复了。

最严重的困难之一是坐标系。在版本 0.9 之前，开发者使用的是 UE4 的默认坐标系，尽管标准是右手坐标系，但它是左手坐标系。这看起来似乎是一个小问题，因为这个问题可以很容易地通过使用变换矩阵来解决。然而，由于时间限制，决定继续使用开发者的方法，主要在分析阶段修改数据。

这个版本的 CARLA 包括四个传感器，这些传感器都在实验中使用。由于 Python API，它们很容易学习：

+   相机

    +   最后一个相机提供了场景的图片。

    +   为了理解周围环境的深度，深度图相机给物品分配 RGB 值。

+   CARLA（参见[`carla.org/`](http://carla.org/)）

    +   语义分割通过以不同颜色显示来自不同类别的物体，以便在视图中对其进行分类。

+   基于射线投射的激光雷达

    通过用激光束照射物体并测量反射光返回传感器的时间，光探测与测距（Light Detection & Ranging，LDR）是一种检测环境并估计物体间距离的技术。

在整个网络的训练阶段，使用了三台摄像头。三个场景最终的摄像头安装在汽车上，以便驾驶员观察周围环境。

由于深度图像相机，车辆可以获得场景中物体间距离的彩色地图。通过向服务器请求地面真实信息，语义分割提供图片分类功能。这无疑是对真实系统的简化，其中最强大的照片软件实际上是其他独立训练过的神经网络。错误分类也可视为控制系统错误。

如果检测到可能的威胁，安全监视器将不会“修正”错误解释；相反，它将立即安全地做出反应以避免后果；因此，这种简化对整个方法没有影响。

CARLA 此版本的另一个可用传感器是基于射线投射的激光雷达。可以轻松调整该传感器的参数以模拟实际的 Velodyne 激光雷达或缺陷，如低数据质量、噪声数据或数据丢失。使用点云格式生成数据。

由于在模拟中模拟真实的激光雷达需要高硬件资源，因此使用了符合给定标准的 Velodyne64 激光雷达的显著修改版本：

+   通道数量 = 64

    +   系统的总激光束数量。这些激光沿 y 轴均匀分布。激光束越多，扫描越精确。

+   范围为 75 米。

    +   激光的范围（以米为单位）

+   旋转频率 = 15 Hz

    +   这些设置定义了扫描束的旋转速率（以 Hz 表示）

+   每秒钟 1,000,000 分数

    +   每幅图像由传感器生成的点的数量

+   视场垂直边界（高 = 24m，低 = -2m）。距离是相对于传感器位置测量的。

    +   扫描的最小和最大高度

模拟器具有用于修改传感器的 Python API，以及对正在模拟的内容（如生成位置、行人和车辆行为以及场景中“演员”的状态，如其位置和速度）的大量控制。

所有这些信息以及地面实况值都由模拟器提供。与模拟相关的度量标准，如模拟时间步长或每秒帧数，可能会被使用。与演员相关的指标包括车辆速度、碰撞严重程度和三维加速度向量。

在测试此工具期间，发现了与激光雷达传感器数据相关的问题，但尚未解决。该问题导致汽车的边界框在移动时变形，导致数据质量非常差。经过大量调查，发现了模拟器的更新版本，修改了每辆车的边界，以产生正确的数据。开发人员目前正在解决这个问题，但在源代码中需要人工干预才能解决。

### 17.12.2 控制器设置

将选择汽车移动所需的行动的神经网络视为控制器实现中最重要的元素。我们需要一个具有以下功能的框架。

+   用于训练的代码。

+   代码库中没有重大缺陷。

+   创建一个网络可以与 CARLA 通信的环境。

+   提供默认的训练方法。

在分析了所有适用于 CARLA 的设备应用程序后，我们选择了英特尔 AI 实验室的强化学习平台 Coach。

这个框架满足以下所有标准：它作为一个可以编辑的 Python 包进行分发。项目的开发团队向我们保证产品将具有高质量。还有许多设置可供选择作为起点。其中两个选择包括 CARLA 模拟器界面和预设的训练策略，这恰好是我们所需要的。

深度确定性策略梯度方法，于 2015 年推出，被实现在这些设置中。正如原始作品所展示的那样，这种方法在车辆驾驶等任务中表现良好。

+   P1: 第一个设置使用单个前置摄像头以及 CARLA 提供的额外数据增强相机来感知环境。这个预设的代理肯定会缺乏常规摄像头提供的深度感知，而是完全依赖深度摄像头。

+   P2: 因为汽车配备了三个常规摄像头以及在前一节描述的所有数据增强相机，所以这个设置利用了 CARLA 中所有可用的摄像头，并具有更加引人入胜的设计。

使用数据增强相机允许我们忽略物体误分类以及其他好处，比如估算物体之间的距离。这是一个简化形式的真实架构，在这种架构中，物体识别单元是必须以不同方式进行训练和评估的神经网络，如前一节所述。

另一方面，误分类肯定会导致控制器以意想不到的方式行动，这是安全监视器必须能够检测并可能纠正的。可悲的是，即使车辆受到积极奖励，初始设置也存在导致它停止油门的缺陷。测试这种设置也会很有趣，看看它如何影响安全监视器在网络数据访问方面的效力。

需要注意的是，我们的目标不是创建“理想”的代理或自主车辆。对代码库进行了检查，但由于时间限制，我们无法检查给定实现的所有细节。该框架作为本书讨论的思想的示例。

### 17.12.3 安全监视器实现

为了开始研究，我们需要能够读取激光雷达数据并映射环境以及检测障碍物的软件。此软件还必须是实时的，并且能够与 CARLA 通信。后者是不言而喻的：每当触发警报时，CARLA 服务器必须接收“刹车”命令。第一个需要一些考虑：一个人可能会设想提前捕获激光雷达数据，然后使用此数据进行模拟。不幸的是，这种方法不起作用，因为我们不仅关心是否有 100%准确的预测，还关心监视器安全措施的质量。

如果在两个独立的模拟中进行了相同的测量，并且结果有所不同，监视器的响应可能与在模型期间提供的实时数据完全不同。如果测量的精度仅与研究模拟器相关，我们就不能忽视制动对特定实验的影响。

为了构建一个适当的安全监视器，进行了最佳“非神经网络”方法的调查，以及对可用的开源工具的评估。为了处理点云数据，选择了开源库点云库。它是用 C++编写的，以处理大量数据为目标。该库最初于 2011 年发布，每个后续版本都对其进行了增强，部分原因是庞大的社区帮助测试和调试新功能。

这个包含一组方法，实现了最常见的点云处理技术。创建对象检测模块的步骤在这里概述：

+   **下采样：** 由于存在相当多的冗余和噪音，单次检查可能会产生 100,000 个记录。作为第一步，通常需要进行下采样以消除所有“无用”的数据。经过深思熟虑，我们选择了体素网格滤波器作为这个阶段的方法。

+   **地面分割：** 下采样后（如有必要）的第一步是过滤掉用于对象识别的无价值数据，例如相对于地面的点。为了区分地面和我们想要识别的东西，必须过滤这些点。在我们的实现中，我们使用了 RANSAC2 算法，这是一种区分“内点”和“外点”的机制。

+   **聚类：** 此阶段必不可少，以正确定义什么构成了场景项目以及哪些数据点与该项目相关联。可以使用基于点接近性的聚类技术来完成此操作。由于它是一种基于测距的方法，计算点之间的欧几里得距离和密集点表示相同项目的前提，因此选择了欧几里得聚类技术。

+   **跟踪和避障：** 在前三个组件中识别的项目必须在时间内被观察，以确定在两个连续阶段观察到的两个对象是否是同一实体。这通常通过将故障安全程序与预测它们随时间变化的物理模型（例如卡尔曼滤波器）相结合来实现。

但是，为这样一个复杂的模型开发卡尔曼滤波器需要花费太长时间，迫使我们暂停研究。因此，我们简化了对象识别和故障避免过程如下：

+   只有汽车前方的数据被保存。这对概念来说是一个重大改进，因为监视器现在只能识别车辆前方的障碍物。然而，虽然这无疑会影响安全监视器的效果，但在前一节讨论的思想仍然有效。

+   使用的故障预防程序基于英特尔提出的 Mobileye 的责任敏感安全范式。当检测到物体时，计算物体相对于系统的速度。如果系统一秒钟内行驶的距离加上距离大于物体行驶的距离加上系统和物体之间的空间，则会启动安全制动。

因为安全监视器是用 C++编写的，所以创建了一个用于与 CARLA 通信的架构，既可使用点云库，又考虑到性能因素。

CARLA 客户端的点云。这些数据与之前的阶段相同方式进行分析，如果必要，会向客户端发送警报。如果监视器收到警报消息，则会覆盖控制器的操作，并施加制动。物体识别模块受到 Engin Bozkurt 的开源项目的影响。为了调整检测算法设置以符合我们的目的并与 CARLA 接口，软件进行了大量更改。

## 17.13 实验活动

本部分解释了在上一章中创建的方法如何付诸实践，以及在过程中出现的技术问题。

教练的默认技术被用来训练控制器在城市环境中产生四个检查点，然后进行评估。

CARLA 提供了 152 个生成点，用于创建场景。针对每个生成点创建了基本配置和三个变体：

+   h0-默认设置：有 30 人和 15 辆汽车，地图是在控制器训练时使用相同情况下生成的。

+   h1- 行人设置：地图是根据行人数量从 30 增加到 60 创建的。

+   h2- 设置车辆：地图是在环境中的汽车数量增加了从 15 辆到 30 辆。

+   h3- 地图是通过合并 h1 和 h2 制作的，结果是一个有 60 名行人和 30 辆汽车的场景。

为了保持一致性和可重现性，产生了 152 对唯一种子，每个种子都有自己的起始点。您可以使用相同的种子来进行多次迭代，以相同的起始点开始。

汽车也被分配了一个目标位置，以达到，同样为了可重复性进行记录，以补充关于系统整体性能的信息。如果达到目标，就记录下成就，并为系统分配一个新的目标以追求。

在正常情况下，崩溃可能需要非常长的时间才会发生。因此，在此工作中，设置了最长操作时间为 15 分钟，以展示本文中提出的原理，之后系统的任务被视为完成。

在调查的第一部分中开发和评估了四个检查点，使用了第三部分中概述的技术。由于 Coach 项目是开源的，编码是公开可用的。

我们能够利用软件探针来监视控制器的活动。源代码已更改，以包括将所有所需数据写入单独文件的指令，以供每次运行使用：

+   情景的起始位置和种子

+   控制器所采取的行动

+   如果发生碰撞会发生什么？

+   如果达到了目标，请记录下目标坐标以及新的目标坐标。

一般来说，修改源代码可能会导致整体性能和结果准确性的降低。幸运的是，CARLA 模拟器允许您在特定的时间步长上运行模拟。为了保证从服务器接收的所有数据都是正确和及时的，这个时间步长被设置为最小值：每秒十帧。因为我们无法控制可变的时间步长，这可能会给数据引入不可预测性。这也为测试的重复性奠定了基础。初步培训部分以及控制器测试大约花费了一个半月的时间。

在第二步中，对每个检查点的安全监视器进行评估。源代码再次更改以建立两个自主的并行进程：一个从 CARLA 服务器接收激光雷达数据并将其发送到安全监视器服务器，而另一个则等待安全监视器决定是否需要刹车。

每帧，CARLA 系统会创建激光雷达数据。由于数据创建的负担完全依赖于 CPU，执行时间显著较慢。不幸的是，如果 FPS 低于十，CARLA 会出现一个导致数据不正确的问题。为了保证每秒十帧的最低限制，需要一台性能强大的机器。在代码库中添加了软件探针，以收集关于监视器警报的信息，并再次修改了源代码。当安全行为监视器被监视时，第一步的运行现在被重复。在测试期间，生成的所有警报都是误报。

为了评估真正阳性的数量，事故发生前两秒启动紧急刹车。这种方法允许我们在其操作环境中评估安全性能监视器。

在第一阶段完成后，获取的数据被处理以计算出在上一章中陈述的测量值。

+   控制器的检查点:

    +   故障之间的平均时间

    +   故障间隔时间（MTBF）

    +   故障率

    +   稳定性

+   安全检查员：

    +   预测矩阵令人困惑

    +   正/负率（真/假）

    +   完美细节

    +   马修相关系数

    +   假阳性百分比

使用先前提到的技术继续训练，测量过程以相同的方式执行。

提到的一些方法需要进行安全监视器培训，导致执行时间异常快速。由于创建激光雷达数据所需的高处理负载，此阶段大约花费了三个月的时间，之后培训被停止。收集的数据可以进行比较，以评估网络是否正确学习，以及安全效能监视器如何随时间演变。

使用 Python 脚本收集和分析数据，以聚合数据并为控制器和整体安全监视器的功能提供度量标准。对于这种类型的工作，数据聚合是必不可少的。然而，由于这些系统的复杂性以及许多有害事件的频率很低，必须在聚合数据之前评估和比较各个运行。

由于获取的数据量巨大，我们主要以聚合形式提供收集到的结果。关于“原始”数据的其他问题，这些问题没有包含在此研究中，但是已单独提供以供评估。

## 17.14 结果

### 17.14.1 控制器测试（第一阶段）

收集的数据存储在每次运行的不同文件中，并且本章中指定的度量是使用 Python 代码计算的。获取的数据进行比较，以确定控制器的良好程度以及安全效能监视器在神经网络阶段之间的修改。

为了确定每种情况下行驶的距离是否增加以及是否存在对系统特别“积极”或“具有挑战性”的情况，绘制了每种情况下行驶的距离。

这是第一步，帮助测试人员区分重要和次要情况。如果控制器在场景 x 中行驶的距离小于所有检查点中通常行驶的距离，有两种选择：

+   如果控制器在爆炸前总是在所有检查点上行进相同的距离，那么可能存在控制器尚未学会处理的危险。

+   如果在短时间间隔内行驶的距离变化，那么可能会由初始条件决定碰撞的可能性。无论如何，使用这种方法，很容易找出哪些情况会导致控制器迅速崩溃，每种情况都可以进一步调查。

重要的是要记住，如果在测试各种检查点时出现模式，例如控制器定期工作异常良好或异常糟糕，那么在这两种情况下都需要对特定实例进行研究。

由于这些原因，“不良”运行的基本原理是不言而喻的。听起来可能有些反直觉，但在相同情况下进行多次“良好”运行需要更多的关注。需要对绩效和起始条件之间的关系进行检查，并且可以使用此方法进行证明或驳斥。

当系统识别出“好模式”时，例如汽车只是重复完全相同的序列而不会遇到其他车辆时，会出现更复杂的问题。

在正常难度下，检查点 1 和 4 之间的数量级差异很大，并且在一些情况下，这些测试的最大长度已经达到。这种方法的另一个引人注目的特点是，对于 C2:4 的行驶距离的下限约束在整个挑战过程中保持不变，保持在 22 米。

对行程距离和运行时间的更仔细的观察表明，有些情况下控制器没有进展，这意味着引发崩溃的事件是控制器无法处理的类型。从确定最短运行是否共享可能导致控制器表现不佳的任何环境变量的角度来看，这些类型的结果无疑是有趣的。 (见图 17-16.)![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig16_HTML.jpg](img/520777_1_En_17_Fig16_HTML.jpg)

图 17-16

在正常难度下，控制器 C1 在任何情况下移动的距离为米。

两个连续活动之间的时间间隔是已知的，因为指定和理解了模拟的两个阶段之间经过的模拟时间：单次运行的真实总长度可以通过计算控制器执行了多少个动作来估计。 (见图 17-17.)![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig17_HTML.jpg](img/520777_1_En_17_Fig17_HTML.jpg)

图 17-17

控制器 C4 在正常困难下每种情况下行进的距离。

我们可以简单地通过使用每个困难程度中的平均 MTTF 近似计算每个检查点的可靠性函数。![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig18_HTML.jpg](img/520777_1_En_17_Fig18_HTML.jpg)

图 17-18

反应 x 分钟后，系统正常运行的机会 y 被图形化地显示。

初始检查点的 MTTF 相对较低（20 秒），正如预期的那样，随着检查点数量的增加而增加。有趣的是，第二个检查点似乎比第三和第四个检查点表现更好。尽管如此，在一部分运行中，第二个检查点在折叠时间和行驶距离方面取得了极好的结果，但分析显示，它的驾驶方式比其他两种更加危险，并且很可能导致一种糟糕的驾驶方式，即汽车几乎每次都在最后一刻转向以防止碰撞。 C2 并不总是优于 C3 和 C4。C3/C4 表示明显增加的安全性很可能是由上面指出的“幸运模式”引起的另一种迹象。

幸运的是，正如第 3 阶段的研究结果将表明的那样，控制器能够克服这个问题。

检查点距离遵循类似的模式：更长的运行实际上是汽车行驶更多米的行程。这确保了系统不会“作弊”：如果汽车根本不动，执行时间将更长。我们可以通过计算每个危险级别中每个检查点的平均行驶距离来估计在碰撞前行驶的公里数方面的耐久性函数。

此外，观察到的失效距离的进展往往与一段时间内的失效进展相一致，这意味着这两个指标是相关的。

由于 CARLA 允许记录碰撞发生的物品类型，所以对于每个检查点，针对每个风险类别计算了发生的物体类型相对于总碰撞的比率。这种方法有许多好处：（见图 17-19。）

+   要查看汽车是否撞上墙壁、灯杆或篱笆，表明它正在偏离道路。

+   了解汽车在不同难度级别下的反应方式；例如，如果提高了人数，减少了行人碰撞，系统可能能够防止人员事故。

+   识别系统与某些物体交互时防止故障的能力。

![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig19_HTML.jpg](img/520777_1_En_17_Fig19_HTML.jpg)

图 17-19

在 x 公里后，系统变得操作性的几率 y 在图形上显示。

![../images/520777_1_En_17_Chapter/520777_1_En_17_Figl_HTML.jpg](img/520777_1_En_17_Figl_HTML.jpg)这些图表可以用来观察系统在训练过程中，随着场景复杂度的增加而表现如何，以及是否有任何碰撞类型和安全检查之间的相关性。第一个检查点与越野物体相撞，显示了控制器驾驶能力的弱点。（见图 17-20。）![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig20_HTML.png](img/520777_1_En_17_Fig20_HTML.png)

图 17-20

图表

还可以看出，与一般障碍物碰撞的比率有一定的趋势，跟随着总检查点完成情况。当将此图与贡献进行比较时，可以看出 C1 与障碍物的碰撞比率最高，而 C2 的比率最低。C3 增加了这些碰撞的频率，伴随着 MTTF/MDTF 的减少，后来由 C4 进一步减少。 

尽管描述的四种困难程度相当简单，但它们被证明是评估系统在训练环境之外情况下表现的有效手段。在问题三和四中，平均无故障时间（MTTF）和平均修复时间（MDTF）显著较低，表明高交通量的情况更难管理。与此同时，所选择的困难程度的要素影响着某种类型物体的碰撞百分比的增加/减少。

这意味着报告的碰撞取决于周围环境。人口增加以及汽车数量增加导致与这些“物体”的碰撞增加。随着人口和汽车数量的增长，碰撞与其他车辆仍然是事故的主要原因，表明拥挤的交通使控制器处于更危险的位置。

这些特征对于定义更困难的问题很重要。这些度量指标还允许检测不同类型碰撞的兴衰之间的联系。

通过使用提供的技术进行第一步，包括情景、问题级别和选择的度量指标的开发，可以在不主动观察其执行的情况下看到控制器的许多特征。此外，通过结合指定的几个措施，可能会忽略环境情况、起始条件和检查点之间的潜在联系。

### 17.14.2 监控评估（第 2 阶段）

在验证控制器并记录其运行以测量其预测准确性以及其对整个系统安全性的影响之后，可以对其进行安全性评估。

正如之前所指出的，Lidar 数据在每一帧都会被收集并传输到安全监控器。然后，这些数据将使用传感器开发部分概述的算法进行评估，并向控制系统发送一条关于车辆是否刹车的具体信息。这两个组件之间没有协调，就像这种类型的真实系统中一样：因为这会导致不稳定的运行，控制器无法在每一帧都等待安全监控器。

以下技术用于计算真正阳性、真正阴性、假阳性和假阴性的数量：

+   在启动部分记录的控制系统运行在附加安全操作到汽车后被复制。

+   允许安全操作发出警报，但直到系统进入警报状态后经过了时间 t，安全刹车才会被应用，如第三章所述。

+   因为选择“早” t 可能会导致处理器管理的活动进行刹车，选择“晚” t 可能会导致安全监控器仅因为安全停止被激活太晚而失败，所以 t 是观察的可靠性的重要参数。当车辆从安全状态转变为警报状态时，安全刹车应该尽快被激活。不幸的是，了解这个转变发生的时间并不总是可行的（如果不是在复杂的运行中则是不可能的）。

+   在 t 之前生成的所有警告都被视为假阳性，基于汽车的平均速度与速度限制之间的关系以及分析 Lidar 数据并从安全监控器获取答案所需的时间，这项研究中设置的时间为两秒。

+   真阴性是监视器达到预测但不发出警报的任何帧。

+   如果系统生存时间达到单次任务设定的最大持续时间，但安全性在时间 t 之后发出警报，则会引发假阳性警报。

+   一个有效的事故规避（如果发生）作为安全刹车监视器的结果被视为真正的积极。

+   无论安全操作是否触发警报，如果发生碰撞，它都被归类为假阴性。

+   在确定真正、假的、肯定的和否定的数量之后，它们可以结合更精确的措施。

本研究提出的技术看起来是理解和验证控制器行为假设以及监视器行为的良好策略。监视器的功效似乎受到控制器可靠性的影响。虽然真阳性率在 0.75 左右保持稳定，但我们可以观察到监视器的精确度在 C2 之后下降，这引发了一些关于安全监视器长期功效的问题。

精确度下降表明假阳性增加，这使我们相信监视器无法准确识别控制器新行为导致的系统状态。每个检查点的 MCC 都支持这一观点，展示了与控制器所教授的相同准确性行为。我们感兴趣的是看看当控制器受限制时，MCC 是否在第 3 阶段降低，因为它是对监视器整体性能的一种衡量。

正如预期的那样，该监视器产生大量的假阳性。这对所述监视方法的功效没有影响，但它确实有助于了解如果两个部分一起运作时系统的行为如何，即通过安全性假警报监视器的警报产生了大量“虚假”安全性。

查看准确度-召回率曲线能够快速直观地展示安全性能监视器的下降，这在“愚蠢”控制器中效果良好，但在训练更好的控制器中几乎变得破坏性。

图 17-21 显示，尽管效率低，但监控器在最高难度设置下表现最佳，即在场景中的人数和汽车数量加倍时。控制器的第二好表现是在第二难的难度下显示的，即在 C1 之后增加车辆数量的水平。尽管控制器的“难”与观察者的“难”之间的联系在这项研究中无法完全检验，但绘制这些图片揭示了意外的行为，促使我们在未来的研究中进一步探讨这一问题。![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig21_HTML.png](img/520777_1_En_17_Fig21_HTML.png)

图 17-21

安全监控器预测控制点 1 到 4 的速率

这些发现与收集和分析的数据一致，因为在 C1 中安全性表现良好，而 C2 到 C4 产生几乎相同的结果，其中 C2 的结果略优。![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig22_HTML.jpg](img/520777_1_En_17_Fig22_HTML.jpg)

图 17-22

基于每个复杂度水平观察值的检查点 C1–4 的准确度召回曲线

![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig23_HTML.jpg](img/520777_1_En_17_Fig23_HTML.jpg)

图 17-23

对比 C1 至 C4 的 PRC

为了理解安全监视器的预测结果，我们不得不亲自执行并观看第 1 阶段检查点 2 的一些最佳运行情况。高速度是 C2.7 监视器故障的主要原因，根据表中显示的假阳性百分比。这种数据收集类型的另一个有趣方面是，随着网络学习处理新情况，安全性会产生更多的误报，更重要的是，最终导致崩溃的场景是一种看守无法检测到的新类型。

图 17-24 中的表格显示了这种方法的工作原理，以及仅通过少量观察就可以收集关于系统行为的大量信息和证据。根据实际可用的硬件和仿真模型，可以获得并组合更多的测量数据以补充这些信息。

图 17-24

C1 生成了大量的假阴性：：：C4

监视器的有效性似乎受到控制器行为的影响，这是我们在项目开始时预期的。最重要的是，证据显示，监视器的预测准确性与控制器的教学时间无关。使用各种技术对网络进行重新培训，并为操作员使用相同的监视方法，可能会证实或否定这一发现。

### 17.14.3 重新培训和重新检查（第三阶段）

如果第 2 阶段表明，将相同的安全性应用于不同的检查点时效率会有所不同，那么使用不同策略进行重构，并将经过这些方法训练的控制器的性能与我们用作默认方法的控制器进行比较，将对证实或否定这一理论至关重要。在这一阶段，我们使用以下五种技术对 C4 进行了重新训练：

+   S0）教练框架的基本技术，用于训练 C1... 4，使用了根据总神经网络质量计算的优化方法。

+   S1）当汽车撞到任何东西时，功能形式现在更加严厉，但刹车稍微更有回报，只要汽车不停止行驶。

+   S2）安全监视器连接到系统，如果发出警报，则传感器的响应优先于网络的响应。

+   S3）如果监视引发警报，网络的活动会被监视器的活动所取代。作为对监视器的行为，网络会得到良好的激励。

+   S4）如果触发了警报，训练阶段将被终止，并且系统会受到不良刺激。

+   结果是{C5S0，C5S1，C5S2，C5S3，C5S4}。

遗憾的是，在 S2、S3 和 S4 技术失败时，基于安全监视的方法并未产生预期的结果。S3 和 S4 阻止控制器移动，而 S2 则在车辆前方有障碍物时经过几米后停车，即使障碍物距离很远。因为不移动是一个糟糕的奖励，这些检查点的行为都没有获得意外的巨大奖励。因此，神经网络在局部最小值和最大值之间被卡住的情况可能还是一个理论，但我们觉得训练时间太短。

显示器极高的误报率可能肯定是罪魁祸首。通过这种方式进行的延长训练教会了车辆不移动，以避开安全警报和监视器。即使这些技术考虑了汽车不移动的可能性，通过对其进行惩罚来获得-ve 效益，但这并不足以阻止汽车保持静止。

我们认为 DDPG 算法的奖励函数定义良好，因为它考虑了所有良好和不良行为，并且即时奖励平衡良好，因为没有意外地巨额支付。然而，由于网络应该被允许驾驶车辆的情况的困难和多样性，调整所有奖励因素以防止我们目睹的结果非常困难。最重要的是，我们无法确定这种行为是奖励函数设计的产物，还是需要更多的训练来观察有趣的行为。

培训的最重要问题是时间投入；使用 n 种技术教授 n 个代理，并在确定哪种方法产生了最佳结果之前等待它们被教授，这是困难的。

网络参数的调整主要依赖于规定和启发式方法，许多出版物已经证明了这一点。然而，这些方法已被证明是耗时且容易出错的。

此外，在这个时候，试错似乎是衡量奖励函数效率的唯一方法。由于培训数据仍在研究中，并且没有为自动驾驶车辆制定明确的法律，因此这个问题，对于这些算法来说是独一无二的，仍然未解决。在学术界，为这些相对新的算法设计奖励函数是一个热门议题，学者们正在努力找出如何提供适当的学习模型。

同时，正如先前所述，AV（自动驾驶）训练需要大量数据，这些数据通常与传统训练方法相比要么无法获取，要么不足。有几种框架可以设计决策规则，用于相关反馈，但其中大多数似乎专注于如何加快学习过程，而不是如何向这些网络添加学习因素。

创建概率模型来帮助在控制器的重新训练阶段之前校准奖励系统参数将是一个有趣的方法。由于保护性能指标被有效地近似，本书介绍的技术将对这些模型的构建产生重大影响。

实际上，奖励函数无法事先知道应将哪个值分配给每个状态。请记住，我们处于一个完全的空间条件下，这很难描述，也使得评估所有潜在事件和转换变得困难，从而使我们的任务变得更加困难。

不幸的是，由于这些系统和技术的复杂性和独特性，需要进行更多的研究来解决这些问题，并且在未来工作中，开发一个辅助微调的模拟过程将至关重要。

## 17.15 总结

本章介绍了如何对由控制器和系统管理员管理的自动驾驶汽车进行检查活动。

由于这些系统的复杂性以及它们所处的生态系统的主要问题，这些系统需要特别关注。这项研究旨在定义这些系统应如何进行监控的第一步。由于自动车辆经常用于军事活动，因此它们并不是一种新型设备。但是，由于自动驾驶汽车将在人类附近和城市环境中运行，因此在应对可能发生的各种事件时需要更多的谨慎。

我们还质疑了当后者使用各种方法长时间教授时，相对安全性和控制元素的效能之间是否存在联系。我们在最初的部分介绍了这些活动的基本原则，例如：

+   可靠性和安全性的定义，这两者都是安全的关键组成部分。在自动驾驶汽车的背景下，我们审查了关键系统。

+   目前阻止我们在都市地区部署自动驾驶汽车的问题。

+   当这些系统的可靠性被错误/欠佳/乐观地评估时，可能会产生灾难性后果，特别是当它们被实施时。

+   分析观察到的新兴行为的问题，这是由两个主要组成部分的相互作用所导致的。

安全监视器的效能是否受到控制器行为的影响，如果受到影响，受到训练的持续时间和训练过程中使用的策略的影响有多大？

在创建这种初始技术时，考虑到了可用于此类活动的工具。我们必须寻求开源替代方案，因为该领域中的大多数解决方案都是私有和专有的，这表明在非专业环境中进行这些研究是困难的。

Lidar 传感器的问题会使我们的研究变得不可行，如果不是因为庄的努力，可能是不可能的，因为我们唯一的选择是依赖地面观测，而这对我们的研究毫无用处。

虽然 Coach 框架是由英特尔人工智能实验室创建的，但它存在着困扰开源项目的通常问题，其中最值得注意的是在第一阶段的几轮训练后，两个 CARLA 代理之一停止移动。这个问题使我们怀疑是否有其他缺陷导致了 C5S2:::4 行为算法的问题。

另一个妨碍框架使用的问题是内存没有被正确释放，导致内存溢出并导致运行进程崩溃。因此，我们不得不在训练过程中保持密切监督，并在每次意外发生后重新进行。

监控活动是根据以下主要特征创建的：

+   **一致性：** 通过在每一帧中保存控制器的活动，以及 RNGs1 的种子，目标目标和每种情况的环境变量。

+   **能够不引人注目：** 由于客户端服务器设计，代码仪器可能提供非实时数据或不正确的测量。这个困难是通过 CARLA 解决的，它允许用户在设定的时间步长进行模拟。但是硬件应该能够实现指定的时间步长。

+   **充分的代表性：** 监控自动驾驶汽车的主要问题之一是测试用例的代表性，因为危险事件可能是如此复杂和繁多，以至于很难评估它们。在这方面，定义场景和难度级别有助于提供基于相同情况的各种场景。对数据集性质的担忧来自于为安全监视器生成的指标的预测价值。解释和证明了在混淆矩阵中要使用的指标的选择，以及排除其他指标的理由。

+   **可用性：** 寻找适合用于此任务的工具是困难的，因为提供了大量选项，其中许多具有重大的实际限制。然而，我们在这个项目中使用的技术使我们能够完成这个任务。

与此同时，我们不能忽视这些举措所存在的问题。这种方法已被证明是分析整个系统性能的有用工具，重点关注于评估系统可靠性和安全监视器效果的知名指标。

创造情境和问题对于确定外部因素是否影响系统性能至关重要，以及对于创建和评估“不常见”情况，这些情况在构建特定安全案例时不能总是涵盖。

启发我们开始这项研究的主要假设是检验“静态”错误检查器的性能是否受到神经网络性能的影响，以及临时训练方法是否也会产生影响。

根据收集到的数据，专家代理的监控效果预计会发生变化，鼓励我们进一步调查这个假设。那些利用安全监控指导训练的方法（S2、S3、S4）的失败并没有为我们提供这一现实的证据，这个问题在章节开始时就被强调了。造成这种失败的两个可能原因是：

+   未定义的奖励函数。

+   训练时间不足。

我们认为神经网络需要更多时间来理解安全性试图教育的内容，因为经过训练的代理人没有因保持静止而获得意外的巨大奖励。更大的仿真时间步长将允许我们比实时更快地运行仿真时间，这将帮助我们节省时间。

我们无法对模型进行长时间的训练或通过改变奖励参数来重新训练网络，因为这需要超级硬件。大约在同一时间，当与产生最佳结果的检查点一起使用时，安全性证明在使用方法 C4 修改训练方法时不太有效，而且当与使用方法 S0 训练的安全检查一起使用时具有相同的 TPR（0.75），除了可能是检查点 C2。

尽管 C2 检查点在前几章中概述的原因下无疑是一个独特的实例，但不能排除相同的理论适用于 C5S1。我们希望未来继续训练 C5S1 以验证这一现实。这项研究展示了在模拟环境中分析自动驾驶汽车的好处，考虑并克服了在计算此类系统的相关指标时出现的许多困难，以及通常的监测关注点。

下一章将总结本书，并对区块链技术和分布式系统环境进行广泛概述。
