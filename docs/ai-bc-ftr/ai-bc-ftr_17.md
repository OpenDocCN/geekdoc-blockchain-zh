© 作者，独家许可给 Springer Nature Switzerland AG 2021 Y. Maleh 等人（编）未来网络安全应用的人工智能和区块链大数据研究

# 基于 X 射线图像的肺炎检测和分类的自动化方法

Khalid El Asnaoui^(1  )，Youness Chawki^(2)和 Ali Idri^(3)(1)应用科学国立学校（ENSAO），电子、计算机科学和电信系，智能信息、通信和技术实验室，莫罕默德一世大学，BP: 669，60000 欧吉达，摩洛哥(2)科学与技术学院，穆拉伊斯梅尔大学，埃拉希迪亚，摩洛哥(3)软件项目管理研究团队，ENSIAS，莫哈比五世大学，拉巴特，摩洛哥

## 摘要

最近，全球的研究人员、专家和公司正在推出基于深度学习和图像处理的系统，这些系统可以快速处理数百张 X 射线和计算机断层摄影（CT）图像，以加速肺炎的诊断，例如 SARS、covid-19 等，并协助其遏制。医学图像分析是最有前途的研究领域之一；它提供了诊断和决策多种疾病的设施，如 MERS、covid-19 等。在本文中，我们提出了最近深度卷积神经网络（CNN）架构的比较，用于基于经过微调的版本（VGG16、VGG19、DenseNet201、Inception_ResNet_V2、Inception_V3、Resnet50、MobileNet_V2 和 Xception）和基线 CNN 的自动二元分类肺炎图像。所提出的工作已经使用胸部 X 射线和 CT 数据集进行了测试，该数据集包含 6087 张图像（4504 张肺炎和 1583 张正常）。结果表明，经过微调的 Resnet50 版本显示出非常满意的性能，训练和测试准确率的增长率超过 96%。

关键词：计算机辅助诊断、肺炎自动检测、CT 和 X 射线图像、肺炎、冠状病毒、Covid-19、深度学习

## 1 引言

流行病和慢性疾病在整个历史上夺走了无数人的生命，并引发了重大紧急情况，这需要长时间的生存。用两个词“流行病”和“爆发”来描述在一段时间内出现在人群中的疾病[1, 2]。实际上，我们可以将流行病定义为在特定地区或特定人群中的某一特定期间内出现的疾病、伤害或其他健康状况的病例超过预期的情况。在大多数情况下，这些病例似乎具有共同的原因[2]。与流行病不同，爆发更为局部化或不太可能引起公众恐慌。

过去的流行病包括肺炎。肺炎是肺部感染，最常由病毒或细菌引起。感染影响肺泡，这些是支气管末端的微小气球状囊泡（图 1）。它通常只影响肺的 5 个叶片（右肺 3 叶，左肺 2 叶），因此称为大叶肺炎。当肺炎也影响支气管时，称为“支气管肺炎”。对于 5 岁以下的儿童，肺炎是世界上最重要的死因之一（约占年度死亡人数的 12.8%）[3，4]。它也是全球成人，特别是在中国[5–7]中的主要发病率和死亡率。对于 80 岁以上的个体，肺炎是日本的第三大死因，老年人死亡率更高[8]。在葡萄牙，除了肺癌外，肺炎是呼吸系统死亡的主要原因[9]。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig1_HTML.png](img/507793_1_En_14_Fig1_HTML.png)

图 1

肺炎图示

自 21 世纪初以来，有几种冠状病毒跨越物种屏障，在人类中引起致命的肺炎。为了了解这些致命流行病的发病机制，专家需要检查感染的结构及其组分。这使他们能够解释并提供有关有效治疗以及可能的疫苗开发的信息[10]。根据表格 1，显示了历史上发生的主要大流行病。我们将总结特定类型冠状病毒的流行病学和历史：SARS，MERS 和 Covid-19。 SARS-Cov（严重急性呼吸综合症冠状病毒）[11，12]是由冠状病毒引起的一种急性呼吸道疾病，特征是发热，咳嗽，呼吸困难，通常伴有肺炎。 SARS 首次出现在中国的广东省，准确地说是在 2002 年，并通过航空旅行路线传播到世界各地。大约有 8098 人受到影响，造成 774 人死亡[13，14]，致死率约为 10%[15]。据推测，它起源于蝙蝠[13，16]。 SARS 症状通常与流感症状相同：发热，寒颤，肌肉疼痛，头痛，偶尔还伴有腹泻。大约一周后，会出现其他症状，如 38°C 或更高的发热，干咳，呼吸急促[15]。表 1

历史上发生过的主要大流行病

| 名称 | 时间段 | 类型/前人类宿主 | 死亡人数 |
| --- | --- | --- | --- |
| 西班牙流感 | 1918–1919 | H1N1 病毒/猪 | 4000–5000 万 |
| 亚洲流感 | 1957–1958 | H2N2 病毒 | 110 万 |
| 香港流感 | 1968–1970 | H3N2 病毒 | 100 万 |
| 艾滋病 | 1981 年至今 | 病毒/黑猩猩 | 2500–3500 万 |
| 猪流感 | 2009–2010 | H1N1 病毒/猪 | 20 万 |
| SARS | 2002–2003 | 冠状病毒/蝙蝠，狸猫 | 774 |
| 埃博拉 | 2014–2016 | 埃博拉病毒/野生动物 | 11 000 |
| MERS | 2015 至今 | 冠状病毒/蝙蝠，骆驼 | 850 |
| Covid-19 | 2019 至今 | 冠状病毒-未知（可能是蝙蝠或穿山甲） | 冠状病毒病例：89,711,341 死亡：1,936,554 恢复：64,572,6242021 年 1 月 10 日，格林尼治标准时间 11:36 |

MERS-Cov（中东呼吸综合征冠状病毒）是由一种病毒引起的病毒性呼吸道疾病[17]。它最初出现在中东，确切地说是在 2012 年的沙特阿拉伯[18，19]。其他病例在约旦[20]、卡塔尔[21]被发现，然后传播到世界各地。MERS 是一种人畜共患病毒，可以在动物和人类之间传播。事实上，世界卫生组织已经确认人类通过与受感染的单峰骆驼接触而受到影响[22–24]。研究表明，病毒从动物传播到人类的方式尚不清楚，除非有密切接触，否则人际传播非常有限[17，25，26]。不同的 MERS 症状如下：发热，咳嗽（干咳，有痰），呼吸急促，腹泻，肌肉疼痛，头痛，恶心，呕吐，腹痛，胸痛，喉咙痛，咳血[17，21，27–30]。

当前，全球正在经历一场危险的病毒流行病，由一种已经导致数万人死亡的病毒引起。这种名为 Covid-19 的新病毒于 2019 年 12 月在中国武汉[5, 31–41]被确认。它属于冠状病毒家族，但比其他冠状病毒更致命和危险[42, 43]。该疾病的首例病例与武汉的一家活动动物海鲜市场有关，表明该流行病的动物源性[36, 41, 44–47]。Covid-19 的传播途径、治疗方法和结果在全球持续受到大量研究关注[31]。事实上，研究人员已经确定了病毒传播的三种主要方式：密切人与人接触、气溶胶传播和触摸传播[10, 42, 48, 49]。冠状病毒非常危险，因为它可以在没有症状的情况下潜伏长达两周。我们可以列举出 Covid-19 的症状：高烧、干咳、疲劳、呼吸急促、肌肉酸痛、喉咙痛，很少有人会报告腹泻、恶心或流鼻涕[10, 43, 50]。随着患这种疾病的患者数量的增加，放射科医生在受限的时间内完成诊断过程变得越来越复杂[51]。医学图像分析是最有前途的研究领域之一；它为诊断提供便利，并对许多疾病如 MERS、COVID-19 做出决策。最近，越来越多的努力和关注都集中在肺炎的影像学和深度学习(DL)上。因此，对这些图像的解释需要专业知识，并需要几种算法以增强、加速和进行准确的诊断。在这种背景下，DL 算法[52]在检测肺炎方面表现出更好的性能，并与先前的最先进方法相比显示出高精度。受到使用 DL 进行肺炎最快和准确的检测率的推动，我们的工作将对近期的深度卷积神经网络架构进行比较，以实现 X-Ray 和 CT 图像在正常和肺炎之间的自动二分类。以回答以下研究问题：**(1)**. 是否有任何 DL 技术明显优于其他 DL 技术？**(2)**. DL 能否用于早期筛查 CT 和 X 射线图像中的肺炎？**(3)**. 基于 CT 和 X 射线图像，DL 能达到什么样的诊断准确度？

我们论文的贡献如下：**(1)** 我们设计了 (VGG16、VGG19、DenseNet201、Inception_ResNet_V2、Inception_V3、Xception、Resnet50 和 MobileNet_V2) 的优化版本，并对基线 CNN 进行了重新训练。**(2)** 为了避免不同模型中的过拟合，我们使用了权重衰减和 L2 正则化器。**(3)** 各种模型已在胸部 X 光和 CT 数据集[53、54]上进行了二分类测试，并优于最先进的算法。

本文的剩余部分安排如下。第 2 节涉及一些相关工作。在第 3 节中，我们描述了我们提出的方法。第 4 节呈现了一些获得的结果并解释这些结果。结论在最后一节中给出。

## 2 相关工作

到目前为止，还没有一种令人信服的方法来预防肺部异常，如癌症和肺炎的发生。因此，早期检测和准确的筛查方法是限制患病风险的最早迹象。在这一部分中，将简要回顾一些现有文献中的重要贡献。肺炎仍然是近年来越来越成为研究热点的疾病之一。事实上，Toğaçar 等人[55]根据肺部 X 光图像采用了卷积神经网络（CNN）作为特征提取器，并使用了一些现有的 CNN 模型，如 AlexNet、VGG16 和 VGG19，用于正常和肺炎之间的分类。作者们采用了最小冗余最大相关性算法，能够减少深度特征的数量。然后，使用了决策树、k-NN、线性判别分析、线性回归和支持向量机进行分类。Liang 和 Zeng[56]提出了一个新的深度学习框架，通过结合残差思想和扩张卷积来对儿童肺炎图像进行分类。因此，为了克服过拟合和模型退化问题，所提出的方法使用了残差结构。作者们还使用了扩张卷积来解决模型深度增加引起的特征空间信息丢失问题。一种用于识别和定位胸部 X 光图像中肺炎的深度学习方法已经由[57]提出。识别模型基于 Mask-RCNN，可以将全局和局部特征合并进行像素级分割。在[58]中提出了使用先进的机器学习算法，特别是深度学习方法进行中风后肺炎预测模型的研究。事实上，作者们使用了经典的分类方法（逻辑回归、支持向量机和极限梯度提升）。他们还实施了基于多层感知器神经网络和循环神经网络的方法，以利用电子健康记录系统中的时间序列信息。得到的结果显示，基于深度学习的预测模型与许多经典机器学习方法相比达到了最佳性能。在[59]中，作者提出了一种使用机器学习解决方案在胸部 X 光图像上自动检测和定位肺炎的方法。他们提出了两种 CNN（RetinaNet 和 Mask R-CNN）。所提出的方法在 Kaggle 肺炎检测挑战的数据集上进行了验证，共有 26,684 张图像。Bhandary 等人[52]报告了一个用于检测肺炎和癌症的深度学习框架。因此，他们提出了两种不同的深度学习技术：第一种是修改版的 AlexNet（MAN）。它旨在使用支持向量机将胸部 X 光图像分类为正常和肺炎类，并使用预训练的深度学习（AlexNet、VGG16、VGG19 和 ResNet50）验证了其性能。同时，第二种方法在 MAN 中实现了手工制作和学习特征的融合，以提高肺癌评估的分类准确性。为了协助放射科医师进行更好的诊断，[60]提出了一种利用深度学习检测胸部 X 光图像中浓缩的方法。作者使用了一个在 ImageNet 数据上预先训练过的深度卷积神经网络来提高模型的准确性。然后，为了增强模型的泛化能力，他们提出了一个三步预处理方法：消除混淆变量、直方图匹配和增强彩色图像的对比度。

## 3 提议的贡献

最近，深度学习方法在图像处理和计算机视觉上展示出巨大潜力，具有最先进的性能[61]。这些技术已应用于各种医学成像模态，在分割、检测和分类方面表现出高性能[62]。一些深度学习方法包括皮肤癌检测、乳腺癌检测和分类、肺癌检测[62]等。尽管这些方法在医学成像领域取得了巨大的成就，但它们需要大量的数据，而这些数据在这个应用领域尚不可用。在医学成像数据集不可用的情况下，受到深度学习和医学图像处理成功的启发，我们的工作将深入比较不同的微调[52]架构：（VGG16、VGG19、DenseNet201、Inception_ResNet_V2、Inception_V3、Xception、Resnet50 和 MobileNet_V2）。下面的章节详细介绍了提议的模型。

### 3.1 提议的基线 CNN 架构

通常，CNN 模型由五个层组成：输入层、卷积层、池化层、全连接层和输出层（见图 2）。此外，众所周知，CNN 模型可以端到端地进行训练，以允许特征提取和选择，最终进行分类或预测。理解网络如何解释图像并处理它是困难的。然而，已经证明，网络的各层提取的特征比人工构建的特征效果更好[63]。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig2_HTML.png](img/507793_1_En_14_Fig2_HTML.png)

图 2

我们基线 CNN 的主要架构

我们实验的提议基线 CNN 的架构如下：

+   输入层：在我们的实验中，输入为 X 射线和 CT 图像。参数定义图像尺寸（244 × 244）。

+   卷积层：卷积是由一组与输入相乘的权重组成的线性操作。它设计用于二维输入；在权重（滤波器）的二维数组和输入数据的数组之间进行乘法运算。在提议的架构中，我们有 3 层卷积层，每层滤波器大小为 3 × 3，零填充。

+   池化层：代表一种通过总结特征图中各个区域的特征存在来对特征图进行降采样的技术。池化方法有两种类型，即平均池化和最大池化。在提议的架构中，我们使用了最大池化来计算每个特征图中每个区域的最大值。最大池化设置为 2 × 2，步长为 2。

+   矫正线性单元（ReLU）层：我们为每个卷积层使用了 4 个 ReLU 层。

+   全连接层：它们将输入数据视为简单向量，并产生单一向量输出。

### 3.2 深度学习架构

自 2016 年以来，深度学习架构被广泛用于诊断肺炎 [52, 53]，最受关注的深度学习技术包括 VGG16、VGG19、Inception_V3、DenseNet201、Xception、Resnet50、Inception_ResnetV_2 和 MobileNet_V2。我们选择了这 8 种技术是因为它们提供的准确性。

+   **VGG16 和 VGG19**

Visual Geometry Group (VGG) 由 Simonyan 和 Zisserman 在 2014 年提出，是一种卷积神经网络架构，赢得了 2014 年 ILSVR 竞赛 [64]。该架构的主要特点是，与其拥有大量的超参数不同，它们专注于卷积层中简单的 3 × 3 大小的核心和最大池化层中的 2 × 2 大小。最后，它有 2 个全连接 (FC) 层，尾随一个 softmax 输出。最常见的 VGG 模型是 VGG16 和 VGG19，分别包含 16 层和 19 层。VGG16 和 VGG19 的区别在于 VGG19 在三个卷积块中每个都多了一层 [65]。

+   **Inception_V3**

Inception 模型是由 Szegedy 在 2014 年开发的一种卷积神经网络 [66]。Inception 模型与普通 CNN 在结构上不同，其中 Inception 模型是 Inception 块，意味着将相同的输入张量与多个滤波器进行重叠并将它们的结果串联起来。Inception_V3 是 Inception 模型的新版本，于 2015 年首次提出 [67]。它是 inception_V1 和 inception_V2 的改进版本，参数更多。事实上，它具有一个并行卷积层块，其中包含 3 种不同尺寸的滤波器 (1 × 1、3 × 3、5 × 5)。

此外，还进行了 3 × 3 最大池化。输出被串联并发送到下一个 inception 模块。此模型接受 299 × 299 像素的输入图像大小。

+   **Resnet50**

Resnet50 是由 [68] 开发的一种深度残差网络，是用于图像分类的卷积神经网络的子类。它是 ILSVRC 2015 的获胜者。其主要创新是引入了新的架构网络内部网络，使用残差层。Resnet50 由五个步骤组成，每个步骤都有一个卷积块和一个标识块，每个卷积块和每个标识块都有 3 个卷积层。Resnet50 有 50 个残差网络，并接受大小为 224 × 224 像素的图像。

+   **Inception_ResNet_V2**

Inception_ResNet_V2 是在 ImageNet 数据库中训练的一种卷积神经网络 [69]。它是一种混合技术，结合了 Inception 结构和残差连接。该模型接受大小为 299 × 299 的图像，并输出估计的类概率列表。Inception_Resnet_V2 的优点是将 Inception 模块转换为残差 Inception 块，添加更多 Inception 模块并在 Stem 模块之后添加一种新类型的 Inception 模块 (Inception-A)。

+   **DenseNet201**

Dense Convolutional Network（DenseNet201）是一个深度为 201 层的卷积神经网络，接受大小为 224 × 224 的输入图像[70]。DenseNet201 是对 ResNet 的改进，其中包括层之间的密集连接。它以前馈方式将每一层连接到每一层。与传统的具有 L 层的卷积网络具有 L 个连接不同，DenseNet201 具有 L（L + 1）/2 个直接连接。事实上，与传统网络相比，DenseNet 可以通过增加计算需求、减少参数数量、鼓励特征重用和加强特征传播来提高性能。

+   **MobileNet_V2**

MobileNet_V2 [71]是 MobileNet_V1 的改进版本的卷积神经网络。它仅由 54 层组成，输入图像尺寸为 224 × 224。它的主要特点是不是使用单个内核执行 2D 卷积，而是使用深度可分离卷积，该卷积由应用两个内核的两个 1D 卷积组成。这意味着，训练时需要更少的内存和参数，从而导致一个小而高效的模型。我们可以区分两种类型的块：第一种是步幅为 1 的残差块，第二种是步幅为 2 的用于降维的块。对于每个块，有三个层：第一层是带有 ReLU6 的 1 × 1 卷积，第二层是深度卷积，第三层是另一个 1 × 1 卷积，但没有任何非线性。

+   **Xception**

Xception，由 Chollet [72] 提出，是一个深度为 71 层的卷积神经网络。它是 Inception 架构的改进版本，涉及深度可分离卷积。更准确地说，Xception 用深度可分离卷积替换了标准的 Inception 模块。它在经典分类问题上与 VGG16、Resnet 和 Inception 相比表现良好。Xception 的输入图像尺寸为 299 × 299。

## 4 实验结果和分析

我们比较了所有上述模型，一旦它们被微调用于两个新的公开可用的图像数据集（胸部 X 射线和 CT 数据集[53, 54]）的自动二进制分类。如图 3 所示，该图显示了比较不同模型所需的主要步骤的图表：数据获取、数据预处理、训练和分类。接下来的章节详细介绍了此比较的步骤。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig3_HTML.png](img/507793_1_En_14_Fig3_HTML.png)

图 3

X 射线和 CT 分类过程的块图

### 4.1 数据集

本研究介绍了两个公开可用的图像数据集，其中包含 X 光和计算机断层扫描图像。第一个数据集[53] 是一个由 5856 张图像组成的胸部 X 光和 CT 数据集，包含两个类别（4273 例肺炎和 1583 例正常），而第二个数据集名为 Covid 胸部 X 光数据集[54]，包含 231 张 Covid-19 胸部 X 光图像。我们将第二个数据集合并到第一个数据集中，形成一个联合数据集，最终由 6087 张图像（jpeg 格式）组成，有两个类别（4504 例肺炎和 1583 例正常）。肺炎类包含细菌性肺炎、病毒性肺炎和 Covid19 的图像。从图 4 可以看出，图示了肺炎患者胸部 X 光的示例，正常的胸部 X 光（图 4(a)）显示清晰的肺部，没有异常浸润区域。此外，图 4(b) 显示了局部大叶实变（白色箭头）。此外，图 4(c) 显示了两肺的更弥漫的“间质”模式[53]，而图 4(d) 则展示了一位感染 Covid19 的患者的图像[54]。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig4_HTML.png](img/507793_1_En_14_Fig4_HTML.png)

图 4

肺炎患者胸部 X 光的示例

### 4.2 数据预处理和分割

下一个阶段是使用不同的预处理技术对输入图像进行预处理。图像预处理背后的动机是改善每个输入图像的视觉信息质量（消除或减少原始输入图像中存在的噪声，通过增加对比度增强图像质量，删除低频或高频等）。在本研究中，我们使用了强度归一化[73] 和限制对比度自适应直方图均衡化（CLAHE）[74, 75]。强度归一化是图像处理应用中的一种直接预处理步骤[73]。在我们的贡献中，我们使用最小-最大归一化将输入图像（图 5(b)）归一化到标准正态分布（式 1）。![$$X_{norm \, } = \frac{{x - x_{\min } }}{{x_{\max } - x_{\min } }}$$](img/507793_1_En_14_Chapter_TeX_Equ1.png)(1)![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig5_HTML.png](img/507793_1_En_14_Fig5_HTML.png)

图 5

X 光图像预处理

此外，在将输入图像输入所提出的模型之前，CLAHE 是必要的，以改善图像的对比度[74, 75]。图 5 说明了使用这些技术的示例。

对于数据分割，我们在这个实验中使用了 60%的图像进行训练，40%的图像进行测试。我们确保所选用于测试的图像在训练过程中没有被使用，以成功执行二元分类任务。此外，我们观察到数据集存在不平衡的情况。因此，75%的图像代表肺炎类别。为了解决这个问题，我们使用数据增强重新取样了数据集。

### 4.3 数据增强

数据增强在数据集预处理和分割之后用于训练过程，旨在避免过拟合的风险。此外，我们使用的策略包括几何变换，如重新缩放、旋转、平移、剪切、缩放和翻转（表 2）。我们从每个单一输入图像生成 2 个具有不同增强技术的新图像。因此，正常类别中的图像总数增加了 2 倍。表 2

使用的数据增强

| 参数 | 参数值 | 描述 |
| --- | --- | --- |
| 重新缩放 | 1/255.0 | 将图像从整数 0–255 缩放为浮点数 0–1 |
| 旋转范围 | 90 | 随机旋转的角度范围 |
| 水平和垂直移位范围 | 0.2 | 水平和垂直移位（20%）的参数值是给定维度的一部分 |
| 剪切范围 | 0.2 | 控制图像允许被剪切的逆时针方向的角度，以弧度表示 |
| 缩放范围 | 0.2 | 允许图像“缩小”或“放大” |
| 水平翻转 | True | 控制在训练过程中何时允许给定输入水平翻转 |
| 填充模式 | 最近 | 这是默认选项，选择最接近的像素值并重复所有空值 |

### 4.4 训练和分类数据集

在数据预处理、分割和数据增强技术之后，我们的训练数据集大小增加了，并且准备好传递给提议模型的特征提取步骤，以提取适当和相关的特征。从每个提议模型中提取的特征被展平在一起以创建向量化的特征映射。生成的特征向量被传递给多层感知器，以将每个图像分类到相应的类别中。最后，使用训练模型对测试图像评估提出的方法的性能。我们重复每个实验三次，并报告其平均结果。

### 4.5 实验设置

针对基于公开可用图像数据集（胸部 X 光数据集[53, 54]）的自动二元分类，我们的实验基于以下实验参数进行：数据集中的所有图像都被调整大小为 224 × 224 像素，除了 Inception_V3、Inception_Resnet_V2 和 Xception 模型的图像，它们被调整大小为 299 × 299。为了训练模型，我们将批量大小设置为 32，将迭代次数设置为 300。训练样本和测试样本的初始化分别为 159 和 109。Adam 优化器的参数为 β1 = 0.9，β2 = 0.999，并将学习率初始化为 0.00001，然后降低到 0.000001。此外，我们使用权重衰减和 L2 正则化器来减少不同模型的过拟合。一个全连接层使用 ReLU 进行训练，接着是一个丢失率为 0.5 的丢失层。我们更新了所有模型中的最后一个密集层，将其输出两个类别，分别对应正常和肺炎，而不是像 ImageNet 那样利用 1000 个类别。所提议模型的实现是使用配置为 Intel (R) Core (TM) i7-7700 CPU @ 3.60 GHz 和 8 GB RAM 的计算机运行 Microsoft Windows 10 专业版（64 位）。对于实现，我们使用 Keras/Tensorflow 作为深度学习后端。我们的训练和测试步骤是在配备 24 GB RAM 的 NVIDIA Tesla P40 上运行的。

### 4.6 评估标准

在提取适当特征之后，最后一步是对获得的数据进行分类并将其分配到特定类别[76]。在不同的分类性能属性中，由于数据集现在是平衡的，我们的研究使用以下基准度量标准：准确率（ACC）、灵敏度（SEN）、特异性（SPE）、精确度（PRE）和 F1 分数（F1）[52, 76]。这些度量标准的定义如下:![$$\begin{aligned} ACC &amp; = \frac{TP + TN}{{TP + TN + FP + FN}} \times 100\quad \quad PRE = \frac{TP}{{TP + FP}} \times 100 \\ &amp; SPE = \frac{TN}{{TN + FP}} \times 100\quad \quad SEN = \frac{TP}{{TP + FN}} \times 100 \\ &amp; \quad \quad \quad \;F1 = 2 \times \frac{ \, Re call \, \times Pr e cision \, }{{ \, Re call \, + \, Pr e cision \, }} \times 100 \\ \end{aligned}$$](img/507793_1_En_14_Chapter_TeX_Equ2.png)(2)

其中：TP 代表：真阳性。FP: 假阳性。TN：真阴性，FN：假阴性。

### 4.7 结果与讨论

本节介绍了对胸部 X 光和 CT 图像进行二元分类的结果[53, 54]，使用了以下架构（基线 CNN、微调 VGG16 的顶层、VGG19、Inception_V3、Xception、Resnet50、Inception_Resnet_V2、DenseNet201 和 MobileNet_V2）。此外，为了检查每个提议模型的性能和稳健性，对胸部 X 光数据集[53, 54] 进行了几个实验。结果分别使用训练和测试曲线的准确率和损失以及混淆矩阵进行呈现。

#### 4.7.1 不同架构的分类结果

本小节介绍并讨论了胸部 X 光和 CT 图像的分类结果[53, 54]。在讨论这些结果之前，让我们定义一些与深度学习过程相关的参数：训练曲线是从提供模型学习情况的训练数据集中计算的，它能够提供模型学习的程度。相反，测试曲线是从一个独立的测试数据集中计算的，用以说明模型的泛化程度。同时，训练和测试损失被定义为在测试或训练集中每个样本中所产生的错误的总和。需要注意的是，与准确率不同，损失不是一个百分比。此外，混淆矩阵显示了分类后图像的详细表示[52]。总之，一个泛化良好的模型既不过度拟合也不欠拟合。

+   **基线 CNN**

根据图 6，观察到训练数据的准确率曲线从第 0 个时期到第 6 个时期迅速增加，其中准确率为 83.17%，之后开始稍微增加，直到第 300 个时期，准确率为 86.28%。相同的情况也适用于测试数据的准确率曲线，第 300 个时期的准确率为 84.84。至于训练数据的损失曲线，它从第 0 个时期到第 6 个时期迅速减小，损失为 43.77。在那一点，它开始稍微减少，直到训练结束（第 300 个时期），损失等于 36.56。对于测试数据的损失曲线也是一样的，在第 300 个时期的损失为 37.85。从混淆矩阵中可以看出，在第一类图像（正常类）中，模型正确识别了 1634 张图像，但有 95 张被标记为肺炎。同样地，对于第二类图像（肺炎），模型成功识别了 1277 张图像，但有 252 张被标记为正常。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig6_HTML.png](img/507793_1_En_14_Fig6_HTML.png)

图 6

基线 CNN 的准确率和损失曲线以及混淆矩阵

+   **VGG16**

图 7 展示了 VGG16 的准确率、损失曲线和混淆矩阵。确实，从第 0 轮到第 11 轮，训练数据的准确率曲线迅速增加，达到 81.05%，然后收敛到 87.51%。测试数据的准确率曲线也是如此，在第 300 轮时为 86.32%。对于训练数据的损失曲线，从第 0 轮到第 25 轮，损失迅速减小，其中损失等于 1.43。在这一轮，可以观察到一种稳定性，直到值为 1.15。测试数据的损失曲线也是如此，在第 300 轮时损失为 2.21。从混淆矩阵中可以看出，模型可以正确预测正常类中的 1517 张图像，但有 212 张被标记为肺炎。对于肺炎类，模型能够正确识别 1466 张图像，263 张被标记为正常。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig7_HTML.png](img/507793_1_En_14_Fig7_HTML.png)

图 7

VGG16 的准确率和损失曲线以及混淆矩阵

+   **VGG19**

如图 8 所示，训练数据（测试数据）的曲线可以分为两个区间：第一个区间从第 0 轮到第 13 轮（从第 0 轮到第 10 轮）。我们可以观察到准确率快速增加，其中准确率等于 81.01%（83.05%）。在第二个区间，准确率变得稳定，并向 87.42%（86.89%）收敛。对于训练和测试数据的损失曲线，我们看到拟合效果良好。确实，从第 0 轮到第 18 轮，损失迅速下降，其中等于 1.27。然后，它开始略微增加，直到训练结束，相当于 1.31。正如在混淆矩阵中观察到的那样，VGG19 模型在正常类中有能力正确预测 1390 张图像和 339 张肺炎图像。该模型还能够将 1582 张图像分类为肺炎和 147 张图像分类为正常。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig8_HTML.png](img/507793_1_En_14_Fig8_HTML.png)

图 8

VGG19 的准确率和损失曲线以及混淆矩阵

+   **Inception_V3**

图 9 显示了 Inception_V3 的准确度、损失曲线和混淆矩阵。因此，对于训练和测试准确度，从第 0 个时期到第 7 个时期，我们可以看到准确度在增加，直到达到 91.03%的值。第 7 个时期之后，准确度开始稳定，分别为训练数据和测试数据的 97.01%和 95.94%。可以注意到对于训练数据的损失曲线拟合良好，无论是从第 0 个时期到第 32 个时期的快速增加，损失为 3.98，还是在减小缓慢并趋于 1.76 的另一个区间。如混淆矩阵所示，对于肺炎类别，该模型能够将 1650 张图像识别为肺炎，79 张图像识别为正常。关于正常类别，Inception_V3 模型可以预测 1621 张图像为正常，108 张图像为肺炎。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig9_HTML.png](img/507793_1_En_14_Fig9_HTML.png)

图 9

Inception_V3 的精调准确度和损失曲线以及混淆矩阵

+   **ResNet50**

图 10 展示了 Resnet50 获得的结果。事实上，从第 0 个时期到第 24 个时期，无论是训练数据还是测试数据的准确度值都在迅速增加，其中最大值为 97.36%。之后，数值开始稳定（分别为训练数据和测试数据的 99.23%和 96.23%）。我们观察到训练数据和测试数据的损失曲线拟合良好，实际上，从第 0 个时期到第 21 个时期，损失迅速减少，其中等于 6.89，之后开始稳定，直到第 300 个时期，其值为 0.85。混淆矩阵表明，对于正常类别的图像，有 1703 张图像被正确预测为正常，26 张标记为肺炎。对于第二类肺炎的图像，模型有 1638 张图像被正确识别，而 91 张被标记为正常。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig10_HTML.png](img/507793_1_En_14_Fig10_HTML.png)

图 10

ResNet50 的精调准确度和损失曲线以及混淆矩阵

+   **Inception_ResNet_V2**

图 11 显示了从第 0 个时期到第 18 个时期，训练和测试准确率曲线都在增加，直到达到 95.51%的值。在第 18 个时期之后，准确度开始稳定，分别为训练数据和测试数据的 99.11%和 96.41%。我们可以看到训练数据和测试数据的损失曲线拟合良好，其中数值分别为 3.99（第 24 个时期）和 1.17（第 300 个时期）。对于混淆矩阵所示的肺炎类别，Inception_ResNet_V2 模型能够正确识别 1618 张图像为肺炎，111 张图像为正常。另一方面，对于正常类别，有 1705 张被正确分类为正常，24 张图像被识别为肺炎。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig11_HTML.png](img/507793_1_En_14_Fig11_HTML.png)

图 11

经过微调的 Inception_Res-Net_V2 的准确率和损失曲线以及混淆矩阵

+   **DensNet201**

训练数据的获得准确率曲线迅速增加，直到 93.49%（图 12）。在第 16 个时期之后，准确率进入稳定阶段，在训练数据和测试数据中分别为 97.16% 和 94.91%。训练和测试数据的损失曲线显示出良好的拟合。事实上，从第 0 个时期到第 17 个时期，损失迅速减小，其中等于 3.99，然后在第 300 个时期之前变得稳定，其值为 1.91。混淆矩阵显示，对于第一类图像（正常类），模型能够正确识别 1712 个图像为正常类，但有 17 个被标记为肺炎。对于第二类图像（肺炎类），模型也能够正确识别 1527 个图像，并将 202 个图像标记为正常。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig12_HTML.png](img/507793_1_En_14_Fig12_HTML.png)

图 12

经过微调的 DensNet201 的准确率和损失曲线以及混淆矩阵

+   **MobileNet_V2**

如图 13 所示，我们可以观察到从第 0 到第 16 个时期，训练和测试准确率都在增加，直到准确率达到 96.38% 的值。在第 16 个时期之后，准确率变得稳定，并且分别为训练数据和测试数据的 98.27% 和 96.64%。对于训练数据的损失曲线，可以看到良好的拟合。直到第 44 个时期，损失的值迅速减小，其中值为 1.49。然后收敛到 0.24。关于混淆矩阵，对于第一类图像（正常类），模型能够正确识别 1696 个图像为正常类，但有 33 个被分类为肺炎。同样，在肺炎类中，有 1634 个图像被正确标记为肺炎，95 个被识别为正常。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig13_HTML.png](img/507793_1_En_14_Fig13_HTML.png)

图 13

经过微调的 MobileNet_V2 的准确率和损失曲线以及混淆矩阵

+   **Xception**

注意到训练数据的准确率在从 epoch 0 到 10 时迅速增加，其中准确率为 93.10%（见图 14）。然后在训练结束时稳定在 95.45%。对于测试数据，在从 epoch 0 到 12 时可以看到快速增加，其中值为 86.87%，之后开始下降，直到 epoch 300 时为 69.03%。对于训练和测试数据的损失曲线，值在从 epoch 0 到 epoch 26 时迅速下降，其中值为 1.10。在 epoch 26 之后，值分别收敛到 0.44 和 0.69，用于训练和测试数据。当我们查看这个混淆矩阵时，我们可以说对于第一张图像（正常类），模型有选项正确识别 1656 张图像。此外，73 张被选为肺炎。该模型还能正确识别 1219 张图像（肺炎类）。因此，对于第二张图像（肺炎类），有 510 张被标记为正常。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig14_HTML.png](img/507793_1_En_14_Fig14_HTML.png)

图 14

精确度和损失曲线以及 Fine-tuned Xception 的混淆矩阵

#### 4.7.2 讨论

在本研究中，我们使用最近的深度学习架构的迁移学习来基于 X-Ray 图像进行二分类（正常和肺炎），以确定根据 Eq. (2) 中定义的几个参数的最佳执行架构。首先，我们通过测量它们的准确性来逐个比较深度学习架构。之后，我们比较每个深度学习架构的准确性和损失结果，以识别表现最佳的架构（图 15，16）。此外，表 3 概述了我们实验中使用的各种深度学习模型在 Eq. (2) 中定义的参数方面的比较。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig15_HTML.png](img/507793_1_En_14_Fig15_HTML.png)

图 15

根据不同架构的准确率曲线总结前面的图表

![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig16_HTML.png](img/507793_1_En_14_Fig16_HTML.png)

图 16

根据不同架构的损失曲线总结前面的图表

表格 3

评估指标（%）

|   | TP | TN | FN | FP | ACC | SEN | SPE | PRE | F1 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 基线 CNN | 1634 | 1277 | 452 | 95 | 84.18 | 78.33 | 93.07 | 94.05 | 85.66 |
| VGG16 | 1517 | 1466 | 263 | 212 | 86.26 | 85.22 | 87.36 | 87.73 | 86.46 |
| VGG19 | 1390 | 1582 | 147 | 339 | 85.94 | 90.43 | 82.35 | 80.39 | 85.11 |
| Xception | 1656 | 1219 | 510 | 73 | 83.14 | 76.45 | 94.34 | 95.77 | 85.03 |
| DensNet201 | 1712 | 1527 | 202 | 17 | 93.66 | 89.44 | 98.89 | 99.01 | 93.98 |
| Inception_V3 | 1621 | 1650 | 79 | 108 | 94.59 | 95.35 | 93.85 | 93.75 | 94.54 |
| Inception_ Resnet_V2 | 1705 | 1618 | 111 | 24 | 96.09 | 93.88 | 98.53 | 98.61 | 96.19 |
| MobileNet_V2 | 1696 | 1634 | 95 | 33 | 96.27 | 94.61 | 98.02 | 98.06 | 96.30 |
| Resnet50 | 1703 | 1638 | 91 | 26 | 96.61 | 94.92 | 98.43 | 98.49 | 96.67 |

对于图 15(a)和(b)中每个模型，它们总结了先前的训练和测试准确度数据，训练和测试准确度的图表增长到稳定点。观察到 Inception_Resnet_V2、Inception_V3、Resnet50、Densnet201 和 Mobilenet_V2 的微调版本表现出令人满意的性能，随着每个时期的训练和测试准确度的增加而增加。它们优于基线 CNN、Xception、VGG16 和 VGG19，这些模型表现不佳。从第 20 个时期开始，它们开始稳定直到训练结束，基线 CNN、VGG16 和 VGG16 的训练和测试准确度等于 85%。然而，Xception 在测试准确度达到 83%，训练准确度达到 95%。在这种情况下，Xception 算法产生的预测模型对训练集不适应（过拟合）。此外，每个提出模型的训练和测试损失的图表（图 16(a)和(b)）减少到稳定点。可以看出，模型的微调版本表现出每个时期训练和测试损失的下降率非常令人满意。

我们基于不同的最新深度学习架构的微调版本进行了多实验分类，根据表 3 统计了结果。该表详细描述了每个实验的分类性能。从结果中可以看出，当我们使用 Xception、基线 CNN、VGG19 和 VGG16 时，准确度较低，因为这些模型帮助分别获得了 83.14%、84.18%、85.94%和 86.26%的准确度。相反，最高的准确度由 DensNet201 (93.66%)、Inception_V3 (94.59%)、Inception_Resnet_V2 (96.09%)、MobileNet_V2 (96.27%) 和 Resnet50 (96.61%) 报告。此外，MobileNet_V2 已被证明在相关任务中获得了显着的结果[77]，而 ResNet50[68, 78]提供了性能和参数数量的良好组合，并且已证明训练速度更快。因此，我们建议将 MobileNet_V2 (96.27%的准确度) 和 Resnet50 (96.61%的准确度) 模型用于计算机辅助诊断系统，以识别 X 射线和 CT 图像中肺炎患者的健康状态，因为这些模型获得了最佳的训练和测试准确度分数。临床检查是这项研究工作的下一步。  

## 5 结论和未来工作

在这项工作中，我们提出了使用八种深度学习架构（VGG16、VGG19、DenseNet201、Inception_ResNet_V2、Inception_V3、Xception、Resnet50 和 MobileNet_V2）和一个基线 CNN 将胸部 X 射线和 CT 图像分类为肺炎和正常类别的自动方法。主要目标是回答以下研究问题：（1）是否有任何 DL 技术明显优于其他 DL 技术？（2）DL 可以用于早期筛查 CT 和 X 射线图像中的肺炎吗？（3）DL 可以基于 CT 和 X 射线图像达到的诊断准确度是多少？实验使用包含 6087 张图像（4504 张肺炎和 1583 张正常）的胸部 X 射线和 CT 数据集进行。肺炎类包含细菌性肺炎、病毒性肺炎和 Covid19 的图像。此外，使用各种性能指标对这些实验的性能进行了评估。此外，所获得的结果显示，Resnet50 相对于本文中引用的其他架构（准确度低于 96%）表现出较高的性能（准确度超过 96%）。由于这些模型的高性能，我们相信这些结果有助于医生在临床实践中做出决策。

进行中的工作旨在通过深度学习检测、分割和分类开发肺炎的完整系统。此外，使用更多数据集、更复杂的特征提取技术（如颜色[79]、纹理[80]、形状[81，82]）可以改善性能。此外，使用更多数据集和更复杂的特征提取技术也可以改善性能。此外，其他融合方法也将是有趣的[83]。

作者贡献：

实验和编程阶段由 Khalid El Asnaoui 完成。所有作者都参与了论文撰写，并且都批准了本次提交。
