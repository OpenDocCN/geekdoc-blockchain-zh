© 作者，独家许可给 Springer Nature Singapore Pte Ltd. 2022M. Dutta Borah 等人 (编辑)在 6G 无线网络中的 AI 和区块链技术 区块链技术[`doi.org/10.1007/978-981-19-2868-0_4`](https://doi.org/10.1007/978-981-19-2868-0_4)

# 6G 中的 AI-启用智能资源管理

Vijayakumar Ponnusamy^(1  ) 和 A. Vasuki^(2  )(1)ECE 系，SRM 科学技术学院，SRM Nagar, Kattankulathur, Chengalpattu, 603203, 印度(2)ECE 系，SRM 科学技术学院，Vadapalani 校区，No.1\. Jawaharlal Nehru Road, Vadapalani, Chennai, 600026, 印度 Vijayakumar Ponnusamy (通讯作者)邮箱: vijayakp@srmist.edu.inA. Vasuki 邮箱: vasukia@srmist.edu.in

## 摘要

下一代 6G 移动网络很可能会智能、高动态，并且具有极低的延迟，以满足不同多样化应用的需求。随着对无线通信的需求不断增加，资源管理在利用可用资源提供更高数据速率和极端服务质量方面起着至关重要的作用。然而，在当前的超密集异构基础设施中，资源分配的复杂性将变得更加严重。随着海量数据和计算资源的增加，人工智能 (AI) 的快速发展最终减轻了未来 6G 及以后版本所需的巨大能力。因此，AI 可能会成为未来复杂 6G 网络中智能资源管理、自动化网络运营和支持的最合适和适当的技术。本章将讨论用于 6G 网络资源管理的不同机器学习技术，可用频谱的有效使用，频谱预测和动态资源分配。

关键词资源管理大规模连接网络管理

## 1 资源管理中的 AI 要点

无线技术的发展仍在继续满足对快速响应时间、更高带宽和安全通信的需求。在 3G 以后系统的发展之后，所有可负担的物理层技术都得到了充分利用。这导致了对可用资源的智能和优化消耗的需求。在本节中，我们将讨论资源管理的重要性以及 AI 在资源管理中的作用，以实现高效的下一代 6G 网络[1]。

### 1.1 面向大规模连接网络的资源管理挑战

资源管理旨在获取适当利用受限物理资源以满足众多流量需求并提高机器的整体性能。学术上使用的现有资源管理技术通常是为固定网络开发的。它依赖于数学函数。相比之下，现实无线网络的条件是可变的，这导致具有高计算复杂性的算法回归。在实际情况下应用假设的静态网络数学条件会导致性能严重下降。除此之外，标准管理方案可能在提取与用户和网络相关的有益记录方面优越。对于庞大数量的节点，需要各种资源管理技术。

### 1.2 5G 中的资源管理

在部署 5G 标准之后，学术界和产业开始关注下一代无线通信标准 6G。该技术实现了高达 1 Tb/s 的数据速率和 100 GHz 到 3 THz 的宽带频率 [2]。除了通信的重要评估参数之外，近来研究人员已将人工智能（AI）视为 6G 的重要特征。在这些应用中，机器学习算法被认为是许多复杂场景的合适解决方案。网络智能预计将满足异构网络的挑战。虽然机器学习技术已在各种应用中使用，但自动化蜂窝通信系统的实现仍有空间。应该关注通信系统、架构及其性能的现有问题，并利用 6G 技术。

### 1.3 从 5G 到 6G 的资源管理

AI 的存在可以在日常场景中看到。如今，机器和人类产生的数据量令人震惊，超出了人类理解和消化这些数据并根据这些数据做出决策的能力。因此，需要 AI 的帮助来克服这些挑战。5G LTE 通信系统是提供高用户体验的有希望的解决方案，涉及提供的速度、数据量和成本。然而，由于其复杂性，LTE 技术在资源管理和优化方面需要一些改进。借助 AI，这两个挑战可以克服。AI 代表着改进的 Q 学习算法与 LTE 中的自组织网络（SON）概念相结合，用于管理和优化系统中的切换（HO）参数和过程 [3]。

AI 在日常活动中变得必不可少。人类和机器产生的数据量巨大。人类需要理解生成的数据并分析它。这有助于做出适当的决策。这可以通过采用 AI 轻松解决。通信中的 5G LTE 被认为是速度、数据速率和成本方面的有利解决方案。然而，资源管理和优化技术需要一些改进，这可以通过使用 AI 技术来克服。在 LTE 中，AI 辅助的 Q 学习算法以及自组织网络（SON）管理和优化了系统中的切换参数和不同阶段[4]。AI 基础的 6G 网络中的挑战如图所示。图 1。AI 算法的作用在图中说明。 2。![](img/517376_1_En_4_Fig1_HTML.png)

该模型描述了推动基于 ML 的 6G 网络的挑战。具有学习效率、端到端合格的服务提供、高效的数据集生成、物理层到应用层、计算开销部署、动态在线学习用于探索、可行性验证、分布式或集中式、标准化、全球智能的可扩展性。

图 1

6G 网络中的挑战

![](img/517376_1_En_4_Fig2_HTML.png)

模型描述了 AI 算法在无线网络中的作用。机器学习包括监督学习、强化学习和无监督学习。每种都有应用和算法。

图 2

AI 算法在无线网络中的作用

## 2 机器学习技术在网络管理中的应用

为了满足巨大的需求管理，6G 的发展被认为是超越了 5G 远程网络改进宽带、无限访问和超高可靠性延迟管理限制的进步。最近，6G 网络的构建变得异常异构、密集分布和动态。为了达到最佳的紧密服务质量（QoS），这种复杂结构将导致网络活动例程的缺陷。因此，机器学习正在成为认识完全智能化的组织协调和管理的关键答案。通过从不确定和动态环境中学习，基于机器学习的介质评估和带宽管理将使管理者能够开辟出为实现超高宽带策略（如太赫兹通信）带来惊人表现的机遇。此外，关于能源和端到端安全通信的超大规模网络所带来的挑战可以通过采用适当的基于机器学习的技术来缓解。此外，智能的管理和资源分配将确保服务的超高可靠性和低延迟。针对这些问题，本章介绍和研究了一些基于机器学习的前沿方法及其在 6G 中的应用，以支持超高宽带、超大规模访问和低延迟管理[5]。

### 2.1 6G 网络中基于机器学习的宽带传输

可用频谱几乎不足以满足不断扩大的需求。例如，一些新兴的应用，如全息技术，可能需要每秒高达 Tb 的数据速率，这大约是平均 5G 通信速度的三倍。因此，需要 THz 通信来协助每秒达到高达 terabits 的信息传输速度，使用的频段范围为 0.1–10 THz，例如 140、220 和 340 GHz 的频率。为了实现这样的极限性能，时间偏移信道的精确数据对于提高太赫兹传输速率部分和进一步改进频谱效率尤为重要。在本节中，我们介绍了一些关于太赫兹信道评估和频谱管理的前沿人工智能/机器学习应用[6]。

在太赫兹频率组中，信道受到由空气中水蒸汽引起的高大气吸收的影响，这对损耗产生了重大影响。此外，自由空间路径损耗在气象收缩方面也是不可避免的。此外，太赫兹信道被视为非固定的，特别是对于用户和物体可能移动的动态环境。因此，基于假设为固定或半固定的传统信道模型目前无法适用于超宽带频谱。机器学习算法可用于分析通信数据并预测保证或不明确环境中损失的可能信号。因此，各种人工智能算法可以应用于处理超宽带频谱的 6G 网络的物理层中所描述的困难。

在许多应用中，为了进一步发展强大情况下的评估精度，基于强化学习的贝叶斯滤波器已经应用于当前研究中的太赫兹直接到达评估。特别是，贝叶斯信道执行当前到达方向的评估，该评估来自当前估计和过去估计。在这种方法中，系统状态之间的先前变化概率对于贝叶斯滤波器的评估执行至关重要。可以使用强化学习算法根据先前测量的结果提高状态变化的概率，从而提高贝叶斯滤波器的性能。机器学习算法的主要分类和应用如下所述。

+   基于充足和有效的带标签数据进行的学习算法称为*监督学习*。这些算法可以熟悉传输路径损耗和阴影预测、阻塞板、信道评估等。一些体系结构，如深度神经网络（DNN）、K-最近邻（KNN）和支持向量机（SVM），是基于监督学习算法的。

    KNN 算法用于识别和分配资源（频谱/功率/定位）要求。例如，如图 3 所示，新要求可以使用 KNN 算法进行分类，其中 K = 3 表示与新样本（数据）的距离由三个最近的数据点计算得出。KNN 使用欧氏距离（d）进行分类，其表达式为 (1)！[](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig3_HTML.png)

    图表描述了使用 KNN 算法对识别和分配资源（频谱/功率/定位）要求的新要求进行分类。图表中标有新样本的位置有箭头 1、2、3。K 等于 3。

    图 3

    KNN 的一个例子

    ![$$d=\sqrt{{\left({x}_{2}-{x}_{1}\right)}^{2}+{\left({y}_{2}-{y}_{1}\right)}^{2}}$$](img/517376_1_En_4_Chapter_TeX_Equ1.png)(1)

    同样，SVM 也用于解决异构网络中的切换问题。在大规模 MIMO 中，通过 SVM 分类器在数百个天线中选择天线。用于有效网络管理的信道噪声估计。

+   在任何无线通信网络中，信道估计和建模对确定通信系统端到端性能起着至关重要的作用。这些问题可以轻松通过另一类称为无监督学习机制的机器学习来解决。*无监督学习*不需要使用带有标签的数据进行训练。其主要应用包括抑制干扰、用户聚类以及克服双工模式下的挑战。K 均值聚类和模糊 C 均值算法是近期通信技术中一些最受欢迎的无监督学习机制。

多径组件（MPC）分析是收集无线信道信息的重要任务。K 均值聚类算法在 MPC 中形成分组，以减小数据之间的欧几里得距离直到收敛。它将具有类似行为的参数进行分组，如延迟（t）、到达方位角（AoA）、离开方位角（AoD）、到达高度角（EoA）和离开高度角（EoD）。以下示例通过执行 K 均值聚类来说明步骤：

> 第 1 步：随机以中心（k[1]、k[2]、k[3]）开始初始聚类，如图 4a 所示。![](img/517376_1_En_4_Fig4_HTML.png)
> 
> 图形说明了 AI 启用的边缘计算、云和边缘计算的架构。 (a) 它随机以中心（k1、k2、k3）开始初始聚类。 (b) 将每个数据点分配给最接近的聚类中心。 (c) 将每个聚类中心移动到每个聚类的平均值。 (d) 计算与新数据点相关的聚类。 (e) 重新计算聚类中心 (f) 将聚类中心移动到聚类均值。
> 
> 图 4
> 
> 在未知数据点上的 K 均值聚类算法示例
> 
> 第 2 步：将每个数据点分配给最接近的聚类中心，如图 4b 所示。
> 
> 第 3 步：将每个聚类中心移动到每个聚类的平均值，如图 4c 所示。
> 
> 第 4 步：计算与新数据点相关的聚类，如图 4d 所示。
> 
> 第 5 步：重新计算聚类中心，如图 4e 所示。
> 
> 第 6 步：将聚类中心移动到聚类均值处，如图 4f 所示。

+   另一个重要的类别是 *深度学习*。深度学习算法被用于提取信道特性、找到动态信道信息、检测不同的调制信号/符号，并从编码数据中恢复原始输入。主要的深度学习结构，如卷积神经网络（CNN）、循环神经网络、深度前馈神经网络和深度信念网络（DBN），可根据应用进行选择。  

CNN 可用于动态功率控制，以改善非直射（NLOS）传输、自动调制分类和下一代无线通信系统中的信道估计。在无线网络中进行定位是一项具有挑战性的任务，因为室内环境中存在阴影和多径衰落。为了满足 6G 无线通信的要求，太赫兹频谱提供了超宽带应用。LSTM 架构（如图 5 所示）可以探索太赫兹无线信号的信道状态信息、到达角、接收功率和延迟，这些是室内环境的有用参数。一系列时间数据（X[o]、X[1]、…X[t]）被输入到 LSTM 中。![](img/517376_1_En_4_Fig5_HTML.png)

一个 LSTM 架构描述了一系列时间数据（Xo、X1、…Xt）被输入到 LSTM 中。

图 5

一个 LSTM 架构

+   *强化学习* 是监督学习和无监督学习算法的结合。这些算法基于行动奖励。应用中的代理程序不断从环境中获取信息以采取适当的行动。如果行动成功，算法会获得积极的反馈，以进一步探索新的未知状态。基于强化学习的算法主要用于跟踪未知的无线介质和选择可行的调制方式。马尔可夫决策过程、Q 学习和模糊强化学习是经常使用的算法。

马尔可夫决策过程应用概率来预测信道估计过程中的未来要求，其基于当前观察到的状态，如图 6 所示。![](img/517376_1_En_4_Fig6_HTML.png)

模型描述了马尔可夫过程的一个例子，未来的要求基于观察到的状态 -y1、y2、y3 和隐藏状态 S1、S2、S3。

图 6

Markov 过程的一个例子

在 6G 网络的各个层面应用深度学习/机器学习算法的示意图如图 7 所示。![](img/517376_1_En_4_Fig7_HTML.png)

模型图解了基于强化学习的 WLANs 在 mIoT（移动物联网）环境中的重要层次结构。它具有云-雾/边缘、SDN、太赫兹通信和智能城市的图像。它具有智能网络管理和优化在 6G 和 A L/M L 技术的部分。

图 7

在 6G 网络中应用深度学习/机器学习算法

## 3 网络管理中机器学习技术的应用

在本节中，将讨论在大规模连接网络中机器学习的必要性，以及基于 ML 的频谱预测[7]。

### 3.1 6G 网络中大规模连接管理的需求

在高维网络中，不同设备之间的连接可以允许终端与各种级别的网络进行多样化整合，并使网络实现覆盖的提升。由于连接的动态性质，有机会插入和移除设备以有效应对大规模连接。网络和物理层之间的连接承受着高延迟的问题。这种延迟导致数据传输，可以通过优化它们的端到端连接来解决。管理众多设备之间的连接取决于当前的无线信道条件，在其中，基站（BSs）的可移动性使得获取信道状态信息更加费力。

### 3.2 高维网络中的无线资源管理

在大规模连接的网络中，通过允许许多设备接入网络来覆盖无法区分的区域。这导致网络中严重的干扰，可以通过使用调度机制来抑制这种干扰。该技术提供了关于动态信道的信息，以改善用户之间的调度。与地面基站之间的超链接相比，卫星间、空中间、卫星-空中间和卫星-地面间的连接是非理想的，因此延迟较高。因此，在大规模连接的网络中需要协作调度。此外，长距离和高移动性的基站导致信道近似程度的严重性增加，这使得设计可行算法变得复杂。

### 3.3 AI 启用的自动化 6G 网络

关键在于**5G 网络**中使用的方法，例如软件定义网络；6G 网络中也考虑了网络功能虚拟化。这些技术具有制作适合 6G 网络的自定义网络的能力。无论如何，在 6G 网络的情况下，这些网络应该引入智能。通过在无线网络中整合人工智能，可以通过充分的训练实现智能化。因此，机器学习/深度学习/人工智能被认为是开发 6G 网络作为自定义网络最合适的技术。

在软件定义网络中整合人工智能可以获得有效的网络架构。与 5G 网络相比，6G 中应用了良好的优化，使其成为自动网络。

基于机器学习的网络管理具有组织网络架构、切片和收集不同的信道接入技术以获取平滑网络、满足动态服务和应用需求的能力。在人工智能优化技术的辅助下，持续观察网络性能指标。根据观察结果，可以更新网络参数以维持最佳服务。这些基于人工智能的技术可以获得实用的网络性能，被视为历史数据。通过部署多层次人工智能也可以获得网络智能。在庞大的联接网络中，可以在路由器上集成人工智能以转发数据。AI 技术已经被引入到无线接入网络中，用于管理诸如可移动性和干扰抑制等多个基站相关流程。人工智能将使大型物联网网络从数据中心转移到社区的边缘成为可能。

## 4. 应用机器学习技术于网络管理

在本节中，我们将讨论机器学习/深度学习技术如何用于多接入边缘计算、移动性、切换管理和频谱管理的资源分配[8]。

### 4.1 基于深度学习的多接入边缘计算

在 6G 网络中，多接入边缘计算已经变得不可避免。MEC 提供数学和分析计算，并将无线接入网络带到与其他设备的近距离。由于 MEC 具有多维、随机不确定和动态属性，因此 MEC 的企业级最大化、位置和样本训练是重要的方面。因此，在复杂网络下，传统的 Lagrangian 对偶算法可能会遇到困难。AI 技术可以检索过去的记录以了解和协助 MEC 的优化、预测和选择。图 4 展示了 AI 支持的蜂窝边缘计算、云计算和边缘计算的架构。由于其有限的能力，轻量级 AI 算法可以被应用于提供智能应用，如交通和农业等其他情景。例如，基于强化学习的边缘计算在资源管理方面非常有用，并且被认为是一种无模型方案，因为它不需要对任何领域有任何先验知识。这可以用于分析环境变化并在实践中选择适当的方法。

+   广泛的深度学习算法预计将在中央云服务器上提供功能性培训。利用 AI 支持的分类算法优化不同的动态和不同服务应用的流量决策。一个 AI 支持的集群用于减少 MEC 服务器中的复杂性，而不是单个决策。

+   从边缘计算服务器接收到的数据可以被很好地训练，以自动提取固有特征。在这种情况下，深度学习算法可能适合训练系统模型，以获取设计目的的服务类型、流量和安全性。

+   此外，深度强化学习（DRL）在寻找极其复杂和时变的 MEC 网络中的适当资源管理策略方面起到了积极作用。为了映射决策和环境，使用了最佳资源管理策略。通过采用 DRL 来利用历史知识，提高效率和准确性，为边缘设备提供了高质量的服务。

### 4.2 基于人工智能的切换管理

由于 6G 网络高度离散、多层次和大维度，移动性和切换管理是 6G 网络的极具挑战性的问题。通过应用适当的人工智能技术来实现无间断服务，实现了移动性预测和切换。

*无人机网络中的人工智能角色：* 在将无人机通信与 6G 网络集成的情况下，这导致了频繁的切换。假设，如果无人机通信与 6G 网络相结合，而无人机的快速动态移动导致了建立的切换。此外，由于诸多提供商的需求，如高统计数据、高可信度和低延迟，这一主题在处理有效切换方面得到了扩展。设备和无人机的过度移动导致了关于它们位置的不可预测性。这个问题可以通过一种 AI 技术，强化学习，来解决。它学会了优化实际场景中的切换技术，以探索设备/无人机的移动行为。这种方法减少了传输延迟，并确保了可靠的 Wi-Fi 连接。

图 4 显示了基于 DRL 的无人机网络中的敏捷移动和切换管理因素。在这些网络中，每个无人机都可以充当与环境进行交互的代理，从而增强了网络覆盖范围。每个代理观察附近的状态，并找到最合适的行动以获得积极的奖励。奖励可以通过连接性、延迟和来自环境的反馈来操纵。基于 DRL 的无人机网络具有自动处理切换和减少延迟、切换失败概率的能力。同时，它提供了最优质的服务。

*车载网络中的 AI 角色：* 随着 6G 网络的演进，大规模车载网络应具有超高速度和低延迟，对进化不敏感。因此，高效的移动性管理是实现端到端可靠和低延迟通信的重要参数。高速车载用户的移动性模式不断被流行的深度学习结构（如 RNN 和 ANN）学习。这些 AI 启用的技术成功地缓解了传统的切换、切换失败。同样，另一个称为长短期记忆（LSTM）的深度学习模型被用于解决切换问题，它利用了过去和未来移动性的历史，并提供了车辆的序列、轨迹的预测以优化切换参数。

多层 LSTM 与自动编码器集成，用于解决无线通信中频繁切换的问题。

### 4.3 基于 AI 的频谱管理

6G 网络的演进需要特殊的频谱，如低 RF、毫米波、THz 和可见光波段，以提供过量的信息数据速率，如图 4 所示[9、10]。当在 6G 网络中使用广泛的设备时，会导致频谱管理。AI 启用被认为是实现设备间大量连接的成功技术，如图 4 所示。

+   一般来说，基于 AI 的结构有三层，即输入层、隐藏层和输出层。大量的频谱数据集作为输入。然后，它训练隐藏层找出频谱利用的重要特征。最后，在实际情景中在输出层中得到有效的频谱管理方法，以支持设备之间的众多连接。

+   AI 框架的适当训练迫使离线训练模型轻松识别在线频谱管理解决方案。各种频谱波段可以更好地用于进行具有大带宽的显著传输，在其中低频波段可以用于广播卫星地面传输的信息。

## 5 AI 启用的动态资源分配

在任何无线网络中，频谱利用、过程计算和体系结构都是 6G 之外至关重要的资源。因此，引入动态资源分配方法来增强有用资源分配的实现。动态资源分配是通过引入 AI 和区块链技术来实现的。本节讨论了基于 AI 的动态资源利用[11–16]。

### 5.1 无线电源的有效共享

在无线通信系统中，有效利用可用的无线资源是改善用户提供无间断服务的必要过程。基于各种网络参数限制了无线资源分配方法。例如，在 Wi-Fi 网络中信息传输引起的不确定性随后影响数据速率和处理时间。动态变化的信道参数会产生干扰，这是由于环境中的高流量和移动性。当为不同类型的用户预测服务时，无线资源分配已成为一项极具挑战性的任务，而频谱有限。

*资源分配的分类：* 无线资源的有效分配被归类为集中式或分散式。

*集中式方法：* 这些方法主要是基于一个单一的核心实体处理，该实体从无线网络的用户那里收集信息。然后，根据网络的能力分配资源。这些方法在牺牲数据传输的同时提供了出色的响应。

*分散式方法：* 在分散式技术的情况下，用户被允许自行选择。这些技术比集中式更灵活，但结果次优。

上述讨论的资源分配方案根据用于实现吞吐量增强、处理延迟、用户公平性、能源和频谱效率的优化技术而变化。因此，有效的资源分配根据网络类型、优化技术和提出的机器学习算法进行分类。

由于需要各种参数，无线资源分配中实现最佳结果是一项繁琐的目标。这可以通过启发式方法来解决，该方法放宽了网络期望，并找到了一个合理的替代方案。但这些方法并不能保证获得优秀的结果。另一种方法是基于理论的博弈技术；网络节点被视为相互关联并影响其他节点选择的玩家。每个玩家都有一些选项来最大化效用。博弈论方法的主要优势是根据网络动态灵活调整。

### 5.2 基于人工智能的动态频谱分配

动态频谱分配可以通过多智能体深度强化学习方法解决，在这种方法中，每个用户在频谱中的占用被称为智能体。在这种方法中，将多智能体环境视为马尔可夫博弈模型。提出了一种邻居-智能体-演员-评论家（NAAC）模型来处理环境中的不确定性。该模型以集中式方式从统计数据中训练相邻节点。在同一时刻共享频谱的设备之间的关系可以提高设备的性能，如可达数据速率和频谱效率。在这样的网络中使用强化学习来根据过去的记录训练节点。

### 5.3 基于 AI 的分布式频谱访问

分布式动态资源访问可以有效地为常规实时网络开发。同时，需要消除大型网络中的计算消耗和网络中的不完全观测。采用 LSTM 方法来实现上述目标，它具有一个内部层，其中包含先前测量值的组合。还采用了双 Deep-Q-Network（DQN）来从未知状态中获得预期奖励。用户需要通过与中央单元通信来使用其训练过的 DQN 权重值，然后根据学习的 DQN 将其本地评论映射到频谱访问移动。

## 6 基于 AI 的动态资源分配

目前，太赫兹频段利用没有限制。这些频谱在一些不同的应用中扮演着重要角色，如卫星服务、光谱学和气象学。最近，美国联邦通信委员会一直在投资利用太赫兹频段进行移动服务和应用。因此，与未来的太赫兹通信和前面列出的其他应用相结合，频谱共享策略变得重要。此外，正如在前一节中讨论的，6G 网络往往是多维的、超密集的和异构的。因此，考虑到在 6G 中的太赫兹通信的传播介质和信道特征与 5G 中的地面网络完全不同，需要更多的努力来优化太赫兹通信的频谱管理。

强化学习可以可能认识到智能或精明的管理范围来解决这些问题，特别是当大量数据可以用于训练和预测时。这些训练和预测结果可以被利用来做出关于带宽是否被使用以及采取行动的决定，例如访问或释放频段。此外，通过用户与无线环境之间的互动，用户可以迭代优化他们的策略，以最大化补偿功能的价值，这可以考虑到频谱效率、网络容量、消耗的能量、干扰等因素。然而，当存在随机噪声或测量误差影响状态观测时，强化学习不能学习到有效的动作价值策略，这意味着在随机噪声存在的状态下的数量是无限的。为了解决这个随机状态测量的问题，深度强化学习被认为是解决 6G 网络中优化选项的合适方法，其中包括灵活的频谱访问、发射功率优化和无线电频谱分配。

### 6.1 强化学习驱动的 6G 网络

近期，对发展超越 5G 网络进行了深入分析，而后又发展到面向交通、超可靠、低延迟通信服务的 6G 无线网络。基于强化学习的算法被调整以从环境中获取可能的资源，以优化异构网络中的容量。例如，如果使用深度学习算法来提高性能，则需要大量内存来存储数据和高计算任务。在强化学习机制的情况下，代理或设备了解要执行的动作，以使相关动作的奖励最大化。因此，基于强化学习的算法学习可能的协议和动作，以匹配最近的动态未知状态。这些算法创建了具有状态、动作、奖励和状态-动作转移概率的新环境。已经证明，强化学习算法更适合未来一代网络。

*基本强化学习方法：*图 6 中描述了代理与环境之间的传统交互。标准的强化学习算法有三个术语，如(i)策略、(ii)奖励和(iii)状态。*策略：*策略是强化学习算法的重要部分；它定义了描述代理如何与环境交互的方法。*奖励：*对于每个动作，代理从系统中获得奖励/反馈。根据所获得的奖励值，决定该特定应用/环境的可能状态-动作策略。*Q 函数：*它描述了算法为采取的行动获得奖励的时间长度。对于准确行动的奖励必须很小，但对于长途操作而言，它将被视为有价值的 Q 值（图 8 和 9）。![](img/517376_1_En_4_Fig8_HTML.png)

描述了基于深度学习的频谱管理。它分为几个部分-频谱管理、频谱数据集经验、RF 频谱、可见光谱。

图 8

基于深度学习的频谱管理

![](img/517376_1_En_4_Fig9_HTML.png)

描述了基于深度学习的边缘计算架构。中央云服务器连接到核心网络，核心网络连接到服务器 1 交通、服务器 2 农业、服务器 3 智能设备。

图 9

基于深度学习的边缘计算架构

给定采取的行动的 Q 值！$$Q\left(s,a\right)=r\left(s,a\right)+\gamma \mathrm{max}Q\left({s}^{,},a\right)$$(2)该表达式(2)说明了来自于状态 s 并采取行动 a 的 Q 值，其奖励为 r(s,a)，加上可能来自下一个状态 s^'的 Q 值。典型的 Q-learning 和深度 Q 网络如图 10 所示。![](img/517376_1_En_4_Fig10_HTML.png)

典型的（a）Q-learning 图中有一个带有标签状态、动作和 Q 值的表格，（b）深度 Q 网络有标签状态、Q 值动作 1、Q 值动作 2 到 Q 值动作 n。

图 10

**a** Q-learning。**b** 深度 Q 网络

假设高价值行动在代理的帮助下经常被采取，导致在未知环境中的利用。 Q-learning 必须成为所有无模型强化学习算法的一部分，以解决通道行为问题。它设置学习率来改变学习能力，解决问题以将更高/更低的价值赋予长期回报、即时回报，并在 Q 值函数中更新以替换当前 Q 值执行。在所提出的算法中，最合适的行动决策最大化了 Q 值。深度 Q-learning 方法主要用于认知无线电和 Wi-Fi 网络的信道访问。

### 6.2 实现了 6G 网络基于 RL 的框架

在本节中，讨论了将强化学习算法逼近到实现 WLAN 网络的信道状态估计。提出了一个混合 RL 感知框架，在其中主模块执行行动计划（策略）。*学习阶段：*算法/模型从存储的信道状态（数据）中学习信道行为。*利用：*模型基于训练优化有用资源。图 11 说明了用于 mIoT（移动物联网）环境中 WLAN 的基于强化学习的架构的重要层次。该模型/系统在 AP 上进行训练，从许多状态行动中收集信道行为统计信息。模型放置也是为了对情景行动作出快速响应。模型可以根据更新的测量记录再次进行训练。

*训练阶段：*

在强化学习框架中，Wi-Fi 环境中的模型学习状态转换的通道，以避免可能的碰撞。然后，基站在上行传输期间收集各种代理/模型的信息。碰撞的概率可以用于学习和算法，以帮助媒体访问控制（MAC）-资源分配层在频段选择时。然后，收集到的记录使用强化学习技术进行预处理，以准确地学习媒体。例如，Q-learning 的应用将收集到的信息转换为奖励值。根据应用程序，奖励可以在 0 到 1 之间进行缩放。即使在开发基于强化学习的模型时，也必须考虑协议。例如，根据可用资源，AP 可能需要最广泛的相关 STA。策略与 Wi-Fi 设备的能力密切相关。一旦基站上的强化学习算法产生输出，它就会分布到整个网络环境中的 STA，然后被重新安排/改造，以提供快速的理想频谱支持分配给新请求。

*放置阶段：*

在这个阶段，基站可以为请求分配新的频谱，或者基于存储的状态行为来移交频谱。基站处理收集到的记录作为学习阶段的一部分。知名的 Q-learning 算法被应用在 AP 上，为未来的请求提供基于奖励的响应。通道访问或分配状态被传达给相应的状态行为。

### 6.3 基于强化学习的频谱管理

在 THz 频谱上没有使用限制。卫星电视链接、光谱学和气象学已经占据了 THz 频谱。如今，移动通信服务和应用程序也被允许使用 THz 频段。因此，在 THz 通信中，为子 GHz [21–23] 提出的频谱分配和共享方法至关重要。根据前几节对 6G 网络的讨论，未来的网络是高维度、超高密度和异构网络。因此，6G 网络应该具有比传统的 5G 网络更好的传播介质和信道状态估计。也就是说，在 THz 通信中，应该投入更多的努力来实现频谱管理。

+   强化学习算法在解决 THz 通信中的频谱管理问题方面具有更大的能力，尽管它涉及大量的历史记录用于学习。这些学习和预测机制在做出行动决策时具有很大的优势。行动确定频谱是否已被占用或自由进一步访问/分配频谱。

+   用户与无线环境之间的持续交互使得优化所提出的技术以获得最大的奖励值成为可能。 奖励值是指频谱效率、网络性能和干扰消减以及接收到的信号强度，这取决于应用程序。 强化学习还具有重要的状态-动作-奖励策略，尽管信道噪声中存在恒定的随机性。 为了解决这些问题，深度强化学习被用作大规模连接网络的频谱管理的合适方法（图 11 和 12）。![](img/517376_1_En_4_Fig11_HTML.png)

    描述了深度强化学习作为大规模连接网络频谱管理的合适方法。 它具有 R L 代理、W L A N 环境、探索/开发区域。

    图 11

    深度强化学习的示例

    ![](img/517376_1_En_4_Fig12_HTML.png)

    描述了 mIoT 环境中基于 RL 的 WLAN 的关键阶段具有 R L 感知框架、放置阶段、训练阶段和称为观察输入数据的正确箭头的优化行动。

    图 12

    *m*IoT 环境中基于 RL 的 WLAN 的关键阶段

## 7 结论

本章讨论了在超可靠低延迟通信（URLLC）中的资源管理的重要性。 通过利用适当的机器学习/深度学习算法，可以解决高维网络中的挑战和问题。 我们讨论了 AI 在资源管理方面的基本要素、机器学习技术在网络管理中的应用、基于机器学习的频谱预测、资源的高效利用、动态资源分配以及强化学习在解决问题中的作用的机会。
