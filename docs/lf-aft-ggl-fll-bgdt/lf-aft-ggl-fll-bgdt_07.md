## 第七章

## 达利的并行范式

这是谷歌之后的生活吗？

比尔·达利即将驾驶他的自动驾驶特斯拉 Model S 带我去帕洛阿尔托 Caltrain 车站。¹

在 Nvidia 圣克拉拉的车库里，我登上了时尚的灰色硼钢和钛制导弹，注意到它未来主义的 1200 磅锂离子电池。应该足够把我带到车站。充电满了，它几乎可以取代内燃机油箱中 60 磅的汽油。这可能看起来不像什么，但在谷歌时代的数学中，它可以拯救世界。

在计算其数据中心的能源预算时，谷歌像硅谷的其他公司一样严谨，就像肯尼亚马拉松选手一样。但当它开始推出在太阳能补贴的阳光下闪闪发光的汽车时，最好重新检查一下它的数字。它们的成本可能比它们说的要“Waymo”多。

这是一辆特斯拉，它的自动驾驶愿景来自英伟达业界领先的 Drive PX 系统。我要把自己系在驾驶座上，但必须把旁边的一张来自附近库比蒂诺的年度 Hot Chips 大会的传单搬开。三十年前，当我为本·罗森和埃斯特·戴森分析半导体时，芯片仍然很热，我常去 Hot Chips 大会保持时效。硅，从那时起直到现在，一直是信息技术整个建筑的基础，物理层的基础。我很放心，尽管谷歌等公司声称“软件吞噬一切”，Hot Chips 依然存在着。

尼克·特雷登尼克是一款过去热门芯片的设计师，这款芯片是史蒂夫·乔布斯的麦金塔电脑背后的摩托罗拉 68,000 微处理器，曾经说过，这个行业试图利用“领先边缘楔形”。三个重叠的设计目标汇聚在芯片设计的这片肥沃的新月之中：零延迟（快速热芯片）、零功耗（低能耗设备）、零成本（晶体管价格为亿分之一便士）。在 1980 年代到 2017 年期间，芯片已经从热快端向着冷廉端迁移，这一趋势是 Dally 带领的。

在特斯拉的前座，我面对着一个两英尺高的屏幕，上面显示着苍白而有条纹的谷歌地图。Dally 指出，自动驾驶车辆“不关心路线在哪里。它们在地图上导航，登记在地图上的位置。如果有空旷的道路，它们就沿着中间画一条线，就像它们在走铁轨一样。只有移动物体，比如行人和其他汽车的存在，才需要它们使用所有的运动感知能力。”

虽然地图来自谷歌，但处理来自 Nvidia GPU。这些芯片计算汽车对激光雷达、雷达、超声波和摄像头信号的响应，使导弹从埃隆·马斯克的领域外降落，进入谷歌地图之外不断变化的高熵世界。

Dally 吩咐道：“导航至加州大道的卡尔特雷恩站”，车辆迅速响应。Dally 评论说：“在过去几年里，语音识别已经大幅提升。提高了百分之三十。两年前它还不能准确理解。但现在有了我们的 Tegra 芯片上的机器学习，每次都能准确理解。” 受益的是亚马逊的 Alexa、苹果的 Siri、微软的 Cortana 和谷歌的 Go 的所有用户。

现在，达利正在操纵方向盘穿越后街。“这只是二级自动驾驶，”他解释道，使用了汽车工程师协会的分类，该分类范围从一级，仅仅是司机助手，到五级，全自动驾驶。马斯克承诺在两年内将特斯拉提升至五级。这就是埃隆。但现在，达利专心盯着道路，因为特斯拉通过几次高电压突发事件，沿着匝道开上 101 号高速公路。现在特斯拉的自动驾驶模式使他能够转身向我展示他最近日食的电影——一系列生动的高对比度图像。

达利指出，机器学习主要是由英伟达的图形处理芯片完成的。一些人工智能的进步源于算法的改进，但这些能力的真正来源是通过摩尔定律和并行处理的爆炸性提升来实现的计算机速度的显著提升。英伟达的图形处理器是达利作为并行处理先知长达三十年的职业生涯的高潮，他的并行处理研究始于三十年前在弗吉尼亚理工学院，他在那里研究了多处理器共同运行的优点。

在 1991 年 8 月斯坦福大学的一个热门芯片会议上，达利和 Norm Jouppi 首次以形成未来计算哲学的对比出现。达利介绍了他的革命性的大规模并行 J 机器，而现在在谷歌工作的 Jouppi 则在 Digital Equipment 公司时称赞将现有处理器管线提速到每个时钟周期“五条指令”的前景。

1991 年的这两篇论文使整个计算机科学产生了两极分化：你是让现有的串行冯·诺伊曼处理器变得更快，寻求零延迟，从越来越快的远程内存中提取指令和数据？还是将内存和处理器分散到整个机器中？在像达利的 J 机器这样的大规模并行扩展中，内存总是靠近处理器。

二十六年后，达利和乔皮仍然在努力。在 2017 年 8 月的 Cupertino 热门芯片展上，所有大公司都在吹捧他们自己的芯片，用于所谓的“深度学习”，这是指与反馈相关的多层次模式识别、相关性和纠正的大规模加速，从而导致性能的累积增益。他们称之为“学习”的东西起源于早期的人工智能企业。猜测、测量错误、调整答案、反馈，这是谷歌数据中心遵循的经典步骤，使得 Google 翻译、Google Soundwriter、Google 地图、Google 助手、Waymo 汽车、搜索、Google Now 等应用能够实时运行⁴。

截至 2012 年，谷歌仍在努力区分狗和猫的区别。YouTube 以其猫视频而闻名，但无法有效地教会其机器识别猫。它们能够数数；数据中心的狗可以跳舞；但这需要一万六千个微处理器核心和六百千瓦电力⁵，而且错误率仍然达到 5％，这对于谷歌的人脸识别项目或需要实时无误识别远程对象的汽车视觉系统来说并不是一个令人印象深刻的预兆。

正如克劳德·香农所示，这些成功率达到 95％，甚至 99.999％的数据是具有误导性的，因为您无法判断哪些实例是错误的⁶。在抵押危机中，绝大多数住房贷款是安全的，但由于没有人知道哪些是不安全的，所有的证券都崩盘了。您不希望自动驾驶汽车出现这种问题。

2012 年在阿斯彭联合露面时，彼得·蒂尔讽刺埃里克·施密特说：“你根本不知道你在做什么。”他指出，公司当时已经积累了大约 500 亿美元的现金，而公司仍然让它以接近零利率的利息放在银行里，而其庞大的数据中心仍然无法像一个三岁的孩子那样辨别出猫。[⁷]

Thiel 是硅谷“不可避免”创新主流哲学的主要批评者。另一方面，Page 是一位机器学习的极端主义者，他相信硅将很快超越人类，无论你如何定义这种差异。如果漫无目的的图灵机器能够产生人类大脑，想象一下 Google 的杰出学者团队将整个数据中心充斥着多个吉赫兹硅来训练数据宝库中的机器所能实现的成就。然而，在 2012 年，结果似乎令人失望。

2012 年与狗和猫危机同时发生时，谷歌 Brain 研究团队的领导 Jeff Dean 对谷歌的数据中心动力之源 Urs Hölzle 说：“我们需要另一个谷歌。” Dean 的意思是谷歌将不得不将其数据中心的容量翻倍，以满足 Android 智能手机上 Google Now 语音识别服务的新需求。

年末，比尔·达利给出了答案。在达利最喜欢的帕洛阿尔托咖啡馆早餐时，他的斯坦福同事安德鲁·吴（Andrew Ng）抱怨起猫的命名。一万六千个昂贵的微处理器核心似乎效率低下。达利建议使用英伟达 GPU。图形处理器专门用于矩阵乘法和浮点数数学运算，这些操作可以教会机器识别模式。图形图像是一个值数组，很容易映射到数学矩阵。通过将图像通过多达十二层矩阵，机器学习可以被视为另一种迭代图形处理。

吴告诉达利，证明一下，谷歌就会购买他的芯片。

第一个粗糙图形处理器的创造者，也就是谷歌所有数据中心神经网络的前身，是康奈尔大学的心理学教授弗兰克·罗森布拉特。1958 年，他向《纽约客》描述了他的“感知机”：“如果一个三角形被拿到感知机的眼睛[光电传感器]前，与眼睛相连的关联单元将捕捉到三角形的图像，并将其沿着一系列随机线路传递到响应单元[现在称为神经元]，在那里图像被注册。。。[所以]所有通向那个响应的连接都会被加强[即它们的权重会增加]，如果拿着不同大小和形状的三角形到感知机前，它的图像将沿着第一个三角形所经过的路径传递。然而，如果呈现的是一个正方形，则会调用一个新的随机线路集。。。感知机被允许扫描的图像越多，其泛化能力就越强。。。它能够区分狗和猫。”⁸

四年后，时年十六岁的雷·库兹韦尔（Ray Kurzweil）拜访了罗森布拉特（Rosenblatt），当时库兹韦尔的 MIT 导师马文·明斯基（Marvin Minsky）揭示了罗森布拉特构建的单层感知器的局限性。罗森布拉特告诉库兹韦尔，他可以通过将感知器叠加在一起形成多层来克服这些局限性。“性能会有显著改善，”他说。八年后，罗森布拉特在一场船只事故中去世，从未构建过多层机器。

现在在 Google，这一遗漏正在得到纠正。Dally 指派 Nvidia 的软件专家 Frank Canizaro 与 Ng 合作，升级 Nvidia 的专有软件 CUDA（Compute Unified Device Architecture）以供其 CUDA 深度神经网络库（cuDNN）使用。斯坦福-谷歌-Nvidia 团队仅用了十二个 GPU，烧掉了仅四千瓦的电，仅用了三万三千美元就解决了猫狗问题。

Dally 为这一成就感到自豪。Nvidia 的机器大约比 Google 以前的设置**成本效益高出 150 倍**。而且这还没有考虑到 GPU 在能源效率上的巨大优势。Nvidia 处理器很快就渗透到了 Google 的数据中心，在机器学习的核心矩阵乘法和累加运算中实现了前所未有的性能。

如今，Google 部署了十至十二层的神经网络，产生了三十艾克斯弗洛普的浮点数数学计算能力——以及大量的矩阵乘法。与罗森布拉特的预测相符，“感知器能够扫描的图像越多，其泛化能力就越高”，Google 的机器根据约十亿参数对数千万张图像进行排序。它促使 Google Brain 经常声称“超过人类”。天啊，十亿参数，我都不懂了！在硅谷，人类编程这些机器，质疑“超人类”能力的说法被视为古怪。

这一切都不会让 Dally 感到困扰，除了谷歌发生的一个至关重要的变化。在 2017 年 Hot Chips 会议上，公司以自助的心态表示，今后将用自己的特定用途硅替换英伟达的设备。Jeff Dean 庆祝 Jouppi 的升级版“Tensor”“矩阵乘法器”，它避开了图形和浮点，专注于机器学习功能。这是一个矩阵乘法器 ASIC（特定应用集成电路）。谷歌的人说，如果没有他们的 Tensor 处理单元，他们将不得不将数据中心的规模加倍。

Dally 指出，将整个系统放入 ASIC 硅片的单个片上始终可能获得巨大的临时收益，这些是专用芯片，硬连线执行一个复杂功能。正如 Dally 告诉我，在执行并行操作时，图形处理器比通用中央处理单元（CPU）具有十倍的成本效益，而 ASIC 比普通 GPU 具有十到一百倍的成本效益。但是，使用 ASIC，你的市场仅限于你选择的特定用途，你的数据中心不再是全能的图灵机器。它们正在变成像达尔斯市的铝厂一样的特定目的工厂。

谷歌可以负担得起为其数据中心中特定插槽定制自己的定制 ASIC，但英伟达正在主导大规模并行处理的整个领域。2017 年第三季度，在 Hot Chips“挫折”之后，英伟达宣布云计算销售收入增长 109％，达到 8.3 亿美元，将公司的市值提高到近 1300 亿美元。

现在英伟达是全球行业提供并行处理器的强大力量，并为谷歌之后的生活提供了新平台。随着谷歌在硬件和软件制造方面的新实力，聘用了行业硬件巨头，例如戴夫·帕特森和诺姆·乔皮来设计领先的芯片架构，所有这些是否即将终结？

我去拜访达利想了解一些情况。五十七岁的达利，棕发工程师，黑帽子、背包、登山靴，他的着装就像硅谷登山者，要带我进行高海拔冒险，涉及微芯片和软件、思想和猜测、Google 地图和埃隆·马斯克的“现实扭曲场”……我们在八月下旬一个星期五下午五点，沿着 101 号公路驶向未来。

这不完全是布朗博士驾驶德洛里安时光机的“回到未来”之旅，但它对计算史的一些简单时光旅行已足够。

自上世纪 70 年代晚期写完他的大学论文以来，达利反抗了被称为冯·诺依曼体系结构的串行步进式计算机制度。在加州理工学院（1983 年）攻读博士学位期间，他在 Chuck Seitz 的“宇宙立方”项目上工作后，带领了麻省理工学院的并行机器设计（J-机器和 M-机器），在 Cray 超级计算机上介绍了大规模并行性（T-3D 和 3E），并在斯坦福大学开创了并行图形领域，推出了 Imagine 项目（一种流式并行设备，融合了可编程的“着色器”，现已广泛应用于英伟达等公司的图形处理器中）。

在所有这些项目中，达利一直在与传统的串行处理计算机体系结构作斗争——这与一个被称为“冯·诺依曼瓶颈”的内存问题有关。你生活在现实世界中，对吧？现实世界提供了本质上的并行问题，比如眼前一下子涌入的图像，不管你是在雪地上开车，还是在召唤由计算机生成的图形或者在“机器学习”海量数据中进行模式匹配。

冯·诺伊曼瓶颈是由冯·诺伊曼本人认识到的。 作为回应，他提出了一种被称为元胞自动机的大规模并行架构，这导致了他在五十七岁去世前的最后一本书。 在《计算机与大脑》中，他考虑了一种被称为神经网络的并行解决方案，这是基于对数十亿神经元如何在人类神经系统中共同工作的一个原始概念。

冯·诺伊曼得出结论，大脑是一个比他在 1957 年为计算机预言的几千兆赫慢了九个数量级的非冯机器。 令人惊讶的是，冯·诺伊曼预见了我们经历的许多百万倍的“摩尔定律”加速。 但他估计，大脑比计算机节能高达九个数量级（十亿倍）。 这甚至比 Google Brain 团队为其 Tensor 芯片声称的节能更多。 在 IBM 的大蓝和沃森的时代，这种比较仍然相关。 当一台超级计算机在国家超级计算机应用中心击败一名棋手时，这名棋手可能只用了十四瓦的功率，而计算机及其网络则依靠哥伦比亚州的千兆瓦云。

在大数据时代，冯·诺伊曼瓶颈具有哲学意义。 放入冯·诺伊曼机器中的知识越多，其内存就越大、越拥挤，其平均数据地址就越远，其功能就越慢。 前 Thinking Machines 的丹尼·希利斯写道：“无论我们将处理器速度提高到多快，这种效率都会保持不变，因为计算时间的长度受限于在处理器和内存之间移动数据所需的时间。” 每一步计算中所走过的距离由光速决定，在芯片上大约是每纳秒九英寸——对于现在承载着长达六十英里微小导线的芯片来说，这是一个显著的延迟。

-   Dally 看到的是串行计算机已经走到了尽头。大多数计算机（智能手机、平板电脑、笔记本电脑，甚至自动驾驶汽车）不再插在墙上。即使是超级计算机和数据中心也受到功率限制的影响，体现在冷却机器的问题上，无论是通过巨大的风扇和空调还是靠近河流或冰川的站点。正如 Hölzle 所评论的，“按照传统的定义，数据中心产生的‘工作’很少，因为大部分能量都转化为热量。”

撞击能源壁和光速障碍，芯片的架构必然会分裂成单独的模块和异步和更多的并行结构。我们可以将这些处理器称为时空“软体动物”——爱因斯坦对相对论世界中的实体的称呼。设置集成电路单元的大小将是微观世界中与宇宙中的光年可比的一种衡量。它将强制执行与人类智能分布类似的计算能力分布。

因此，Dally 表示，回顾 Tredennick 的观点，领先的计算机性能现在必须通过每瓦的操作来衡量，而不是传统的每秒操作或硅面积的指标。基于眼睛一次性接收到的图像的自然并行性，图形处理器不仅像视觉一样普遍存在，而且具有极高的并行性。因此，今天许多“酷炫芯片”往往是由 Nvidia 制造的。

然而，以每瓦操作而论，目前的冠军并非由硅而成，而是由碳组成。它就是原始的神经网络，人类大脑及其的十四瓦，这还不足以点亮卡通连环画中人物头顶上的灯泡。未来，计算机将追求大蓝（IBM）甚至是巨大的空调数据中心的兆瓦数而不是能耗优化。所有计算机都将必须采用在电池供电的智能手机行业中开发的省电技术，然后继续探索真实碳基大脑的能源经济。

可编程机器和程序员之间存在关键差异。机器是确定性的，而程序员则具有创造性。

这意味着人工智能运动与其取代人类大脑不如说是在模仿它们。大脑展示了边缘胜过核心的优越性：它不是集结在几个空调节点上，而是分散在各处，通过无数的感觉和媒体渠道相互连接。全球计算机和电缆的新型全球节块的考验是它们如何迅速利用来自各种创造性和多样性的自由人类思想的意外贡献，这甚至不能用计算机科学的度量标准来衡量。

硅谷传奇人物加州理工学院的卡弗·米德在他数十年的神经形态计算实验中已经表明，任何真正的人工智能可能都不得不使用碳基材料而不是硅基底物。有大约 200,000 种化合物的碳比硅具有更高的适应性和化学复杂性。近年来，出现了许多新的碳材料，如现在慢慢占据显示市场的有机发光二极管和光电探测器。最有前途的是石墨烯，一种透明碳的一层厚度的片材，可以卷曲成碳纳米管，在石墨块中堆叠，或者构建成 C-60 “巴克球”。

石墨烯有许多优点。它的拉伸强度是钢的 60 倍，导电性是铜的 200 倍。它没有带隙来减速，为电子提供了相对巨大的 60 微米平均自由程。正如莱斯大学的纳米技术大师詹姆斯·图尔在他的实验室中所证明的那样，石墨烯、碳纳米管漩涡及其化合物使各种纳米机器、车辆和引擎成为可能。它们提供了远未实现的新型计算机架构的希望，如能够实际模拟物理现实并因此最终可能产生一些真正智能的量子计算机。

当今硅谷的这一代人还没有接受冯·诺依曼和哥德尔在上个世纪早期的发现，也没有接受克劳德·香农、格雷戈里·查伊廷、安东·科尔莫戈洛夫和约翰·皮尔斯在信息理论方面的突破。在一系列强有力的论证中，发明了算法信息论的查伊廷将哥德尔的理论转化为现代术语。当硅谷的人工智能理论家把他们的案例逻辑推向爆炸性的极端时，他们违背了二十世纪数学和计算机科学最关键的发现。所有逻辑方案都是不完全的，并且依赖于它们无法证明的命题。将任何逻辑或数学论证推向极端——无论是“重标度”无限大还是平行宇宙的多重性——科学家们都会将它推向哥德尔的不完全性的悬崖。

Chaitin 的“创造力数学”建议，为了推动技术的发展，有必要超越存在于现有计算机中的确定性数学逻辑。任何确定性的东西都会阻碍那些定义信息并反映真正创造力的惊喜。哥德尔规定了一种创造性的数学。

这种数学首先将在当前世界的主流系统的惊人成功中遇到一个重大障碍，这不仅存在于硅谷，也存在于金融领域。
