# 基于 DAG 的 BFT 共识的执行和并行

> 原文：<https://blog.chain.link/execution-and-parallelism-for-dag-based-bft-consensus/>

*作者:乔治·达内齐斯和达丽雅·马尔基*

在 [基于 DAG 的 BFT 共识](https://blog.chain.link/bft-on-a-dag/) 中，多个块提议由所有验证器并行发送，并且可能不清楚如何以及何时处理它们包含的交易并证明结果。

是时候讨论基于 DAG 的一致性协议的事务执行了。

## **背景:基于 DAG 的排序**

在基于 DAG 的 BFT 共识协议中，每个共识消息都直接用于形成提交事务的总排序。更具体地说，参与 DAG 共识的每个验证器独立地将尚未确认的事务或它们的摘要打包到一个块中，添加对先前传递的(下面定义的)消息的引用，并向所有验证器广播携带该块和因果引用的消息。块被可靠地传递，并且它们携带的引用成为因果有序有向无环图(DAG)结构的主干。然后，验证器在本地解释它们的 DAG，而不交换更多的消息，并通过查看累积事务的总排序来确定视图。

在每个视图中，跨验证器的一组公共块被提交或可能被提交。集合中的每个块包含一组事务。可以通过过滤掉任何已经排序的事务(重复和重新提交)，使用协议特定的序列号或帐户、使用拓扑排序对事务进行因果排序，然后使用用于非因果约束事务的某种平局打破规则来最终确定序列，例如给予具有较高燃气费的事务优先权，或其他考虑，如 DAG 上的 MEV 保护，来从这组块中提取序列。虽然可以设计出上述的许多变体，但是提交或潜在提交会导致一系列事务。为了区分视图中的事务集和块中的事务集，我们称它们为(事务的)视图集。

问题是视图集事务应该在什么时候由谁来处理，结果应该在哪里以及如何发布？

## **DAG 执行临近**

### 选项#1:后订购非 DAG

在此选项中，DAG 仅按照上述建议对交易进行排序。所有观察者——包括验证者和客户端——在 DAG 协议之外处理它们。每个观察者需要处理当前已提交前缀中的所有事务，以便达到处理整个已提交前缀所产生的状态。随着新视图集的提交，观察者可以增量地处理这个链。

这种方法很简单，并且符合当前流行的以模块化方式构建区块链的理念，将不同的子系统结合起来以实现可用性、排序和执行。在这种情况下，DAG 共识只是排序(也许还有一些可用性)，但依赖于其他层来执行。这种方法的缺点是，默认情况下，它不提供关于已执行状态的证书来支持由 DAG 共识验证器共同签名的轻量客户端。因此，需要在执行层做出额外的安全假设，以确保整个系统的安全性。

### 选项#2:在 DAG 上排序后检查点

在该选项中，当验证器观察提交时，它们“懒惰地”和异步地(即，没有具体的协议步骤或时间限制)构建和执行事务序列，然后在 DAG 块中或作为共识中排序的事务提交其结果的签名提交。客户端(尤其是轻量级客户端)可能会等待 F+1 个状态承诺(其中 F 是拜占庭验证器的最大数量)被发布到 DAG，并依赖这些来验证读取，而不是自己处理事务。

异步执行很简单，并且不在排序的关键路径之内。与前面的方法相比，它产生一个集体签名的状态检查点，包含足够的信息来支持轻型客户端。不利的一面是，异步要求轻量级客户端等待，可能要等待很长时间，而且时间长短未知，直到它们可以验证读取。如果执行是系统的瓶颈，这种延迟可能会越来越长；并且可能会阻止轻型客户端构建新的事务进行处理。

### 选项#3:领导提议的执行

这个选项可以很好地与基于 DAG 的 BFT 共识协议一起工作，这些协议旨在与预先指定的领导者一起工作，如 [Fino](https://arxiv.org/abs/2208.00940) (在[以前的帖子](https://blog.chain.link/bft-on-a-dag/)中解释过)和牛鲨的[部分同步组件](https://arxiv.org/pdf/2209.05633.pdf)。它也可能适用于异步协议，如 [Tusk](https://arxiv.org/abs/2105.11827) 和 [Bullshark](https://arxiv.org/abs/2201.05677%22) ，但可能效率低下。

它的工作原理如下。

当领导者共识提案被嵌入 DAG 中时，领导者已经知道提案中包括什么(即，提案的因果历史)。因此，尽管所有的块提议都是并行进行的，但领导者可以根据提议的块对执行序列的结果进行预处理，并将其付诸表决。领导者将提议的结果作为国家承诺，当验证者投票时，他们也检查并隐含地投票赞成结果。

由领导者提议的执行方法在 Fino 中运行良好，但在 Tusk 和 Bullshark 中，领导者是在事后决定的:因此，为了实现这一点，所有区块提议者都必须提出国家承诺，所有投票都应该预先执行提议——尽管事实上只有一个会被选中。这是正确的，但计算效率低，至少在这种天真的形式。

该方法的好处是允许在区块认证和 DAG 构建的同时遵守国家承诺。轻型客户端可以立即使用它们。它还允许 DAG 结构感受来自执行延迟的反压力，以防执行成为瓶颈，从而保持两个子系统相互协调。后一点也是它的缺点:在排序(一个受网络限制的活动)和执行(一个受 CPU /存储限制的活动)之间轮流投入资源可能会导致两者的资源利用不足，从而降低系统的整体效率。

值得指出这种方法的另一个变体:在 x 延迟的领导者提议的执行中，对于某个值 x，视图 k+x 的领导者发布视图 k 的输出，包括在其对 k+x 的提议中。验证者对领导者 k+x 提议的投票更是对视图 k 的结果的投票。

## **并行执行**

无论谁何时执行程序块(如上所述)，都有办法通过并行化工作来加速执行。这对于高吞吐量至关重要:除非执行可以满足排序吞吐量，否则可能会形成提交状态未知的已提交事务积压，这可能会导致客户端延迟观察提交状态，并且无法产生新的事务。

在高层次上，有两种通过并行工作加速执行的关键方法:

利用事务之间固有的并发性，通过并行性来加快处理速度。并行执行可以利用可用的多核计算资源，与顺序处理相比，可以显著提高性能。

通过各种预处理策略为更快的验证准备事务，利用验证器或外部助手的集体计算能力来完成准备任务。

我们主要讨论如何加速单一视图的执行。回想一下，在一个视图中，跨验证器的一组公共块被提交，每个块包含一组事务。在由所有已提交块中的事务组成的事务视图集中提取序列排序。

### 并行选项#1:通过并行处理进行后排序加速

在这个选项中，目标是处理一个有序的事务视图集，就好像它是顺序执行的一样，并得到顺序结果。然而，不是一个接一个地执行事务，关键思想是一些事务可能不冲突，也就是说，它们不读或写任何公共数据项。因此，它们可以并行处理，从而加速执行，获得正确的顺序结果。另一个性能提升可以通过将事务的输出组合成批量写入来获得。

订单后事务处理加速是上一篇文章的主题，“ [Block-STM:加速智能合同处理](https://blog.chain.link/block-stm/) ”。我们可以对有序视图集使用 Block-STM，而不是对块应用 Block-STM。每个验证者独立地使用 Block-STM 来并行处理领导者的提议。

### 并行选项#2:并发提示

借鉴“向智能契约添加并发性”的开创性工作，我们可以向并行选项#1 添加各种方式，其中验证器通过共享关于并发性的提示来相互帮助。

提示可以在预处理阶段产生，其中每个验证器临时处理和/或静态分析它自己块中的事务。对于每个事务，它生成一个临时读集和写集，并记录这些集以指导并行执行，并将它们嵌入块建议中。关于事务相关性的信息可以为 Block-STM 等并行执行引擎提供种子，并有助于降低中止率。

这个机制的一个重要方面是，验证器可以并行地预处理块，在某些情况下，可以同时将事务收集到块中并将其发送到 DAG。在这种情况下，花费在预处理上的时间与(网络密集型)订购阶段重叠，因此，这可能导致对可用计算资源的非常好的利用。

一个不同的机制是让一个(或几个)验证者经历一个试错的推测性事务处理，然后与其他人共享他们“发现”的并发调度的副本。我们可以指定验证器在循环的基础上发现并发性，其中在每个视图中，一些验证器将资源转移到执行，而其他验证器确定性地但同时地重新执行并行调度，节省了他们的工作和时间。或者，我们可以简单地让快速验证器通过共享他们发现的并发性来帮助落后者赶上。

## **其他加速器和未来研究**

ZK-roll up 的最新进展允许从验证器中卸载计算和存储资源(关于出色的概述，请参见“[](https://vitalik.ca/general/2021/01/05/rollup.html)”不完整的 roll up 指南，Vitalik，2021)。这些方法允许称为“证明者”的强大实体执行事务并生成提交状态的简洁证明，其验证非常快。重要的是，只有一个证明者需要执行事务，因为证明者不需要被信任；证据是自我验证应用了正确的处理来产生提交状态。因此，证明者可以在专用的、强大的硬件上运行。相对于完全处理事务，验证者验证这种证明所需的工作显著减少。

一般来说，ZK 证明生成很慢，目前比处理事务还慢，ZK 的主要用途不是加速，而是压缩状态和卸载验证器的计算。然而，特定的上滚有可能被用于加速。例如，最近使用 STARKs“[聚合和阈值化基于散列的签名”的方法可以被应用来减少由交易集合上的签名验证引起的计算负荷。](https://eprint.iacr.org/2021/1048)

另一种可能的加速来自于分割执行，以避免每个验证器重复执行每个事务。这种方法代表了信任模型的转变，因为它需要信任具有执行结果的验证器的子集，或者将执行委托给专用的可信执行者(例如，在[Hyperledger Fabric]和[ParBlockchain]中)。

跨子集的分割执行可以基于账户所有权，其中代表每个账户的动作在其专用执行者上处理。在像 Sui 和 Solana 这样的网络中，事务分别用它们访问的对象或帐户进行注释，因此以这种方式分割执行更容易。以对象或帐户为中心的计算的优势在于并行处理不会产生冲突，但这种模式下的编程必须进行调整和约束，以充分利用这种并行机会。

另一种方法是基于预处理或静态分析来创建事务间的依赖图。然后，我们可以使用该图将事务划分为可以并行处理的并行“桶”。这种策略在许多学术著作中使用，其中一个专门关注预排序批处理的小样本包括:

[反思可串行化多版本并发控制](https://www.cs.umd.edu/~abadi/papers/rethink-mvcc.pdf) ”，法莱罗等人，2015

“[给智能合约添加并发](https://arxiv.org/abs/1702.04467) ”，Dickerson 等人，2017

“[通过事务批处理和操作重排序提高乐观并发控制](https://dl.acm.org/doi/10.14778/3282495.3282502) ”，丁等，2018

"[" par block chain:在许可的区块链系统中利用交易并行性](https://arxiv.org/abs/1902.01457) "，Amiri 等人，2019"

[OptSmart:一个空间高效的乐观并发执行的智能合约](https://arxiv.org/abs/2102.04875) ”，安贾纳等人，2021

## **总结**

在区块链，对扩展核心共识引擎的长期追求带来了共识排序算法的重大进步，并在最近一波基于 DAG 的 BFT 排序协议中达到高潮。然而，为了支持高吞吐量，我们需要实现满足订购速度的高吞吐量事务处理。这篇文章介绍了基于 DAG 共识的事务执行的几个范例，并展示了通过并行性加速事务处理的方法。