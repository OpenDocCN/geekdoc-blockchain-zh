© 作者，独家许可给 Springer Nature Switzerland AG 2021R. Kumar 等，互联网、人工智能和区块链技术[`doi.org/10.1007/978-3-030-74150-1_12`](https://doi.org/10.1007/978-3-030-74150-1_12)

# 12. 双向 GRU 模型与堆叠嵌入用于情感分析：一个案例研究

Sanjana Kavatagi^(1) 和 Vinayak Adimule^(2  )(1)卡纳塔克邦贝拉加维的 Angadi 技术与管理学院计算机科学与工程系，印度(2)卡纳塔克邦贝拉加维的 Angadi 技术与管理学院研究与开发院院长，印度关键词机器学习情感分析 LSTMGRUCNN 基于极性的技术嵌入式 Prof. Sanjana M. Kavatagi

她在卡纳塔克邦贝拉加维的维斯韦沙拉雅工业大学获得学士学位和硕士学位。她目前在贝拉加维的 Angadi 技术与管理学院计算机科学与工程系担任助理教授。她在国内外期刊上发表了两篇论文。她的研究兴趣包括人工智能、机器学习和大数据。![../images/504166_1_En_12_Chapter/504166_1_En_12_Figa_HTML.jpg](img/504166_1_En_12_Figa_HTML.jpg)

Prof. Dr. Vinayak Adimule

拥有 13 年的研究经验，曾在 TATA（Advinus）、Astra Zeneca India、Trans. Chem. Ltd 等研发组织担任高级科学家和副研究科学家。他在药物化学（抗癌药物）、纳米科学与技术、材料化学和生物化学领域是专家。他在 Scopus 和 Google Scholar（SJR）索引期刊上发表了 30 多篇研究文章和书籍章节；参加并在国内外会议上发表论文；获得最佳口头/海报奖；在 Notion Press International Inc.出版了几本书籍；主持了几次与材料电子相关的国际和国内会议研讨会。他是许多国际学会、研究机构的编辑委员会成员、终身会员和副会员。他被认可为 VTU 贝拉格维的研究指导教师。目前，他正在指导一位研究生攻读博士学位。他的研究兴趣包括纳米电子学、材料化学、传感器和执行器、生物纳米材料和药物化学。![../images/504166_1_En_12_Chapter/504166_1_En_12_Figb_HTML.jpg](img/504166_1_En_12_Figb_HTML.jpg)

## 12.1 引言

随着当今世界互联网的增长，数据呈指数级增长。电子商务是一个人们最常使用的领域之一。像 Flipkart、Amazon、Snapdeal、Grofers、big basket 等电子商务应用程序是在线购物的高度使用平台。由于电子商务技术的指数级发展和普及，每个人都喜欢在众多电子商务页面上购物（Liang & Wang，2019）。

随着网络购物的兴起，消费者越来越热衷于在互联网上分享他们的意见和感受。从在线评论中提取用户的情感至关重要，这不仅可以通过帮助他们做出购买决策吸引潜在用户，还可以让组织获得产品的反馈。在商品或服务上，客户可能会分享他们的观点、意见和用户体验。他们还可能向其他人提供明确的建议（陈等人，2018a，b）。如今，顾客在线给出的评论被认为是支持潜在客户对商品或服务的在线购买决策的最佳和成功的来源（高等人，2017；加维兰等人，2018）。在自然语言处理（NLP）中，情感分析在从在线社区和协作媒体中收集和处理用户反馈相关信息方面起着至关重要的作用。从应用角度来看，观察到的数据在智能科学和商业系统中变得越来越重要，以克服并提高其服务和产品的质量（拉西奥·迪亚斯，2018；邢等人，2018）。

通常，在线评论的数据是复杂而全面的，它还包含了对被评论产品或服务的多个特征（也称为文学方面）（张等人，2010）。评论中的词语可以被解释为积极或消极。描述产品质量为“好”的词语可以被认为是对产品的积极看法，而用于表达成本的“高”这个词则可能被认为对产品有些消极看法。

在评论中的每个陈述都会假设对正面感知、负面感知或某种中立感知有一定了解，因为人类偏好和决策中固有的微妙和模糊性。因此，评估如此广泛的在线评级是具有挑战性的。如果我们只考虑一般产品情感价值，并忽视在线反馈中不同特征的模糊性和随机性，就会忽视或扭曲宝贵的细节。

至今，对情感分析进行了大量研究。研究人员已经实施了许多关于情感分析的工具和算法。情感分析研究不仅可以针对消费者评论结果进行，还可以针对广告、社交媒体数据等进行。用户提供的评论可能含有讽刺，一些评论可能与产品无关，这意味着客户关系、产品分销等可能是需要考虑的重要评论。

我们最初集中研究了**Kajal & Vandana**（2017）提出的方面级情感，首先需要确定论点是否真实或是推测性的。句子级 SA 必须确定句子是否主观，以及句子是否代表积极或消极观点。**Liu**（2012）声称，情感的表达并不总是具有任意性质。然而，文本分类与句子级分类之间并没有根本的区别，因为句子只是简短的文档。**Yu Liang-Chih** 等人（2013）。

在方面级别上，它试图根据人们在评论中用词表达的情感对其进行分类。对于同一产品的不同特征，每个人可能有不同的看法。例如，表述“手机的显示质量很好但电池不耐用。” 这项调查涵盖了前两种情感分析形式。

除了产品评级外，情感分析也适用于资本市场（Hagenau 等，2013）；新闻报道（Kim 等，2018）；以及议会讨论（Graham，2009）。由于海量数据的发展以及每秒交换和生成的数据量的增加，人们对学习、挖掘和分析这些知识的愿望急剧增加。由于标准机器学习技术和神经网络不足以收集这些大数据，深度学习成为大数据时代的关键（Chitkara 等，2019）。

深度学习是机器学习的一门学科，也是神经网络的一种变体。换句话说，在隐藏层之间，标准神经网络是一个具有输入和输出层的单个网络，在其中进行计算，而深度神经网络基本上由多个神经网络组成，其中一个网络的输出是下一个网络的输入，依此类推。

深度学习网络能够自行学习特征，即已经成为一种强大的机器学习技术，能够学习多层数据特征并诱导出预测性能。在信号和信息处理领域的各种应用中，近年来深度学习已经被广泛应用，特别是随着大数据的发展（Zeng 等人，2018）。此外，在情感分析和观点挖掘中，深度学习网络已经被使用。近年来，在许多领域取得了巨大成就。与传统的机器学习方法相比，深度学习不需要人工干预特征；但是，深度学习需要大数据作为支持。深度学习方法可以自动从各种神经网络技术中提取特征，并通过自己的错误改进（Yang 等人，2019）。

在本章中，我们讨论了基于极性的模型，将门循环单元（GRU）与卷积神经网络（CNN）相结合，以及长短期记忆（LSTM）模型。我们开发了一个新颖的模型，使用堆叠嵌入来对亚马逊产品评论进行情感分析，与先前的模型相比，提高了准确性。

在第 12.2 节中，我们讨论了文献综述。然后我们在第 12.3 节中解释了用于情感分析的各种方法。然后在第 12.4 节中，我们介绍了我们为亚马逊产品评论开发的新模型。结果在第 12.5 节中讨论，随后在最后一节总结了本章和未来的研究方向。

## 12.2 文献综述

情感分析的研究是一门研究对客户意见、思想和情感进行分析和分类的领域。目前，关于情感分析技术的研究可以分为三类，即基于机器学习的情感分析技术，基于词典的情感分析技术（Liu 等，2017; Zhou 等，2017），还有一些混合模型。

机器学习策略成功地优化了系统参数，这门系统具有大量的训练数据。在基于词典的方法中，积极和消极的词集用于区分情感，而混合版本则结合了两种模型。在最近的研究中，研究了涉及监督学习模型的机器学习方法（Agarwal 等，2015; Xia 等，2014）半监督学习模型 和无监督学习模型（Guo 等，2017）。其中重点是通过手动或自动过程开发情感词典（Loughran＆Mcdonald，2011）。有关基于词典的情感分析方法的现有文献主要包含基于词典和基于语料库的分类。其中此方法用于识别句法模式并开发一系列表述的词。通过 SVM 模型分析推特数据集中的情感表现被（Ramasamy 等，2021a）分析。

在本评论中，我们使用后者来区分产品的情感，将其划分为积极、中立和消极的，尽管机器学习技术面临许多局限性，但在不同领域，基于词典的情感分析技术显示出了可移植性和稳健性的优势。

### 12.2.1 基于情感词典的情感分析

Jurek 等人（2015）表明，字典中具有极性和情感强度指示的词语在这种方法中被用来从文档中提取情感。基于词典的情感分析算法是由（Ashhar 等人，2017）提出的，使用基于证据的混合特征和情感归一化技术。Ashhar 等人。除了使用情感词汇之外，为了分析在线用户反馈的情感处理，还添加了一些领域特定的修饰词。（Bandhakavi 等人，2017）建议使用基于 DSEL 的单词混合模型（UMM）。情感分类是通过使用标记和粗略标记的情感文本来提取有效特征来完成的。Dhaoui 等人（2017）使用了 LIWC2015 词典的机器学习包，以及 RTextTools 来评估基于词典和机器学习的情感研究过程（Ramasamy 等人，2021b）。为了情感分析任务选择最优的支持向量机超参数值，使用了自然启发式优化方法。Khoo 和 Johnkhan（2018）引入了一个通用情感词典，名为 WKWSCI 情感词典，并通过与现有情感词典（Zhang 等人，2018）进行比较来进行评估。为了测试中文微博文本的情感，使用了不同的情感词典。Keshavarz 和 Abadeh（2017）通过使用语料库和词典的混合来产生自适应情感词汇，以提高微博情感分类的准确性。（Feng 等人，2015）开发了一个两层图模型，使用了不同的表情符号和候选情感术语，并从模型中选择了流行的术语作为情感短语。因此，基于机器学习的会自动生成情感特征的解决方案已成为研究人员的更安全选择，几乎没有人工参与。

### 12.2.2 基于机器学习的情感分析

通过使用基尼指数和支持向量机（SVM）的分类，(Manek 等人 2017) 提出了一种函数提取方法。一种新颖的概率监督联合情感模型（SJSM）由 (Hai 等人，2017) 提出，它接受用户评论数据中的语义情感，但也假设评论数据的总体情感。由 (Singh 等人，2017) 提出了一个与情感分析的多模型联合开发的主题模型。该模型聚焦于用户的个性特征和具有情感影响的单词，使用隐狄利克雷分配（LDA）来确定用户在文字中表达的情感。Huq 等人 2017 研究了评估 Twitter 数据情感的各种算法。Long 等人（2018）使用 SVM 利用包含先前信息的额外样本来识别股票论坛消息。虽然机器学习过程可以自动提取特征，但也依赖于手动选择特征。基于深度学习的策略不需要手动干预。通过神经网络框架，它可以自动选择并提取特征，并且可以从自己的错误中学习。

### 12.2.3 基于深度学习的情感分析

在推特词汇中对语义特征和一些共现特征的定性分析，以及测试情感极性的 n-gram 卷积神经网络的方法参考（Jianqiang 等人，2018）使用了统计特性。Ma 等人（2018）开发了一个模型，使用了目标相关的卷积神经网络，在这个模型中，词汇环绕着目标词，影响着它，以及目标词与其周围词汇之间的距离。如果我们关注过程，句子中的每个词都会对决定句子的极性产生一些情感影响。Ma 等人使用 LSTM 模型开发了一个模型，结合了一些主导特征和一些非主导特征。这需要在输出门处分别注入标记级别的内存。基于回归网络数学理论提出了一种模型（Chen 等人 2018a, b）。Abid 等人开发了一个结合了 CNN 和 RNN 的综合框架（2014）。顾客对他们购买的产品的意见可以通过他们对产品的评论来识别，这可以通过使用情感分析来实现。借助以上观点分析，我们可以利用这一点，制定一些可以纳入业务决策的政策和指导方针。

在 2014 年，刘等人通过程度和标点副词定义了情感强度，并创建了情感特征向量，以通过依赖解析来检验产品评论的情感极性。王等人利用统计和点互信息数据来挖掘和识别新的意义和情感，定义了不同语义层次的情感计算原则，并在 2015 年通过构建情感词典和规则集合来进行中文情感分析，将情感计算纳入其中。刘等人开发了产品与其各种属性之间的关系，还准备了一个模型来匹配词性模式，以提取功能词和描述情感的词，使用领域情感本体。为了基于属性对文本进行分类，用标记的输入训练模型，而这个学习过的模型将预测情感的模式。各种机器学习算法，如最大熵（ME）、朴素贝叶斯和支持向量机（SVM）被用来训练数据，并取得了成果。通过专注于深度学习的技术计算情感词中的情感概率和情感的极性，得出有价值的人工文本信息。

在 2017 年开发的一个产品评论情感分析模型中，研究人员尝试使用卷积神经网络（CNN），并取得了改进的性能（胡等人，2017）。使用 RNN 和 LSTM 开发的特殊模型可以解决 RNN 中梯度值爆炸或梯度消失的问题，相比传统的长短期记忆模型和 RNN 模型多了一个额外的单元。

因此，针对基于 LSTM 的双向编码的电子商务评论情感分析，在本文中开发了一个模型。关于基于方面的情感分析，主要涉及到的任务是提取方面术语、识别方面术语中的极性、识别方面群组和找出方面类别的极性（Hochreiter & Schmidhuber，2017）。作者采用了一种基于词频的方法，该方法将最频繁出现的名词标识并提名为元素。

## 12.3 方法论

在这一部分，我们讨论了基于极性的机制、结合了 CNN 的 GRU 模型、双向 GRU 层和 LSTM 模型用于情感分析。

### 12.3.1 基于极性的机制

这种方法被广泛用于识别用户评论中存在的文本的极性。分类通常分为积极、消极和中性。积极的陈述是指在描述他们购买的产品时包含所有积极词的陈述。消极的陈述是指包含一些带有负面含义的词语的陈述。中性的陈述是指在含义上既不积极也不消极的陈述。

用于该方法的数据集是用户提供的产品评论。产品的评论是从 Python 爬虫中收集的。在数据收集步骤中，确定用于研究的数据集。在这种情况下，考虑了用户在线购买的产品的评论。其次，在预处理步骤中，首先确定句子的边界，经过验证后，将文本中的句子边界标记为单个单词。数据预处理过程还包括删除停用词、删除空格、删除 HTML 标签、删除情感和删除特殊符号。

在分词步骤中，每个单词都应该被赋予一个标记，并且该单词的分数是从名为 SentiWordNet 的库中获取的，基于分配的标记。在词干提取过程中，会删除数据集中存在的相同单词，以确保评论中没有相同单词的重复。最后，进行词性标注。用户提供的评论可能包含使用自然语言工具包（NLTK）标记的不同词性。所有的副词都会从评论中提取出来。之后，必须计算句子的分数和评论的分数，评论中的句子的分数由给定特定句子中存在的单词的分数计算得出。评论的分数可以通过计算评论中存在的句子的分数来计算。

要对一条评论进行分类，必须使用各种副词及其变体进行标记。在标记过程之后，可以获取评论和各种形式的副词。

一旦这些被提取出来，就可以使用 SentiWordNet 合并它们以获得分数。最初，在句子级别，分数也会分配到评论分数的级别。最后，在结束时，获取评论的最终分数，并且使用分类算法对其进行评级为 5 星，其中包括强烈负面、负面、中立、积极和强烈积极。在这里，我们使用了朴素贝叶斯分类器。

### 12.3.2 GRU 结合 CNN

为了在用户在线购买产品的评论中提供高准确率的情感分析，采用了 CNN 和 GRU 的结合模型。最初，使用情感词典对用户提供的特征进行增强。然后，通过 CNN 和 GRU 网络提取情感的主要特征，并使用注意力机制进行权重处理。最后，对加权情感的特征进行分类。模型的结构如图 12.1 所示。该模型由六层组成：嵌入层、卷积层、池化层、Bi-GRU 层、注意力层和全连接层。![../images/504166_1_En_12_Chapter/504166_1_En_12_Fig1_HTML.png](img/504166_1_En_12_Fig1_HTML.png)

图 12.1

结合了 CNN 的 GRU 模型的结构

我们考虑了输入文本，其中包含了语句 S，每个语句 S 由单词组成；因此*S* = {*w*[1], *w*[2], *w*[3], *w*[4]………...*w*[n]}，其中*w*[i]表示语句*S*中的一个词。这里的工作是预测数据集中语句*S*的极性，即在文本中找到语句*S*的极性*P*。情感词典为*S*中的每个词*w*[i]赋予了相应的权重*SW*[i]。为此使用了各种开源情感词典。

首先，我们去掉了一些中性含义的情感词，保留了具有负面和贬义含义的情感词，即极性为 1 和 2 的词语必须保留。根据它们的强度，情感词被分为五组，分别为 1、3、5、7 和 9，情感的权重为情感的严重程度，情感极性为负的词语用-1 乘以情感权重。

构造后的词表达的情感权重如下：

![$$ \mathrm{Senti}\left({w}_{\mathrm{i}}\right)=\Big\{{\displaystyle \begin{array}{cc}{\mathrm{SW}}_{\mathrm{i}},&amp; {w}_{\mathrm{i}}\in \mathrm{SD}\\ {}1,&amp; {w}_{\mathrm{i}}\notin \mathrm{SD}\end{array}} $$](img/504166_1_En_12_Chapter_TeX_Equ1.png)(12.1)其中，*w*[i]表示一个单词，SW[i]表示情感词典中单词*w*[i]的权重，情感词典由 SD 表示。

此模型中的嵌入层将数据集中的语句 S 表示为加权单词的向量矩阵。在这种方法中，使用 BERT 嵌入模型训练单词向量。

*V*[i]是一个 768 维向量，并且使用 BERT 模型，语句*S*中的每个单词*w*[i]都转换为单词向量*V*[i]。随后，使用情感权重，检查单词向量的权重：

![$$ {V}_{\mathrm{i}}^{\prime }={V}_{\mathrm{i}}\ast \mathrm{senti}\left({w}_{\mathrm{i}}\right) $$](img/504166_1_En_12_Chapter_TeX_Equ2.png)(12.2)

嵌入层的输出将是一个由加权单词组成的向量矩阵。在卷积层中，从输入矩阵中提取重要的局部特征。在自然语言处理领域完成了单词向量的完整表示。因此，卷积层中核的宽度占用了整个单词向量的区域。接下来在池化层中，从卷积层获取的文本特征被压缩，提取了主要特征。池化操作分为平均池化和最大池化。在文本的情感分析中，一些短语或词语会对句子产生影响；因此，使用了 k-max 池化。

### 12.3.3 双向门控循环单元（Bi-GRU）层

对于 Bi-GRU 层，从输入矩阵中提取特征是主要任务。循环神经网络的另一种变体是 GRU 模型，该模型通过这种方式处理信息序列。此方法将早期时间点的历史数据影响当前输出以及顺序上下文数据的特征提取结合在一起。在文本数据的句子中，当前单词受到前后单词的影响；因此，Bi-GRU 模型通过处理输入的上下文数据来提取特征。Bi-GRU 模型由处理前向数据的前向 GRU 和处理反向数据的反向 GRU 组成。对于时间*t*的输入文本*x*[t]和由前向 GRU 获得的隐藏状态为*H*[t]′，以及由反向 GRU 获得的隐藏状态为*H*[t]″，它们分别为

![$$ {H}_{\mathrm{t}}^{\prime }=\left({x}_{\mathrm{t}},{H_{\mathrm{t}-1}}^{\prime}\right) $$](img/504166_1_En_12_Chapter_TeX_Equ3.png)(12.3)![$$ {H_{\mathrm{t}}}^{\prime \prime }=\left({x}_{\mathrm{t}},{H_{\mathrm{t}-1}}^{\prime \prime}\right) $$](img/504166_1_En_12_Chapter_TeX_Equ4.png)(12.4)

前向 GRU 和反向 GRU 的组合被认为是时间*t*的输出。在注意力层中，文本中的每个单词对整个句子的情感极性都有重要影响。句子将包含一些对整个文本情感产生部分影响的词，也可能包含一些对该句子情感没有任何贡献的词。因此，利用注意力层，可以为给定句子中的各个词分配各种权重。最后在全连接层中，对输入特征矩阵进行分类。

这一层的输出可以描述如下：

![$$ P=f\left(M\ast X\right)+D $$](img/504166_1_En_12_Chapter_TeX_Equ5.png)(12.5)

其中*f*表示激活 sigmoid 函数，*M*表示权重矩阵，*D*表示偏移量。在此层中，输入特征用区间[0, 1]中的值表示。如果该值接近 0，则表示文本情感极性接近负向，另一方面，如果该值接近 1，则表示句子的极性朝向正极性。

### 12.3.4 长短期记忆

另一个广泛用于情感分析的方法是长短期记忆（LSTM），它是循环神经网络（RNN）架构中的一个独特模型，更专门地用于建模时间序列及其长期依赖性，而不是传统的 RNN。为了解决 RNN 模型提出的问题，可以使用 LSTM。因此，它可用于解决 RNN 中的长期依赖问题以及梯度消失和梯度爆炸的问题。LSTM 网络的灵魂是其单元，它为 LSTM 网络提供了一小部分可以记住过去数据的存储。LSTM 存储单元的结构如图 12.2 所示。LSTM 网络由门组成，其中包括输入门、遗忘门和输出门。LSTM 中的门仅仅是一个 sigmoid 激活函数的函数，这意味着它们输出一个介于 0 和 1 之间的值。在大多数情况下，它将是 0 或 1。LSTM 中门的方程为：![../images/504166_1_En_12_Chapter/504166_1_En_12_Fig2_HTML.png](img/504166_1_En_12_Fig2_HTML.png)

图 12.2

LSTM（长短期记忆）存储单元的结构

![$$ {I}_{\mathrm{t}}=\sigma \left({M}_{\mathrm{i}}\left[{P}_{\mathrm{t}-1},{Q}_{\mathrm{t}}\right]+{Z}_{\mathrm{i}}\right) $$](../images/504166_1_En_12_Chapter/504166_1_En_12_Chapter_TeX_Equ6.png)(12.6)![$$ {G}_{\mathrm{t}}=\sigma \left({M}_{\mathrm{f}}\left[{P}_{\mathrm{t}-1},{Q}_{\mathrm{t}}\right]+{Z}_{\mathrm{f}}\right) $$](../images/504166_1_En_12_Chapter/504166_1_En_12_Chapter_TeX_Equ7.png)(12.7)![$$ {K}_{\mathrm{t}}=\sigma \left({M}_{\mathrm{o}}\left[{P}_{\mathrm{t}-1},{Q}_{\mathrm{t}}\right]+{Z}_{\mathrm{o}}\right) $$](../images/504166_1_En_12_Chapter/504166_1_En_12_Chapter_TeX_Equ8.png)(12.8)其中 *I*[t] 表示输入门，*G*[t] 表示遗忘门，*K*[t] 表示输出门，*σ* 表示 sigmoid 函数，*M*[x] 表示相应门的权重(*x*)，*H*[t-1] 表示前一块的输出（在时间戳 t-1），*Q*[t] 表示当前时间戳的输入，*Z*[x] 表示相应门(*x*)的偏置。

第一个方程用于输入门，给出了将要存储在细胞状态中的新数据的信息。第二个方程用于遗忘门，给出了将要从细胞状态中移除的信息。第三个方程用于输出门，用于提供 LSTM 块在时间“*t*”的最终输出。

我们将给出细胞状态、候选细胞状态和最终输出的方程：

![$$ {C_{\mathrm{t}}}^{\prime }=\tanh \left({M}_{\mathrm{c}}\left[{P}_{\mathrm{t}-1},{Q}_{\mathrm{t}}\right]+{Z}_{\mathrm{c}}\right) $$](../images/504166_1_En_12_Chapter/504166_1_En_12_Chapter_TeX_Equ9.png)(12.9)![$$ {C}_{\mathrm{t}}={G}_{\mathrm{t}}\ast {C}_{\mathrm{t}-1}+{I}_{\mathrm{t}}\ast {C_{\mathrm{t}}}^{\prime } $$](img/504166_1_En_12_Chapter_TeX_Equ10.png)(12.10)![$$ {P}_{\mathrm{t}}={K}_{\mathrm{t}}\ast \tanh \left({C}^{\mathrm{t}}\right) $$](img/504166_1_En_12_Chapter_TeX_Equ11.png)(12.11)其中 *C*[t] 表示时间戳 *t* 处内存中的细胞状态，*C*[t]′ 表示时间戳 *t* 处细胞状态的候选项，*I*[t] 表示输入门，*G*[t] 表示遗忘门，*K*[t] 表示输出门，*M*[c] 表示各门（*x*）的权重，*P*[t-1] 表示前一个块的输出（在时间戳 t-1 处），*Q*[t] 表示当前时间戳处的输入，*Z*[c] 表示各门（*x*）的偏置。

在时间“*t*”使用上述方程，可以看到细胞状态将具有应该忘记的前一状态的信息以及需要从当前时间“*t*”考虑的信息。最后，细胞状态需要经过滤波，然后必须通过激活函数，该函数会预测 LSTM 当前单元在时间“*t*”的输出的哪一部分应该出现。然后，LSTM 当前块的输出传递到 Softmax 层，以获得从当前 LSTM 块预测的输出。

## 12.4 案例研究

在本节中，我们讨论了关于亚马逊产品评论的案例研究。首先，我们描述了数据集，然后在接下来的部分中，解释了用于亚马逊产品评论情感分析的新模型。

### 12.4.1 数据集

我们使用的数据集来自 Kaggle 网站。我们考虑了用户对产品的评分，评分范围从 1 到 5。对产品评分为 3–5 的评论被视为积极的评论，而对产品评分为 1–2 的评论被视为消极的评论。然后我们对数据集进行手动筛选，以确保正面数据集下的评论都是积极的，负面数据集下的评论都是消极的。我们的数据集总共有 3000 条记录。其中 1500 条是积极的评论，另外 1500 条是消极的评论。我们将这个数据集分成了两部分。数据集中 70% 的记录，即 2100 条记录，用于训练模型，数据集中 30% 的记录，即 900 条记录，用于测试模型。

所开发的新模型的架构如图所示。12.3![../images/504166_1_En_12_Chapter/504166_1_En_12_Fig3_HTML.png](img/504166_1_En_12_Fig3_HTML.png)

图 12.3

使用堆叠嵌入的模型架构

该架构由预处理单元、嵌入层和带有注意力层的双向 GRU 模型组成。

### 12.4.2 数据预处理

我们的语料库存在不干净的数据，因此在将其作为模型的输入之前，我们对其进行了清理。在清理过程中，我们删除了所有冗余数据和空数据，并删除了所有 HTML 字符。我们的数据集包含一些复杂的符号，我们对其进行解码并清楚地解释了这些内容，删除了所有标点符号，并删除了所有停用词。然后将清理后的数据输入到分词器进行分词；我们使用了来自 SK 库的 Natural Language Toolkit (NLTK) 分词器进行分词。此外，分词后的数据会被送入嵌入器进行嵌入。

### 12.4.3 堆叠嵌入

我们在实验中使用了两种基于上下文的嵌入方法，如 BERT 和 GloVe，借助 Flair Library 的帮助。"BERT-base-uncased" 的嵌入维度为 768，GloVe 的向量维度为 100，分别是 BERT 和 GloVe 的基本选项模板。生成的嵌入被作为输入提供给 Bi-GRU 模型。

下一步，嵌入层的输出被提供给双向 GRU 模型。该模型利用前一步和下一步的知识来预测当前状态。在我们的实验中，我们使用了三个隐藏层大小分别为 120、60 和 30 的 Bi-GRU。第三层的输出被传递给注意力层。注意力层根据情感对每个词的影响分配不同的权重。可能有些词对任何词的情感都没有贡献，或者它们的影响较小。基于此，必须分配权重。注意力层的输出再次通过密集层传递以降低维度。最后，密集层的输出被传递给一个 Sigmoid 层，以将我们的语料库分类为正类或负类。我们模型的发现见下一节。

## 12.5 结果

我们提出的模型的研究结果表明，我们的模型准确率为 95.32%，F1 分数为 95%。此外，我们尝试通过使用 k 折交叉验证来提升模型性能。结果表明，使用 k 折交叉验证的模型性能略有提高。这里使用了十折交叉验证。表 12.1 展示了结果。表 12.1

模型的 F1 分数和准确率

| 准确率 | F1 分数 | 十折交叉验证 |
| --- | --- | --- |
| 准确率 | F1 分数 |
| --- | --- |
| 95.32% | 95.10% | 95.92% | 95.89% |

我们试图探索迭代次数和辍值对我们模型输出的影响。我们发现，在辍值为 0.4 的情况下，我们的模型在八次迭代时达到最大效率。后续输出将继续下降。表 12.2 和 12.3 展示了迭代次数和辍值对我们模型输出的影响。表 12.2

模型中迭代次数的影响

| 迭代 | 准确率 | F1 |
| --- | --- | --- |
| 3 | 95.3% | 95.1% |
| 5 | 95.5% | 95.2% |
| 8 | 95.9% | 95.8% |
| 10 | 95.3% | 95.2% |
| 12 | 95.0% | 95.1% |
| 15 | 94.6% | 94.5% |

表 12.3

模型中辍值的影响

| 辍值 | 准确率 | F1 |
| --- | --- | --- |
| 0.2 | 95.1% | 95.1% |
| 0.4 | 95.8% | 95.6% |
| 0.5 | 95.5% | 95.2% |
| 0.6 | 95.5% | 95.5% |
| 0.8 | 94.7% | 94.8% |

模型的准确率被计算为 95.32%。该模型比使用其他算法生成的模型更准确。Flair 库开发的堆叠嵌入的新颖性为研究结果的准确性做出了贡献。

## 12.6 结论

随着在线商务平台的巨大增长，情感分析对用户评价的产品具有重要意义。在本文中，我们采用堆叠嵌入的模型对亚马逊产品评论进行情感分析。首先，解释了各种方法，如基于极性的情感分类、长短期记忆（LSTM）和双向 GRU 模型。考虑到案例研究，我们开发了一个模型，其中将亚马逊产品评论专门作为案例研究，因为它是一个流行的电子商务平台。我们开发了一个堆叠嵌入模型，其中使用 Flair 库来实现 GloVe 和 BERT 嵌入模型。然后，双向 GRU 模型用于提取评论文本句子中的情感特征。然后在注意层，根据其在每个词上的情感贡献分配不同的权重。然后将这些通过稠密层传递给 sigmoid 层。利用 sigmoid 函数，该模型通过将值分配为 0 或 1 将评论的语句分类为积极或消极。考虑了一个包含 3000 个样本的数据集，对于该数据集，我们的模型相对于其他模型获得了最高的准确性。随着提供给模型的数据集增加，它将实现持续改进的准确性。我们开发的模型可用于情感分析的各种应用。

为了满足对情感分析更高级别细化要求的领域，必须进一步研究情感的细腻程度。
