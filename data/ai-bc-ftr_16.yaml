- en: © The Author(s), under exclusive license to Springer Nature Switzerland AG 2021Y.
    Maleh et al. (eds.)Artificial Intelligence and Blockchain for Future Cybersecurity
    ApplicationsStudies in Big Data90[https://doi.org/10.1007/978-3-030-74575-2_13](https://doi.org/10.1007/978-3-030-74575-2_13)
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: © 作者（s），独家许可给Springer Nature Switzerland AG 2021Y. Maleh et al. (eds.)Artificial
    Intelligence and Blockchain for Future Cybersecurity ApplicationsStudies in Big
    Data90[https://doi.org/10.1007/978-3-030-74575-2_13](https://doi.org/10.1007/978-3-030-74575-2_13)
- en: A Framework Using Artificial Intelligence for Vision-Based Automated Firearm
    Detection and Reporting in Smart Cities
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一种使用人工智能进行视觉火器检测和报告的框架
- en: 'Muhammad Hunain^([1](#Aff7) [ ](#ContactOfAuthor1)), Talha Iqbal^([1](#Aff7) [ ](#ContactOfAuthor2)),
    Muhammad Assad Siyal^([1](#Aff7)), Muhammad Azmi Umer^([2](#Aff8) [ ](#ContactOfAuthor4))
    and Muhammad Taha Jilani^([3](#Aff9) [ ](#ContactOfAuthor5))(1)DHA Suffa University,
    Karachi, Pakistan(2)DHA Suffa University, and KIET Karachi, Karachi, Pakistan(3)Karachi
    Institute of Economics and Technology, Karachi, PakistanMuhammad HunainEmail:
    [Hunain@techonventures.com](mailto:Hunain@techonventures.com)Talha IqbalEmail:
    [Talha@techonventures.com](mailto:Talha@techonventures.com)Muhammad Azmi Umer (Corresponding
    author)Email: [azmi.umer@dsu.edu.pk](mailto:azmi.umer@dsu.edu.pk)Muhammad Taha JilaniEmail:
    [m.taha@pafkiet.edu.pk](mailto:m.taha@pafkiet.edu.pk)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'Muhammad Hunain^([1](#Aff7) [ ](#ContactOfAuthor1)), Talha Iqbal^([1](#Aff7) [ ](#ContactOfAuthor2)),
    Muhammad Assad Siyal^([1](#Aff7)), Muhammad Azmi Umer^([2](#Aff8) [ ](#ContactOfAuthor4))
    和 Muhammad Taha Jilani^([3](#Aff9) [ ](#ContactOfAuthor5))(1)巴基斯坦卡拉奇DHA Suffa大学(2)巴基斯坦卡拉奇DHA
    Suffa大学，卡拉奇KIET Karachi(3)巴基斯坦卡拉奇Karachi Institute of Economics and TechnologyMuhammad HunainEmail:
    [Hunain@techonventures.com](mailto:Hunain@techonventures.com)Talha IqbalEmail:
    [Talha@techonventures.com](mailto:Talha@techonventures.com)Muhammad Azmi Umer (通讯作者)Email:
    [azmi.umer@dsu.edu.pk](mailto:azmi.umer@dsu.edu.pk)Muhammad Taha JilaniEmail:
    [m.taha@pafkiet.edu.pk](mailto:m.taha@pafkiet.edu.pk)'
- en: Abstract
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: For a few decades, mega-cities are facing some huge challenges. Among them,
    the prevention of crime seems to be more challenging than others. The safety of
    citizens in the dense urban population with conventional practices are unable
    to control the increasing crime rate. This work is aimed to develop a framework
    for the autonomous surveillance of public places, with visual-based handheld arms
    detection in a near real-time. It scans all the objects that come in front of
    the camera and when any type of weapon comes in contact with a lens it gives an
    alert, locks that object and the person holding it and identifies the person using
    facial recognition. If the alert does not get responded in a few minutes, the
    system will automatically notify the 3rd person or agency about the incident.
    It can also manually highlight any object in a frame to keep track of its movement
    for security purposes. Machine and Deep Learning techniques were used to train
    models for object detection and facial recognition. The model achieved an accuracy
    of 97.33% in object detection and 90% in facial recognition.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 几十年来，超大城市面临着一些巨大的挑战。其中，犯罪预防似乎比其他挑战更具挑战性。在人口密集的城市中，传统做法无法控制犯罪率的增长。本文旨在开发一个框架，用于自主监视公共场所，在几乎实时的视觉基础上检测手持武器。它扫描摄像头前出现的所有物体，当任何类型的武器与镜头接触时，会发出警报，锁定该物体和持有它的人，并使用面部识别来识别该人。如果警报在几分钟内得不到回应，系统将自动通知第三方或机构有关事件。它还可以手动突出显示框架中的任何对象，以跟踪其运动以进行安全目的。使用机器学习和深度学习技术训练了用于对象检测和面部识别的模型。该模型在对象检测方面的准确率为97.33%，在面部识别方面的准确率为90%。
- en: 1 Introduction
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Over the past few decades, various urban areas within developing countries have
    experienced a growing population and rural-to-urban migration rate. It is estimated
    that nearly half the population of the world is now living in the cities [[1](#CR1)],
    now making them mega-cities which can be seen by World Economic Forum (WEF) reports’
    statistics in Fig. [1](#Fig1). This rapid transition has presented many challenges,
    including risks to the immediate and surrounding environment, to natural resources,
    to health conditions, to social cohesion, and individual rights [[2](#CR2)]. The
    later has introduced the safety and security concerns for the citizens living
    in a megacity. Similarly, for governments and administrative agencies, one of
    the most important consideration is to monitor and control the criminal activities.
    Table [1](#Tab1) has described the number of incidences and crime rates in major
    cities of India.![../images/507793_1_En_13_Chapter/507793_1_En_13_Fig1_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Fig1_HTML.png)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几十年里，发展中国家内的各个城市地区都经历了人口增长和农村向城市的迁移率不断增长。据估计，全球近一半人口现在居住在城市里 [[1](#CR1)]，这些城市现在被认为是巨型城市，这可以从世界经济论坛（WEF）报告的统计数据中看出，见图 [1](#Fig1)。这种迅速的转变带来了许多挑战，包括对当地和周边环境的风险，对自然资源的风险，对健康状况的风险，对社会凝聚力的风险，以及对个人权利的风险 [[2](#CR2)]。后者为生活在巨型城市中的公民带来了安全和安全方面的担忧。同样，对于政府和行政机构来说，最重要的考虑之一是监测和控制犯罪活动。表格 [1](#Tab1)
    描述了印度主要城市的事件数量和犯罪率。![../images/507793_1_En_13_Chapter/507793_1_En_13_Fig1_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Fig1_HTML.png)
- en: Fig. 1
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1
- en: Urban population growth [[3](#CR3)]
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 城市人口增长 [[3](#CR3)]
- en: Table 1
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 1
- en: Incidences and crime rates in mega cities [[4](#CR4)]
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 巨型城市的事件数量和犯罪率 [[4](#CR4)]
- en: '| Year | No. of incidence | Crime rate |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| 年份 | 事件数量 | 犯罪率 |'
- en: '| --- | --- | --- |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 2009 | 8,91,576 | 826.5 |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 2009 | 8,91,576 | 826.5 |'
- en: '| 2010 | 11,19,621 | 1037.8 |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 2010 | 11,19,621 | 1037.8 |'
- en: '| 2011 | 11,49,059 | 713.2 |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 2011 | 11,49,059 | 713.2 |'
- en: '| 2012 | 11,03,858 | 685.2 |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 2012 | 11,03,858 | 685.2 |'
- en: '| 2013 | 12,03,514 | 748.8 |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 2013 | 12,03,514 | 748.8 |'
- en: In conventional practice, such issues are addressed by using CCTV based surveillance
    and monitoring only. However, current developments in ICT have opened new opportunities
    to develop some intelligent methods for effective control and monitoring of crime.
    Over the past few years, some topics have been top in research areas in computer
    technological era. Those are detection, tracking, and understanding the moving
    objects to prevent crime. Similarly, Intelligent visual surveillance system (IVSS)
    are one of the surveillance system that refers to automate visual monitoring process
    involving interpretation and analysis of object detection and behavior, also the
    tracking of that object to understand the current scene of that visual events.
    Two main tasks that are highly focused are discussed in [[5](#CR5)] i.e. scene
    anomaly and large area surveillance control. All detection and tracking of moving
    objects in a sequence and behavior analysis are in scene interpretation. The control
    task multiple cameras are to tackle captured or fixed objects which are in motion
    in a wide-area surveillance.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统做法中，这些问题仅通过基于闭路电视的监视和监控来解决。然而，信息技术的当前发展已经为开发一些智能方法以有效控制和监控犯罪打开了新的机会。在过去几年中，一些话题在计算机技术时代的研究领域备受关注。这些是检测、跟踪和理解移动物体以预防犯罪。同样，智能视觉监视系统（IVSS）是涉及自动化视觉监视过程的一种监视系统，包括对目标检测和行为的解释和分析，以及对该目标的跟踪以了解该视觉事件的当前场景。两个主要关注的任务讨论在 [[5](#CR5)]，即场景异常和大范围监控。所有移动对象的检测和跟踪以及行为分析都在场景解释中。控制任务是处理多个摄像头拍摄或固定物体在广域监控中移动的物体。
- en: Detection of moving objects is a hectic task as well as it is an important task
    for any video surveillance system. Secondly, tracking is required in upper-level
    applications after detection because it requires the location and shape of objects
    in every camera region or frame via detection algorithm [[6](#CR6)]. A video surveillance
    might embody a minimum of one sensing unit capable of being operated in a very
    scanning mode and a video process unit coupled to the sensing unit, the video
    process unit to receive and method image information from the sensing unit and
    to find scene events and target activity [[7](#CR7)]. Similarly, a system proposed
    in [[8](#CR8)], which was mostly based on hardware devices like motion sensors,
    light sensors, alarms, etc. It detects the anomaly and reports the user through
    push notification on any handheld device like a mobile or laptop.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 检测移动物体是一项繁重的任务，也是任何视频监控系统的重要任务。其次，在检测后，跟踪在上层应用中是必需的，因为它需要通过检测算法在每个摄像机区域或帧中找到对象的位置和形状[[6](#CR6)]。视频监控可能包含至少一个能够以扫描模式运行的传感器单元和与传感器单元耦合的视频处理单元，视频处理单元接收和处理来自传感器单元的图像信息，并查找场景事件和目标活动[[7](#CR7)]。同样，一种在[[8](#CR8)]提出的系统，主要基于硬件设备如运动传感器、光传感器、警报等。它检测异常并通过推送通知报告用户，可以在手机或笔记本电脑等任何手持设备上实现。
- en: The campus security system was proposed in [[9](#CR9)]. This system is consist
    of a school gate state monitor, an entrance guide terminal and a base station,
    in this system entrance gate terminal monitors the presence of entrance guard
    or check whether the guard is on duty or not in the campus. Second is the school
    gate state monitor which monitors the state of the gate whether it is open or
    close. Third is a base station which receives information from the entrance guide
    terminal and school gate state monitor and generate alarm signals when the entrance
    guard is missing and the school gate is opened. This campus security system can
    monitor in real-time and can alert when detects an anomaly, which helps to improve
    the security system of the campus.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 校园安全系统是在[[9](#CR9)]提出的。该系统由校门状态监控器、入口指引终端和基站组成，在这个系统中，入口门终端监控校园内是否有门卫或检查门卫是否值班。其次是校门状态监控器，监控门的状态是否开启或关闭。第三个是基站，它接收来自入口指引终端和校门状态监控器的信息，并在门卫缺失且校门打开时生成警报信号。这个校园安全系统可以实时监控并在检测到异常时发出警报，有助于提高校园安全系统的安全性。
- en: As the violent criminals, burglars and intruders have become so dangerous for
    the properties and lives of people. Protection and security for households become
    a necessity. Anti-Intruder Monitoring and Alarm [[10](#CR10)] with the purpose
    to help homeowners and make them informed about criminals and alarm triggering
    decisions. The alarm system uses images and locations of sensed motion and offers
    the option of allowing multiple key holders to receive security alerts via cellular
    network short message service (SMS). The alarm system also gives the option of
    sending distress messages to the police or trusted neighbors. The security system
    can be easily controlled by using a mobile device or remote control. The algorithm
    of this system has been designed simply and made the probability of false alarms
    almost non-existence.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 随着暴力犯罪分子、入室盗窃者和闯入者对人们的财产和生命变得越来越危险，家庭的保护和安全成为必需。防入侵监控和报警[[10](#CR10)]的目的是帮助业主并使他们了解犯罪分子和报警触发决定。报警系统利用感测到的运动的图像和位置，并提供了允许多个钥匙持有人通过蜂窝网络短信服务（SMS）接收安全警报的选项。该报警系统还提供了向警方或可信邻居发送求救信息的选项。安全系统可以通过使用移动设备或遥控器轻松控制。该系统的算法设计简单，几乎消除了误报的可能性。
- en: 'According to the research carried out, there is no such application/software
    which is capable of doing surveillance and as well as identifying objects and
    people in real-time. Some products have some similarities in terms of facial recognition,
    data extraction, object detection, notifying 3rd party or security agency and
    generate an alarm system. But no one is completely satisfied by implementing all
    functionalities mentioned above in a single program as in the proposed system.
    These are the aspect that lead to this system an upend over previously launched
    products. Rest of the chapter is organized as follows: Sect. [2](#Sec2) is an
    overview of the related work. Section [3](#Sec3) has described the methodology.
    Section [4](#Sec12) has discussed the experimental evaluations and results, while
    Sect. [5](#Sec15) has discussed the conclusion and possible future work.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 根据进行的研究，还没有一款能够在实时进行监视的同时识别物体和人物的应用程序/软件。一些产品在面部识别、数据提取、物体检测、通知第三方或安全机构和生成报警系统方面具有一些相似之处。但是没有人通过在单个程序中实现上述所有功能来完全满意，就像在所提出的系统中一样。这些是导致该系统超越先前推出的产品的因素。本章的其余部分安排如下：第[2](#Sec2)节是相关工作的概述。第[3](#Sec3)节描述了方法。第[4](#Sec12)节讨论了实验评估和结果，而第[5](#Sec15)节讨论了结论和可能的未来工作。
- en: 2 Related Work
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: In today’s modern life there is an increasing interest in the precautionary
    and protective measures in the world and private space of social welfare. Therefore,
    there is a need to look for the surveillance arrangement to provide a safe and
    sound environment for the citizens. Currently, technologies like cameras, sensors,
    microphones, and detectors are being used. Trespasser detection is the new increasing
    demand in the commercial and private sectors. However, it is difficult to eradicate
    the concept of using these technologies without being detected. Hence looking
    at this flaw [[11](#CR11)] proposed the idea of a multi-sensor intelligent system
    that can operate on the principle of entropy from several sources to find the
    danger or any internet breach. Therefore they developed a generic ontology that
    allowed the integration of all the input heterogeneous knowledge in a homogeneous
    way.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今现代生活中，对社会福利领域的世界和私人空间中的预防和保护措施越来越感兴趣。因此，有必要寻找监视安排，为公民提供一个安全和良好的环境。目前，像摄像头、传感器、麦克风和探测器这样的技术正在被使用。入侵者检测是商业和私人部门的新增需求。然而，要在不被察觉的情况下根除使用这些技术的概念是困难的。因此，针对这一缺陷提出了一个多传感器智能系统的概念，该系统可以根据来自多个来源的熵原理来查找危险或任何互联网侵犯。因此，他们开发了一个通用本体论，允许以同质化的方式集成所有输入的异构知识。
- en: Handheld gun detection was performed in [[12](#CR12)]. They used Convolutional
    Neural Network (CNN) to detect guns from cluttered scenes. They particularly used
    Deep Convolution Network (DCN) through transfer learning. The model was evaluated
    on a benchmark Internet Movie Firearms Database (IMFDB). Similarly, CNN has been
    used in [[13](#CR13)] for gun detection. They got training accuracy of 93% and
    testing accuracy of 89%. Gun detection was also performed in [[14](#CR14)] using
    color-based segmentation. They used k-means clustering to omit objects other than
    the weapons from the images. Harris interest point detector and Fast Retina Keypoint
    (FREAK) were used to locate the weapons in the segmented images.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[12](#CR12)]中进行了手持枪械检测。他们使用卷积神经网络（CNN）从混乱的场景中检测枪支。他们特别使用了深度卷积网络（DCN）进行迁移学习。该模型在基准互联网电影枪支数据库（IMFDB）上进行了评估。类似地，CNN在[[13](#CR13)]中用于枪械检测。他们获得了93%的训练精度和89%的测试精度。还在[[14](#CR14)]中使用基于颜色的分割进行了枪械检测。他们使用k均值聚类来从图像中排除除武器以外的对象。Harris兴趣点检测器和快速视网膜关键点（FREAK）用于定位分割图像中的武器。
- en: Nowadays home security and its safety become one of the biggest concerns for
    homeowners. Leveraging audio/video recording and communication devices provides
    methods for information about crime. An approach was proposed in [[15](#CR15)],
    which includes a method of comprising, a method of receiving from an audio/video
    recording, and a communication device. It has a first alert signal and a first
    video signal, the first video signal including images captured by a camera of
    the A/V recording and communication device, transmitting to a client device, in
    response to receiving the first alert signal and the first video signal, a second
    alert signal and a second video signal, the second video signal including the
    images captured by the camera of the A/V recording and communication device, receiving
    a report signal from the client device; It work on the images captured by the
    camera of the A/V recording and communication device, that a crime may have been
    committed, posting an offer of a reward for information about the crime.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，家庭安全及其安全性已成为业主最大的关注之一。利用音频/视频记录和通信设备提供了有关犯罪信息的方法。在[[15](#CR15)]中提出了一种方法，包括一种从音频/视频记录接收的方法和一种通信设备的方法。它具有第一个警报信号和第一个视频信号，其中第一个视频信号包括由A/V记录和通信设备的摄像头捕获的图像，将第一个警报信号和第一个视频信号传输到客户设备，在收到第一个警报信号和第一个视频信号的响应中，第二个警报信号和第二个视频信号，第二个视频信号包括由A/V记录和通信设备的摄像头捕获的图像，从客户设备接收报告信号；它在A/V记录和通信设备的摄像头捕获的图像上工作，可能已经发生了犯罪，发布有关犯罪信息的奖励。
- en: An intelligent visual surveillance system has been proposed in [[16](#CR16)]
    with the help of cameras attached in the network to observe the people and vehicles.
    The system modules are proposed to perform critical works like the management
    of cameras, tracking objects, recognition of people via biometric technology,
    monitoring the crowd to catch anomaly. Similarly, [[17](#CR17)] is also based
    on the video surveillance system in which the system uses metadata rule for analyzing
    and exchange of information between intelligent video surveillance system that
    analyzes the required data through streaming on camera. The metadata rule is just
    to enhance the indexing method by indexing a large database and collaboratively
    searches and manages the integrated security environment more accurately and efficiently.
    The system focused on both high-level and low-level context to utilize metadata
    as a raw back source for security system services. Physical sensors (metal detector,
    cameras, scanners) in public areas are for the low-level context of the system.
    The situation is being captured in the high-level context-aware system by analyzing
    the context data coming through sensors in the low-level system. The system also
    provides the tracking system by moving an object in the field of view called FOVs.
    The system also supports real-time tracking of moving objects by tilting, panning
    and zooming in FOVs.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[16](#CR16)]提出了一种智能视觉监控系统，该系统利用网络中附加的摄像头观察人员和车辆。系统模块旨在执行关键任务，如摄像头管理、物体跟踪、通过生物识别技术识别人员、监控人群以捕捉异常。类似地，[[17](#CR17)]也基于视频监控系统，该系统使用元数据规则来分析和交换智能视频监控系统之间的信息，该系统通过在摄像头上流式传输来分析所需数据。元数据规则只是通过索引大型数据库并协作搜索和更准确、更有效地管理集成安全环境来增强索引方法。系统侧重于高级和低级上下文，以利用元数据作为安全系统服务的原始后备源。公共区域中的物理传感器（金属探测器、摄像头、扫描仪）属于系统的低级上下文。通过分析低级系统中传感器传递的上下文数据来捕获高级上下文感知系统中的情况。系统还通过移动视野中的对象提供跟踪系统，称为FOV。系统还支持通过FOV的倾斜、旋转和缩放实时跟踪移动对象。
- en: The digital surveillance system is pre-install by the ubiquitous approach and
    generates a huge amount of video streaming and other data as well. The development
    of the cloud environment has empowered to deploy intelligent video surveillance
    technologies through Web Services to enhance public security. The introduction
    of the novel system and the combination of cloud computing techniques with the
    automatized license plate recognition engines have been discussed in [[18](#CR18)].
    Its approach was to analyze big data to detect as well as to keep track of a target
    vehicle in a city with a license plate number issued to vehicles. Likewise, [[19](#CR19)]
    has discussed the reviews about the recent development techniques of relevant
    technologies like pattern recognition and computer vision. They have discussed
    the multi-camera tracking, topologies of computing with integrated cameras, multi-level
    frames object detection and tracking, identification and some sort of re-identification,
    and both static and active cameras’ cooperative video security. The detailed explanation
    of the technical aspect used by these terminologies and comparison of pros and
    cons between different approaches for solution has been provided. It mainly focuses
    on the connection and integration of different modules within the application.
    They have also focused on improving the efficiency, accuracy, and complexity.
    An intelligent video surveillance system (IVSS) has also been proposed in [[20](#CR20)]
    by having a functionality detection and identification of anomaly and alarming
    situations by sensing the moving objects. The main motive of this system design
    was to reduce video processing and transmission, therefore, allowing a huge number
    of cameras deploying on the system to satisfy its usage as a security solution
    with safety integration in smart cities. Here alarming and detection were performed
    based on moving objects using the feature parameters of performed detection results
    and also using ontologies and semantic reasoning.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 数字监控系统是通过无处不在的方式预先安装的，并产生大量视频流和其他数据。云环境的发展使得通过 Web 服务部署智能视频监控技术成为可能，以增强公共安全。在[[18](#CR18)]中讨论了新系统的引入以及将云计算技术与自动化车牌识别引擎相结合的方法。其方法是分析大数据以便在城市中检测并跟踪具有车牌号的目标车辆。同样，在[[19](#CR19)]中讨论了与模式识别和计算机视觉等相关技术的最新发展技术的评论。他们讨论了多摄像头跟踪、计算机与集成摄像头的拓扑结构、多级帧对象检测和跟踪、识别和某种重新识别，以及静态和主动摄像头的合作视频安全。对这些术语使用的技术方面进行了详细的解释，并提供了不同解决方案之间的优缺点比较。其主要侧重于应用程序内不同模块的连接和集成。他们还着重于提高效率、准确性和复杂性。智能视频监控系统（IVSS）也在[[20](#CR20)]中提出，通过具有功能检测和通过感知移动物体来识别异常和警报情况。该系统设计的主要动机是减少视频处理和传输，从而允许在系统上部署大量摄像头，以满足其作为安全解决方案在智能城市中的使用。这里的警报和检测是基于移动物体的特征参数，使用执行的检测结果、本体和语义推理进行的。
- en: Threat-detection in a distributed multi-camera surveillance system was proposed
    in [[21](#CR21)]. They observed the threats by analyzing the motion of an object
    in software installed at the first camera then detection of a suspicious object
    at the camera when motion of the object does not match to a motion flow model
    at the first camera. Then the tracking process is being entertained from the first
    frame to the second camera frame based upon the suspicious detection of objects.
    Just like the first camera, the second camera processing for detection is being
    done via the same software installed in it. As the first camera and assigned threat
    scores aside when motion of the object does not match to a motion flow model at
    the second camera, like the initial one and finally generating an alarm based
    on part of the threat scores detected at these frames of cameras and notifying
    the authorities.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[21](#CR21)]中提出了分布式多摄像头监视系统中的威胁检测。他们通过分析第一个摄像头安装的软件中物体的运动来观察威胁，然后在第一个摄像头检测到可疑物体时，检测到物体的运动与第一个摄像头的运动流模型不匹配。然后基于可疑物体的检测，从第一个帧到第二个摄像头帧进行跟踪过程。就像第一个摄像头一样，第二个摄像头的检测处理也是通过安装在其中的相同软件进行的。当物体的运动与第二个摄像头的运动流模型不匹配时，就像初始的那样，第一个摄像头和分配的威胁分数一样，最终基于在这些摄像头帧上检测到的部分威胁分数生成警报，并通知当局。
- en: The security system has been used for safety for homes and other areas greatly.
    The security system proposed in [[22](#CR22)] consists of a main automatic circuit
    which have motions detector for activating an audible alarm and provides further
    detections to identify criminals and crime. It has an emergency light flasher
    which is manually activated by the user. It provides an inside home control panel.
    Inside the home control panel also responds to remote manually. This system has
    been used more effectively that easily terminate possible home invasion or robbery.
    This system also enhances safety and security.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 安全系统在家庭和其他区域的安全方面得到了广泛应用。[[22](#CR22)]提出的安全系统由一个主自动电路组成，该电路具有用于激活可听报警器并提供进一步检测以识别罪犯和犯罪的运动检测器。它还具有用户手动激活的紧急灯闪光器。它提供了一个内部家庭控制面板。家庭控制面板还会对远程手动作出响应。这个系统被更有效地使用，可以轻松终止可能发生的入室抢劫。这个系统还增强了安全性和保障。
- en: An intelligent image processing method for the video surveillance systems was
    proposed in [[23](#CR23)]. It includes a technology of tracking and detecting
    multiple moving objects, which can be easily applied to business and home surveillance
    systems consisting of a network video recorder (NVR) and internet protocol (IP)
    camera. It also provides the easiest way for detection and tracking, in which
    it uses the red-green-blue (RGB) color background modeling with a sensitivity
    parameter to extract moving regions, the blob-labeling to group moving objects
    and the morphology to eliminate noises. If it comes to the tracking of the fast-moving
    object then this method can define the direction as well as the velocity of the
    group formed by the objects which are in motion.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[23](#CR23)]中提出了一种用于视频监控系统的智能图像处理方法。它包括一种跟踪和检测多个移动物体的技术，可以轻松应用于由网络视频录像机（NVR）和互联网协议（IP）摄像机组成的企业和家庭监控系统。它还提供了最简单的检测和跟踪方法，其中它使用红绿蓝（RGB）颜色背景建模与灵敏度参数来提取移动区域，使用斑点标记来分组移动物体，并使用形态学来消除噪声。如果涉及快速移动物体的跟踪，那么这种方法也可以定义由运动中的物体组成的群体的方向和速度。
- en: An intelligent video/sound analysis and ID database framework was proposed in [[24](#CR24)].
    It may define a security zone or gathering of zones. The framework may distinguish
    vehicles and people entering or leaving the zone through picture acknowledgement
    of the vehicle or individual when compared with prerecorded data available in
    a database. The framework may alarm the security workforce as to warrants or other
    data found relating to the perceived vehicle or individual coming out because
    of a database seek. The framework may analyze pictures of a presume vehicle, for
    example, an undercarriage picture to standard vehicle pictures recorded in the
    database. The framework may additionally take in the standard occasions and areas
    of vehicles or people followed by the framework and to make security workforce
    ready upon deviation from standard movement.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[24](#CR24)]提出了一种智能视频/音频分析和识别数据库框架。它可以定义安全区域或区域集合。通过将车辆或人员的图像与数据库中可用的预先录入数据进行比较，该框架可以区分进入或离开区域的车辆和人员。当有关数据库搜索结果的拘捕或其他信息与识别的车辆或人员相关时，该框架可以向安全人员发出警报。该框架可以分析嫌疑车辆的图像，例如车辆底盘图像与数据库中记录的标准车辆图像。该框架还可以学习系统跟踪的车辆或人员的标准事件和位置，并在偏离标准运动时提醒安全人员。
- en: Parallel execution of an ongoing canny video surveillance system on Illustrations
    Preparing Unit (GPU) was portrayed in [[25](#CR25)]. The system depends on foundation
    subtraction and made out of movement detection, camera attack detection (moved
    camera, out-of-center camera, and secured camera discovery), surrendered object
    detection, and object tracking algorithms. As the calculation algorithms have
    diverse qualities, their GPU executions have distinctive acceleration rates. Test
    results demonstrate that when all the available algorithms run simultaneously,
    parallelization in GPU influences the system to up to 21.88 times quicker than
    the central processing unit partner, empowering real-time analysis of a higher
    number of cameras.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[25](#CR25)]描述了一个在图形处理单元（GPU）上实现实时智能视频监控系统的并行执行。该系统基于背景减除，并由运动检测、摄像机攻击检测（移动摄像机、失焦摄像机和被覆盖的摄像机检测）、遗弃物体检测和物体跟踪算法组成。由于算法的不同特性，它们在GPU上的执行具有不同的加速率。测试结果表明，当所有可用算法同时运行时，GPU上的并行化使系统速度比中央处理单元快高达21.88倍，从而实现对更多摄像机的实时分析。
- en: 3 Methodology
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 方法论
- en: Machine and Deep Learning techniques were used to train models for object detection
    and facial recognition. Further Transfer Learning was performed on the inception
    R-CNN V2 dataset. Extra layers were added to identify the weapon. Facial Identification
    was performed using the inception Haar Cascade Frontal Face dataset while Recognition
    was done using the MTCNN method. Object Locking was done using OCF-CRS algorithm.
    Data Extraction from social media was done using jsoup while the 3rd party notification
    was implemented using Twilio SMS. The complete GUI built in python using PyQt
    v4.11\. The comparison of the proposed system with existing work is described
    in Table [2](#Tab2).Table 2
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 使用机器学习和深度学习技术训练模型进行物体检测和人脸识别。在 Inception R-CNN V2 数据集上执行了进一步的迁移学习。额外的层被添加以识别武器。人脸识别使用
    Inception Haar Cascade Frontal Face 数据集进行，而识别则使用 MTCNN 方法进行。使用 OCF-CRS 算法进行对象锁定。从社交媒体中提取数据使用
    jsoup，第三方通知使用 Twilio SMS 实现。完整的 GUI 使用 PyQt v4.11 构建。提出的系统与现有工作的比较见表 [2](#Tab2)。表2
- en: Comparison with existing work
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 与现有工作的比较
- en: '| Existing work | Features |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 现有工作 | 特征 |'
- en: '| --- | --- |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Object detection | Object tracking | Specification of unethical object |
    Database maintenance | Alarming system | Extraction of culprit’s information |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 物体检测 | 物体跟踪 | 不道德对象的规范 | 数据库维护 | 报警系统 | 提取罪犯信息 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Proposed system | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figa_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figa_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figb_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figb_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figc_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figc_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figd_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figd_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Fige_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Fige_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figf_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figf_HTML.gif)
    |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 提出的系统 | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figa_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figa_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figb_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figb_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figc_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figc_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figd_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figd_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Fige_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Fige_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figf_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figf_HTML.gif)
    |'
- en: '| [[26](#CR26)] | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figg_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figg_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figh_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figh_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figi_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figi_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figj_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figj_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figk_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figk_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figl_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figl_HTML.gif)
    |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| [[26](#CR26)] | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figg_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figg_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figh_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figh_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figi_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figi_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figj_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figj_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figk_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figk_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figl_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figl_HTML.gif)
    |'
- en: '| [[27](#CR27)] | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figm_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figm_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Fign_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Fign_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figo_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figo_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figp_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figp_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figq_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figq_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figr_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figr_HTML.gif)
    |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| [[27](#CR27)] | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figm_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figm_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Fign_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Fign_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figo_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figo_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figp_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figp_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figq_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figq_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figr_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figr_HTML.gif)
    |'
- en: '| [[28](#CR28)] | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figs_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figs_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figt_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figt_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figu_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figu_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figv_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figv_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figw_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figw_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figx_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figx_HTML.gif)
    |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| [[28](#CR28)] | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figs_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figs_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figt_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figt_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figu_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figu_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figv_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figv_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figw_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figw_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figx_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figx_HTML.gif)
    |'
- en: '| [[29](#CR29)] | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figy_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figy_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figz_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figz_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figaa_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figaa_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figab_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figab_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figac_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figac_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figad_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figad_HTML.gif)
    |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| [[29](#CR29)] | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figy_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figy_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figz_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figz_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figaa_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figaa_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figab_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figab_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figac_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figac_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figad_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figad_HTML.gif)
    |'
- en: '| [[30](#CR30)] | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figae_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figae_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figaf_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figaf_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figag_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figag_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figah_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figah_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figai_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figai_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figaj_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figaj_HTML.gif)
    |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| [[30](#CR30)] | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figae_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figae_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figaf_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figaf_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figag_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figag_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figah_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figah_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figai_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figai_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figaj_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figaj_HTML.gif)
    |'
- en: '| [[31](#CR31)] | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figak_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figak_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figal_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figal_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figam_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figam_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figan_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figan_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figao_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figao_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figap_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figap_HTML.gif)
    |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| [[31](#CR31)] | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figak_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figak_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figal_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figal_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figam_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figam_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figan_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figan_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figao_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figao_HTML.gif)
    | ![../images/507793_1_En_13_Chapter/507793_1_En_13_Figap_HTML.gif](../images/507793_1_En_13_Chapter/507793_1_En_13_Figap_HTML.gif)
    |'
- en: High Level Architecture, Software Architecture, Sequence diagram, and State
    diagram of the system are shown in Fig. [2](#Fig2), [3](#Fig3), [4](#Fig4), and
    [5](#Fig5) respectively.![../images/507793_1_En_13_Chapter/507793_1_En_13_Fig2_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Fig2_HTML.png)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 系统的高层架构、软件架构、时序图和状态图分别显示在图 [2](#Fig2)、[3](#Fig3)、[4](#Fig4) 和 [5](#Fig5) 中。![../images/507793_1_En_13_Chapter/507793_1_En_13_Fig2_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Fig2_HTML.png)
- en: Fig. 2
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2
- en: High level architecture
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 高层架构
- en: '![../images/507793_1_En_13_Chapter/507793_1_En_13_Fig3_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Fig3_HTML.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![../images/507793_1_En_13_Chapter/507793_1_En_13_Fig3_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Fig3_HTML.png)'
- en: Fig. 3
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3
- en: Software architecture
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 软件架构
- en: '![../images/507793_1_En_13_Chapter/507793_1_En_13_Fig4_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Fig4_HTML.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![../images/507793_1_En_13_Chapter/507793_1_En_13_Fig4_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Fig4_HTML.png)'
- en: Fig. 4
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4
- en: Sequence diagram
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 时序图
- en: '![../images/507793_1_En_13_Chapter/507793_1_En_13_Fig5_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Fig5_HTML.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![../images/507793_1_En_13_Chapter/507793_1_En_13_Fig5_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Fig5_HTML.png)'
- en: Fig. 5
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5
- en: State diagram
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 状态图
- en: 3.1 Transfer Learning
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 迁移学习
- en: Innovation plays an important role in the utilization of a pre-trained model.
    For instance, a model can be used without making any changes into it, for example,
    it can be used in an application to categorize new photos. The pre-trained model
    can be used in coordination with other neural network model. In this case, the
    load of the pre-trained model can be frozen considering the fact that they are
    not updated based on the newly trained model. Similarly, the load can be refreshed
    based on the training of new model. However, there could be a lower learning rate.
    This allows pre-trained model to behave like a weight initialization program during
    the training of the new model. Some of its common usages are as classifier and
    standalone feature extractor. The pre-trained model can be directly used as a
    classifier to classify new photos. The pre-trained model or some segment of the
    model can also be used to pre-process new photos and to extract useful attributes.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 创新在利用预训练模型中扮演着重要角色。例如，一个模型可以在不进行任何更改的情况下使用，比如，它可以用于应用程序来对新照片进行分类。预训练模型可以与其他神经网络模型协同使用。在这种情况下，考虑到预训练模型不是基于新训练模型进行更新的事实，预训练模型的负载可以被冻结。同样，可以根据新模型的训练来刷新负载。然而，可能会有较低的学习速率。这允许预训练模型在新模型训练期间行为像权重初始化程序。它的一些常见用途是作为分类器和独立特征提取器。预训练模型可以直接用作分类器来对新照片进行分类。预训练模型或模型的一部分也可以用来预处理新照片并提取有用的属性。
- en: 3.2 Model Selection
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 模型选择
- en: There are many models for image identification. Some of them includes VGG (e.g.
    VGG16 or VGG19), GoogLeNet (e.g. InceptionV2), and Residual Network (e.g. ResNet50).
    They are usually used for transfer learning becasue of their architectural innovations.
    The process of loading the InceptionV3 pre-trained model is described below.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多用于图像识别的模型。其中一些包括 VGG（例如 VGG16 或 VGG19）、GoogLeNet（例如 InceptionV2）和残差网络（例如
    ResNet50）。它们通常用于迁移学习，因为它们的架构创新。加载 InceptionV3 预训练模型的过程如下所述。
- en: 3.2.1 InceptionV3 Pre-trained Model
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 InceptionV3 预训练模型
- en: The InceptionV3 is commonly known as the third iteration of the inception architecture.
    Initially, it was developed for GoogLeNet. The model requires the colour images
    should be ![$$299\times 299$$](../images/507793_1_En_13_Chapter/507793_1_En_13_Chapter_TeX_IEq1.png).
    The script described in this section was taken from [[32](#CR32)]. Run the following
    script to load the model.![../images/507793_1_En_13_Chapter/507793_1_En_13_Figaq_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figaq_HTML.png)After
    executing the above code, the model will be loaded. It will also download the
    required weights. It will summarize the model architecture to ensure that the
    model got loaded correctly. Now download photos to train the model and save these
    photos in current working directory with some filename like “knife1.jpg”. A pre-trained
    model can be utilized to group new photos among the 1,000 known classes. The photo
    needs to be stacked and reshaped to a ![$$224\times 224$$](../images/507793_1_En_13_Chapter/507793_1_En_13_Chapter_TeX_IEq2.png)
    square. Moreover, the pixel esteems are scaled in the route required by the model.
    The model works on different tests. Along these lines the components of a stacked
    picture should be extended by 1 for one picture with ![$$224\times 224$$](../images/507793_1_En_13_Chapter/507793_1_En_13_Chapter_TeX_IEq3.png)
    pixels and three channels.![../images/507793_1_En_13_Chapter/507793_1_En_13_Figar_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figar_HTML.png)Now
    the model is loaded and ready to make a prediction. This means that it will calculate
    the probability of the image belonging to each of the thousand classes.![../images/507793_1_En_13_Chapter/507793_1_En_13_Figas_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figas_HTML.png)After
    combining all of this together, a new image is loaded and the prediction is made
    to its most likely class.![../images/507793_1_En_13_Chapter/507793_1_En_13_Figat_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figat_HTML.png)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: InceptionV3通常被称为Inception架构的第三次迭代。最初，它是为GoogLeNet开发的。该模型要求彩色图像应为 ![$$299\times
    299$$](../images/507793_1_En_13_Chapter/507793_1_En_13_Chapter_TeX_IEq1.png)。本节中描述的脚本取自[[32](#CR32)]。运行以下脚本以加载模型。![../images/507793_1_En_13_Chapter/507793_1_En_13_Figaq_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figaq_HTML.png)执行以上代码后，模型将被加载。它还将下载所需的权重。它将总结模型架构以确保模型已正确加载。现在下载照片以训练模型，并将这些照片保存在当前工作目录中，文件名类似于“knife1.jpg”。可以利用预训练模型将新照片分组到1,000个已知类别中。需要将照片堆叠并重塑为
    ![$$224\times 224$$](../images/507793_1_En_13_Chapter/507793_1_En_13_Chapter_TeX_IEq2.png)
    正方形。此外，像素值应按模型所需的方式进行缩放。该模型适用于不同的测试。因此，堆叠图像的组件应扩展1以适应具有 ![$$224\times 224$$](../images/507793_1_En_13_Chapter/507793_1_En_13_Chapter_TeX_IEq3.png)
    像素和三个通道的图像。![../images/507793_1_En_13_Chapter/507793_1_En_13_Figar_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figar_HTML.png)现在模型已加载并准备好进行预测。这意味着它将计算图像属于每个千个类别的概率。![../images/507793_1_En_13_Chapter/507793_1_En_13_Figas_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figas_HTML.png)将所有这些组合在一起后，加载一个新图像并对其进行预测，找出其最可能的类别。![../images/507793_1_En_13_Chapter/507793_1_En_13_Figat_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figat_HTML.png)
- en: 3.3 Object Tracking
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 对象跟踪
- en: 'For tracking the object we have used MIL Tracker that is designed in OpenCV.
    The reason for choosing the MIL tracker is its high accuracy. The script described
    in this section was taken from [[33](#CR33)]. For object tracking using OpenCV,
    create a new .py file and insert the following script:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了在OpenCV中设计的MIL跟踪器来跟踪对象。选择MIL跟踪器的原因是其高准确性。本节中描述的脚本取自[[33](#CR33)]。要使用OpenCV进行对象跟踪，请创建一个新的.py文件并插入以下脚本：
- en: '![../images/507793_1_En_13_Chapter/507793_1_En_13_Figau_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figau_HTML.png)![../images/507793_1_En_13_Chapter/507793_1_En_13_Figav_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figav_HTML.png)![../images/507793_1_En_13_Chapter/507793_1_En_13_Figaw_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figaw_HTML.png)![../images/507793_1_En_13_Chapter/507793_1_En_13_Figax_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figax_HTML.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![../images/507793_1_En_13_Chapter/507793_1_En_13_Figau_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figau_HTML.png)![../images/507793_1_En_13_Chapter/507793_1_En_13_Figav_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figav_HTML.png)![../images/507793_1_En_13_Chapter/507793_1_En_13_Figaw_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figaw_HTML.png)![../images/507793_1_En_13_Chapter/507793_1_En_13_Figax_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figax_HTML.png)'
- en: 3.4 SMS Alert on Weapon Detection
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 武器检测时的短信提醒
- en: 3.4.1 SMS API
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.4.1 短信API
- en: Twilio’s Programmable SMS API [[34](#CR34)] was used to send the SMS alert on
    weapon detection. Using this REST API, messages can be send and received. It can
    also keep track of the send messages. Moreover, it can recover and change the
    messages history.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Twilio 的可编程 SMS API [[34](#CR34)] 发送武器检测的短信警报。使用此 REST API，可以发送和接收消息。它还可以跟踪已发送的消息。此外，它还可以恢复和更改消息历史记录。
- en: 3.4.2 SMS API Authentication
  id: totrans-72
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 短信 API 鉴权
- en: Hyper-text Transfer Protocol appeal to the API are ensured with HTTP Basic confirmation.
    Use the following script to do the basic authentication.![../images/507793_1_En_13_Chapter/507793_1_En_13_Figay_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figay_HTML.png)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 HTTP 基本确认保证 API 的超文本传输协议。使用以下脚本进行基本认证。![../images/507793_1_En_13_Chapter/507793_1_En_13_Figay_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figay_HTML.png)
- en: 3.4.3 Send an SMS with Twilio’s API
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 发送短信的 Twilio API
- en: For sending a new message from a Twilio’s phone number to an outside number,
    execute the following script:![../images/507793_1_En_13_Chapter/507793_1_En_13_Figaz_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figaz_HTML.png)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 要从 Twilio 的电话号码发送新消息到外部号码，请执行以下脚本：![../images/507793_1_En_13_Chapter/507793_1_En_13_Figaz_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Figaz_HTML.png)
- en: 4 Experimental Evaluations and Results
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验评估与结果
- en: 4.1 Evaluation Testbed
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 评估测试平台
- en: This system is based on the python model for the object, face feature and their
    response time. Therefore, the only professional way of testing the system is through
    checking the model usability and the response time for the particular model used
    in this system. Further system can capture the video via camera and makes its
    frame too slow to compare the object with the system’s database and gives a comparative
    result with a percentage of accuracy about the object. System can capture multiple
    frames means that multiple object can be detected at the same time as shown in
    Fig. [6](#Fig6), while Fig. [7](#Fig7) is showing the Facial Recognition using
    the machine learning model.![../images/507793_1_En_13_Chapter/507793_1_En_13_Fig6_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Fig6_HTML.png)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 该系统基于用于对象、人脸特征及其响应时间的 Python 模型。因此，测试系统的唯一专业方法是通过检查所用于该系统的模型的可用性和响应时间。进一步，系统可以通过摄像头捕获视频并使其帧速率变慢，以将物体与系统数据库进行比较，并给出关于物体的准确性百分比的比较结果。系统可以捕获多个帧，这意味着可以同时检测到多个对象，如图[6](#Fig6)所示，而图[7](#Fig7)显示了使用机器学习模型进行人脸识别。![../images/507793_1_En_13_Chapter/507793_1_En_13_Fig6_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Fig6_HTML.png)
- en: Fig. 6
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图6
- en: Object detection
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 物体检测
- en: '![../images/507793_1_En_13_Chapter/507793_1_En_13_Fig7_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Fig7_HTML.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![../images/507793_1_En_13_Chapter/507793_1_En_13_Fig7_HTML.png](../images/507793_1_En_13_Chapter/507793_1_En_13_Fig7_HTML.png)'
- en: Fig. 7
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图7
- en: Facial recognition
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸识别
- en: 4.2 Results and Discussion
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 结果与讨论
- en: Data Model training was done on about 1700+ pictures for object detection. Results
    were tested and found an accuracy of about 97.3% with the performance rate a bit
    low due to camera resolution and dataset unavailability. For facial recognition,
    training was done for at most 25 images per person with an accuracy rate of about
    90%. The notification test was done using the Twilio API and got the response
    time performance rate of about 5 s for a single message. The accuracy of existing
    work was found to be around 83 to 93% except for the two products i.e. the faceter
    which has an accuracy of 98.33% but limited to face only. Further, they use blockchain
    technology to gather and retrieve data. While the second one is Chinese surveillance
    which has claimed the accuracy of 98%. So far the proposed system has meanwhile
    improved and collectively highly functional by achieving the accuracy level up to
    97.33%.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 数据模型训练约1700+张图片进行物体检测。结果经过测试，准确率约为97.3%，性能略低由于相机分辨率和数据集不足所致。对于人脸识别，每个人最多使用25张图像进行训练，准确率约为90%。使用
    Twilio API 进行通知测试，得到了约5秒的响应时间性能。现有工作的准确率在83%到93%之间，除了两个产品，即准确率为98.33%但仅限于人脸的 faceter
    以及声称准确率为98%的中国监控。到目前为止，所提出的系统已经得到了显着改进，并且在实现了97.33%的准确性水平的同时也具有高度的功能性。
- en: 5 Conclusion and Future Work
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论和未来工作
- en: An Intelligent Surveillance System proposed in this chapter. This system can
    be used to fulfill the concept of Smart Cities where surveillance is one of the
    fundamental building blocks. Yet there are things which can be added to make the
    system more appropriate like this system can be enhanced by adding sensors based
    detection and recognition, weapon integration with camera, enhancing accuracy
    up to maximum level, third-party control panel, and client’s database configuration.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 本章提出了一个智能监控系统。该系统可用于实现智慧城市的概念，其中监控是其中一个基本构建模块。然而，还有一些可以添加的内容，以使系统更加合适，比如可以通过添加基于传感器的检测和识别、将武器与摄像头集成、提高准确度至最大水平、第三方控制面板以及客户数据库配置来增强该系统。
