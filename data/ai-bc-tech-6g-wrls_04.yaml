- en: © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022M.
    Dutta Borah et al. (eds.)AI and Blockchain Technology in 6G Wireless NetworkBlockchain
    Technologies[https://doi.org/10.1007/978-981-19-2868-0_4](https://doi.org/10.1007/978-981-19-2868-0_4)
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: © 作者，独家许可给 Springer Nature Singapore Pte Ltd. 2022M. Dutta Borah 等人 (编辑)在 6G
    无线网络中的 AI 和区块链技术 区块链技术[https://doi.org/10.1007/978-981-19-2868-0_4](https://doi.org/10.1007/978-981-19-2868-0_4)
- en: AI-Enabled Intelligent Resource Management in 6G
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6G 中的 AI-启用智能资源管理
- en: 'Vijayakumar Ponnusamy^([1](#Aff7) [ ](#ContactOfAuthor1)) and A. Vasuki^([2](#Aff8) [ ](#ContactOfAuthor2))(1)Department
    of ECE, SRM Institute of Science and Technology, SRM Nagar, Kattankulathur, Chengalpattu,
    603203, India(2)Department of ECE, SRM Institute of Science and Technology, Vadapalani
    campus, No.1\. Jawaharlal Nehru Road, Vadapalani, Chennai, 600026, IndiaVijayakumar Ponnusamy (Corresponding
    author)Email: [vijayakp@srmist.edu.in](mailto:vijayakp@srmist.edu.in)A. VasukiEmail:
    [vasukia@srmist.edu.in](mailto:vasukia@srmist.edu.in)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'Vijayakumar Ponnusamy^([1](#Aff7) [ ](#ContactOfAuthor1)) 和 A. Vasuki^([2](#Aff8) [ ](#ContactOfAuthor2))(1)ECE
    系，SRM 科学技术学院，SRM Nagar, Kattankulathur, Chengalpattu, 603203, 印度(2)ECE 系，SRM 科学技术学院，Vadapalani
    校区，No.1\. Jawaharlal Nehru Road, Vadapalani, Chennai, 600026, 印度Vijayakumar Ponnusamy (通讯作者)邮箱:
    [vijayakp@srmist.edu.in](mailto:vijayakp@srmist.edu.in)A. Vasuki邮箱: [vasukia@srmist.edu.in](mailto:vasukia@srmist.edu.in)'
- en: Abstract
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: The next-generation 6G mobile networks are likely to be intelligent, highly
    dynamic, and extremely low latency to satisfy the needs of different diversified
    applications. With the increasing demand for wireless communications, resource
    management plays an essential role in providing higher data rates and extreme
    quality of service with the available resources. However, the complexity of allocating
    resources will become greater in the current ultra-dense heterogeneous infrastructures.
    With massive data and computing resources, the rapid progress of Artificial Intelligence
    (AI) eventually lightens the enormous capabilities needed for the future regularization
    of 6G and beyond. As a result, an AI-enabled network will be the most appropriate
    and suitable technique for intelligent resource management, automated network
    operations, and support in future complex 6G networks. This chapter will discuss
    the different machine learning techniques used for resource management in 6G networks,
    effective usage of available spectrum, prediction of the spectrum, and dynamic
    resource allocation.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 下一代 6G 移动网络很可能会智能、高动态，并且具有极低的延迟，以满足不同多样化应用的需求。随着对无线通信的需求不断增加，资源管理在利用可用资源提供更高数据速率和极端服务质量方面起着至关重要的作用。然而，在当前的超密集异构基础设施中，资源分配的复杂性将变得更加严重。随着海量数据和计算资源的增加，人工智能
    (AI) 的快速发展最终减轻了未来 6G 及以后版本所需的巨大能力。因此，AI 可能会成为未来复杂 6G 网络中智能资源管理、自动化网络运营和支持的最合适和适当的技术。本章将讨论用于
    6G 网络资源管理的不同机器学习技术，可用频谱的有效使用，频谱预测和动态资源分配。
- en: KeywordsResource managementMassive connectivityNetwork management
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 关键词资源管理大规模连接网络管理
- en: 1 Essentials of AI in Resource Management
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 资源管理中的 AI 要点
- en: Development in wireless technologies still continues to satisfy demands for
    quick response time, higher bandwidth, and secure communication. All affordable
    physical layer technologies are utilized thoroughly after the development of post-3G
    systems in industries. This has led to the requirement of intelligent and optimized
    consumption of the available resources. In this section, we discuss the importance
    of resource management and the role of AI in resource management toward achieving
    efficient next-generation 6G networks [[1](#CR1)].
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 无线技术的发展仍在继续满足对快速响应时间、更高带宽和安全通信的需求。在 3G 以后系统的发展之后，所有可负担的物理层技术都得到了充分利用。这导致了对可用资源的智能和优化消耗的需求。在本节中，我们将讨论资源管理的重要性以及
    AI 在资源管理中的作用，以实现高效的下一代 6G 网络[[1](#CR1)]。
- en: 1.1 Challenges in Resource Management Toward Massive Connected Networks
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1 面向大规模连接网络的资源管理挑战
- en: Resource management aims to obtain proper employment of constrained physical
    sources to fulfill numerous traffic needs and enhance the machine’s overall performance.
    The existing resource management techniques in academic usage are often developed
    for fixed networks. It depends upon the mathematical functions. In contrast, the
    conditions of the realistic wireless network are variable, which leads to regression
    of algorithms with high computational complexity. The application of assumed mathematical
    conditions of a static network in practical cases results in drastic performance
    loss. In addition to that, standard management schemes may be superior in extracting
    beneficial records related to users and networks. Various resource management
    techniques are desired for the massive number of nodes.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 资源管理旨在获取适当利用受限物理资源以满足众多流量需求并提高机器的整体性能。学术上使用的现有资源管理技术通常是为固定网络开发的。它依赖于数学函数。相比之下，现实无线网络的条件是可变的，这导致具有高计算复杂性的算法回归。在实际情况下应用假设的静态网络数学条件会导致性能严重下降。除此之外，标准管理方案可能在提取与用户和网络相关的有益记录方面优越。对于庞大数量的节点，需要各种资源管理技术。
- en: 1.2 Resource Management in 5G
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2 5G 中的资源管理
- en: After the deployment of the 5G standards, academia and industries have started
    to focus on the next-generation wireless communication standard 6G. This technology
    achieves a high data rate of up to 1 Tb/s and a broadband frequency of 100 GHz
    to 3 THz [[2](#CR2)]. Apart from important evaluation parameters of communication,
    Artificial Intelligence (AI) has been accepted as the essential feature of 6G
    by researchers in recent times. Wherein the applications of machine learning algorithms
    are believed to provide an appropriate solution for many complex scenarios. Network
    intelligence is expected to meet the challenges of heterogeneous networks. Though
    machine learning techniques have been employed in various applications, there
    is still scope for the realization of automated cellular communication systems.
    The existing problems in communication systems, architectures, and their performance
    should be focused on making use of 6G technologies.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署 5G 标准之后，学术界和产业开始关注下一代无线通信标准 6G。该技术实现了高达 1 Tb/s 的数据速率和 100 GHz 到 3 THz 的宽带频率
    [[2](#CR2)]。除了通信的重要评估参数之外，近来研究人员已将人工智能（AI）视为 6G 的重要特征。在这些应用中，机器学习算法被认为是许多复杂场景的合适解决方案。网络智能预计将满足异构网络的挑战。虽然机器学习技术已在各种应用中使用，但自动化蜂窝通信系统的实现仍有空间。应该关注通信系统、架构及其性能的现有问题，并利用
    6G 技术。
- en: 1.3 Resource Management from 5G to 6G
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3 从 5G 到 6G 的资源管理
- en: The existence of AI can be seen in everyday scenarios. Nowadays, the amount
    of produced data by both machines and human is overwhelming, which exceeds the
    ability of humans to understand and digest that data and make decisions depending
    on that data. Thus, a hand of help from AI is needed to overcome such challenges.
    The 5G LTE communication system is a promising solution to provide a high user
    experience in terms of the provided speed, amount of data, and cost. However,
    due to its complexity, the technology of LTE needs some improvement in terms of
    resource management and optimization. With the aid of AI, these two challenges
    can be overcome. The AI represented by the improved Q-learning algorithm with
    the Self-Organizing Network (SON) concept in LTE is used to manage and optimize
    Handover (HO) parameters and processes in the system [[3](#CR3)].
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: AI 的存在可以在日常场景中看到。如今，机器和人类产生的数据量令人震惊，超出了人类理解和消化这些数据并根据这些数据做出决策的能力。因此，需要 AI 的帮助来克服这些挑战。5G
    LTE 通信系统是提供高用户体验的有希望的解决方案，涉及提供的速度、数据量和成本。然而，由于其复杂性，LTE 技术在资源管理和优化方面需要一些改进。借助 AI，这两个挑战可以克服。AI
    代表着改进的 Q 学习算法与 LTE 中的自组织网络（SON）概念相结合，用于管理和优化系统中的切换（HO）参数和过程 [[3](#CR3)]。
- en: AI has become necessary in day-to-day activities. The data produced by humans
    and machines is huge. There is a need for humans to understand the generated data
    and analyze it. This helps in making appropriate decisions. This can be easily
    solved by employing AI. The 5G LTE in communication has been considered as an
    auspicious solution in terms of speed, data rate, and cost. However, there is
    a need for some enhancements in resource management and optimization techniques
    which could be overcome by using AI techniques. AI-aided Q-learning algorithm
    along with Self-Organizing Network (SON) in LTE manages and optimizes the handover
    parameters and different stages in the system [[4](#CR4)]. The challenges in AI-based
    6G networks are depicted in Fig. [1](#Fig1). The role of AI-based algorithms is
    illustrated in Fig. [2](#Fig2).![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig1_HTML.png)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: AI在日常活动中变得必不可少。人类和机器产生的数据量巨大。人类需要理解生成的数据并分析它。这有助于做出适当的决策。这可以通过采用AI轻松解决。通信中的5G
    LTE被认为是速度、数据速率和成本方面的有利解决方案。然而，资源管理和优化技术需要一些改进，这可以通过使用AI技术来克服。在LTE中，AI辅助的Q学习算法以及自组织网络（SON）管理和优化了系统中的切换参数和不同阶段[[4](#CR4)]。AI基础的6G网络中的挑战如图所示。图 [1](#Fig1)。AI算法的作用在图中说明。 [2](#Fig2)。![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig1_HTML.png)
- en: The model depicts the challenges for advancing M L-based 6G networks. It has
    Learning efficiency, End-to-end qualified service provision, Efficient dataset
    generation, Physical layer to ap-plication layer, Computation over-head deployment,
    Dynamic online learning for exploration, Feasibility verification, Distributed
    or centralized, Standardization, Scalability for global intelligence.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型描述了推动基于ML的6G网络的挑战。具有学习效率、端到端合格的服务提供、高效的数据集生成、物理层到应用层、计算开销部署、动态在线学习用于探索、可行性验证、分布式或集中式、标准化、全球智能的可扩展性。
- en: Fig. 1
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1
- en: Challenges in 6G networks
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 6G网络中的挑战
- en: '![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig2_HTML.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig2_HTML.png)'
- en: Model depicts the role of AI-based algorithms in wireless networks. Machine
    learning includes Supervised learning, Reinforcement learning and Unsupervised
    learning. Each with applications and algorithms.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 模型描述了AI算法在无线网络中的作用。机器学习包括监督学习、强化学习和无监督学习。每种都有应用和算法。
- en: Fig. 2
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2
- en: Role of AI algorithms in wireless networks
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: AI算法在无线网络中的作用
- en: 2 Application of Machine Learning Techniques in Network Management
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 机器学习技术在网络管理中的应用
- en: To fulfill the enormous requesting management, the growth of 6G has been considered
    as progress that overcomes the limits of improved broadband, unlimited access,
    and ultra-reliable latent management in 5G remote networks. As of late, the construction
    of 6G networks has been amazingly heterogeneous, thickly conveyed, and dynamic.
    In order to reach the best tight Quality of Service (QoS), this complex structure
    will lead to a defect in network activity routines. Therefore, machine learning
    is emerging as a crucial answer to acknowledge completely wise organization coordination
    and the executives. By gaining from unsure and dynamic conditions, machine learning-based
    medium assessment and bandwidth management will allow the executives to open up
    promising circumstances for bringing the amazing presentation of ultra-broadband
    strategies, like terahertz interchanges. Furthermore, difficulties carried by
    ultra-massive networks concerning power and end-to-end secure communication can
    be moderated by employing appropriate machine learning-based techniques. Also,
    shrewd versatility among the executives and asset assignment will ensure the ultra-unwavering
    quality and low inactivity of administrations. Concerning these issues, this chapter
    presents and studies some cutting-edge methods dependent on machine learning and
    their applications in 6G to help with ultra-broadband, ultra-massive access, and
    low inertness management [[5](#CR5)].
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了满足巨大的需求管理，6G 的发展被认为是超越了 5G 远程网络改进宽带、无限访问和超高可靠性延迟管理限制的进步。最近，6G 网络的构建变得异常异构、密集分布和动态。为了达到最佳的紧密服务质量（QoS），这种复杂结构将导致网络活动例程的缺陷。因此，机器学习正在成为认识完全智能化的组织协调和管理的关键答案。通过从不确定和动态环境中学习，基于机器学习的介质评估和带宽管理将使管理者能够开辟出为实现超高宽带策略（如太赫兹通信）带来惊人表现的机遇。此外，关于能源和端到端安全通信的超大规模网络所带来的挑战可以通过采用适当的基于机器学习的技术来缓解。此外，智能的管理和资源分配将确保服务的超高可靠性和低延迟。针对这些问题，本章介绍和研究了一些基于机器学习的前沿方法及其在
    6G 中的应用，以支持超高宽带、超大规模访问和低延迟管理[[5](#CR5)]。
- en: 2.1 ML-Enabled Broadband Transmission in 6G Networks
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 6G 网络中基于机器学习的宽带传输
- en: The available spectrum is scarcely enough to satisfy the expanding needs. For
    example, some arising applications, like holography, may require a data rate of
    up Tb/sec, which is roughly three times of magnitude faster compared to average
    5G correspondences. Accordingly, THz correspondences, using groups within the
    scope of 0.1–10 THz such as 140, 220, and 340 GHz frequencies, are required to
    help an information pace of up to terabits each second. To accomplish such a limit
    moving toward execution, exact data of time-shifting channels is particularly
    imperative to advance the terahertz transfer speed portion and further develop
    range productivity. In this segment, we present some cutting-edge AI/ML applications
    in terahertz channel assessment and range the executives [[6](#CR6)].
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 可用频谱几乎不足以满足不断扩大的需求。例如，一些新兴的应用，如全息技术，可能需要每秒高达 Tb 的数据速率，这大约是平均 5G 通信速度的三倍。因此，需要
    THz 通信来协助每秒达到高达 terabits 的信息传输速度，使用的频段范围为 0.1–10 THz，例如 140、220 和 340 GHz 的频率。为了实现这样的极限性能，时间偏移信道的精确数据对于提高太赫兹传输速率部分和进一步改进频谱效率尤为重要。在本节中，我们介绍了一些关于太赫兹信道评估和频谱管理的前沿人工智能/机器学习应用[[6](#CR6)]。
- en: At the terahertz recurrence groups, the channels experience the ill effects
    of high climatic retention coming about because of the water fume noticeable all
    around, which impacts misfortunes fundamentally. Moreover, the free-space path
    loss is likewise unavoidable actually as far as climatic constriction is concerned.
    Moreover, terahertz channels are seen as non-fixed, particularly for dynamic situations
    where the two clients and items may be moving. Accordingly, customary channel
    models dependent on suppositions of being fixed or semi-fixed can’t currently
    have any significant bearing on the ultra-wideband spectrum. Machine learning
    calculations are equipped to examine the correspondence information and foresee
    likely signs of misfortune in a guaranteed or obscure climate. Subsequently, a
    wide range of Artificial Intelligence calculations could be employed to the physical
    layer of 6G organizations that manage the hardships portrayed for ultra-wideband
    spectrum assessment.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在太赫兹频率组中，信道受到由空气中水蒸汽引起的高大气吸收的影响，这对损耗产生了重大影响。此外，自由空间路径损耗在气象收缩方面也是不可避免的。此外，太赫兹信道被视为非固定的，特别是对于用户和物体可能移动的动态环境。因此，基于假设为固定或半固定的传统信道模型目前无法适用于超宽带频谱。机器学习算法可用于分析通信数据并预测保证或不明确环境中损失的可能信号。因此，各种人工智能算法可以应用于处理超宽带频谱的
    6G 网络的物理层中所描述的困难。
- en: In many applications, in order to further develop assessment precision in powerful
    situations, the Bayesian filter based on reinforcement learning has been acquainted
    with the direction of arrival assessment in THz directs in present examinations.
    In particular, the Bayesian channel executes the assessment of the current direction
    of arrival from both current estimation and past gauges. In this methodology,
    the earlier change probabilities between framework states are essential to the
    assessment execution of the Bayesian filter. A reinforcement learning algorithm
    could be employed to enhance the probabilities of state changes from the results
    of previous measures and henceforth work on the exhibition of the Bayesian filter.
    The major classifications and applications of machine learning algorithms are
    described below.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多应用中，为了进一步发展强大情况下的评估精度，基于强化学习的贝叶斯滤波器已经应用于当前研究中的太赫兹直接到达评估。特别是，贝叶斯信道执行当前到达方向的评估，该评估来自当前估计和过去估计。在这种方法中，系统状态之间的先前变化概率对于贝叶斯滤波器的评估执行至关重要。可以使用强化学习算法根据先前测量的结果提高状态变化的概率，从而提高贝叶斯滤波器的性能。机器学习算法的主要分类和应用如下所述。
- en: The learning algorithm which is based on enough and efficient training with
    labeled data is known as *supervised learning*. These algorithms can be acquainted
    with transmission path loss and shadowing forecast, obstruction board, channel
    assessment, etc. Some of the architectures, such as Deep Neural Networks (DNN),
    K-Nearest Neighbor (KNN), and Support Vector Machines (SVM), are based on supervised
    learning algorithms.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于充足和有效的带标签数据进行的学习算法称为*监督学习*。这些算法可以熟悉传输路径损耗和阴影预测、阻塞板、信道评估等。一些体系结构，如深度神经网络（DNN）、K-最近邻（KNN）和支持向量机（SVM），是基于监督学习算法的。
- en: KNN algorithm is used for identifying and allocating the resources (spectrum/power/positioning)
    requirements. For example, as shown in Fig. [3](#Fig3), the new requirement can
    be categorized using KNN algorithm, where K = 3 represents the distance from the
    new sample (data) is calculated with three nearest data points. KNN uses Euclidean
    distance (d) for classification which is expressed in ([1](#Equ1))![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig3_HTML.png)
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: KNN 算法用于识别和分配资源（频谱/功率/定位）要求。例如，如图 [3](#Fig3) 所示，新要求可以使用 KNN 算法进行分类，其中 K = 3
    表示与新样本（数据）的距离由三个最近的数据点计算得出。KNN 使用欧氏距离（d）进行分类，其表达式为 ([1](#Equ1))！[](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig3_HTML.png)
- en: Graph depicts the new requirement can be categorized using the KNN algorithm
    used for identifying and allocating the resources (spectrum/power/positioning)
    requirements. The spot in the graph labeled new sample has arrows 1,2,3\. K equal
    3.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图表描述了使用 KNN 算法对识别和分配资源（频谱/功率/定位）要求的新要求进行分类。图表中标有新样本的位置有箭头 1、2、3。K 等于 3。
- en: Fig. 3
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3
- en: An example of KNN
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: KNN 的一个例子
- en: '![$$d=\sqrt{{\left({x}_{2}-{x}_{1}\right)}^{2}+{\left({y}_{2}-{y}_{1}\right)}^{2}}$$](../images/517376_1_En_4_Chapter/517376_1_En_4_Chapter_TeX_Equ1.png)(1)'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![$$d=\sqrt{{\left({x}_{2}-{x}_{1}\right)}^{2}+{\left({y}_{2}-{y}_{1}\right)}^{2}}$$](../images/517376_1_En_4_Chapter/517376_1_En_4_Chapter_TeX_Equ1.png)(1)'
- en: Similarly, SVM also is used to solve handover problems in heterogeneous networks.
    Antenna selection in massive MIMO is achieved with the aid of an SVM classifier
    among hundreds of antennas. Estimating channel noise for effective network management.
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 同样，SVM也用于解决异构网络中的切换问题。在大规模MIMO中，通过SVM分类器在数百个天线中选择天线。用于有效网络管理的信道噪声估计。
- en: In any wireless communication network, channel estimation and modeling play
    an essential role in determining the end-to-end performance of the communication
    system. These problems could be easily solved by yet another category of machine
    learning called unsupervised learning mechanisms. *Unsupervised learning* does
    not require training with labeled data. The major applications are suppressing
    interference, user clustering, and overcoming challenges in duplex mode. K-means
    clustering and fuzzy-C-means algorithms are some of the most popular unsupervised
    learning mechanisms in recent communication technologies.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在任何无线通信网络中，信道估计和建模对确定通信系统端到端性能起着至关重要的作用。这些问题可以轻松通过另一类称为无监督学习机制的机器学习来解决。*无监督学习*不需要使用带有标签的数据进行训练。其主要应用包括抑制干扰、用户聚类以及克服双工模式下的挑战。K均值聚类和模糊C均值算法是近期通信技术中一些最受欢迎的无监督学习机制。
- en: 'The Multipath Component (MPC) analysis is an essential task in gathering information
    on the wireless channel. K-means clustering algorithm forms the grouping in the
    MPC to reduce the Euclidean distance between the data until it becomes converging.
    It groups the parameters such as the delay (t), azimuth angle of arrival (AoA),
    azimuth angle of departure (AoD), the elevation angle of arrival (EoA), and the
    elevation angle of departure (EoD) which have similar behavior. The following
    example illustrates the step by execution of K-means clustering:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 多径组件（MPC）分析是收集无线信道信息的重要任务。K均值聚类算法在MPC中形成分组，以减小数据之间的欧几里得距离直到收敛。它将具有类似行为的参数进行分组，如延迟（t）、到达方位角（AoA）、离开方位角（AoD）、到达高度角（EoA）和离开高度角（EoD）。以下示例通过执行K均值聚类来说明步骤：
- en: 'Step1: It starts initial clusters randomly with centers (k[1], k[2], k[3]),
    as shown in Fig. [4](#Fig4)a.![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig4_HTML.png)'
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 第 1 步：随机以中心（k[1]、k[2]、k[3]）开始初始聚类，如图 [4](#Fig4)a 所示。![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig4_HTML.png)
- en: ''
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Graphs illustrate the architecture of AI-enabled cell edge computing, cloud,
    and edge computing. (a) It starts initial clusters randomly with centers (k1,
    k2, k3). (b) It assigns each data point closest cluster center. (c) Move each
    cluster center to the mean of each cluster. (d) It calculates the clusters related
    to the new data points. (e) Recomputes the cluster centers (f) Move the cluster
    centers to cluster means.
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图形说明了AI启用的边缘计算、云和边缘计算的架构。 (a) 它随机以中心（k1、k2、k3）开始初始聚类。 (b) 将每个数据点分配给最接近的聚类中心。
    (c) 将每个聚类中心移动到每个聚类的平均值。 (d) 计算与新数据点相关的聚类。 (e) 重新计算聚类中心 (f) 将聚类中心移动到聚类均值。
- en: ''
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 4
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图 4
- en: ''
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An illustration of K-means clustering algorithm in unknown data points
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在未知数据点上的K均值聚类算法示例
- en: ''
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 2: It assigns each data point closest cluster center, as shown in Fig.
    [4](#Fig4)b.'
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 第 2 步：将每个数据点分配给最接近的聚类中心，如图 [4](#Fig4)b 所示。
- en: ''
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 3: Move each cluster center to the mean of each cluster as shown in Fig.
    [4](#Fig4)c.'
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 第 3 步：将每个聚类中心移动到每个聚类的平均值，如图 [4](#Fig4)c 所示。
- en: ''
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 4: It calculates the clusters related to the new data points as shown
    in Fig. [4](#Fig4)d.'
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 第 4 步：计算与新数据点相关的聚类，如图 [4](#Fig4)d 所示。
- en: ''
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 5: Recomputes the cluster centers as shown in Fig. [4](#Fig4)e.'
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 第 5 步：重新计算聚类中心，如图 [4](#Fig4)e 所示。
- en: ''
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 6: Move the cluster centers to cluster means as shown in Fig. [4](#Fig4)f.'
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 第 6 步：将聚类中心移动到聚类均值处，如图 [4](#Fig4)f 所示。
- en: Another important category is *Deep learning*. Deep learning algorithms are
    employed for extracting channel characteristics, finding dynamic channel information,
    detecting different modulated signals/symbols, and recovering the original raw
    input from encoded data. The major deep learning structures such as Convolutional
    Neural Network (CNN), Recurrent Neural Network, Deep feed Forward Neural Network,
    and Deep Belief Networks (DBN) could be employed depending upon the applications.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '另一个重要的类别是 *深度学习*。深度学习算法被用于提取信道特性、找到动态信道信息、检测不同的调制信号/符号，并从编码数据中恢复原始输入。主要的深度学习结构，如卷积神经网络（CNN）、循环神经网络、深度前馈神经网络和深度信念网络（DBN），可根据应用进行选择。  '
- en: CNN could be applied for dynamic power control for improving Non-Line of Sight
    (NLOS) transmission, automatic modulation classification, and channel estimation
    in a next-generation wireless communication system. Localization in wireless networks
    is a challenging task because of shadowing and multi-path fading in indoor environments.
    In order to fulfill the requirements of 6G wireless communication, the THz spectrum
    provides ultra-wideband for application. An LSTM architecture (as illustrated
    in Fig. [5](#Fig5)) could explore the channel state information of THz wireless
    signals, AoA, received power, and delay which are useful parameters of the indoor
    environment. A series of temporal data (X[o], X[1], …X[t]) is given input to the
    LSTM.![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig5_HTML.png)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 可用于动态功率控制，以改善非直射（NLOS）传输、自动调制分类和下一代无线通信系统中的信道估计。在无线网络中进行定位是一项具有挑战性的任务，因为室内环境中存在阴影和多径衰落。为了满足
    6G 无线通信的要求，太赫兹频谱提供了超宽带应用。LSTM 架构（如图 [5](#Fig5) 所示）可以探索太赫兹无线信号的信道状态信息、到达角、接收功率和延迟，这些是室内环境的有用参数。一系列时间数据（X[o]、X[1]、…X[t]）被输入到
    LSTM 中。![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig5_HTML.png)
- en: A LSTM architecture depicts series of temporal data (Xo, X1, …Xt) is given input
    to the LSTM.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 LSTM 架构描述了一系列时间数据（Xo、X1、…Xt）被输入到 LSTM 中。
- en: Fig. 5
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5
- en: An LSTM architecture
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 LSTM 架构
- en: '*Reinforcement learning* is a combination of supervised and unsupervised learning
    algorithms. These algorithms are based on action rewards. The agent in the application
    continuously gets the information from the environment to take appropriate action.
    If the action is successful, the algorithm gets positive feedback to further explore
    the new unknown state. Reinforcement learning-based algorithms are mainly used
    in tracking the unknown wireless medium and choosing feasible modulation modes.
    Markov decision process, Q-learning, and fuzzy-reinforcement learning are algorithms
    used often.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*强化学习* 是监督学习和无监督学习算法的结合。这些算法基于行动奖励。应用中的代理程序不断从环境中获取信息以采取适当的行动。如果行动成功，算法会获得积极的反馈，以进一步探索新的未知状态。基于强化学习的算法主要用于跟踪未知的无线介质和选择可行的调制方式。马尔可夫决策过程、Q
    学习和模糊强化学习是经常使用的算法。'
- en: Markov decision process applies probability to predict the future requirements
    based on the present observed state in the channel estimation process which is
    illustrated in Fig. [6](#Fig6).![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig6_HTML.png)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫决策过程应用概率来预测信道估计过程中的未来要求，其基于当前观察到的状态，如图 [6](#Fig6) 所示。![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig6_HTML.png)
- en: Model depicts an example of the Markov process the future requirements based
    on the observed state -y1, y2, y3 and hidden state S1, S2, S3.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 模型描述了马尔可夫过程的一个例子，未来的要求基于观察到的状态 -y1、y2、y3 和隐藏状态 S1、S2、S3。
- en: Fig. 6
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6
- en: An example of the Markov process
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Markov 过程的一个例子
- en: The application of the deep learning/machine learning algorithm in various levels
    of the 6G network is illustrated in Fig. [7](#Fig7).![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig7_HTML.png)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在 6G 网络的各个层面应用深度学习/机器学习算法的示意图如图 [7](#Fig7) 所示。![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig7_HTML.png)
- en: Model diagram illustrates the important layers of reinforcement learning based
    architecture for WLANs in mIoT (mobile Internet of Things) environment. It has
    images of Cloud-Fog/edge, S D N, T Hz Communication and smart city. It has sections
    intelligent network management and optimization in 6G and A L/M L technique.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 模型图解了基于强化学习的 WLANs 在 mIoT（移动物联网）环境中的重要层次结构。它具有云-雾/边缘、SDN、太赫兹通信和智能城市的图像。它具有智能网络管理和优化在
    6G 和 A L/M L 技术的部分。
- en: Fig. 7
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7
- en: Application of deep learning/machine learning algorithm in 6G network
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在6G网络中应用深度学习/机器学习算法
- en: 3 Application of Machine Learning Techniques in Network Management
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 网络管理中机器学习技术的应用
- en: In this section, the necessity of machine learning in a massive connected network,
    spectrum prediction based on ML will be discussed [[7](#CR7)].
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，将讨论在大规模连接网络中机器学习的必要性，以及基于ML的频谱预测[[7](#CR7)]。
- en: 3.1 Need for Massive Connectivity Management in 6G Network
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 6G网络中大规模连接管理的需求
- en: In high-dimensional networks, connectivity among different devices can allow
    the terminals to create diversified integration with various levels of network
    and make the network to reach uplift in coverage. Because of the dynamic nature
    of the connectivity, there is a chance for inserting and removing devices to cope
    with massive connectivity effectively. The connectivity between network and physical
    layer bears with high delay in higher order networks. This delay results in data
    transfer, which could be optimized in their end-to-end connectivity. Managing
    connectivity among numerous devices depends on present wireless channel conditions,
    wherein the portability of Base Stations (BSs) makes getting channel state information
    more tedious.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在高维网络中，不同设备之间的连接可以允许终端与各种级别的网络进行多样化整合，并使网络实现覆盖的提升。由于连接的动态性质，有机会插入和移除设备以有效应对大规模连接。网络和物理层之间的连接承受着高延迟的问题。这种延迟导致数据传输，可以通过优化它们的端到端连接来解决。管理众多设备之间的连接取决于当前的无线信道条件，在其中，基站（BSs）的可移动性使得获取信道状态信息更加费力。
- en: 3.2 Radio Resource Management in High-Dimensional Networks
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 高维网络中的无线资源管理
- en: In massively connected networks, coverage of indistinguishable areas is done
    by allowing many devices to the network. This results in severe interference in
    the network, which could be suppressed by using a scheduling mechanism. This technique
    provides information about the dynamic channel to improve scheduling among users.
    In contrast to hyperlinks between terrestrial BSs, the inter-satellite, inter-aerial,
    inter-satellite–aerial, and inter-satellite–terrestrial are non-ideal, and hence
    has a poor delay. So, there is a necessity for collaborative scheduling in massively
    connected networks. Moreover, long-distance and high-mobility shifting BSs lead
    to the severity in channel approximation, which makes designing the feasible algorithm
    as a complex one.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在大规模连接的网络中，通过允许许多设备接入网络来覆盖无法区分的区域。这导致网络中严重的干扰，可以通过使用调度机制来抑制这种干扰。该技术提供了关于动态信道的信息，以改善用户之间的调度。与地面基站之间的超链接相比，卫星间、空中间、卫星-空中间和卫星-地面间的连接是非理想的，因此延迟较高。因此，在大规模连接的网络中需要协作调度。此外，长距离和高移动性的基站导致信道近似程度的严重性增加，这使得设计可行算法变得复杂。
- en: 3.3 AI-Enabled Automated 6G Networks
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 AI启用的自动化6G网络
- en: The key enables methods used in 5G networks such as software-defined networks;
    network function virtualization is considered in 6G networks also. These techniques
    have the capability of making self-defined networks that are suitable for 6G networks.
    Anyhow, these networks should be introduced with intelligence in the case of 6G
    networks. With the integration of artificial intelligence in wireless networks,
    intelligence could be achieved with sufficient training. So, machine learning/deep
    learning/Artificial Intelligence has been considered as the most suitable technique
    for developing 6G networks as self-defined networks.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 关键在于**5G网络**中使用的方法，例如软件定义网络；6G网络中也考虑了网络功能虚拟化。这些技术具有制作适合6G网络的自定义网络的能力。无论如何，在6G网络的情况下，这些网络应该引入智能。通过在无线网络中整合人工智能，可以通过充分的训练实现智能化。因此，机器学习/深度学习/人工智能被认为是开发6G网络作为自定义网络最合适的技术。
- en: The integration of Artificial Intelligence in software-defined networks can
    obtain effective network architecture. Good optimization applied in 6G makes it
    autonomous networks compared to 5G networks.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件定义网络中整合人工智能可以获得有效的网络架构。与5G网络相比，6G中应用了良好的优化，使其成为自动网络。
- en: Machine learning-based network management has the ability to organize the network
    architecture, slice and collect different channel access technologies to get smooth
    networks, and satisfy the requirements of dynamic services and applications. The
    network performance metrics are continuously observed with the aid of AI-based
    optimization techniques. Based on the observations, network parameters could be
    updated to maintain the best services. These AI-based techniques can get practical
    network performance, which is considered as historical data. Network intelligence
    can also be obtained by deploying multilevel AI. In huge connected networks, AI
    could be integrated at the routers to forward the data. AI-enabled techniques
    were introduced in Radio Access Networks to manage multiple BS-related processes
    like portability and interference suppression. AI will enable the large IoT network
    to shift from the facts center to the edge of the community.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 基于机器学习的网络管理具有组织网络架构、切片和收集不同的信道接入技术以获取平滑网络、满足动态服务和应用需求的能力。在人工智能优化技术的辅助下，持续观察网络性能指标。根据观察结果，可以更新网络参数以维持最佳服务。这些基于人工智能的技术可以获得实用的网络性能，被视为历史数据。通过部署多层次人工智能也可以获得网络智能。在庞大的联接网络中，可以在路由器上集成人工智能以转发数据。AI技术已经被引入到无线接入网络中，用于管理诸如可移动性和干扰抑制等多个基站相关流程。人工智能将使大型物联网网络从数据中心转移到社区的边缘成为可能。
- en: 4 Application of Machine Learning Techniques in Network Management
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4. 应用机器学习技术于网络管理
- en: In this section, we will discuss how machine learning/deep learning techniques
    are used for allocating the available resources in terms of multi-access edge
    computing, mobility, handover management, and spectrum management [[8](#CR8)].
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论机器学习/深度学习技术如何用于多接入边缘计算、移动性、切换管理和频谱管理的资源分配[[8](#CR8)]。
- en: 4.1 Deep Learning-Based Multi-Access Edge Computing
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 基于深度学习的多接入边缘计算
- en: Multi-access edge computing has become inevitable in the 6G networks. MEC furnishes
    mathematical and analytical computations and brings radio access networks to mere
    closeness with other devices. Because of their multidimensional, randomly uncertain,
    and dynamic properties, MEC’s firm-level maximization, whereabouts, and sample
    training are important aspects. Hence, a conventional Lagrangian duality algorithm
    may face threads under complex networks. AI-enabled strategies can retrieve past
    records to know and assist for optimization, forecasting, and choice in MEC. Figure [4](#Fig4)
    llustrates the architecture of AI-enabled cell edge computing, cloud and edge
    computing. As proven because of the confined capability, lightweight AI algorithms
    may be applied to offer clever programs for other situations like transportation
    and agriculture. For instance, reinforcement learning-based edge computing is
    helpful in resource management and is considered a model-free scheme since it
    is not essential to have any prerequisite knowledge about any area. This can be
    implemented in analyzing the changes in the environment and choosing the appropriate
    method in practice.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在6G网络中，多接入边缘计算已经变得不可避免。MEC提供数学和分析计算，并将无线接入网络带到与其他设备的近距离。由于MEC具有多维、随机不确定和动态属性，因此MEC的企业级最大化、位置和样本训练是重要的方面。因此，在复杂网络下，传统的Lagrangian对偶算法可能会遇到困难。AI技术可以检索过去的记录以了解和协助MEC的优化、预测和选择。图 [4](#Fig4)
    展示了AI支持的蜂窝边缘计算、云计算和边缘计算的架构。由于其有限的能力，轻量级AI算法可以被应用于提供智能应用，如交通和农业等其他情景。例如，基于强化学习的边缘计算在资源管理方面非常有用，并且被认为是一种无模型方案，因为它不需要对任何领域有任何先验知识。这可以用于分析环境变化并在实践中选择适当的方法。
- en: Extensive deep learning algorithms are expected to furnish functional training
    on the central cloud server. The AI-enabled classification algorithm is utilized
    to optimize traffic flow decisions for different service applications that are
    dynamic and different. An AI-based cluster is used to reduce complexity in MEC
    servers instead of individual decisions.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 广泛的深度学习算法预计将在中央云服务器上提供功能性培训。利用AI支持的分类算法优化不同的动态和不同服务应用的流量决策。一个AI支持的集群用于减少MEC服务器中的复杂性，而不是单个决策。
- en: The data received from the edge computing servers can be well trained to extract
    inherent features automatically. In such cases, the deep learning algorithm could
    be suited to train the system model to obtain the type of service, traffic, and
    security for which it is designed.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从边缘计算服务器接收到的数据可以被很好地训练，以自动提取固有特征。在这种情况下，深度学习算法可能适合训练系统模型，以获取设计目的的服务类型、流量和安全性。
- en: In addition to that, Deep Reinforcement Learning (DRL) is made active in finding
    adequate resource management policy in extremely complex and time-varying MEC
    networks. To map the decisions and the environment, optimal resource management
    policies are used. Edge devices are supported with high-quality services by adopting
    DRL to use historical knowledge by improving efficiency and accuracy.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，深度强化学习（DRL）在寻找极其复杂和时变的MEC网络中的适当资源管理策略方面起到了积极作用。为了映射决策和环境，使用了最佳资源管理策略。通过采用DRL来利用历史知识，提高效率和准确性，为边缘设备提供了高质量的服务。
- en: 4.2 AI-Based Handover Management
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 基于人工智能的切换管理
- en: Being 6G networks are highly discrete, multi-layer and large-dimensional, mobility,
    and handover management are highly challenging issues of 6G networks. Mobility
    prediction and handover are achieved by applying suitable AI techniques to achieve
    uninterrupted services.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 由于6G网络高度离散、多层次和大维度，移动性和切换管理是6G网络的极具挑战性的问题。通过应用适当的人工智能技术来实现无间断服务，实现了移动性预测和切换。
- en: '*Role of AI in UAV networks:* In the case of integrating UAV communication
    with 6G networks, this results in frequent handovers. Suppose, if UAV communications
    are combined with 6G networks, and the fast dynamic mobility of UAVs results in
    established handovers. Furthermore, the subject is extended in processing efficient
    handover due to the numerous provider needs such as high statistics, high trustability,
    and low latency. The immoderate mobility of devices and UAVs results in unpredictability
    about their locations. This problem could be resolved by one of the AI techniques,
    reinforcement learning. It learns to optimize the handover techniques in the practical
    scenario to explore the mobility behaviors of devices/UAVs in online mode. This
    approach reduces the transmission delay and ensures reliable Wi-Fi connectivity.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*无人机网络中的人工智能角色：* 在将无人机通信与6G网络集成的情况下，这导致了频繁的切换。假设，如果无人机通信与6G网络相结合，而无人机的快速动态移动导致了建立的切换。此外，由于诸多提供商的需求，如高统计数据、高可信度和低延迟，这一主题在处理有效切换方面得到了扩展。设备和无人机的过度移动导致了关于它们位置的不可预测性。这个问题可以通过一种AI技术，强化学习，来解决。它学会了优化实际场景中的切换技术，以探索设备/无人机的移动行为。这种方法减少了传输延迟，并确保了可靠的Wi-Fi连接。'
- en: Figure [4](#Fig4) shows the factors of shrewd mobility and handover management
    based on DRL in UAV-enabled networks. In these networks, every UAV can act as
    an agent to interact with the environment, thereby enhancing the network coverage.
    Each agent observes the nearby states and finds the most appropriate action to
    achieve the positive reward. The reward can be manipulated with the help of connectivity,
    delay, and feedback from the environment. DRL-based UAV network can have the ability
    to process handover mechanically and reduce the delay, handover failure probability.
    At the same time, it offers the best grade of service.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [4](#Fig4) 显示了基于DRL的无人机网络中的敏捷移动和切换管理因素。在这些网络中，每个无人机都可以充当与环境进行交互的代理，从而增强了网络覆盖范围。每个代理观察附近的状态，并找到最合适的行动以获得积极的奖励。奖励可以通过连接性、延迟和来自环境的反馈来操纵。基于DRL的无人机网络具有自动处理切换和减少延迟、切换失败概率的能力。同时，它提供了最优质的服务。
- en: '*Role of AI in Vehicular networks:* Large-scale vehicular networks should have
    ultra-high speed and low delay insensitive with the evolution of 6G networks.
    Therefore, efficient mobility management is an essential parameter to achieve
    end-to-end reliable and low latent communication. The mobility patterns of high-speed
    vehicular users are continuously learned by the popular deep learning structures
    like RNN and ANN. These AI-enabled techniques successfully mitigate conventional
    handovers, handover failures. Similarly, another deep learning model called Long
    Short-Term-Memory (LSTM) is utilized for solving handover problems, where it exploits
    the history of past and future mobility and provides the prediction of sequence,
    trajectories of vehicles to optimize the handover parameters.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*车载网络中的 AI 角色：* 随着 6G 网络的演进，大规模车载网络应具有超高速度和低延迟，对进化不敏感。因此，高效的移动性管理是实现端到端可靠和低延迟通信的重要参数。高速车载用户的移动性模式不断被流行的深度学习结构（如
    RNN 和 ANN）学习。这些 AI 启用的技术成功地缓解了传统的切换、切换失败。同样，另一个称为长短期记忆（LSTM）的深度学习模型被用于解决切换问题，它利用了过去和未来移动性的历史，并提供了车辆的序列、轨迹的预测以优化切换参数。'
- en: A multilayered LSTM integrated with autoencoder is used to resolve the frequent
    handover problems in wireless communication.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 多层 LSTM 与自动编码器集成，用于解决无线通信中频繁切换的问题。
- en: 4.3 AI-Based Spectrum Management
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 基于 AI 的频谱管理
- en: The evolution of 6G networks requires exceptional frequency spectrum such as
    low RF, millimeter wave, THz, and visible band to provide excessive information
    data rates, as illustrated in Fig. [4](#Fig4) [[9](#CR9), [10](#CR10)]. When a
    broad range of gadgets are used in 6G networks, it leads to spectrum management.
    AI enabled is considered a successful technique for making massive connectivities
    among devices, as shown in Fig. [4](#Fig4).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 6G 网络的演进需要特殊的频谱，如低 RF、毫米波、THz 和可见光波段，以提供过量的信息数据速率，如图 [4](#Fig4) 所示[[9](#CR9)、[10](#CR10)]。当在
    6G 网络中使用广泛的设备时，会导致频谱管理。AI 启用被认为是实现设备间大量连接的成功技术，如图 [4](#Fig4) 所示。
- en: In general, AI-based structures have three layers, namely, input layer, hidden
    layer, and output layer. A wide range of spectrum datasets is given as input.
    Then it trains the hidden layers to find out considerable characteristics of spectrum
    utilization. At last, the effective spectrum management methods are derived in
    the output layer in the practical scenario to support numerous connectivity among
    devices.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一般来说，基于 AI 的结构有三层，即输入层、隐藏层和输出层。大量的频谱数据集作为输入。然后，它训练隐藏层找出频谱利用的重要特征。最后，在实际情景中在输出层中得到有效的频谱管理方法，以支持设备之间的众多连接。
- en: The proper training of the AI framework forces an offline training model to
    easily recognize online spectrum management solutions. Various spectrum bands
    could be better used for making remarkable transmissions with massive bandwidth,
    wherein low-frequency bands could be allocated for broadcasting information for
    satellite-ground transmissions.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI 框架的适当训练迫使离线训练模型轻松识别在线频谱管理解决方案。各种频谱波段可以更好地用于进行具有大带宽的显著传输，在其中低频波段可以用于广播卫星地面传输的信息。
- en: 5 AI-Enabled Dynamic Resource Allocation
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 AI 启用的动态资源分配
- en: In any wireless network, spectrum utilization, process computation, and architectures
    are crucial resources beyond 6G. Therefore, the enhancement of useful resource
    allocation is achieved by introducing dynamic resource allocation methods. Dynamic
    resource allocation is implemented with the aid of AI and blockchain technologies.
    AI-based dynamic resource utilization is discussed in this section [[11](#CR11)–[16](#CR16)].
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何无线网络中，频谱利用、过程计算和体系结构都是 6G 之外至关重要的资源。因此，引入动态资源分配方法来增强有用资源分配的实现。动态资源分配是通过引入
    AI 和区块链技术来实现的。本节讨论了基于 AI 的动态资源利用[[11](#CR11)–[16](#CR16)]。
- en: 5.1 Efficient Sharing of Radio Sources
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 无线电源的有效共享
- en: In wireless communication systems, effective usage of available radio resources
    is an essential process to improve uninterrupted service providing for users.
    Radio resource allocation methods are restricted based on various network parameters.
    For example, the uncertainty caused in information transmission at Wi-Fi networks
    subsequently affects the data rate and processing time. Dynamic, varying channel
    parameter creates interference, which is because of high traffic and mobility
    in the environment. Radio resource allocation has become a highly challenging
    task when forecasting the services for different kinds of users with a limited
    spectrum.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在无线通信系统中，有效利用可用的无线资源是改善用户提供无间断服务的必要过程。基于各种网络参数限制了无线资源分配方法。例如，在 Wi-Fi 网络中信息传输引起的不确定性随后影响数据速率和处理时间。动态变化的信道参数会产生干扰，这是由于环境中的高流量和移动性。当为不同类型的用户预测服务时，无线资源分配已成为一项极具挑战性的任务，而频谱有限。
- en: '*Categories of resource allocation:* Effective allocation of radio resources
    is classified as centralized or decentralized.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '*资源分配的分类：* 无线资源的有效分配被归类为集中式或分散式。'
- en: '*Centralized method:* These methods are processed mainly based on a single
    core entity that gathers information from the users of the wireless networks.
    After that, resources are allocated based on the capabilities of the network.
    These methods provide outstanding responses with compromised data transfer.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '*集中式方法：* 这些方法主要是基于一个单一的核心实体处理，该实体从无线网络的用户那里收集信息。然后，根据网络的能力分配资源。这些方法在牺牲数据传输的同时提供了出色的响应。'
- en: '*Decentralized method:* In the case of decentralized techniques, users are
    permitted to make selections on their own. These techniques are more flexible
    than centralized with the aid of sub-optimal results.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*分散式方法：* 在分散式技术的情况下，用户被允许自行选择。这些技术比集中式更灵活，但结果次优。'
- en: The above-discussed resource allocation schemes change based on the optimization
    techniques used for achieving throughput enhancement, processing delay, user fairness,
    energy, and spectral efficiency. So, the effective resource allocations are categorized
    based on the type of networks, optimization technique, and proposed machine learning
    algorithms.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 上述讨论的资源分配方案根据用于实现吞吐量增强、处理延迟、用户公平性、能源和频谱效率的优化技术而变化。因此，有效的资源分配根据网络类型、优化技术和提出的机器学习算法进行分类。
- en: Achieving optimal results in radio resource allocation is a tedious objective
    due to the requirement of various parameters. This could be solved by the heuristic
    approach, which loosens up the network expectations and finds a sensible alternate
    solution. But these methods are not promised to obtain excellent results. The
    other approach is theory-based game techniques; the network nodes are considered
    players are interrelating and influencing the other’s options. Each player has
    a couple of options to maximize utility. The main advantage of game theory approaches
    is the flexibility to alter based on network dynamics.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 由于需要各种参数，无线资源分配中实现最佳结果是一项繁琐的目标。这可以通过启发式方法来解决，该方法放宽了网络期望，并找到了一个合理的替代方案。但这些方法并不能保证获得优秀的结果。另一种方法是基于理论的博弈技术；网络节点被视为相互关联并影响其他节点选择的玩家。每个玩家都有一些选项来最大化效用。博弈论方法的主要优势是根据网络动态灵活调整。
- en: 5.2 AI-Based Dynamic Spectrum Allocation
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 基于人工智能的动态频谱分配
- en: Dynamic spectrum allocation could be solved by multi-agent deep reinforcement
    learning methods, wherein each user occupancy in the spectrum is referred to as
    the agent. In this approach, a multi-agent environment is considered a Markov
    game model. A Neighbor-Agent-Actor-Critic (NAAC) model is proposed to tackle the
    uncertainties in the environment. This model trains the neighbor nodes from the
    statistics in a centralized manner. The relationship among devices that share
    the spectrum at the same instance improves device performance like achievable
    data rate and spectrum efficiency. Reinforcement learning is used in such a network
    for training the nodes based on past records.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 动态频谱分配可以通过多智能体深度强化学习方法解决，在这种方法中，每个用户在频谱中的占用被称为智能体。在这种方法中，将多智能体环境视为马尔可夫博弈模型。提出了一种邻居-智能体-演员-评论家（NAAC）模型来处理环境中的不确定性。该模型以集中式方式从统计数据中训练相邻节点。在同一时刻共享频谱的设备之间的关系可以提高设备的性能，如可达数据速率和频谱效率。在这样的网络中使用强化学习来根据过去的记录训练节点。
- en: 5.3 AI-Based Distributed Spectrum Access
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 基于 AI 的分布式频谱访问
- en: Distributed dynamic resource access could be developed for common real-time
    networks effectively. At the same time, the computational consumption of huge
    networks and incomplete observations in the network should be eliminated. LSTM
    approach is employed to achieve the mentioned objective, which has an internal
    layer with combinations of previously measured values. A dual Deep-Q-Network (DQN)
    is also employed to reach expected rewards from unknown states. Users need to
    use their trained DQN weight values by communicating with the central unit and
    then map its local commentary to spectrum get entry to move based on the learned
    DQN.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式动态资源访问可以有效地为常规实时网络开发。同时，需要消除大型网络中的计算消耗和网络中的不完全观测。采用 LSTM 方法来实现上述目标，它具有一个内部层，其中包含先前测量值的组合。还采用了双
    Deep-Q-Network（DQN）来从未知状态中获得预期奖励。用户需要通过与中央单元通信来使用其训练过的 DQN 权重值，然后根据学习的 DQN 将其本地评论映射到频谱访问移动。
- en: 6 AI-Enabled Dynamic Resource Allocation
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 基于 AI 的动态资源分配
- en: As of now, there is no limitation on terahertz frequency band utilization. The
    spectra play an important role in some different applications, like satellite
    services, spectroscopy, and meteorology. As of late, the Federal Communications
    Commission has been putting resources into using terahertz ranges for portable
    administrations and applications. Accordingly, range sharing strategies are important
    in conjunction with future terahertz interchanges and the other applications recorded
    beforehand. What's more, as examined in the past area, 6G networks will, in general,
    be multidimensional, super thick, and heterogeneous. Consequently, taking into
    account that the engendering medium and divert trademark in coordinated 6G networks
    are altogether unmistakable contrasted and earthbound organizations in 5G, it
    requires more exertion to upgrade the range of the executives of terahertz interchanges
    in 6G [[17](#CR17)–[20](#CR20)].
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，太赫兹频段利用没有限制。这些频谱在一些不同的应用中扮演着重要角色，如卫星服务、光谱学和气象学。最近，美国联邦通信委员会一直在投资利用太赫兹频段进行移动服务和应用。因此，与未来的太赫兹通信和前面列出的其他应用相结合，频谱共享策略变得重要。此外，正如在前一节中讨论的，6G
    网络往往是多维的、超密集的和异构的。因此，考虑到在 6G 中的太赫兹通信的传播介质和信道特征与 5G 中的地面网络完全不同，需要更多的努力来优化太赫兹通信的频谱管理。
- en: Reinforcement learning can possibly acknowledge the keen or astute range of
    the board to manage these issues, particularly when a lot of information can be
    utilized to prepare and anticipate. These preparation and forecast results can
    be exploited to settle on choices concerning whether the bandwidth is involved
    and to make a move, for example, getting to or delivering the range band. What's
    more, through the collaboration among clients and the remote climate, clients
    can enhance their methodologies iteratively to amplify the worth of remuneration
    capacities, which can be set up thinking about range productivity, network limit,
    devoured energy, obstruction, etc. Notwithstanding, reinforcement learning isn't
    skilled for learning a viable activity esteem strategy when there exist arbitrary
    commotion or estimation blunders involving the state perceptions, implying that
    the quantity of states within sight of irregular clamor is endless by and by.
    Resolving this issue of arbitrary state estimations, deep reinforcement learning
    is considered as an appropriate method to solve the streamline options in 6G networks,
    which incorporate flexible spectrum access, transmit power optimization, and radio
    spectrum allocation.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习可以可能认识到智能或精明的管理范围来解决这些问题，特别是当大量数据可以用于训练和预测时。这些训练和预测结果可以被利用来做出关于带宽是否被使用以及采取行动的决定，例如访问或释放频段。此外，通过用户与无线环境之间的互动，用户可以迭代优化他们的策略，以最大化补偿功能的价值，这可以考虑到频谱效率、网络容量、消耗的能量、干扰等因素。然而，当存在随机噪声或测量误差影响状态观测时，强化学习不能学习到有效的动作价值策略，这意味着在随机噪声存在的状态下的数量是无限的。为了解决这个随机状态测量的问题，深度强化学习被认为是解决
    6G 网络中优化选项的合适方法，其中包括灵活的频谱访问、发射功率优化和无线电频谱分配。
- en: 6.1 Reinforcement Learning-Enabled 6G Network
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 强化学习驱动的 6G 网络
- en: Recently, intensive analysis on developing Beyond 5G networks has been developed,
    moreover delivered up into 6G wireless networks which have geared toward transportation,
    ultra-reliable, low-latency conversation services. Reinforcement learning-based
    algorithms are adapted to obtain the possible resources from the environment to
    optimize the capacity in heterogeneous networks. For instance, if deep learning
    algorithms are used to improve performance, it requires huge memory for storing
    the data and high computational tasks. In the case of the reinforcement learning
    mechanism, the agent or device understands the actions to be taken in order to
    maximize the reward for the related actions. Therefore, a reinforcement learning-based
    algorithm learns the possible protocols and actions to match the recent dynamic
    unknown states. These algorithms create a new environment with states, actions,
    rewards, and state-action transition probabilities. It has been proven that reinforcement
    learning algorithms are more suitable for future generation networks.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 近期，对发展超越5G网络进行了深入分析，而后又发展到面向交通、超可靠、低延迟通信服务的6G无线网络。基于强化学习的算法被调整以从环境中获取可能的资源，以优化异构网络中的容量。例如，如果使用深度学习算法来提高性能，则需要大量内存来存储数据和高计算任务。在强化学习机制的情况下，代理或设备了解要执行的动作，以使相关动作的奖励最大化。因此，基于强化学习的算法学习可能的协议和动作，以匹配最近的动态未知状态。这些算法创建了具有状态、动作、奖励和状态-动作转移概率的新环境。已经证明，强化学习算法更适合未来一代网络。
- en: '*Basics RL-based approach:* The conventional interaction between agent and
    environment is illustrated in Fig. [6](#Fig6). The standard reinforcement learning
    algorithm has three terms such as (i) Policy, (ii) Reward, and (iii) States. *Policy:*
    Policy is an essential part of reinforcement learning algorithm; it defines the
    method to describe about how an agent could interact with the environment. *Reward:*
    For every action, the agent gains reward/feedback from the system. Based on the
    value obtained as a reward, decide the possible state-action policy for that particular
    application/environment. *Q-function:* It describes how long the algorithm earns
    a reward for the action taken. The reward for the accurate action must be small,
    but it would be considered as a worthy Q-value for long-haul operation (Figs.
    [8](#Fig8) and [9](#Fig9)).![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig8_HTML.png)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '*基本强化学习方法：*图 [6](#Fig6)中描述了代理与环境之间的传统交互。标准的强化学习算法有三个术语，如(i)策略、(ii)奖励和(iii)状态。*策略：*策略是强化学习算法的重要部分；它定义了描述代理如何与环境交互的方法。*奖励：*对于每个动作，代理从系统中获得奖励/反馈。根据所获得的奖励值，决定该特定应用/环境的可能状态-动作策略。*Q函数：*它描述了算法为采取的行动获得奖励的时间长度。对于准确行动的奖励必须很小，但对于长途操作而言，它将被视为有价值的Q值（图 [8](#Fig8)和[9](#Fig9)）。![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig8_HTML.png)'
- en: Illustration depicts deep learning-based spectrum management. It is divided
    into sections- spectral management, spectrum dataset experience, R F spectrum,
    Visible spectrum.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 描述了基于深度学习的频谱管理。它分为几个部分-频谱管理、频谱数据集经验、RF频谱、可见光谱。
- en: Fig. 8
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图8
- en: Deep learning-based spectrum management
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 基于深度学习的频谱管理
- en: '![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig9_HTML.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig9_HTML.png)'
- en: Illustration depicts deep learning-based edge computing architecture. There
    is a central cloud server connected to core network, which connects to server
    1 transportation, server 2 agriculture, server 3 smart device.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 描述了基于深度学习的边缘计算架构。中央云服务器连接到核心网络，核心网络连接到服务器1交通、服务器2农业、服务器3智能设备。
- en: Fig. 9
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图9
- en: Deep learning-based edge computing architecture
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 基于深度学习的边缘计算架构
- en: Q-value for the action taken is given![$$Q\left(s,a\right)=r\left(s,a\right)+\gamma
    \mathrm{max}Q\left({s}^{,},a\right)$$](../images/517376_1_En_4_Chapter/517376_1_En_4_Chapter_TeX_Equ2.png)(2)The
    expression ([2](#Equ2)) states that Q-value achieved from being at state s and
    taking an action a, with the reward of r(s,a) plus the possible Q-value from the
    next state s^’. The typical Q-learning and deep Q-network is illustrated as shown
    in Fig. [10](#Fig10).![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig10_HTML.png)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 给定采取的行动的Q值！[$$Q\left(s,a\right)=r\left(s,a\right)+\gamma \mathrm{max}Q\left({s}^{,},a\right)$$](../images/517376_1_En_4_Chapter/517376_1_En_4_Chapter_TeX_Equ2.png)(2)该表达式([2](#Equ2))说明了来自于状态s并采取行动a的Q值，其奖励为r(s,a)，加上可能来自下一个状态s^'的Q值。典型的Q-learning和深度Q网络如图[10](#Fig10)所示。![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig10_HTML.png)
- en: Image of typical (a)Q-learning has a table with labels state, action, and Q-value
    and (b)deep Q-network has labels state, Q-value action 1, Q-value action 2 to
    Q-value action n.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的（a）Q-learning图中有一个带有标签状态、动作和Q值的表格，（b）深度Q网络有标签状态、Q值动作1、Q值动作2到Q值动作n。
- en: Fig. 10
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图10
- en: '**a** Q-learning. **b** Deep-Q-network'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**a** Q-learning。**b** 深度Q网络'
- en: Suppose the high-value action is taken very often with the help of the agent
    results in exploitation in unknown surroundings. Q-learning must be a part of
    all model-free reinforcement learning algorithms to solve the channel behavioral
    problems. It sets use of learning rate to change the ability of learning, bargain
    problem to carry higher/lower well worth to the long-run reward, immediate reward,
    and update in Q-value function to replace present Q-value perform. Most appropriate
    action decisions maximize the Q-value in the proposed algorithm. Deep-Q-learning
    methods are mostly used in cognitive radios and channel access in Wi-Fi networks.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 假设高价值行动在代理的帮助下经常被采取，导致在未知环境中的利用。 Q-learning必须成为所有无模型强化学习算法的一部分，以解决通道行为问题。它设置学习率来改变学习能力，解决问题以将更高/更低的价值赋予长期回报、即时回报，并在Q值函数中更新以替换当前Q值执行。在所提出的算法中，最合适的行动决策最大化了Q值。深度Q-learning方法主要用于认知无线电和Wi-Fi网络的信道访问。
- en: 6.2 Realization of RL-Based Framework for 6G Networks
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 实现了6G网络基于RL的框架
- en: In this section, the approximation of reinforcement learning algorithms to realize
    the channel state estimation for WLAN networks is discussed. A hybrid RL aware
    framework is proposed, wherein the main module executes the action plans (policy).
    *Learning phase:* The algorithm/model learns the channel behaviors from the stored
    channel state (data). *Exploitation:* The model optimizes the useful resources
    based on the training. Figure [11](#Fig11) illustrates the important layers of
    reinforcement learning-based architecture for WLANs in mIoT (mobile Internet of
    Things) environment. The model/system is trained at the AP to collect the channel
    behavior statistics from many state actions. The model placement is also performed
    to get quick responses to circumstance actions. The model could be re-trained
    again and again based on the updated measured records.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，讨论了将强化学习算法逼近到实现WLAN网络的信道状态估计。提出了一个混合RL感知框架，在其中主模块执行行动计划（策略）。*学习阶段：*算法/模型从存储的信道状态（数据）中学习信道行为。*利用：*模型基于训练优化有用资源。图[11](#Fig11)说明了用于mIoT（移动物联网）环境中WLAN的基于强化学习的架构的重要层次。该模型/系统在AP上进行训练，从许多状态行动中收集信道行为统计信息。模型放置也是为了对情景行动作出快速响应。模型可以根据更新的测量记录再次进行训练。
- en: '*Training phase:*'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*训练阶段：*'
- en: In the reinforcement learning framework, the model in a Wi-Fi environment learns
    the channel for state transition, which avoids possible collisions. Then, the
    BS collects the information of various agents/models during the uplink transmission.
    The probability of collision could be used for learning and algorithm to help
    the Medium Access Control (MAC)-Resource Allocation layer during frequency band
    selection. Then the gathered record is pre-processed with the reinforcement learning
    technique to learn the medium accurately. For example, the application of Q-learning
    transforms the gathered information as a reward value. Based on the application,
    the reward can be scaled between 0 and 1\. Even as developing the reinforcement
    learning-based model, protocols have to be considered. For instance, based on
    available resources, an AP may require the widest variety of related STAs. The
    policies are strongly related to the competencies of the Wi-Fi gadgets. Once the
    reinforcement learning algorithm on the BS produces the output, it's far disbursed
    all over the network environments to the STAs, which can be then arranged/remodeled
    to provide fast ideal spectrum aid allocation to new requests.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在强化学习框架中，Wi-Fi 环境中的模型学习状态转换的通道，以避免可能的碰撞。然后，基站在上行传输期间收集各种代理/模型的信息。碰撞的概率可以用于学习和算法，以帮助媒体访问控制（MAC）-资源分配层在频段选择时。然后，收集到的记录使用强化学习技术进行预处理，以准确地学习媒体。例如，Q-learning
    的应用将收集到的信息转换为奖励值。根据应用程序，奖励可以在 0 到 1 之间进行缩放。即使在开发基于强化学习的模型时，也必须考虑协议。例如，根据可用资源，AP
    可能需要最广泛的相关 STA。策略与 Wi-Fi 设备的能力密切相关。一旦基站上的强化学习算法产生输出，它就会分布到整个网络环境中的 STA，然后被重新安排/改造，以提供快速的理想频谱支持分配给新请求。
- en: '*Placement phase:*'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '*放置阶段：*'
- en: In this phase, BS can allocate a new spectrum for the requests or hand over
    the spectrum based on the stored behavior from state actions. BS processes the
    collected records as a part of the learning phase. The well-known Q-learning algorithm
    is applied on the AP to provide a reward-based response for future requests. The
    channel access or allocation status is communicated to the corresponding state
    actions.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，基站可以为请求分配新的频谱，或者基于存储的状态行为来移交频谱。基站处理收集到的记录作为学习阶段的一部分。知名的 Q-learning 算法被应用在
    AP 上，为未来的请求提供基于奖励的响应。通道访问或分配状态被传达给相应的状态行为。
- en: 6.3 Reinforcement Learning-Based Spectrum Management
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 基于强化学习的频谱管理
- en: There are no restrictions on using the THz spectrum. Satellite-TV link, spectroscopy,
    and meteorology occupied the THz spectrum already. Nowadays, cellular services
    and applications are also allowed to use the THz band. So, spectrum allocation
    and sharing methods proposed for sub-GHz [[21](#CR21)–[23](#CR23)] are essential
    in THz communications. Based on the discussion about 6G networks in the previous
    sections, future generation networks are high-dimensional, ultra-high density,
    and heterogeneous networks. Therefore, 6G networks should have better propagation
    medium and channel state estimation compared with conventional 5G networks. That
    is, more efforts should be involved in achieving spectrum management in THz communications.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在 THz 频谱上没有使用限制。卫星电视链接、光谱学和气象学已经占据了 THz 频谱。如今，移动通信服务和应用程序也被允许使用 THz 频段。因此，在
    THz 通信中，为子 GHz [[21](#CR21)–[23](#CR23)] 提出的频谱分配和共享方法至关重要。根据前几节对 6G 网络的讨论，未来的网络是高维度、超高密度和异构网络。因此，6G
    网络应该具有比传统的 5G 网络更好的传播介质和信道状态估计。也就是说，在 THz 通信中，应该投入更多的努力来实现频谱管理。
- en: Reinforcement learning algorithms have greater capabilities to solve the spectrum
    management problems in THz communication, though it involves a large amount of
    the previous history of records for learning. These learning and prediction mechanism
    results in high advantage while taking decisions for action. The actions find
    whether the spectrum is already occupied or free to further access/allocate the
    spectrum.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强化学习算法在解决 THz 通信中的频谱管理问题方面具有更大的能力，尽管它涉及大量的历史记录用于学习。这些学习和预测机制在做出行动决策时具有很大的优势。行动确定频谱是否已被占用或自由进一步访问/分配频谱。
- en: The continuous interaction between users and the wireless environment makes
    to optimize the proposed technique for the achievement of maximum reward values.
    The reward values are referred to spectrum efficiency, networkability, and interference
    mitigation and received signal strength depending upon the applications. Reinforcement
    learning also has a significant state-action-reward policy, which could process
    precisely though there is a constant presence of randomness in channel noise.
    In order to address these problems, deep reinforcement learning is utilized as
    an appropriate method for spectrum management of massively connected networks
    (Figs. [11](#Fig11) and [12](#Fig12)).![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig11_HTML.png)
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户与无线环境之间的持续交互使得优化所提出的技术以获得最大的奖励值成为可能。 奖励值是指频谱效率、网络性能和干扰消减以及接收到的信号强度，这取决于应用程序。
    强化学习还具有重要的状态-动作-奖励策略，尽管信道噪声中存在恒定的随机性。 为了解决这些问题，深度强化学习被用作大规模连接网络的频谱管理的合适方法（图[11](#Fig11)和[12](#Fig12)）。![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig11_HTML.png)
- en: Illustration of deep reinforcement learning as an appropriate method for spectrum
    management of massively connected networks is illustrated. It has R L agent, W
    L A N environment, exploration/ exploitation area.
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 描述了深度强化学习作为大规模连接网络频谱管理的合适方法。 它具有 R L 代理、W L A N 环境、探索/开发区域。
- en: Fig. 11
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11
- en: An example of deep reinforcement learning
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 深度强化学习的示例
- en: '![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig12_HTML.png)'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig12_HTML.png)'
- en: Illustration depicts key stages of R L-based WLAN in mIoT environment has R
    L aware framework, placement phase, training phase, and right sign arrows called
    observed input data, and optimized action.
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 描述了 mIoT 环境中基于 RL 的 WLAN 的关键阶段具有 R L 感知框架、放置阶段、训练阶段和称为观察输入数据的正确箭头的优化行动。
- en: Fig. 12
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 12
- en: Key stages of RL-based WLAN in *m*IoT environment
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*m*IoT 环境中基于 RL 的 WLAN 的关键阶段'
- en: 7 Conclusions
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: This chapter discusses the importance of resource management in Ultra-Reliable
    Low-Latent Communication (URLLC). The challenges and problems in the high-dimensional
    networks can be resolved by utilizing suitable machine learning/deep learning
    algorithms. We discussed the opportunities in terms of essentials of AI in resource
    management, applications of machine learning techniques in network management,
    machine learning-based spectrum prediction, efficient utilization of resources,
    dynamic resource allocation, and the role of reinforcement learning in solving
    problems.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了在超可靠低延迟通信（URLLC）中的资源管理的重要性。 通过利用适当的机器学习/深度学习算法，可以解决高维网络中的挑战和问题。 我们讨论了AI在资源管理方面的基本要素、机器学习技术在网络管理中的应用、基于机器学习的频谱预测、资源的高效利用、动态资源分配以及强化学习在解决问题中的作用的机会。
