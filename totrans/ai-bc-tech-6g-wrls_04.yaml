- en: © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022M.
    Dutta Borah et al. (eds.)AI and Blockchain Technology in 6G Wireless NetworkBlockchain
    Technologies[https://doi.org/10.1007/978-981-19-2868-0_4](https://doi.org/10.1007/978-981-19-2868-0_4)
  prefs: []
  type: TYPE_NORMAL
- en: AI-Enabled Intelligent Resource Management in 6G
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Vijayakumar Ponnusamy^([1](#Aff7) [ ](#ContactOfAuthor1)) and A. Vasuki^([2](#Aff8) [ ](#ContactOfAuthor2))(1)Department
    of ECE, SRM Institute of Science and Technology, SRM Nagar, Kattankulathur, Chengalpattu,
    603203, India(2)Department of ECE, SRM Institute of Science and Technology, Vadapalani
    campus, No.1\. Jawaharlal Nehru Road, Vadapalani, Chennai, 600026, IndiaVijayakumar Ponnusamy (Corresponding
    author)Email: [vijayakp@srmist.edu.in](mailto:vijayakp@srmist.edu.in)A. VasukiEmail:
    [vasukia@srmist.edu.in](mailto:vasukia@srmist.edu.in)'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next-generation 6G mobile networks are likely to be intelligent, highly
    dynamic, and extremely low latency to satisfy the needs of different diversified
    applications. With the increasing demand for wireless communications, resource
    management plays an essential role in providing higher data rates and extreme
    quality of service with the available resources. However, the complexity of allocating
    resources will become greater in the current ultra-dense heterogeneous infrastructures.
    With massive data and computing resources, the rapid progress of Artificial Intelligence
    (AI) eventually lightens the enormous capabilities needed for the future regularization
    of 6G and beyond. As a result, an AI-enabled network will be the most appropriate
    and suitable technique for intelligent resource management, automated network
    operations, and support in future complex 6G networks. This chapter will discuss
    the different machine learning techniques used for resource management in 6G networks,
    effective usage of available spectrum, prediction of the spectrum, and dynamic
    resource allocation.
  prefs: []
  type: TYPE_NORMAL
- en: KeywordsResource managementMassive connectivityNetwork management
  prefs: []
  type: TYPE_NORMAL
- en: 1 Essentials of AI in Resource Management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Development in wireless technologies still continues to satisfy demands for
    quick response time, higher bandwidth, and secure communication. All affordable
    physical layer technologies are utilized thoroughly after the development of post-3G
    systems in industries. This has led to the requirement of intelligent and optimized
    consumption of the available resources. In this section, we discuss the importance
    of resource management and the role of AI in resource management toward achieving
    efficient next-generation 6G networks [[1](#CR1)].
  prefs: []
  type: TYPE_NORMAL
- en: 1.1 Challenges in Resource Management Toward Massive Connected Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Resource management aims to obtain proper employment of constrained physical
    sources to fulfill numerous traffic needs and enhance the machine’s overall performance.
    The existing resource management techniques in academic usage are often developed
    for fixed networks. It depends upon the mathematical functions. In contrast, the
    conditions of the realistic wireless network are variable, which leads to regression
    of algorithms with high computational complexity. The application of assumed mathematical
    conditions of a static network in practical cases results in drastic performance
    loss. In addition to that, standard management schemes may be superior in extracting
    beneficial records related to users and networks. Various resource management
    techniques are desired for the massive number of nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2 Resource Management in 5G
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After the deployment of the 5G standards, academia and industries have started
    to focus on the next-generation wireless communication standard 6G. This technology
    achieves a high data rate of up to 1 Tb/s and a broadband frequency of 100 GHz
    to 3 THz [[2](#CR2)]. Apart from important evaluation parameters of communication,
    Artificial Intelligence (AI) has been accepted as the essential feature of 6G
    by researchers in recent times. Wherein the applications of machine learning algorithms
    are believed to provide an appropriate solution for many complex scenarios. Network
    intelligence is expected to meet the challenges of heterogeneous networks. Though
    machine learning techniques have been employed in various applications, there
    is still scope for the realization of automated cellular communication systems.
    The existing problems in communication systems, architectures, and their performance
    should be focused on making use of 6G technologies.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3 Resource Management from 5G to 6G
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The existence of AI can be seen in everyday scenarios. Nowadays, the amount
    of produced data by both machines and human is overwhelming, which exceeds the
    ability of humans to understand and digest that data and make decisions depending
    on that data. Thus, a hand of help from AI is needed to overcome such challenges.
    The 5G LTE communication system is a promising solution to provide a high user
    experience in terms of the provided speed, amount of data, and cost. However,
    due to its complexity, the technology of LTE needs some improvement in terms of
    resource management and optimization. With the aid of AI, these two challenges
    can be overcome. The AI represented by the improved Q-learning algorithm with
    the Self-Organizing Network (SON) concept in LTE is used to manage and optimize
    Handover (HO) parameters and processes in the system [[3](#CR3)].
  prefs: []
  type: TYPE_NORMAL
- en: AI has become necessary in day-to-day activities. The data produced by humans
    and machines is huge. There is a need for humans to understand the generated data
    and analyze it. This helps in making appropriate decisions. This can be easily
    solved by employing AI. The 5G LTE in communication has been considered as an
    auspicious solution in terms of speed, data rate, and cost. However, there is
    a need for some enhancements in resource management and optimization techniques
    which could be overcome by using AI techniques. AI-aided Q-learning algorithm
    along with Self-Organizing Network (SON) in LTE manages and optimizes the handover
    parameters and different stages in the system [[4](#CR4)]. The challenges in AI-based
    6G networks are depicted in Fig. [1](#Fig1). The role of AI-based algorithms is
    illustrated in Fig. [2](#Fig2).![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig1_HTML.png)
  prefs: []
  type: TYPE_NORMAL
- en: The model depicts the challenges for advancing M L-based 6G networks. It has
    Learning efficiency, End-to-end qualified service provision, Efficient dataset
    generation, Physical layer to ap-plication layer, Computation over-head deployment,
    Dynamic online learning for exploration, Feasibility verification, Distributed
    or centralized, Standardization, Scalability for global intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 1
  prefs: []
  type: TYPE_NORMAL
- en: Challenges in 6G networks
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig2_HTML.png)'
  prefs: []
  type: TYPE_IMG
- en: Model depicts the role of AI-based algorithms in wireless networks. Machine
    learning includes Supervised learning, Reinforcement learning and Unsupervised
    learning. Each with applications and algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 2
  prefs: []
  type: TYPE_NORMAL
- en: Role of AI algorithms in wireless networks
  prefs: []
  type: TYPE_NORMAL
- en: 2 Application of Machine Learning Techniques in Network Management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To fulfill the enormous requesting management, the growth of 6G has been considered
    as progress that overcomes the limits of improved broadband, unlimited access,
    and ultra-reliable latent management in 5G remote networks. As of late, the construction
    of 6G networks has been amazingly heterogeneous, thickly conveyed, and dynamic.
    In order to reach the best tight Quality of Service (QoS), this complex structure
    will lead to a defect in network activity routines. Therefore, machine learning
    is emerging as a crucial answer to acknowledge completely wise organization coordination
    and the executives. By gaining from unsure and dynamic conditions, machine learning-based
    medium assessment and bandwidth management will allow the executives to open up
    promising circumstances for bringing the amazing presentation of ultra-broadband
    strategies, like terahertz interchanges. Furthermore, difficulties carried by
    ultra-massive networks concerning power and end-to-end secure communication can
    be moderated by employing appropriate machine learning-based techniques. Also,
    shrewd versatility among the executives and asset assignment will ensure the ultra-unwavering
    quality and low inactivity of administrations. Concerning these issues, this chapter
    presents and studies some cutting-edge methods dependent on machine learning and
    their applications in 6G to help with ultra-broadband, ultra-massive access, and
    low inertness management [[5](#CR5)].
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 ML-Enabled Broadband Transmission in 6G Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The available spectrum is scarcely enough to satisfy the expanding needs. For
    example, some arising applications, like holography, may require a data rate of
    up Tb/sec, which is roughly three times of magnitude faster compared to average
    5G correspondences. Accordingly, THz correspondences, using groups within the
    scope of 0.1–10 THz such as 140, 220, and 340 GHz frequencies, are required to
    help an information pace of up to terabits each second. To accomplish such a limit
    moving toward execution, exact data of time-shifting channels is particularly
    imperative to advance the terahertz transfer speed portion and further develop
    range productivity. In this segment, we present some cutting-edge AI/ML applications
    in terahertz channel assessment and range the executives [[6](#CR6)].
  prefs: []
  type: TYPE_NORMAL
- en: At the terahertz recurrence groups, the channels experience the ill effects
    of high climatic retention coming about because of the water fume noticeable all
    around, which impacts misfortunes fundamentally. Moreover, the free-space path
    loss is likewise unavoidable actually as far as climatic constriction is concerned.
    Moreover, terahertz channels are seen as non-fixed, particularly for dynamic situations
    where the two clients and items may be moving. Accordingly, customary channel
    models dependent on suppositions of being fixed or semi-fixed can’t currently
    have any significant bearing on the ultra-wideband spectrum. Machine learning
    calculations are equipped to examine the correspondence information and foresee
    likely signs of misfortune in a guaranteed or obscure climate. Subsequently, a
    wide range of Artificial Intelligence calculations could be employed to the physical
    layer of 6G organizations that manage the hardships portrayed for ultra-wideband
    spectrum assessment.
  prefs: []
  type: TYPE_NORMAL
- en: In many applications, in order to further develop assessment precision in powerful
    situations, the Bayesian filter based on reinforcement learning has been acquainted
    with the direction of arrival assessment in THz directs in present examinations.
    In particular, the Bayesian channel executes the assessment of the current direction
    of arrival from both current estimation and past gauges. In this methodology,
    the earlier change probabilities between framework states are essential to the
    assessment execution of the Bayesian filter. A reinforcement learning algorithm
    could be employed to enhance the probabilities of state changes from the results
    of previous measures and henceforth work on the exhibition of the Bayesian filter.
    The major classifications and applications of machine learning algorithms are
    described below.
  prefs: []
  type: TYPE_NORMAL
- en: The learning algorithm which is based on enough and efficient training with
    labeled data is known as *supervised learning*. These algorithms can be acquainted
    with transmission path loss and shadowing forecast, obstruction board, channel
    assessment, etc. Some of the architectures, such as Deep Neural Networks (DNN),
    K-Nearest Neighbor (KNN), and Support Vector Machines (SVM), are based on supervised
    learning algorithms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: KNN algorithm is used for identifying and allocating the resources (spectrum/power/positioning)
    requirements. For example, as shown in Fig. [3](#Fig3), the new requirement can
    be categorized using KNN algorithm, where K = 3 represents the distance from the
    new sample (data) is calculated with three nearest data points. KNN uses Euclidean
    distance (d) for classification which is expressed in ([1](#Equ1))![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig3_HTML.png)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Graph depicts the new requirement can be categorized using the KNN algorithm
    used for identifying and allocating the resources (spectrum/power/positioning)
    requirements. The spot in the graph labeled new sample has arrows 1,2,3\. K equal
    3.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Fig. 3
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: An example of KNN
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![$$d=\sqrt{{\left({x}_{2}-{x}_{1}\right)}^{2}+{\left({y}_{2}-{y}_{1}\right)}^{2}}$$](../images/517376_1_En_4_Chapter/517376_1_En_4_Chapter_TeX_Equ1.png)(1)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Similarly, SVM also is used to solve handover problems in heterogeneous networks.
    Antenna selection in massive MIMO is achieved with the aid of an SVM classifier
    among hundreds of antennas. Estimating channel noise for effective network management.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In any wireless communication network, channel estimation and modeling play
    an essential role in determining the end-to-end performance of the communication
    system. These problems could be easily solved by yet another category of machine
    learning called unsupervised learning mechanisms. *Unsupervised learning* does
    not require training with labeled data. The major applications are suppressing
    interference, user clustering, and overcoming challenges in duplex mode. K-means
    clustering and fuzzy-C-means algorithms are some of the most popular unsupervised
    learning mechanisms in recent communication technologies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Multipath Component (MPC) analysis is an essential task in gathering information
    on the wireless channel. K-means clustering algorithm forms the grouping in the
    MPC to reduce the Euclidean distance between the data until it becomes converging.
    It groups the parameters such as the delay (t), azimuth angle of arrival (AoA),
    azimuth angle of departure (AoD), the elevation angle of arrival (EoA), and the
    elevation angle of departure (EoD) which have similar behavior. The following
    example illustrates the step by execution of K-means clustering:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step1: It starts initial clusters randomly with centers (k[1], k[2], k[3]),
    as shown in Fig. [4](#Fig4)a.![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig4_HTML.png)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Graphs illustrate the architecture of AI-enabled cell edge computing, cloud,
    and edge computing. (a) It starts initial clusters randomly with centers (k1,
    k2, k3). (b) It assigns each data point closest cluster center. (c) Move each
    cluster center to the mean of each cluster. (d) It calculates the clusters related
    to the new data points. (e) Recomputes the cluster centers (f) Move the cluster
    centers to cluster means.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An illustration of K-means clustering algorithm in unknown data points
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 2: It assigns each data point closest cluster center, as shown in Fig.
    [4](#Fig4)b.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 3: Move each cluster center to the mean of each cluster as shown in Fig.
    [4](#Fig4)c.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 4: It calculates the clusters related to the new data points as shown
    in Fig. [4](#Fig4)d.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 5: Recomputes the cluster centers as shown in Fig. [4](#Fig4)e.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 6: Move the cluster centers to cluster means as shown in Fig. [4](#Fig4)f.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Another important category is *Deep learning*. Deep learning algorithms are
    employed for extracting channel characteristics, finding dynamic channel information,
    detecting different modulated signals/symbols, and recovering the original raw
    input from encoded data. The major deep learning structures such as Convolutional
    Neural Network (CNN), Recurrent Neural Network, Deep feed Forward Neural Network,
    and Deep Belief Networks (DBN) could be employed depending upon the applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CNN could be applied for dynamic power control for improving Non-Line of Sight
    (NLOS) transmission, automatic modulation classification, and channel estimation
    in a next-generation wireless communication system. Localization in wireless networks
    is a challenging task because of shadowing and multi-path fading in indoor environments.
    In order to fulfill the requirements of 6G wireless communication, the THz spectrum
    provides ultra-wideband for application. An LSTM architecture (as illustrated
    in Fig. [5](#Fig5)) could explore the channel state information of THz wireless
    signals, AoA, received power, and delay which are useful parameters of the indoor
    environment. A series of temporal data (X[o], X[1], …X[t]) is given input to the
    LSTM.![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig5_HTML.png)
  prefs: []
  type: TYPE_NORMAL
- en: A LSTM architecture depicts series of temporal data (Xo, X1, …Xt) is given input
    to the LSTM.
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 5
  prefs: []
  type: TYPE_NORMAL
- en: An LSTM architecture
  prefs: []
  type: TYPE_NORMAL
- en: '*Reinforcement learning* is a combination of supervised and unsupervised learning
    algorithms. These algorithms are based on action rewards. The agent in the application
    continuously gets the information from the environment to take appropriate action.
    If the action is successful, the algorithm gets positive feedback to further explore
    the new unknown state. Reinforcement learning-based algorithms are mainly used
    in tracking the unknown wireless medium and choosing feasible modulation modes.
    Markov decision process, Q-learning, and fuzzy-reinforcement learning are algorithms
    used often.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Markov decision process applies probability to predict the future requirements
    based on the present observed state in the channel estimation process which is
    illustrated in Fig. [6](#Fig6).![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig6_HTML.png)
  prefs: []
  type: TYPE_NORMAL
- en: Model depicts an example of the Markov process the future requirements based
    on the observed state -y1, y2, y3 and hidden state S1, S2, S3.
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 6
  prefs: []
  type: TYPE_NORMAL
- en: An example of the Markov process
  prefs: []
  type: TYPE_NORMAL
- en: The application of the deep learning/machine learning algorithm in various levels
    of the 6G network is illustrated in Fig. [7](#Fig7).![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig7_HTML.png)
  prefs: []
  type: TYPE_NORMAL
- en: Model diagram illustrates the important layers of reinforcement learning based
    architecture for WLANs in mIoT (mobile Internet of Things) environment. It has
    images of Cloud-Fog/edge, S D N, T Hz Communication and smart city. It has sections
    intelligent network management and optimization in 6G and A L/M L technique.
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 7
  prefs: []
  type: TYPE_NORMAL
- en: Application of deep learning/machine learning algorithm in 6G network
  prefs: []
  type: TYPE_NORMAL
- en: 3 Application of Machine Learning Techniques in Network Management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, the necessity of machine learning in a massive connected network,
    spectrum prediction based on ML will be discussed [[7](#CR7)].
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Need for Massive Connectivity Management in 6G Network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In high-dimensional networks, connectivity among different devices can allow
    the terminals to create diversified integration with various levels of network
    and make the network to reach uplift in coverage. Because of the dynamic nature
    of the connectivity, there is a chance for inserting and removing devices to cope
    with massive connectivity effectively. The connectivity between network and physical
    layer bears with high delay in higher order networks. This delay results in data
    transfer, which could be optimized in their end-to-end connectivity. Managing
    connectivity among numerous devices depends on present wireless channel conditions,
    wherein the portability of Base Stations (BSs) makes getting channel state information
    more tedious.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Radio Resource Management in High-Dimensional Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In massively connected networks, coverage of indistinguishable areas is done
    by allowing many devices to the network. This results in severe interference in
    the network, which could be suppressed by using a scheduling mechanism. This technique
    provides information about the dynamic channel to improve scheduling among users.
    In contrast to hyperlinks between terrestrial BSs, the inter-satellite, inter-aerial,
    inter-satellite–aerial, and inter-satellite–terrestrial are non-ideal, and hence
    has a poor delay. So, there is a necessity for collaborative scheduling in massively
    connected networks. Moreover, long-distance and high-mobility shifting BSs lead
    to the severity in channel approximation, which makes designing the feasible algorithm
    as a complex one.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 AI-Enabled Automated 6G Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The key enables methods used in 5G networks such as software-defined networks;
    network function virtualization is considered in 6G networks also. These techniques
    have the capability of making self-defined networks that are suitable for 6G networks.
    Anyhow, these networks should be introduced with intelligence in the case of 6G
    networks. With the integration of artificial intelligence in wireless networks,
    intelligence could be achieved with sufficient training. So, machine learning/deep
    learning/Artificial Intelligence has been considered as the most suitable technique
    for developing 6G networks as self-defined networks.
  prefs: []
  type: TYPE_NORMAL
- en: The integration of Artificial Intelligence in software-defined networks can
    obtain effective network architecture. Good optimization applied in 6G makes it
    autonomous networks compared to 5G networks.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning-based network management has the ability to organize the network
    architecture, slice and collect different channel access technologies to get smooth
    networks, and satisfy the requirements of dynamic services and applications. The
    network performance metrics are continuously observed with the aid of AI-based
    optimization techniques. Based on the observations, network parameters could be
    updated to maintain the best services. These AI-based techniques can get practical
    network performance, which is considered as historical data. Network intelligence
    can also be obtained by deploying multilevel AI. In huge connected networks, AI
    could be integrated at the routers to forward the data. AI-enabled techniques
    were introduced in Radio Access Networks to manage multiple BS-related processes
    like portability and interference suppression. AI will enable the large IoT network
    to shift from the facts center to the edge of the community.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Application of Machine Learning Techniques in Network Management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will discuss how machine learning/deep learning techniques
    are used for allocating the available resources in terms of multi-access edge
    computing, mobility, handover management, and spectrum management [[8](#CR8)].
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Deep Learning-Based Multi-Access Edge Computing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Multi-access edge computing has become inevitable in the 6G networks. MEC furnishes
    mathematical and analytical computations and brings radio access networks to mere
    closeness with other devices. Because of their multidimensional, randomly uncertain,
    and dynamic properties, MEC’s firm-level maximization, whereabouts, and sample
    training are important aspects. Hence, a conventional Lagrangian duality algorithm
    may face threads under complex networks. AI-enabled strategies can retrieve past
    records to know and assist for optimization, forecasting, and choice in MEC. Figure [4](#Fig4)
    llustrates the architecture of AI-enabled cell edge computing, cloud and edge
    computing. As proven because of the confined capability, lightweight AI algorithms
    may be applied to offer clever programs for other situations like transportation
    and agriculture. For instance, reinforcement learning-based edge computing is
    helpful in resource management and is considered a model-free scheme since it
    is not essential to have any prerequisite knowledge about any area. This can be
    implemented in analyzing the changes in the environment and choosing the appropriate
    method in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Extensive deep learning algorithms are expected to furnish functional training
    on the central cloud server. The AI-enabled classification algorithm is utilized
    to optimize traffic flow decisions for different service applications that are
    dynamic and different. An AI-based cluster is used to reduce complexity in MEC
    servers instead of individual decisions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The data received from the edge computing servers can be well trained to extract
    inherent features automatically. In such cases, the deep learning algorithm could
    be suited to train the system model to obtain the type of service, traffic, and
    security for which it is designed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition to that, Deep Reinforcement Learning (DRL) is made active in finding
    adequate resource management policy in extremely complex and time-varying MEC
    networks. To map the decisions and the environment, optimal resource management
    policies are used. Edge devices are supported with high-quality services by adopting
    DRL to use historical knowledge by improving efficiency and accuracy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 4.2 AI-Based Handover Management
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Being 6G networks are highly discrete, multi-layer and large-dimensional, mobility,
    and handover management are highly challenging issues of 6G networks. Mobility
    prediction and handover are achieved by applying suitable AI techniques to achieve
    uninterrupted services.
  prefs: []
  type: TYPE_NORMAL
- en: '*Role of AI in UAV networks:* In the case of integrating UAV communication
    with 6G networks, this results in frequent handovers. Suppose, if UAV communications
    are combined with 6G networks, and the fast dynamic mobility of UAVs results in
    established handovers. Furthermore, the subject is extended in processing efficient
    handover due to the numerous provider needs such as high statistics, high trustability,
    and low latency. The immoderate mobility of devices and UAVs results in unpredictability
    about their locations. This problem could be resolved by one of the AI techniques,
    reinforcement learning. It learns to optimize the handover techniques in the practical
    scenario to explore the mobility behaviors of devices/UAVs in online mode. This
    approach reduces the transmission delay and ensures reliable Wi-Fi connectivity.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure [4](#Fig4) shows the factors of shrewd mobility and handover management
    based on DRL in UAV-enabled networks. In these networks, every UAV can act as
    an agent to interact with the environment, thereby enhancing the network coverage.
    Each agent observes the nearby states and finds the most appropriate action to
    achieve the positive reward. The reward can be manipulated with the help of connectivity,
    delay, and feedback from the environment. DRL-based UAV network can have the ability
    to process handover mechanically and reduce the delay, handover failure probability.
    At the same time, it offers the best grade of service.
  prefs: []
  type: TYPE_NORMAL
- en: '*Role of AI in Vehicular networks:* Large-scale vehicular networks should have
    ultra-high speed and low delay insensitive with the evolution of 6G networks.
    Therefore, efficient mobility management is an essential parameter to achieve
    end-to-end reliable and low latent communication. The mobility patterns of high-speed
    vehicular users are continuously learned by the popular deep learning structures
    like RNN and ANN. These AI-enabled techniques successfully mitigate conventional
    handovers, handover failures. Similarly, another deep learning model called Long
    Short-Term-Memory (LSTM) is utilized for solving handover problems, where it exploits
    the history of past and future mobility and provides the prediction of sequence,
    trajectories of vehicles to optimize the handover parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: A multilayered LSTM integrated with autoencoder is used to resolve the frequent
    handover problems in wireless communication.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 AI-Based Spectrum Management
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The evolution of 6G networks requires exceptional frequency spectrum such as
    low RF, millimeter wave, THz, and visible band to provide excessive information
    data rates, as illustrated in Fig. [4](#Fig4) [[9](#CR9), [10](#CR10)]. When a
    broad range of gadgets are used in 6G networks, it leads to spectrum management.
    AI enabled is considered a successful technique for making massive connectivities
    among devices, as shown in Fig. [4](#Fig4).
  prefs: []
  type: TYPE_NORMAL
- en: In general, AI-based structures have three layers, namely, input layer, hidden
    layer, and output layer. A wide range of spectrum datasets is given as input.
    Then it trains the hidden layers to find out considerable characteristics of spectrum
    utilization. At last, the effective spectrum management methods are derived in
    the output layer in the practical scenario to support numerous connectivity among
    devices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The proper training of the AI framework forces an offline training model to
    easily recognize online spectrum management solutions. Various spectrum bands
    could be better used for making remarkable transmissions with massive bandwidth,
    wherein low-frequency bands could be allocated for broadcasting information for
    satellite-ground transmissions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 5 AI-Enabled Dynamic Resource Allocation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In any wireless network, spectrum utilization, process computation, and architectures
    are crucial resources beyond 6G. Therefore, the enhancement of useful resource
    allocation is achieved by introducing dynamic resource allocation methods. Dynamic
    resource allocation is implemented with the aid of AI and blockchain technologies.
    AI-based dynamic resource utilization is discussed in this section [[11](#CR11)–[16](#CR16)].
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Efficient Sharing of Radio Sources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In wireless communication systems, effective usage of available radio resources
    is an essential process to improve uninterrupted service providing for users.
    Radio resource allocation methods are restricted based on various network parameters.
    For example, the uncertainty caused in information transmission at Wi-Fi networks
    subsequently affects the data rate and processing time. Dynamic, varying channel
    parameter creates interference, which is because of high traffic and mobility
    in the environment. Radio resource allocation has become a highly challenging
    task when forecasting the services for different kinds of users with a limited
    spectrum.
  prefs: []
  type: TYPE_NORMAL
- en: '*Categories of resource allocation:* Effective allocation of radio resources
    is classified as centralized or decentralized.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Centralized method:* These methods are processed mainly based on a single
    core entity that gathers information from the users of the wireless networks.
    After that, resources are allocated based on the capabilities of the network.
    These methods provide outstanding responses with compromised data transfer.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Decentralized method:* In the case of decentralized techniques, users are
    permitted to make selections on their own. These techniques are more flexible
    than centralized with the aid of sub-optimal results.'
  prefs: []
  type: TYPE_NORMAL
- en: The above-discussed resource allocation schemes change based on the optimization
    techniques used for achieving throughput enhancement, processing delay, user fairness,
    energy, and spectral efficiency. So, the effective resource allocations are categorized
    based on the type of networks, optimization technique, and proposed machine learning
    algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Achieving optimal results in radio resource allocation is a tedious objective
    due to the requirement of various parameters. This could be solved by the heuristic
    approach, which loosens up the network expectations and finds a sensible alternate
    solution. But these methods are not promised to obtain excellent results. The
    other approach is theory-based game techniques; the network nodes are considered
    players are interrelating and influencing the other’s options. Each player has
    a couple of options to maximize utility. The main advantage of game theory approaches
    is the flexibility to alter based on network dynamics.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 AI-Based Dynamic Spectrum Allocation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Dynamic spectrum allocation could be solved by multi-agent deep reinforcement
    learning methods, wherein each user occupancy in the spectrum is referred to as
    the agent. In this approach, a multi-agent environment is considered a Markov
    game model. A Neighbor-Agent-Actor-Critic (NAAC) model is proposed to tackle the
    uncertainties in the environment. This model trains the neighbor nodes from the
    statistics in a centralized manner. The relationship among devices that share
    the spectrum at the same instance improves device performance like achievable
    data rate and spectrum efficiency. Reinforcement learning is used in such a network
    for training the nodes based on past records.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3 AI-Based Distributed Spectrum Access
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Distributed dynamic resource access could be developed for common real-time
    networks effectively. At the same time, the computational consumption of huge
    networks and incomplete observations in the network should be eliminated. LSTM
    approach is employed to achieve the mentioned objective, which has an internal
    layer with combinations of previously measured values. A dual Deep-Q-Network (DQN)
    is also employed to reach expected rewards from unknown states. Users need to
    use their trained DQN weight values by communicating with the central unit and
    then map its local commentary to spectrum get entry to move based on the learned
    DQN.
  prefs: []
  type: TYPE_NORMAL
- en: 6 AI-Enabled Dynamic Resource Allocation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As of now, there is no limitation on terahertz frequency band utilization. The
    spectra play an important role in some different applications, like satellite
    services, spectroscopy, and meteorology. As of late, the Federal Communications
    Commission has been putting resources into using terahertz ranges for portable
    administrations and applications. Accordingly, range sharing strategies are important
    in conjunction with future terahertz interchanges and the other applications recorded
    beforehand. What's more, as examined in the past area, 6G networks will, in general,
    be multidimensional, super thick, and heterogeneous. Consequently, taking into
    account that the engendering medium and divert trademark in coordinated 6G networks
    are altogether unmistakable contrasted and earthbound organizations in 5G, it
    requires more exertion to upgrade the range of the executives of terahertz interchanges
    in 6G [[17](#CR17)–[20](#CR20)].
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning can possibly acknowledge the keen or astute range of
    the board to manage these issues, particularly when a lot of information can be
    utilized to prepare and anticipate. These preparation and forecast results can
    be exploited to settle on choices concerning whether the bandwidth is involved
    and to make a move, for example, getting to or delivering the range band. What's
    more, through the collaboration among clients and the remote climate, clients
    can enhance their methodologies iteratively to amplify the worth of remuneration
    capacities, which can be set up thinking about range productivity, network limit,
    devoured energy, obstruction, etc. Notwithstanding, reinforcement learning isn't
    skilled for learning a viable activity esteem strategy when there exist arbitrary
    commotion or estimation blunders involving the state perceptions, implying that
    the quantity of states within sight of irregular clamor is endless by and by.
    Resolving this issue of arbitrary state estimations, deep reinforcement learning
    is considered as an appropriate method to solve the streamline options in 6G networks,
    which incorporate flexible spectrum access, transmit power optimization, and radio
    spectrum allocation.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 Reinforcement Learning-Enabled 6G Network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Recently, intensive analysis on developing Beyond 5G networks has been developed,
    moreover delivered up into 6G wireless networks which have geared toward transportation,
    ultra-reliable, low-latency conversation services. Reinforcement learning-based
    algorithms are adapted to obtain the possible resources from the environment to
    optimize the capacity in heterogeneous networks. For instance, if deep learning
    algorithms are used to improve performance, it requires huge memory for storing
    the data and high computational tasks. In the case of the reinforcement learning
    mechanism, the agent or device understands the actions to be taken in order to
    maximize the reward for the related actions. Therefore, a reinforcement learning-based
    algorithm learns the possible protocols and actions to match the recent dynamic
    unknown states. These algorithms create a new environment with states, actions,
    rewards, and state-action transition probabilities. It has been proven that reinforcement
    learning algorithms are more suitable for future generation networks.
  prefs: []
  type: TYPE_NORMAL
- en: '*Basics RL-based approach:* The conventional interaction between agent and
    environment is illustrated in Fig. [6](#Fig6). The standard reinforcement learning
    algorithm has three terms such as (i) Policy, (ii) Reward, and (iii) States. *Policy:*
    Policy is an essential part of reinforcement learning algorithm; it defines the
    method to describe about how an agent could interact with the environment. *Reward:*
    For every action, the agent gains reward/feedback from the system. Based on the
    value obtained as a reward, decide the possible state-action policy for that particular
    application/environment. *Q-function:* It describes how long the algorithm earns
    a reward for the action taken. The reward for the accurate action must be small,
    but it would be considered as a worthy Q-value for long-haul operation (Figs.
    [8](#Fig8) and [9](#Fig9)).![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig8_HTML.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Illustration depicts deep learning-based spectrum management. It is divided
    into sections- spectral management, spectrum dataset experience, R F spectrum,
    Visible spectrum.
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 8
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning-based spectrum management
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig9_HTML.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration depicts deep learning-based edge computing architecture. There
    is a central cloud server connected to core network, which connects to server
    1 transportation, server 2 agriculture, server 3 smart device.
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 9
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning-based edge computing architecture
  prefs: []
  type: TYPE_NORMAL
- en: Q-value for the action taken is given![$$Q\left(s,a\right)=r\left(s,a\right)+\gamma
    \mathrm{max}Q\left({s}^{,},a\right)$$](../images/517376_1_En_4_Chapter/517376_1_En_4_Chapter_TeX_Equ2.png)(2)The
    expression ([2](#Equ2)) states that Q-value achieved from being at state s and
    taking an action a, with the reward of r(s,a) plus the possible Q-value from the
    next state s^’. The typical Q-learning and deep Q-network is illustrated as shown
    in Fig. [10](#Fig10).![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig10_HTML.png)
  prefs: []
  type: TYPE_NORMAL
- en: Image of typical (a)Q-learning has a table with labels state, action, and Q-value
    and (b)deep Q-network has labels state, Q-value action 1, Q-value action 2 to
    Q-value action n.
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 10
  prefs: []
  type: TYPE_NORMAL
- en: '**a** Q-learning. **b** Deep-Q-network'
  prefs: []
  type: TYPE_NORMAL
- en: Suppose the high-value action is taken very often with the help of the agent
    results in exploitation in unknown surroundings. Q-learning must be a part of
    all model-free reinforcement learning algorithms to solve the channel behavioral
    problems. It sets use of learning rate to change the ability of learning, bargain
    problem to carry higher/lower well worth to the long-run reward, immediate reward,
    and update in Q-value function to replace present Q-value perform. Most appropriate
    action decisions maximize the Q-value in the proposed algorithm. Deep-Q-learning
    methods are mostly used in cognitive radios and channel access in Wi-Fi networks.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2 Realization of RL-Based Framework for 6G Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, the approximation of reinforcement learning algorithms to realize
    the channel state estimation for WLAN networks is discussed. A hybrid RL aware
    framework is proposed, wherein the main module executes the action plans (policy).
    *Learning phase:* The algorithm/model learns the channel behaviors from the stored
    channel state (data). *Exploitation:* The model optimizes the useful resources
    based on the training. Figure [11](#Fig11) illustrates the important layers of
    reinforcement learning-based architecture for WLANs in mIoT (mobile Internet of
    Things) environment. The model/system is trained at the AP to collect the channel
    behavior statistics from many state actions. The model placement is also performed
    to get quick responses to circumstance actions. The model could be re-trained
    again and again based on the updated measured records.
  prefs: []
  type: TYPE_NORMAL
- en: '*Training phase:*'
  prefs: []
  type: TYPE_NORMAL
- en: In the reinforcement learning framework, the model in a Wi-Fi environment learns
    the channel for state transition, which avoids possible collisions. Then, the
    BS collects the information of various agents/models during the uplink transmission.
    The probability of collision could be used for learning and algorithm to help
    the Medium Access Control (MAC)-Resource Allocation layer during frequency band
    selection. Then the gathered record is pre-processed with the reinforcement learning
    technique to learn the medium accurately. For example, the application of Q-learning
    transforms the gathered information as a reward value. Based on the application,
    the reward can be scaled between 0 and 1\. Even as developing the reinforcement
    learning-based model, protocols have to be considered. For instance, based on
    available resources, an AP may require the widest variety of related STAs. The
    policies are strongly related to the competencies of the Wi-Fi gadgets. Once the
    reinforcement learning algorithm on the BS produces the output, it's far disbursed
    all over the network environments to the STAs, which can be then arranged/remodeled
    to provide fast ideal spectrum aid allocation to new requests.
  prefs: []
  type: TYPE_NORMAL
- en: '*Placement phase:*'
  prefs: []
  type: TYPE_NORMAL
- en: In this phase, BS can allocate a new spectrum for the requests or hand over
    the spectrum based on the stored behavior from state actions. BS processes the
    collected records as a part of the learning phase. The well-known Q-learning algorithm
    is applied on the AP to provide a reward-based response for future requests. The
    channel access or allocation status is communicated to the corresponding state
    actions.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3 Reinforcement Learning-Based Spectrum Management
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are no restrictions on using the THz spectrum. Satellite-TV link, spectroscopy,
    and meteorology occupied the THz spectrum already. Nowadays, cellular services
    and applications are also allowed to use the THz band. So, spectrum allocation
    and sharing methods proposed for sub-GHz [[21](#CR21)–[23](#CR23)] are essential
    in THz communications. Based on the discussion about 6G networks in the previous
    sections, future generation networks are high-dimensional, ultra-high density,
    and heterogeneous networks. Therefore, 6G networks should have better propagation
    medium and channel state estimation compared with conventional 5G networks. That
    is, more efforts should be involved in achieving spectrum management in THz communications.
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning algorithms have greater capabilities to solve the spectrum
    management problems in THz communication, though it involves a large amount of
    the previous history of records for learning. These learning and prediction mechanism
    results in high advantage while taking decisions for action. The actions find
    whether the spectrum is already occupied or free to further access/allocate the
    spectrum.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The continuous interaction between users and the wireless environment makes
    to optimize the proposed technique for the achievement of maximum reward values.
    The reward values are referred to spectrum efficiency, networkability, and interference
    mitigation and received signal strength depending upon the applications. Reinforcement
    learning also has a significant state-action-reward policy, which could process
    precisely though there is a constant presence of randomness in channel noise.
    In order to address these problems, deep reinforcement learning is utilized as
    an appropriate method for spectrum management of massively connected networks
    (Figs. [11](#Fig11) and [12](#Fig12)).![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig11_HTML.png)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Illustration of deep reinforcement learning as an appropriate method for spectrum
    management of massively connected networks is illustrated. It has R L agent, W
    L A N environment, exploration/ exploitation area.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Fig. 11
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: An example of deep reinforcement learning
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../images/517376_1_En_4_Chapter/517376_1_En_4_Fig12_HTML.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Illustration depicts key stages of R L-based WLAN in mIoT environment has R
    L aware framework, placement phase, training phase, and right sign arrows called
    observed input data, and optimized action.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Fig. 12
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Key stages of RL-based WLAN in *m*IoT environment
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 7 Conclusions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This chapter discusses the importance of resource management in Ultra-Reliable
    Low-Latent Communication (URLLC). The challenges and problems in the high-dimensional
    networks can be resolved by utilizing suitable machine learning/deep learning
    algorithms. We discussed the opportunities in terms of essentials of AI in resource
    management, applications of machine learning techniques in network management,
    machine learning-based spectrum prediction, efficient utilization of resources,
    dynamic resource allocation, and the role of reinforcement learning in solving
    problems.
  prefs: []
  type: TYPE_NORMAL
