- en: CHAPTER 17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Yuanfen
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When Stephen Balaban proposed to Betty Meng, the skies above blessed the event
    with a giant diamond ring. He had first glimpsed her across a crowded room at
    Oren’s Hummus Shop on University Avenue in Palo Alto four years earlier. Now,
    on the morning of August 21, 2017, the two were standing in Madras, Oregon, at
    an optimal point in the seventy-mile-wide “path of totality” of the solar eclipse.
  prefs: []
  type: TYPE_NORMAL
- en: The winter stars came out. An eclipse wind chilled the air. Two minutes and
    four seconds of daytime darkness passed. Eerie bands of shadow shimmered on the
    ground. Then, at exactly 10:29 a.m., the sun signaled its return. The expected
    diamond of sunlight burst out from behind the moon, and Stephen presented his
    girlfriend with a terrestrial version. The awed Betty said yes.
  prefs: []
  type: TYPE_NORMAL
- en: 'As Peter Thiel writes in Zero to One, “every great entrepreneur is first and
    foremost a designer. . . . ”[¹](notes.html#ch17note-1) But the designs do not
    always work on the first try. Balaban had bought that diamond ring on the crest
    of a sudden, unexpected, and growing wave of business success doing something
    no one, including himself, expected him to do: beat Google and Amazon at one of
    their own games. But a crucible of deep learning preceded this triumphal proposal
    scene.'
  prefs: []
  type: TYPE_NORMAL
- en: Fluent in Mandarin, Balaban went to Beijing in 2010 as a college senior, taking
    a semester off from studying computer science and economics at the University
    of Michigan. In China, he helped found “a clone,” as he describes it, of the Y-Combinator
    startup accelerator. He named it for Yuan Fen, the Chinese concept of the fate
    that brings people together. He had the educational experience of eventually watching
    the venture fizzle because of conflicts among the founders.
  prefs: []
  type: TYPE_NORMAL
- en: Returning to Michigan, he took his degree and headed for Silicon Valley—after
    Beijing, “the real deal.” He moved into a room in San Francisco’s historic Chinatown
    with its own sink and a shared bathroom down the hall, an hour by bicycle and
    Caltrain from Palo Alto. It was April 2012, and Balaban was starting a company
    to teach machines to see and learn, working on face recognition for mobile devices.
    He gave this company a Greek rather than a Chinese name—Lambda Labs—after Alonzo
    Church’s universal model of computation, an American version of a Turing machine.
  prefs: []
  type: TYPE_NORMAL
- en: In 2012, people knew that face recognition was coming to handsets, but no one
    had been able to make it compact and fast enough. Balaban’s work caught the attention
    of the academic image gurus Zak Stone and Nicolas Pinto at Perceptio Corporation,
    and they hired him in November to develop mobile face recognition technology for
    the iPhone.
  prefs: []
  type: TYPE_NORMAL
- en: Like all such projects by then, this one would be based on deep neural-network
    processing. But it was mobile machine learning, Balaban explains, “meaning running
    face recognition and other neural nets on the phone’s own graphics processing
    unit, not even uploading to the sky.” He saw that artificial intelligence did
    not need to take place in giant data warehouses. This was a contrarian insight
    worthy of a Thiel Fellow (and by mid-2013 he was living with two of them, Austin
    Russell and Thomas Sohmers), but it took some years before he capitalized on it.
    “Basically I was learning deep learning.”
  prefs: []
  type: TYPE_NORMAL
- en: He left Perceptio in November 2013\. Two years later, Stone and Pinto sold the
    company to Apple for $200 million. Its face-recognition functions are now standard
    in new iPhones. Meanwhile, Balaban lured his fraternal twin brother, Michael,
    away from the growing success story NextDoor, which provides localized information
    and services, to be chief technology officer of Lambda Labs. Michael seems to
    have shared his twin’s impeccable timing—by 2015, NextDoor had become a unicorn
    worth more than a billion dollars.
  prefs: []
  type: TYPE_NORMAL
- en: The Balabans started working on hardware. Using portable AI and face recognition,
    they conceived a wearable camera embedded in a baseball cap, resembling Google
    Glass or Snapchat spectacles. The problem was that no one in Silicon Valley could
    build the “Lambda Hat” prototypes, so Stephen was back in China for six months
    of exploring the manufacturing hives of Shenzhen, across the bay from Hong Kong.
    He ended up with a cool hat, better Mandarin, and a sharper sales pitch but no
    manufacturer or market for the product. “The technology was not mature,” Stephen
    decided.
  prefs: []
  type: TYPE_NORMAL
- en: Despite the disappointment, he still did not want to work on “something that
    wasn’t mine.” In early 2015, Gary Bradski—the robotics pioneer who developed computer
    vision at Intel, founded the Willow Garage robotics incubator, which convinced
    Wired’s Kevin Kelly that “robots have wants,” and started Industrial Perception,
    which made “stevedore robots” that could, as Stephen Balaban described it, “pick
    up and chuck a box so elegantly” that Google bought them—that Gary Bradski—invited
    Balaban to join his deep-learning team at Magic Leap. Launched in 2010, the Google-funded
    virtual reality venture in Florida had heretofore raised half a billion dollars
    while generating more national magazine covers than virtual reality advances.
    Neal Stephenson had just joined the company (as chief futurist), but Balaban wasn’t
    convinced, however magic and well-funded the leap.
  prefs: []
  type: TYPE_NORMAL
- en: What direction to leap instead?
  prefs: []
  type: TYPE_NORMAL
- en: In July 2015, the house in Atherton that Balaban, Austin Russell, and Thomas
    Sohmers were renting finally sold for its $10 million asking price. At the same
    time, Sohmers caught the eye of Thiel’s prestigious Founders Fund. Thiel put up
    $2 million to tape-out Sohmers’s new chip at Taiwan Semiconductor Manufacturing
    Company. Meanwhile, venture money from Thiel, 1517, and other funds rolled in
    for Russell’s “stealth” driverless car project up at Pony Tracks. And Balaban
    found an unexpected direction.
  prefs: []
  type: TYPE_NORMAL
- en: 'The month before, Chris Olah, Vitalik Buterin’s high school friend who beat
    him to the Thiel Fellowship and was now an intern at Google Brain, published a
    blog post with two Google software engineers. It was titled “Inceptionism: Going
    Deeper into Neural Networks.”[²](notes.html#ch17note-2)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The name itself was multilayered—a reference to the neural net architecture
    they were using, which in turn was a reference to an Internet meme about “going
    deeper,” which in turn was a quotation from the 2010 Christopher Nolan film Inception,
    in which a thief tunnels through other people’s dreams. The blog post laconically
    presented “some simple techniques for peeking inside these [neural] networks”
    and then showed a series of increasingly trippy photos, as if the machine were
    hallucinating. A little gray kitten became the stuff of nightmares: a shaggy beast
    with forehead and haunches bubbling with dark dog eyes and noses.'
  prefs: []
  type: TYPE_NORMAL
- en: To Balaban, the code and its results were a visual confirmation of what Yoshua
    Bengio, a colleague of Geoffrey Hinton in the Montreal crucible of AI, calls the
    “manifold learning hypothesis.” Bengio sees the essential job of a neural network
    as learning a hierarchy of representations in which each new layer is built up
    out of representations resolved in a previous layer. The machine begins with raw
    pixels and combines them into lines and curves transitioning from dark to light
    and then into geometrical shapes, which finally can be encoded into elements of
    human faces or other targeted figures. Scramble this process at an early stage
    and you get an artfully inflected picture; scramble it higher up in the hierarchy
    and you get a phantasia of “dream and nightmare” images, as Bengio puts it. In
    dreams and nightmares, as in machine-learning feedback loops, no new information
    is perceived. Without new inputs, the mind or machine churns the old images in
    intriguing but unresolved patterns.[³](notes.html#ch17note-3)
  prefs: []
  type: TYPE_NORMAL
- en: Balaban was one of hundreds of people who were captivated by Olah’s post. On
    July 1, Google released the code, now named “Deep Dream,” and coders leapt on
    the chance to make their own dream images.
  prefs: []
  type: TYPE_NORMAL
- en: Balaban himself set out to develop a deep learning-powered image editor for
    the general public, which he offered on a simple website with various filters,
    most with names extracted from either art (“charcoal,” “art deco”) or the psychedelic
    subculture (“salvia,” “self-transforming machine elves”).
  prefs: []
  type: TYPE_NORMAL
- en: It was less than two months before the 2015 Burning Man festival. The website
    “burners.me” discovered Balaban’s app, which he had named “Dreamscope,” and published
    a blog post referring to Philip K. Dick’s novel of slippery reality, Do Androids
    Dream of Electric Sheep? Thirteen vividly Dreamscoped Burning Man photographs
    followed, full of psychedelic eyes, mushrooming shaggy-dog faces, merging human
    chimeras, and iterated swirls.[⁴](notes.html#ch17note-4)
  prefs: []
  type: TYPE_NORMAL
- en: The Dreamscope app “took off faster than anything I had ever seen. . . . Millions
    of downloads in the first day,” remembers Balaban. “It was the first time people
    got a real peek into how neural networks could see the world.”
  prefs: []
  type: TYPE_NORMAL
- en: Then Stephen and Michael Balaban figured out how to support nearly one million
    users, each running his own little machine-learning gradient and editor. (Lambda
    Labs was still just the Balaban twins and their cousin.) Scaled up by a distributed
    queue-processing system, “it allowed us to add new nodes to the pool on demand.”
    The flaw was that all the GPUs were controlled by Amazon Web Services, which had
    to be paid.
  prefs: []
  type: TYPE_NORMAL
- en: Stephen Balaban was following the Google model of giving your product away and
    charging for “premium” subscriptions. The problem was that most of his “customers”
    found the free access to addictive psychedelic photo-paintings good enough. There
    were a hundred thousand takers for the $9.95 “premium edition,” but a million
    dollars wasn’t enough.
  prefs: []
  type: TYPE_NORMAL
- en: Within a few months, Dreamscope pretty much died of its own success. Amazon
    Web Service bills mounted to forty thousand dollars a month. The company still
    had $150,000 in the bank, but it was running out of runway. As Alexandra Wolfe
    documents in her rousing book on the initial class of Thiel Fellows, Valley of
    the Gods, not all their projects flourish, no matter how good their system of
    the world.
  prefs: []
  type: TYPE_NORMAL
- en: '“That’s the time most startups don’t make it,” Stephen says. That is also the
    time, as Danielle Strachman stresses, that the power of an entrepreneurial community
    comes into play. Balaban remembered appreciating that about Strachman and Gibson
    when he first encountered them: “Mike and Danielle recognize the emotional component
    of starting a company that a lot of people neglect—the emotional rollercoaster
    that is very draining. I observed that they were really good at making sure that
    everyone had support networks for when you are, in Elon Musk’s apt description,
    staring into the abyss and chewing on glass.”'
  prefs: []
  type: TYPE_NORMAL
- en: Facing the ballooning Amazon Web Services bills, Balaban went back to 1517;
    Danielle and Mike supplied another $150,000\. That extended the runway another
    four or five months. Not enough. Austin Russell invested twenty thousand dollars
    in it (he later added another hundred thousand), and so did Gary Bradski at Magic
    Leap, among others. Balaban managed to put together another half-million-dollar
    round.
  prefs: []
  type: TYPE_NORMAL
- en: At that point, he felt a visceral resistance to sending any more money to Amazon.
    He simply couldn’t do it. It was a “Zero to One” moment, defying the most settled
    consensus in the Valley, the assurance of venture capitalists that it is suicidal
    to compete with Amazon and Google by building infrastructure. This consensus was
    powerfully confirmed by two of the greatest success stories of the past decade,
    Netflix and Instagram, both of which scaled up to a valuation of scores of billions
    by using AWS. Balaban was told, “despite the cost, you focus on your users and
    scaling your business and let Amazon scale up the servers.”
  prefs: []
  type: TYPE_NORMAL
- en: Balaban, however, decided to quit AWS cold turkey. He spent sixty thousand dollars
    to build his own servers from scratch, influenced, perhaps, by Thomas Sohmers’s
    insight that present-day servers are kludges that waste 98 percent of their energy
    running data over wires to and from memory or sitting around in “wait states.”
    Balaban decided he had spent enough time and money on wait states. There had to
    be a better way than sending off terabytes of learning data over the Internet
    to a queue at the Amazon GPU farm. “It would be cheaper and faster,” he calculated,
    “to put them on disks and call Fed Ex.”
  prefs: []
  type: TYPE_NORMAL
- en: Epitomizing the excesses of the elaborate Amazon setup, in Balaban’s view, were
    top-of-the-line “machine learning” Tesla GPUs from Nvidia. He discovered that
    Nvidia’s gaming chips were not only ten times cheaper but also faster. What mattered
    to Balaban’s machine-learning algorithms were not all the custom “machine-learning
    features” but the number of usable floating-point operations per dollar. As Bill
    Dally had shown at Nvidia, machine learning is essentially a product of Moore’s
    Law advances in processing speeds and parallelization. If you can do it on a handset,
    why do you need The Dalles?
  prefs: []
  type: TYPE_NORMAL
- en: Balaban resolved to maximize the usable FLOPS per buck. That meant using game-machine
    GeForce processors, not the Teslas that were Dally’s pride at Nvidia or the Tensor
    Processing Units that Urs Hölzle cherished at Google.
  prefs: []
  type: TYPE_NORMAL
- en: The Nvidia representatives would try to frighten him by explaining that the
    game chips “were not meant for a datacenter. They couldn’t be relied on for machine-learning
    tasks. We can’t stand behind them.” It was what Silicon Valley calls “FUD”—the
    fear, uncertainty, and doubt that the established producers like IBM spread about
    cheap alternative devices, such as those produced a decade ago by Nvidia.
  prefs: []
  type: TYPE_NORMAL
- en: But keeping his eye on the key metric of FLOPS per buck, Balaban calculated
    that the up-market Tesla chips cost around five thousand dollars for Floating
    Point-32 performance teraflops of 10.6\. The gaming chips (GeForce GTX 1080 TI)
    produced 11.3 teraflops and could be bought for $580 per module. It was not a
    close call. In Balaban’s model of FLOPS per buck, the gaming chips were around
    twenty-four times better.
  prefs: []
  type: TYPE_NORMAL
- en: At that point, Balaban made the disappointing discovery that Nvidia did not
    sell its GeForce GPU boards in the minuscule numbers that he needed for his server
    farm. This looked like a “show-stopper.” But he recalled his discussions with
    Austin Russell about building GPU clusters of gaming boards for crypto-mining.
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution was obvious: “buy ’em at Fry’s,” the Valley’s dominant electronics
    retail chain, selling boards made by Zotac and Asus in Taiwan. The Lambda team
    cleared out the Bay Area’s supply of 1080 TIs, provoking something of a crisis
    for crypto-miners who needed the modules for their own servers.'
  prefs: []
  type: TYPE_NORMAL
- en: At that point in January 2016, Russell invited the Lambda team up to the garage
    behind the pool at Pony Tracks Ranch. He let them use the space for free; Lambda
    would just have to pay its power bill. Balaban and his team set out to build the
    servers from the bottom up, using the gaming boards with the GPU clusters. They
    installed their own one-hundred-amp breakout box at twenty-four kilowatts.
  prefs: []
  type: TYPE_NORMAL
- en: At 4:27 a.m. on February 13, 2016, they got the first server up and running
    with the GTX 980 TI Maxwell architecture. The peak compute rate was 5.63 teraflops,
    so they had four modules per machine, for a total of 225.2 teraflops, putting
    them on the list of the world’s top supercomputers with a near-quarter-petaflop
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Among the people taking an interest in Balaban’s progress was Georges Harik,
    a Silicon Valley titan who had, like Balaban, studied computer science at the
    University of Michigan and had then gone on to develop Google’s AdWords. Harik
    observed, “I don’t know how Dreamscope will go, but if you guys are good at Linux
    systems administration, what you can do is GPU cloud services.” That was the number-ten
    Google employee recommending that they compete with Google in the cloud. It was
    an idea.
  prefs: []
  type: TYPE_NORMAL
- en: Balaban and his team had learned how to maximize FLOPS per dollar on their machines,
    with the immediate result of ending the bills from Amazon. Paying off in six weeks,
    the sixty-thousand-dollar investment earned the runway to make Dreamscope a success.
    They had built up a team of Stephen and his brother, Michael; Chaun Li, their
    chief scientist and an expert in using neural networks for converting photos into
    paintings; and Steve Clarkson, who had dropped out of his Berkeley Ph.D. project
    in software engineering.
  prefs: []
  type: TYPE_NORMAL
- en: By December 2016, the monetization plan for Dreamscope was sort of working—they
    had many avid users and were making some five thousand dollars a month on millions
    of downloads. With more money and a longer runway, it might take off as a profitable
    product.
  prefs: []
  type: TYPE_NORMAL
- en: Balaban, however, decided to downgrade Dreamscope and go into the computer infrastructure
    market. He would sell boxes, like Michael Dell in his early years. Mixing up the
    family group, Balaban brought in a high school pal named Jackson Sengle, lured
    away from a Ph.D. in bioengineering at Dartmouth. He understood the ribosomes
    that manufacture all the proteins in your body. Why not defy the new Silicon Valley
    norm and, as Peter Thiel put it to the Fellows in 2014, “do something that everyone
    thinks is stupid”—sell homemade computers?
  prefs: []
  type: TYPE_NORMAL
- en: They began putting them together manually, step-by-step, deep into the night
    above Silicon Valley. With their big advantage in GPU costs at $580 per module,
    they would not have to be especially efficient in assembly. Their product was
    a GPU workstation that contained four GPU GeForce gaming modules from Nvidia,
    which Lambda priced at ten thousand dollars apiece; if you want them rack-mounted
    for your cloud, they cost twenty-five thousand.
  prefs: []
  type: TYPE_NORMAL
- en: They put it up on their own Lambda Labs website and on Amazon.com. “Not AWS,”
    Balaban points out, “just Amazon.com.” They called it the “Deep Learning DevBox”—“Dev”
    for development. They used Google AdWords to advertise. Harik was presumably pleased.
  prefs: []
  type: TYPE_NORMAL
- en: In March 2017, the DevBoxes began to sell. They brought in twenty-five thousand
    dollars, which was five times more than Dreamscope. That was something. Then in
    April they sold seventy-five thousand dollars, fifteen times more than Dreamscope.
    In May they sold $135,000\. In August came the eclipse and proposal. By November
    they were up to nearly $500,000 and ready to launch a datacenter business, tested
    by Dreamscope, which Balaban said would be used to “dogfood our cloud service.”
  prefs: []
  type: TYPE_NORMAL
- en: Harik’s idea that they could go into the Linux Administrator business for GPU
    deep-learning clusters seemed to make sense. Another ex-Googler also encouraged
    Balaban. Ken Patchett, who built Google’s green field data centers in Asia and
    then went on to build data centers for Facebook, explained to him the sources
    of the excess costs in data centers. There was all that 24/7 reliability, redundancy,
    and battery backup, all the costly carbon offset energy cosmetics, all the high-end
    ASICS and air conditioning.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps the giant Google data fortresses around the world were becoming seriously
    suboptimal in FLOPS per watt and FLOPS per dollar. They sure can do searches,
    but a new Bell’s Law regime is at hand—a new era of decentralization, face recognition
    in handsets, datacenters in cars and in movable containers—opening up a new era
    of “sky” computing, dispersing the clouds.
  prefs: []
  type: TYPE_NORMAL
