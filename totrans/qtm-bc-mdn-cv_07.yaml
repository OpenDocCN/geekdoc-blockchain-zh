- en: '© The Author(s), under exclusive license to Springer Nature Switzerland AG 2022A.
    Kumar et al. (eds.)Quantum and Blockchain for Modern Computing Systems: Vision
    and AdvancementsLecture Notes on Data Engineering and Communications Technologies133[https://doi.org/10.1007/978-3-031-04613-1_7](https://doi.org/10.1007/978-3-031-04613-1_7)'
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: © 作者（The Author(s)，独家许可给斯普林格自然瑞士有限公司 2022A. Kumar 等人（eds.）现代计算系统的量子和区块链：愿景与进展数据工程与通信技术讲义133[https://doi.org/10.1007/978-3-031-04613-1_7](https://doi.org/10.1007/978-3-031-04613-1_7)
- en: Quantum Generative Modelling and Its Use Cases
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 量子生成建模及其应用案例
- en: 'Kusal M. Abeywickrama^([1](#Aff5)), Srinjoy Ganguly^([2](#Aff6) [ ](#ContactOfAuthor2)),
    Luis Gerardo Ayala Bertel^([3](#Aff7) [ ](#ContactOfAuthor3)) and Saurav Mohanty^([4](#Aff8))(1)University
    of Sri Jayewardenepura, Nugegoda, Sri Lanka(2)Technical University of Madrid,
    Madrid, Spain(3)Cartagena University, Cartagena, Colombia(4)John Moore’s University,
    Liverpool, UKSrinjoy Ganguly (Corresponding author)Email: [srinjoyganguly@gmail.com](mailto:srinjoyganguly@gmail.com)Luis Gerardo
    Ayala BertelEmail: [layalab@unicartagena.edu.co](mailto:layalab@unicartagena.edu.co)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Kusal M. Abeywickrama^([1](#Aff5))，Srinjoy Ganguly^([2](#Aff6) [ ](#ContactOfAuthor2))，Luis Gerardo
    Ayala Bertel^([3](#Aff7) [ ](#ContactOfAuthor3)) 和 Saurav Mohanty^([4](#Aff8))（1）斯里兰卡努瓜杜瓦大学（University
    of Sri Jayewardenepura），努盖戈达，斯里兰卡（2）马德里理工大学（Technical University of Madrid），马德里，西班牙（3）卡塔赫纳大学（Cartagena
    University），卡塔赫纳，哥伦比亚（4）约翰·摩尔大学（John Moore’s University），利物浦，英国Srinjoy Ganguly （通讯作者）邮箱：[srinjoyganguly@gmail.com](mailto:srinjoyganguly@gmail.com)Luis Gerardo
    Ayala Bertel邮箱：[layalab@unicartagena.edu.co](mailto:layalab@unicartagena.edu.co)
- en: Abstract
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: A generative model describes how a dataset is generated according to a probability
    model and how new data can be generated by sampling this model. In the following
    work, we present the generative models’ approach in quantum along with other algorithms
    that have been developed for the optimization of generative models as well for
    a quantum generative model-based. We have described a use case of molecular simulation
    and optimization using variational quantum eigen solver. The quantum generative
    model that we describe has several important use cases in which we discuss the
    generation of probability distributions, drugs, and option pricing for financial
    application. Various applications and their impact evaluations have been reviewed
    to determine if the use of quantum generator algorithms is more appropriate than
    traditional machine learning methods. The use of quantum generator algorithms
    has proven to be more appropriate than traditional machine learning methods according
    to previous works. This leads us to the place of quantum development in the field
    of artificial intelligence.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型描述了数据集如何根据概率模型生成以及如何通过对该模型进行抽样生成新数据。在以下工作中，我们介绍了量子中的生成模型方法以及为生成模型优化开发的其他算法，同时也介绍了基于量子生成模型的一些算法。我们描述了使用变分量子本征求解器进行分子模拟和优化的用例。我们描述的量子生成模型在许多重要用例中具有重要用途，其中我们讨论了概率分布、药物和金融应用中的期权定价的生成。我们回顾了各种应用及其影响评估，以确定量子生成器算法的使用是否比传统机器学习方法更合适。根据先前的工作，量子生成器算法的使用已被证明比传统机器学习方法更合适。这使我们将量子发展置于人工智能领域的位置。
- en: KeywordsQuantum computingQuantum machine learningQuantum generative adversarial
    networkGenerative adversarial networkMachine learningAbbreviations
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 关键词量子计算量子机器学习量子生成对抗网络生成对抗网络机器学习缩写词
- en: DL
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: DL
- en: Deep Learning
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习
- en: GAN
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: GAN
- en: Generative Adversarial Networks
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: KNN
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: KNN
- en: K-Nearest Neighbours
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: K-最近邻算法
- en: ML
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ML
- en: Machine Learning
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习
- en: NN
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: NN
- en: Neural Network
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络
- en: QGAN
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: QGAN
- en: Quantum Generative Adversarial Networks
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 量子生成对抗网络
- en: QAE
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: QAE
- en: Quantum Amplitude Assessment
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 量子振幅评估
- en: RL
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: RL
- en: Reinforcement Learning
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习
- en: SVM
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: SVM
- en: Support-Vector Machines
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机
- en: VQE
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: VQE
- en: Variational Quantum Algorithm
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 变分量子算法
- en: 1 Machine Learning in Classical Computing
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 经典计算中的机器学习
- en: Currently, machine learning is one of the most prominent and powerful technologies.
    More significantly, we have yet to fully realize its potential. It will, without
    a question, continue to make headlines for the foreseeable future. Within this
    is a subset called deep learning that focuses on mimicking the behaviour of neural
    networks to solve more tangled and non-linear problems. Thus, having a broader
    spectrum with tools capable of working with tensors.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，机器学习是最突出和最强大的技术之一。更重要的是，我们尚未完全发挥其潜力。它毫无疑问将继续在可预见的未来成为头条新闻。其中有一个子集称为深度学习，它专注于模仿神经网络的行为，以解决更复杂和非线性的问题。因此，拥有能够处理张量的更广泛的工具。
- en: 'What is machine learning? In 1959, Arthur Samuel [[1](#CR1)] defined machine
    learning as “the field of study that gives computers the ability to learn without
    being explicitly programmed.” A more technical definition given by Tom M. Mitchell
    [[2](#CR2)] in 1997: “A computer program is said to learn from experience E with
    respect to some class of tasks T and performance measure P, if its performance
    at tasks in T, as measured by P, improves with experience E.”'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是机器学习？1959年，Arthur Samuel [[1](#CR1)]将机器学习定义为“赋予计算机学习能力而不是显式编程的研究领域”。1997年，Tom
    M. Mitchell [[2](#CR2)]给出了一个更技术性的定义：“一台计算机程序被认为在某一类任务T上通过性能度量P从经验E中学习，如果它在任务T上的表现，由性能度量P衡量，随着经验E的增加而提高”。
- en: The way humans interact with and relate to data has radically changed as a result
    of machine learning. Self-driving automobiles to intelligent agents capable of
    beating the greatest humans at Jeopardy and Go are just a few examples. Large
    data sets are present in many applications, pushing current techniques and processing
    resources to their limits. The main types are supervised learning, unsupervised
    learning, and reinforcement learning.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 人类与数据的交互方式和关系由于机器学习的影响已经发生了根本性的变化。从自动驾驶汽车到能够击败最优秀人类的智能代理在“危险边缘”和围棋方面都有着出色的表现，这只是少数例子。大型数据集存在于许多应用中，推动着当前的技术和处理资源达到极限。主要类型包括监督学习、无监督学习和强化学习。
- en: Supervised learning is considered a machine learning algorithm that trains on
    tagged data. Algorithms are trained using supervised learning data when input
    variables are added and their output is known. We have X as independent variables
    and Y as dependent variables. A data is processed and then split or fold. One
    is used to train and the remaining is used to test.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习被认为是一种在标记数据上训练的机器学习算法。当输入变量添加并且它们的输出已知时，算法使用监督学习数据进行训练。我们将X作为自变量，Y作为因变量。数据被处理，然后被分割或折叠。一个用于训练，剩下的用于测试。
- en: Now in unsupervised Learning instead of the first one, the used data is unlabelled,
    implying that it’s applied to data with no previous knowledge doing a clustering
    approach. The goal is to look into the data and discover any hidden patterns in
    the data. Let’s cover the remarkable central algorithms in ML. Linear Regression
    is considered the basic algorithm. The use of linear regression to establish a
    link among two connected variables is fairly accurate. To do this, it's primarily
    established which is the independent variable, while a dependent variable will
    be used to set up a conditional probability. It searches for analytical relationships
    rather than predetermined ones. For example, using this method it is possible
    to identify the correlation between weight and height. A brother of linear regression,
    Logistic Regression, is utilized for classification preferably than regression
    problems. It uses the same input feature vector as linear regression, but instead
    of a continuous numeric value, it returns a class label. An algorithm that predicts
    whether a patient has an illness or not based on his medical information is an
    example of Logistic Regression.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在无监督学习中，与第一种不同，使用的数据是未标记的，这意味着它适用于没有先前知识的数据，采用聚类方法。目标是查看数据并发现其中的任何隐藏模式。让我们来看看机器学习中的一些显著的核心算法。线性回归被认为是基本算法。使用线性回归建立两个相关变量之间的联系是相当准确的。为此，首先确定独立变量，而将使用一个依赖变量来建立条件概率。它搜索的是分析关系而不是预先确定的关系。例如，使用这种方法可以确定体重和身高之间的相关性。线性回归的一个衍生算法，逻辑回归，用于分类而不是回归问题。它使用与线性回归相同的输入特征向量，但返回的不是连续的数值，而是一个类别标签。基于病人的医疗信息预测病人是否患病的算法就是逻辑回归的一个例子。
- en: Another that we can highlight is Decisions Trees, an ML technique that divide
    large input sets toward tinier groups based on a representative characteristic
    continuously to reach small suitable information to be described as accurate output.
    Its demands that we label the data (data need has to be assigned in one or many
    labels, such as the name in a photograph, as an example a plant), and then this
    method attempt to remark new data using that knowledge.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以强调的另一个是决策树，一种机器学习技术，根据代表性特征将大型输入集分成较小的组，以连续地达到较小的适合信息以描述准确的输出。它要求我们对数据进行标记（数据需要分配一个或多个标签，例如照片中的名称，例如植物的名称），然后该方法尝试使用该知识来标记新数据。
- en: On the other hand, Binary Classification, a discrete ML procedure that sorts
    data into classes, the most common example is the spam-email, where assign 0 if
    is a faulty and 1 if is a normal mail, besides this method, exist the Regression
    that to predict values is needed continuously and dependent variables such as
    size with respect the price, like house pricings related to its area. This kind
    of query is ideal for DTs algorithms. When a conditioned variable is quantitative
    for example, to assign a loan customer likelihood, estimation regression trees
    can be utilized. Random forests are an ensemble of decision trees. Ensemble learning
    is a way to improve prediction performance using several learning algorithms.
    This way, the model is generalized more effectively and is less likely to overfit
    [[3](#CR3)].
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，二元分类是一种离散的机器学习过程，将数据分类，最常见的例子是垃圾邮件，其中将 0 分配给故障邮件，将 1 分配给正常邮件，除了这种方法之外，还存在回归，需要连续和依赖变量来预测值，例如尺寸与价格之间的关系，比如房屋价格与其面积相关。这种查询对决策树算法非常理想。当一个条件变量是定量的时候，例如，为了确定贷款客户的可能性，可以使用估计回归树。随机森林是决策树的集成。集成学习是一种使用多个学习算法来提高预测性能的方法。这样，模型更有效地泛化，并且不太可能过度拟合[[3](#CR3)]。
- en: There is also a special algorithm, support vector machine, the method that strives
    to determine a hyper-plane that is capable of being useful in a space of N variables
    concerning its application or insight analyzing data structures for classification
    or regression. There are many hyper-planes where two types of data points can
    be formed. Its main objective is to identify the plane with highest margins or
    gaps separating data points in two classes. Maximizing every boundary distance
    provides remarkable support, addressing more straightforward to classify data
    objects.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 也有一个特殊的算法，支持向量机（Support Vector Machine），这种方法致力于确定一个在 N 个变量空间中有用的超平面，用于分析数据结构以进行分类或回归。有许多超平面，两种类型的数据点可以形成。其主要目标是识别具有最大间隔或将数据点分离为两个类的平面。最大化每个边界距离提供了显著的支持，更容易地解析数据对象。
- en: One of the basic algorithms, K-Nearest Neighbours (KNN), can work in both classification
    or regression queries. This determination locates the k-closest neighbours and
    provides an expected output based on the class of the majority vote regarding
    the nearest set-points in the plane.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最基本的算法之一，K-最近邻算法（K-Nearest Neighbours，KNN），可以在分类或回归查询中工作。这个决定找到 k 个最近的邻居，并根据平面上最近的一组点的类的多数投票提供预期的输出。
- en: For regression problems, their aim is to discover the k-closest neighbours and
    predict the ideal output via computing significant mean estimation along with
    the nearest neighbours. This is an unsupervised learning algorithm, which means
    it learns patterns from data that hasn't been labelled. This means that a model
    can be trained to construct clusters on any dataset without needing to label the
    data first.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于回归问题，其目的是通过计算显著的均值估计和最近邻居，发现 k 个最接近的邻居，并预测理想输出。这是一种无监督学习算法，这意味着它从未被标记的数据中学习模式。这意味着模型可以被训练来在不需要首先标记数据的情况下在任何数据集上构建集群。
- en: There is also a special method as Principal Component Analysis which avoids
    concerns like over-fitting in high-dimensional space. It is a method for decreasing
    the data quantity of the variables picking the most relevant of a large input
    data collection. This shortens the data space size and conserves the best potential
    information. This strategy merges highly correlated variables to produce a smaller
    amount of insight variables known as ‘principal components’ that works for the
    preponderance data reduce the variance and don't fall in overfitting or underfitting.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种特殊的方法，即主成分分析，它避免了在高维空间中的过拟合等问题。这是一种降低变量数据量的方法，选择大量输入数据集中最相关的部分。这缩短了数据空间大小并保留了最佳潜在信息。这种策略合并高度相关的变量以生成更少的洞察变量，称为“主成分”，可用于大多数数据减少方差并避免过度拟合或拟合不足。
- en: Now we cover the basics of Deep Learning. is an ML subset at its most involved
    level. It develops a ‘learn’ to the computer by predicting, analyzing information
    inputs within layers. The data can be unstructured as writing, and waves-sound,
    images, expressed into matrices for investigations to solve or provide a certain
    application. It tries to mimic the human brain following the scheme of neural
    systems. Its goal is to produce some actual magic by simulating how the human
    brain functions. Deep learning algorithms are used to identify the correlations
    between inputs and outputs using what is termed a neural network. Neural network
    structure example is shown in Fig. [1](#Fig1).![](../images/516210_1_En_7_Chapter/516210_1_En_7_Fig1_HTML.png)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们介绍深度学习的基础知识。它是 ML 的一个最复杂的子集。它通过预测、分析层内的信息输入来为计算机“学习”。数据可以是非结构化的，如文本、声波、图像，可被表达为矩阵以进行解决或提供特定的应用。它试图模仿神经系统的工作方案。其目标是通过模拟人脑的功能来产生一些真正的魔法。深度学习算法用于识别输入和输出之间的相关性，使用所谓的神经网络。神经网络结构示例如图[1](#Fig1)所示。![](../images/516210_1_En_7_Chapter/516210_1_En_7_Fig1_HTML.png)
- en: Fig. 1
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1
- en: Schematic diagram of a three-layer neuron network
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 三层神经网络的示意图
- en: Next, we can see that have inputs, after hidden layers for feed-forward, and
    the output, it can be one or many, where each layer consists of nodes manipulating
    the amount of this. The input layers represent the data numerically, for images,
    the information is seen as RGB matrices associated in each pixel, the output layers
    are a reference for the test set and give proof about works or have the accuracy,
    meanwhile, the hidden layers do the greatest computation by processing, analyzing
    and updating the parameters in order to reduce the loss-error of expected values.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以看到输入，经过前馈隐藏层，以及输出，输出可以是单个或多个，每个层由节点组成，处理其数量。输入层以数字形式表示数据，对于图像来说，信息被视为每个像素中的RGB矩阵，输出层则是测试集的参考，并提供了关于工作的证据或准确性，同时，隐藏层通过处理、分析和更新参数来进行最大的计算，以减小期望值的损失误差。
- en: So, why is it referred to as “Deep” Learning? Deep learning is defined as the
    creation of many hidden layers called deep networks. Now depending on a large
    number of layers can or not improve the algorithm capability to estimate composite
    functions by adding additional weights and biases. Deep learning is a fascinating
    area that is changing our society dramatically. We should be interested in deep
    learning and the foundations of deep learning because it is straightforward to
    comprehend.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，为什么它被称为“深度学习”？深度学习被定义为创建许多称为深层网络的隐藏层。现在，通过添加额外的权重和偏差，依赖大量层是否可以改善算法估计复合函数的能力。深度学习是一个令人着迷的领域，它正在大大改变我们的社会。我们应该对深度学习和深度学习的基础感兴趣，因为它很容易理解。
- en: Exist diverse kinds of models in neural networks to name two, like Convolutional
    Neural Network and Recurrent Neural Network, these practices depend on the problem
    standard that we'll be dealing with. NN's overall is designed and described in
    terms of layers that are a response by an activation function and are fed using
    the previous data inputs together with weight plus bias.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经网络中存在各种类型的模型，比如卷积神经网络和循环神经网络，这些实践取决于我们将要处理的问题标准。神经网络总体上是以层的形式设计和描述的，这些层通过激活函数做出响应，并使用先前的数据输入以及权重和偏差进行馈送。
- en: Last but not least, Reinforcement Learning, ML technique which the input isn't
    raw data and the algorithm needs to identify the scenario on its own. Reinforcement
    learning is a type of learning that is commonly employed in instructions for the
    sequence of future independent steps as robotics devices, strategy games, or self-navigation.
    RL cognition learns through trial and error, performing every time to produce
    outstanding results.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但并非最不重要的是，强化学习，一种机器学习技术，其输入不是原始数据，算法需要自行识别场景。强化学习是一种常用于未来独立步骤序列的指导，比如机器人设备、策略游戏或自主导航。强化学习通过反复尝试和错误来学习，每次执行都会产生出色的结果。
- en: In the next section, we will look into Quantum Machine Learning which is an
    exciting field as it’s a union of Quantum and ML.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将探讨量子机器学习，这是一个令人兴奋的领域，因为它是量子和机器学习的结合。
- en: 2 Quantum Machine Learning
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 量子机器学习
- en: The machine learning algorithm must be extremely effective at manipulating large
    amounts of data, including previously gathered input–output data pairs. As the
    volume of data stored worldwide increases by about 20 percent each year [[4](#CR4)],
    there is pressure to find new ways to execute machine learning algorithms. If
    the data point is projected in higher order, classical computers cannot perform
    such calculations. Even though it can be handled by a classic computer, it takes
    more time. Due to that, the purpose of merging quantum information processing
    and machine learning has been a major body of research in recent years [[5](#CR5)–[7](#CR7)].
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法必须非常有效地处理大量数据，包括先前收集的输入-输出数据对。随着全球存储的数据量每年增长约20％[[4](#CR4)]，有压力寻找执行机器学习算法的新方法。如果数据点投影到更高的维度，经典计算机无法执行这样的计算。即使经典计算机可以处理，也需要更长的时间。因此，将量子信息处理和机器学习相结合的目的已成为近年来的重要研究方向[[5](#CR5)–[7](#CR7)]。
- en: 2.1 The Rise of Quantum Machine Learning
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 量子机器学习的兴起
- en: Quantum machine learning is a field of combination of both, machine learning
    and quantum computers, which will change what the future holds [[6](#CR6)]. Large
    quantities of data are computed by using machine learning methods, whereas quantum
    machine learning enhances computing speed and data storage using qubits and quantum
    operations or specific quantum algorithms.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 量子机器学习是机器学习和量子计算机结合的领域，它将改变未来的发展方向[[6](#CR6)]。大量数据通过机器学习方法进行计算，而量子机器学习则利用量子比特和量子操作或特定的量子算法增强了计算速度和数据存储能力。
- en: Depending on how data are created or handled, there are several ways to combine
    quantum computing and machine learning as shown in Fig. [2](#Fig2). This includes
    a combination of both classical and quantum processing, where computationally
    expensive classical algorithms are executed by a quantum device [[5](#CR5)]. The
    first approach is that the classical datasets generated by classical experiments
    can be processed using quantum algorithms. Another approach is, quantum algorithms
    can be applied instead of classical data to measure quantum states based on quantum
    experiments [[8](#CR8)]. Besides that, classical machine learning methods apply
    to data generated by quantum experiments such as learning phase transitions of
    many-body quantum systems [[9](#CR9)]. The final approach is to process quantum
    data by quantum computers [[7](#CR7)].![](../images/516210_1_En_7_Chapter/516210_1_En_7_Fig2_HTML.png)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 根据数据的生成或处理方式，可以通过几种方式将量子计算和机器学习结合起来，如图[2](#Fig2)所示。这包括经典和量子处理的组合，其中计算成本高昂的经典算法由量子设备执行[[5](#CR5)]。第一种方法是，通过经典实验生成的经典数据集可以使用量子算法进行处理。另一种方法是，可以应用量子算法而不是经典数据来测量基于量子实验的量子状态[[8](#CR8)]。除此之外，经典机器学习方法适用于由量子实验生成的数据，例如学习多体量子系统的相变[[9](#CR9)]。最后一种方法是通过量子计算机处理量子数据[[7](#CR7)]。![](../images/516210_1_En_7_Chapter/516210_1_En_7_Fig2_HTML.png)
- en: Fig. 2
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图2
- en: Quantum computing approaches
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 量子计算方法
- en: 2.2 Review of Quantum Information Processing Concepts^([1](#Fn1))
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 量子信息处理概念回顾^([1](#Fn1))
- en: A Qubit (or a quantum bit) is the quantum counterpart of the classical bit that
    consists of two states. These two-qubit states, known as the Dirac notation, are
    similar to the classical binary state and can be in both states and the superposition
    state of both states simultaneously. A qubit can be described by using the following
    notation as, |*ψ*⟩ = *α* | 0⟩ + *β* | 1⟩, where *α, β* ∈ *C* and | *0*⟩, | *1*⟩
    is in Hilbert Space *H*^(*2*). Quantum dynamics always maintain normalization
    conditions that | *α* |² + | *β* |² = 1\. The Bloch sphere gives the graphical
    representation of the qubit as shown in Fig. [3](#Fig3). The quantum theory is
    based on an observation that indicates the probability of measurement in state
    | 0⟩ or | 1⟩ with squared amplitudes | *α* |², | *β* |². Therefore, the state
    of the qubit cannot be defined as only ‘0’ or ‘1’ state, and there is a probability
    of it being measured in either of two states. This allows calculations to be performed
    in both states simultaneously, it is called quantum parallelism. Qubits can be
    shown in the Bloch Sphere.![](../images/516210_1_En_7_Chapter/516210_1_En_7_Fig3_HTML.png)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 量子位（或量子比特）是经典比特的量子对应物，由两个状态组成。这两个量子位态，称为狄拉克符号，类似于经典的二进制状态，并且可以同时处于两个状态以及两个状态的叠加态。量子位可以使用以下符号描述，|*ψ*⟩ = *α*
    | 0⟩ + *β* | 1⟩，其中 *α, β* ∈ *C*，且 | *0*⟩，| *1*⟩ 在希尔伯特空间 *H*^(*2*) 中。量子动力学始终保持归一化条件，即
    | *α* |² + | *β* |² = 1。Bloch 球给出了量子位的图形表示，如图 [3](#Fig3) 所示。量子理论基于一种观察，即测量在态 |
    0⟩ 或 | 1⟩ 中的概率，其平方振幅为 | *α* |²，| *β* |²。因此，量子位的状态不能仅定义为‘0’或‘1’状态，并且可能在两种状态中的任一状态中被测量。这允许在两种状态中同时执行计算，这称为量子并行性。量子位可以在
    Bloch 球中显示。![](../images/516210_1_En_7_Chapter/516210_1_En_7_Fig3_HTML.png)
- en: Fig. 3
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3
- en: The representation of qubit using Bloch sphere
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Bloch 球表示量子位
- en: The power of quantum machine learning is evident when considering an N number
    of qubit systems with two quantum states. A superposition of all 2n combinations
    can be allowed for the quantum system. For instance, considering a system of 2
    qubits, the superposition includes a total of 4 states, {| *00*⟩ + | *01*⟩ + |
    *10*⟩ + | *11*⟩}. All these combinations can be processed in parallel with an
    algorithm. However, the uncertainty of the results that happen by measurements
    always constrains the efficiency of quantum computers. When measuring a qubit,
    it will be either | 0⟩ or | 1⟩, and then the system will collapse to the quantum
    state which has been observed. After this measurement, the system will only generate
    the observed state as the output.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当考虑具有两个量子状态的 N 个量子位系统时，量子机器学习的力量显而易见。量子系统可以允许所有 2^n 组合的叠加态存在。例如，考虑一个由 2 个量子位组成的系统，叠加态包括总共
    4 个状态，{| *00*⟩ + | *01*⟩ + | *10*⟩ + | *11*⟩}。所有这些组合都可以通过算法并行处理。然而，通过测量产生的结果的不确定性总是限制量子计算机的效率。当测量一个量子位时，它将是
    | 0⟩ 或 | 1⟩，然后系统将会坍缩到观察到的量子态。在此测量之后，系统将只生成观察到的状态作为输出。
- en: The introduction of certain formal concepts of quantum information theory is
    crucial. One of the most important concepts, in quantum mechanics, is the Unitary
    operators (U) which represent the conversion of vectors. It shall always be equal
    to one if we analyse the product of Unitary Operators and its Hermitian conjugates
    (*U*^† *U* = 1, where *U*^† is the Hermitian conjugate) [[10](#CR10)]. A quantum
    algorithm is a collection of unitary operators that define the dynamics of quantum
    systems, and these unitary transformations are the quantum counterpart of the
    classical gates of bit manipulation. A certain number of these quantum gates are
    for single-qubit only. For instance, the X-gate can flip the state of qubits while
    the Z-gate can change the amplitude sign of the single qubit. A superposition
    state can be generated by applying the Hadamard gate (H-gate) [[11](#CR11)]. But
    gates like Controlled-NOT (C-NOT) gate need more than one qubit to complete its
    operation and only if the first qubit is in state | 1⟩, it flips the state of
    the second qubit [[11](#CR11)]. The unitary transformation *U* = *e*^(*−iHt*)
    can give a much more general formula for a quantum gate obtained from the Schrödinger
    equation which is a fundamental of quantum theory.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 引入量子信息理论的特定形式概念非常重要。在量子力学中，最重要的概念之一是幺正算符（U），它代表向量的转换。如果我们分析幺正算符及其共轭转置的乘积时，它始终等于一（*U*^†
    *U* = 1，其中 *U*^† 是共轭转置）[[10](#CR10)]。量子算法是一组定义量子系统动态的幺正算符，这些幺正变换是比特操作的量子对应物。一定数量的这些量子门仅适用于单量子比特。例如，X
    门可以翻转量子比特的状态，而 Z 门可以改变单一量子比特的振幅符号。通过应用哈达玛门（H 门）可以产生叠加态[[11](#CR11)]。但是像控制非门（C-NOT）门这样的门需要多于一个量子比特才能完成其操作，并且只有当第一个量子比特处于状态
    | 1⟩ 时，它才会翻转第二个量子比特的状态[[11](#CR11)]。幺正变换 *U* = *e*^(*−iHt*) 可以从薛定谔方程得到量子门的更一般公式，而薛定谔方程是量子理论的基础。
- en: Qubits have a different property of quantum physics called entanglement [[12](#CR12)],
    similar to superposition. Due to the superposition, the qubit can be being in
    many states at the same time whereas entanglement creates a correlation between
    two qubits even though they are in separate locations physically. When the quantum
    entanglement takes place between two particles, the individual quantum states
    are indeterminate until measured, and one determines the measurement result of
    the other, even though the measurement process is far from each other. The above
    figure (Fig. [4](#Fig4)) is one of the graphical representations of the quantum
    entanglement circuit. The quantum state of n qubits means that all possible configurations
    are in a superposition state (2n). The quantum entanglement of the electron spins
    of n qubits expands the dimensions of the Hilbert space exponentially from 2 to
    2^(*n*).![](../images/516210_1_En_7_Chapter/516210_1_En_7_Fig4_HTML.png)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 量子比特具有一种称为纠缠的量子物理不同属性[[12](#CR12)]，类似于叠加。由于叠加，量子比特可以同时处于许多状态，而纠缠则在两个量子比特之间创建了相关性，即使它们在物理上是分开的位置。当量子纠缠发生在两个粒子之间时，个体量子态在测量之前是不确定的，并且一个粒子的测量结果决定了另一个粒子的测量结果，即使测量过程相距甚远。上图（图 [4](#Fig4)）是量子纠缠电路的图形表示之一。n个量子比特的量子态意味着所有可能的配置都处于叠加态（2n）。n个量子比特的电子自旋的量子纠缠将希尔伯特空间的维度指数级地从2扩展到2^(*n*)。![](../images/516210_1_En_7_Chapter/516210_1_En_7_Fig4_HTML.png)
- en: Fig. 4
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4
- en: Quantum circuit (quantum entanglement circuit)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 量子电路（量子纠缠电路）
- en: Therefore, quantum algorithms provide more computational benefits than classical
    algorithms. The quantum paradigm is not to solve a problem fast, but to solve
    it with completely new technology and more effectively. Besides, when using techniques
    in which conventional calculation cannot generate so many states once using concepts
    like superposition or entanglement, Quantum algorithms can have a significant
    advantage.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，量子算法提供的计算优势比经典算法更多。量子范式不是为了快速解决问题，而是要用全新的技术和更有效的方式来解决问题。此外，当使用传统计算无法一次生成如此多状态的技术时，使用叠加或纠缠等概念，量子算法可以具有显着优势。
- en: 2.3 Variational Quantum Algorithms (VQAs)
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 变分量子算法（VQAs）
- en: When running in the quantum realm, the behaviour of the qubits is highly delicate
    and unpredictable. Furthermore, parallel to the increment of the number of qubits,
    the fragility of the qubits also rises. The quality of the material, that is used
    in the fabrication, affects directly the stability of qubits. Because of this
    instability, it is hard to maintain a high coherence time for qubits. However,
    we need a large number of qubits to work on advanced problems, with high coherence
    time. Currently, it is impossible to access these types of quantum computers,
    but noisy intermediate-scale quantum (NISQ) computers [[8](#CR8), [13](#CR13)]
    which are composed of a large number of qubits that are very noisy with less coherence
    time, can be used.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在量子领域运行时，量子位（qubits）的行为非常微妙且难以预测。此外，随着量子位数量的增加，量子位的脆弱性也增加。用于制造的材料质量直接影响量子位的稳定性。由于这种不稳定性，很难保持量子位的高相干时间。然而，我们需要大量量子位来解决高相干时间的先进问题。目前，还无法访问这类量子计算机，但是由大量具有较低相干时间且非常嘈杂的量子位组成的嘈杂中间尺度量子（NISQ）计算机[[8](#CR8),
    [13](#CR13)]可以使用。
- en: Variational quantum algorithms (VQAs) [[14](#CR14), [15](#CR15)] are an improvement
    in quantum computing that runs on NISQ computers that employ classical optimizers
    to train parameterized quantum circuits. It is possible to use variational algorithms
    as the building blocks for a number of use cases, including the design of a quantum
    classifier. It is similar in operation to a classical support-vector machine in
    terms of complexity and speed of operation. Support-vector machines, often known
    as SVMs, are supervised learning models that are used in machine learning to address
    classification and regression problems. The same as any support-vector machine,
    the quantum variational circuit performs hyperplane slices in the same way that
    a normal SVM does.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 变分量子算法（VQAs）[[14](#CR14), [15](#CR15)] 是量子计算中的一个改进，运行在采用经典优化器来训练参数化量子电路的NISQ计算机上。可以将变分算法用作许多用例的构建模块，包括量子分类器的设计。在复杂性和操作速度方面，其操作方式类似于经典支持向量机。支持向量机（SVMs），通常称为SVMs，是一种用于解决分类和回归问题的监督学习模型，常用于机器学习中。与任何支持向量机一样，量子变分电路以与普通SVM相同的方式进行超平面切片。
- en: As long as the kernel function is performed efficiently on a classical computer,
    quantum logic-based classifiers have no advantage over classical computers in
    terms of performance. However, when the feature space is very wide and kernel
    functions are difficult to discover, quantum computing can be highly beneficial.
    The variational algorithm, like a conventional support-vector machine, uses the
    Hilbert space in which the quantum processor runs to determine the best Hyperplane
    cut. The algorithm is used for both training and classification. The training
    stage makes use of a previously categorized dataset. Quantum algorithms that rely
    on free parameters are known as variational or parameterized quantum circuits.
    They, like normal quantum circuits (as shown in Fig. [5](#Fig5)), are made up
    of three components [[16](#CR16)]; (i) Preparation of a fixed initial state; (ii)
    creation of the *quantum circuit* ***U(θ)***, defined by a collection of free
    parameters ***θ***; and (iii) At the output, an observable ***B̂*** is measured.![](../images/516210_1_En_7_Chapter/516210_1_En_7_Fig5_HTML.png)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 只要核函数在经典计算机上高效执行，基于量子逻辑的分类器在性能上就没有优势。然而，当特征空间非常宽广且核函数难以发现时，量子计算可能会带来极大的好处。变分算法，就像传统的支持向量机一样，利用量子处理器运行的希尔伯特空间来确定最佳的超平面切割。该算法用于训练和分类。训练阶段利用先前分类的数据集。依赖自由参数的量子算法被称为变分或参数化量子电路。它们，就像普通的量子电路（如图 [5](#Fig5) 所示），由三个组成部分构成[[16](#CR16)]；（i）固定初始状态的准备；（ii）由一组自由参数
    ***θ*** 定义的量子电路 ***U(θ)*** 的创建；以及（iii）在输出时，测量一个观测算符 ***B̂***。![](../images/516210_1_En_7_Chapter/516210_1_En_7_Fig5_HTML.png)
- en: Fig. 5
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5
- en: Variational quantum circuit
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 变分量子电路
- en: 2.4 Variational Quantum Eigensolver (VQE)
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 变分量子本征求解器（VQE）
- en: 'When we analyse the quantum mechanics precisely applied to computation requires
    the introduction of certain postulates that shape the theory and serve as a basis
    for other reasoning. Here we want to establish a formal perspective of what VQE
    is, we must know the relevance of the following claims:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们精确分析应用于计算的量子力学时，需要引入一些假设，这些假设塑造了理论并作为其他推理的基础。在这里，我们想要建立对VQE的正式视角，我们必须了解以下声明的相关性：
- en: The observables of a system are represented by hermitic linear operators. The
    set of eigenvalues of the observable is called a spectrum and its eigenvectors,
    exact or approximate, define a base in the Hilbert space.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统的可观测量由厄米线性算符表示。可观测量的本征值集称为谱，其精确或近似的本征矢量在希尔伯特空间中定义了一个基。
- en: When a system is in the normalized state, the measurement of an observable A
    will result in the eigenvalue a, with a probability ![$$PA|\Psi \rangle ={|\langle
    a|\Psi \rangle |}^{2}$$](../images/516210_1_En_7_Chapter/516210_1_En_7_Chapter_TeX_IEq1.png).
    The eigenvector is associated with the eigenvalue a, which in Hilbert space notation
    is expressed as A|a⟩ = a|a⟩ [[17](#CR17)].
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当系统处于归一化态时，对可观测量 A 的测量将得到本征值 a，概率为 ![$$PA|\Psi \rangle ={|\langle a|\Psi \rangle
    |}^{2}$$](../images/516210_1_En_7_Chapter/516210_1_En_7_Chapter_TeX_IEq1.png)。特征向量与本征值
    a 相关联，在希尔伯特空间表示中表达为 A|a⟩ = a|a⟩ [[17](#CR17)]。
- en: Then is possible to affirm VQE is an application of the variational method of
    quantum mechanics by doing algorithm in the quantum–classical hybrid way mostly
    used to find eigenvalues of Hamiltonian matrices which is done by preparing an
    arbitrarily selecting wave function |Ψ⟩ and making use of Ansatz, a parameterized
    quantum circuit with rotation gate which creates the state vector providing measurement
    to estimate the expectation value [[17](#CR17)].
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 随后可以肯定 VQE 是量子力学变分方法的一个应用，通过以量子-经典混合方式进行算法，主要用于找到哈密顿矩阵的本征值，方法是准备一个任意选择的波函数 |Ψ⟩
    并利用 Ansatz，即一个带旋转门的参数化量子电路，创建提供测量以估算期望值的状态向量 [[17](#CR17)]。
- en: 2.4.1 Quantum Variational Algorithm for Eigenvector
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.4.1 量子特征向量的变分算法
- en: The VQE is correlated to a variational quantum algorithm whose most common purpose
    is trying to approximate the ground state of quantum systems. It is a method for
    approximating certain ground states |Ψ⟩ and the lowest energy E[min] consisting
    of two primary steps.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: VQE 与一个变分量子算法相关联，其最常见目的是尝试近似量子系统的基态。它是一种用于近似某些基态 |Ψ⟩ 和最低能量 E[min] 的方法，包括两个主要步骤。
- en: First select ansatz or criterion trial state by some parameters theta |Ψ(θ)⟩
    on condition that only belong into a subspace instead of looking at the full Hilbert
    Space describing all the possible quantum states, then the second step is to vary
    the theta parameters to minimize the energy value, finding the proper parameters
    theta for which this energy of the trial state becomes lowest, automatically we
    can approximate the ground state |Ψ⟩, therefore the choices of ansatz are very
    important for the variational methods work. Figure [6](#Fig6) is a simple representation
    of such a quantum circuit.![](../images/516210_1_En_7_Chapter/516210_1_En_7_Fig6_HTML.png)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 首先通过一些参数 theta 选择试探态或标准态 |Ψ(θ)⟩，条件是只属于一个子空间，而不是查看描述所有可能的量子态的完整希尔伯特空间，然后第二步是变化
    theta 参数以使能量值最小化，找到使试探态能量最低的合适参数 theta，自动我们可以近似得到基态 |Ψ⟩，因此标准态的选择对变分方法的工作非常重要。图
    [6](#Fig6) 是这样一个量子电路的简单表示。![](../images/516210_1_En_7_Chapter/516210_1_En_7_Fig6_HTML.png)
- en: Fig. 6
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6
- en: Quantum circuit that depends on parameters θ; Initial state, parameterized circuit,
    and observable measurement
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖于参数 θ 的量子电路；初始态、参数化电路和可观测量测量
- en: Preparing the quantum state with variational quantum circuit U(θ) is the basis
    for obtaining the ansatz state providing in such way to minimize the loss of theta
    parameters by running the circuit on a quantum computer giving us the measurements
    of the energy value which will be using it as input in a classical optimizer for
    feedforward and after that get a hybrid quantum/classical feedback iteration to
    update the parameters.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 使用变分量子电路U(θ)准备量子态是获取提供如此方式的假设态，通过在量子计算机上运行电路来最小化theta参数的损失，从而给出能量值的测量结果，这将作为经典优化器的输入进行前馈，然后进行混合量子/经典反馈迭代以更新参数。
- en: 2.4.2 VQE Use Case—Chemistry
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.4.2 VQE使用案例 - 化学
- en: Variational Quantum Eigensolver is one of the attractive algorithms when it
    comes to large-scale matrices, in chemistry we can highlight its use due to big
    data as the number of atoms increases, this algorithm has worked in finding the
    ground state energy by simulating molecules and chemical reactions. Since one
    of the VQE main reasons is to have this approximation with the eigenvalues of
    a matrix, its principle for chemistry in quantum is solving the molecular Hamiltonian
    eigenvalue problem which shows an approach about these properties of large molecules
    in a way that a classical computer is difficult and not efficiently to do it.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 变分量子本征求解器是一种吸引人的算法，尤其是在大规模矩阵中，化学中我们可以强调其用途，由于大数据如原子数的增加，当涉及到化学反应时，该算法已在模拟分子和化学反应中寻找基态能量中发挥作用。由于VQE的主要原因之一是与矩阵的本征值进行近似，其在量子化学中的原理是解决分子哈密顿本征值问题，这显示了关于大分子性质的一种途径，而经典计算机难以高效地做到这一点。
- en: In a practical case, there are already demonstrations of VQE in chemical compounds
    such H[2]O, LiH, BeH[2], the last one in 2017 was successfully implemented VQE
    for the estimation of the ground state energies of molecules on an IBM quantum
    computer [[18](#CR18)]. By studying the molecules’ ground-state is possible to
    obtain the energy potential between two atoms in the variating interatomic distance
    and the lowest energy in potential-energy surfaces corresponds to the most stable
    structure of the molecules [[19](#CR19)].
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际情况中，已经有化学化合物中VQE的演示，例如H[2]O，LiH，BeH[2]，2017年最后一种成功在IBM量子计算机上实现了分子的基态能量的估计[[18](#CR18)]。通过研究分子的基态，可以获得变化的原子间距之间的能量势和在势能面上最低的能量对应于分子的最稳定结构[[19](#CR19)]。
- en: To have high efficiency in the superconducting quantum processor for solving
    molecular structure problems if we take the BeH[2] compound reference is necessary
    based on mappings between fermionic and qubit operators [[20](#CR20)]. The BeH[2]
    Hamiltonian is defined upon the 1 s, 2 s, 2px orbitals associated to Be, and 1 s
    orbital associated with each H atom. To obtain the potential energy surfaces for
    BeH[2], the authors search for the ground state energy of their molecular Hamiltonians,
    using 2, 4, and 6 qubits respectively, for depth d = 1, for a range of different
    interatomic distances [[19](#CR19)].
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 要在超导量子处理器中高效解决分子结构问题，如果我们以 BeH[2] 化合物为参考，则基于费米子和量子比特算符之间的映射是必要的[[20](#CR20)]。BeH[2]
    哈密顿量定义了与 Be 相关联的 1s，2s，2px 轨道和与每个 H 原子相关联的 1s 轨道。为了获取 BeH[2] 的势能曲面，作者分别使用 2、4
    和 6 个量子比特，在 d = 1 的深度下，针对不同原子间距的范围，搜索其分子哈密顿量的基态能量[[19](#CR19)]。
- en: Showing a perspective for using a single qubit in the variational form to solve
    a problem similar to ground state energy, should be given a random probability
    vector and figure out how to determine a possible parameterization for this qubit
    where it has to generate a close probability distribution to the vector.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 展示使用变分形式中的单量子比特来解决类似于基态能量的问题的视角，应该给出一个随机概率向量，然后找出如何确定这个量子比特的可能参数化，其中它必须生成与该向量接近的概率分布。
- en: 3 Quantum Generative Adversarial Networks
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 量子生成对抗网络
- en: One of the most promising advances which have been made in the field of classical
    deep learning is GAN’s which is the acronym for Generative Adversarial Networks
    [[21](#CR21)] and it is part of generative machine learning models. The idea of
    GANs is to generate as realistic data samples as possible based on other training
    data samples provided. GANs are much larger models and more difficult to train
    than traditional in-deep learning models, but despite their training limitations,
    they have found some quite useful applications in the industry. Some of the primary
    applications include image super-resolution, image generation, 3D objects generation,
    and text generation.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在经典深度学习领域取得的最有前途的进展之一是 GAN（生成对抗网络）[[21](#CR21)]，它是生成式机器学习模型的一部分。GAN 的思想是基于提供的其他训练数据样本生成尽可能逼真的数据样本。GAN
    是更大的模型，比传统的深度学习模型更难训练，但尽管它们的训练限制，它们在工业中找到了一些非常有用的应用。一些主要应用包括图像超分辨率，图像生成，3D 对象生成和文本生成。
- en: The construction of classical GAN’s consists of two parts as shown in Fig. [7](#Fig7)—*generator*
    which generates new data samples, it can be images or text or audio, and *discriminator*
    whose job is to distinguish the samples generated by the generator and real-world
    data samples. Architecturally, generator and discriminator, both are composed
    of neural networks layers which can approximate complex functions and can capture
    the essence of data features provided to them. Now we are going to see the architecture
    of classical GAN’s in detail from which a generalization of quantum GAN’s will
    make much more sense and you will see that it is fairly intuitive.![](../images/516210_1_En_7_Chapter/516210_1_En_7_Fig7_HTML.png)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 经典 GAN 的构建由两部分组成，如图 [7](#Fig7) 所示—*生成器* 生成新的数据样本，可以是图像、文本或音频，以及 *判别器* 其工作是区分生成器生成的样本和真实世界的数据样本。
    在结构上，生成器和判别器都由神经网络层组成，可以近似复杂的函数，并捕捉提供给它们的数据特征的本质。 现在我们将详细了解经典 GAN 的架构，从中量子 GAN
    的泛化将更有意义，您将看到它相当直观。![](../images/516210_1_En_7_Chapter/516210_1_En_7_Fig7_HTML.png)
- en: Fig. 7
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7
- en: Common GAN components are shown in this figure
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 本图显示了常见的 GAN 组件
- en: 3.1 Architecture and Training of GAN’s
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 GAN 的架构和训练
- en: Recall from the explanation of GAN’s previously that the generator tries to
    generate samples as close as possible to the real-world samples. For convenience,
    the generator will be called G and the discriminator will be called D. Therefore,
    we can suppose that we have some real data samples source R, which can generate
    a certain probability distribution of these real data samples called *p*[*R*]*(x)*.
    Also, the generator distribution of the data samples is given by *p*[*G*]*(x)*
    where *x* is the input data samples. The G network takes a random variable *z*
    as an input which is drawn from some normal or uniform distribution and then the
    task for G is to transform this input to data samples thereby generating the *p*[*G*]*(x)*.
    The D takes real or the G-generated data samples as inputs and compares whether
    they are closer to each other or not. Now according to the adversarial learning
    principle, G would want to maximize the probability that D misclassifies its generated
    data points compared to the real data samples. On the other hand, D would like
    to maximize the probability of successfully classifying the real data samples
    which are opposite to what G wants, and this creates an adversarial training system.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾之前对生成对抗网络（GAN）的解释，生成器试图生成尽可能接近真实样本的样本。为方便起见，生成器将被称为G，鉴别器将被称为D。因此，我们可以假设我们有一些真实数据样本源R，它可以生成这些真实数据样本的某种概率分布，称为*p*[*R*]*(x)*。此外，数据样本的生成器分布由*p*[*G*]*(x)*给出，其中*x*是输入数据样本。G网络将一个随机变量*z*作为输入，该变量从某个正态或均匀分布中抽取，然后G的任务是将这个输入转换为数据样本，从而生成*p*[*G*]*(x)*。D将真实数据或G生成的数据样本作为输入，并比较它们是否彼此更接近。现在根据对抗学习原理，G希望最大化D误分类其生成的数据点的概率，而不是真实数据样本。另一方面，D希望最大化成功分类与G希望相反的真实数据样本的概率，这创建了一个对抗性训练系统。
- en: 3.2 Architecture and Training of Quantum GAN’s
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 量子生成对抗网络（Quantum GAN）的结构和训练
- en: Throughout the entire discussion of this work on quantum machine learning, we
    considered only the supervised machine learning approach as that is the most popular
    and used by various industries as well. Here also for the quantum GAN’s discussion
    [[22](#CR22), [23](#CR23)], we are going to take the case of supervised learning
    as well and this means labels associated with the data samples. The primary quantum
    generative model structure and training which we are going to describe has been
    explained in [[24](#CR24)] and we are going to explain briefly the main structure
    of GAN’s and its properties. We will be focusing on conditional GAN’s aspect of
    quantum GAN’s as they provide conditioning into labels for samples generation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Now, architecturally, the classical one and the quantum GAN’s shown in Fig. [8](#Fig8)
    above are very similar, where we have a quantum D which discriminates the quantum
    states it gets as input from the quantum G (quantum G takes a quantum noise vector
    state | *z* > , similar to that of classical G case of you recall) and the real
    data source R. You can recall that G and D in the classical case are deep neural
    network layers and therefore in the case of quantum GAN’s these are replaced by
    variational quantum circuits where quantum G is parameterized by *θ*[*G*] and
    it takes the input label state | *λ* > and quantum noise | *z* > to produce a
    density matrix that has the corresponding similarity to that of real data. When
    the | *z* > fluctuates randomly, more output samples can be created for a particular
    label, and by tuning | *z* > various latent properties of generated samples can
    be captured which are not captured by the labels *λ*.![](../images/516210_1_En_7_Chapter/516210_1_En_7_Fig8_HTML.png)
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 8
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: The basic QGAN components are shown in this figure
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: For the training of the quantum GAN model, a quantum objective function is utilized
    so that the training happens efficiently. As for every training process, the G
    and D parameters are initialized to some random values and then a fair coin is
    made to select the process of commencement for either G or D. For the training
    of the model, quantum gradients can be utilized which relies on the numerical
    finite difference method. By the usage of this technique, the gradients can be
    calculated on the quantum computer itself.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练量子 GAN 模型，使用量子目标函数，以便训练过程高效进行。对于每个训练过程，G 和 D 参数都被初始化为一些随机值，然后通过公平硬币来选择 G
    或 D 的启动过程。对于模型的训练，可以使用量子梯度，它依赖于数值有限差分法。通过使用这种技术，梯度可以在量子计算机上计算出来。
- en: 4 QGAN’s Use Case—Drug Discovery
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4. QGAN 的用例 —— 药物发现
- en: With the working of QGAN’s covered in the previous section, we will now consider
    a use case or a practical application of the QGAN technique. This application
    is in the field of chemistry, more specifically on drug discovery where the chemical
    space to search is very large in dimensions and classical GAN’s are not suitable
    to carry out these discoveries because of the curse of dimensionality. GAN’s try
    to discover those molecular compounds which have more affinity toward the disease
    cell and will have higher success in defeating the disease mechanism.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 通过前面部分介绍的 QGAN 的工作原理，我们现在将考虑 QGAN 技术的一个用例或实际应用。这个应用是在化学领域，更具体地说是在药物发现领域，其中要搜索的化学空间在维度上非常大，经典的
    GAN 不适合进行这些发现，因为存在维度灾难。GAN 试图发现那些对疾病细胞更具亲和力的分子化合物，并在击败疾病机制方面取得更高的成功率。
- en: The technique called QGAN with Hybrid Generator (QGAN-HG) used in the paper
    [[25](#CR25)] will be reviewed as it is one of the significant case studies for
    the QGAN’s for chemistry/drug discovery applications apart from usual financial
    applications. Usually, we require a larger number of qubits to even generate a
    small molecule, but QGAN-HG is very qubit efficient and molecules can be generated
    with a fewer number of qubits.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中使用的称为 QGAN with Hybrid Generator（QGAN-HG）的技术将被审查，因为它是 QGAN 在化学/药物发现应用中的一个重要案例研究，除了通常的金融应用之外。通常，我们需要更多的量子比特来生成一个小分子，但是
    QGAN-HG 在量子比特利用上非常高效，可以用更少的量子比特来生成分子。
- en: QGAN-HG, just like QGAN’s consists of a variational quantum circuit which is
    composed of initialization layers, parametric layers, and measurement layers.
    By the application of the measurement layers, a feature vector is extracted which
    is then fed into a classical neural network layer (HG part of QGAN-HG) followed
    by a layer of atom and bond layer to form that atom vectors and bond matrices
    successfully. A QM9 dataset [[25](#CR25)] has been used for training the QGAN-HG
    model and Frechet Distance has been used as a metric to measure the performance
    of the QGAN-HG generated molecules by comparing them with real molecules from
    the dataset.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: QGAN-HG，就像QGAN一样，由一个变分量子电路组成，其中包括初始化层、参数层和测量层。通过应用测量层，提取一个特征向量，然后将其馈送到经典神经网络层（QGAN-HG的HG部分），接着是一个原子和键层，成功形成原子向量和键矩阵。QM9数据集[[25](#CR25)]用于训练QGAN-HG模型，并且使用Frechet距离作为度量标准，通过将其与数据集中的真实分子进行比较，来衡量QGAN-HG生成的分子的性能。
- en: With the architecture and setup as described before, the QGAN-HG performs significantly
    well than, its classical GAN counterparts even with only 4 qubits because of the
    expressive power of the variational quantum circuits being used for the experiment.
    The Frechet distance values obtained are consistent with the original value results.
    The generated molecules are evaluated for their various chemical properties using
    the RDKit and then finally the prediction scores generated are backpropagated
    to the classical neural network (HG) and the variational quantum circuit for the
    update of their parameters.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前面描述的体系结构和设置，即使只有4比特，QGAN-HG的性能也比其经典GAN对应物表现显著，这是因为使用的变分量子电路的表达能力强。获得的Frechet距离值与原始值结果一致。使用RDKit评估生成的分子的各种化学性质，然后最终将生成的预测分数反向传播到经典神经网络（HG）和变分量子电路，以更新其参数。
- en: 4.1 QGANs for Loading Random Distributions
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 QGAN用于加载随机分布
- en: In this subsection, we are discussing a QGAN version with a quantum generator
    and a classical discriminator that records the distribution of the probability
    of classical training samples which has been published in IBM Documentations [[22](#CR22)].
    We will examine how QGAN can be implemented, in polynomial time in quantum states,
    for loading distribution data.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们讨论了一种具有量子生成器和经典鉴别器的QGAN版本，该版本记录了经典训练样本的概率分布，该版本已在IBM文档[[22](#CR22)]中发表。我们将研究如何在多项式时间内使用量子态加载分布数据的QGAN。
- en: A quantum Generative Adversarial Network (QGAN) can be used, for a given k-dimensional
    data sample, to learn the random distribution of the database, and to load it
    directly into a quantum state:![$$\left| {{\text{g}}_{\theta } } \right. = \mathop
    \sum \limits_{i = 0}^{{2^{n} - 1}} \sqrt {p_{i} } \left| i \right._{n}$$](../images/516210_1_En_7_Chapter/516210_1_En_7_Chapter_TeX_Equ1.png)(1)
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: where describe the occurrence probabilities of the basis states | *j*⟩
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: The QGAN training aims to generate a state | *g*⟩ where, for, describes a probability
    distribution that is close to the distribution underlying the training data. Loading
    a uniform distribution into a quantum state is straightforward since it only takes
    one Hadamard gate per qubit [[23](#CR23), [26](#CR26)]. Although loading a normal
    distribution requires more advanced approaches, the required *O(poly(n))* gates
    [[24](#CR24)] will seldom dominate the quantum algorithm's total gate complexity.
    Here is a summary of the steps of training and evaluating the QGAN model.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: The QGAN consists of a quantum generator *G*[*θ*], a variational quantum circuit,
    and a classical discriminator *D*[*ϕ*], a neural network. To implement the quantum
    generator, a depth-1 variational form was selected, that implements *R*[*Y*] rotations
    and *C*[*Z*] gates which take a uniform distribution as an input state. In particular,
    the parameters of the generator must be carefully selected for k > 1\. The circuit
    depth should, for example, be > 1, as higher circuit depths allow more complex
    structures to be shown. The classical discriminator has been used based on an
    implementation of the neural network, implemented by NumPy.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: During training, the parameters of the discriminator and generator are changed
    concerning the following loss functions:![$$L_{G} \left( {\phi ,\theta } \right)
    = - \frac{1}{m}\mathop \sum \limits_{I = 1}^{m} \left[ {\log \left( {D_{\phi }
    \left( {g^{l} } \right)} \right)} \right]$$](../images/516210_1_En_7_Chapter/516210_1_En_7_Chapter_TeX_Equ2.png)(2)and![$$L_{D}
    \left( {\phi ,\theta } \right) = \frac{1}{m}\mathop \sum \limits_{I = 1}^{m} \left[
    {\log \left( {D_{\phi } \left( {x^{l} } \right)} \right) + log\left( {1 - \left(
    {D_{\phi } \left( {g^{l} } \right)} \right)} \right)} \right]$$](../images/516210_1_En_7_Chapter/516210_1_En_7_Chapter_TeX_Equ3.png)(3)
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，鉴别器和生成器的参数根据以下损失函数进行调整：![$$L_{G} \left( {\phi ,\theta } \right) = - \frac{1}{m}\mathop
    \sum \limits_{I = 1}^{m} \left[ {\log \left( {D_{\phi } \left( {g^{l} } \right)}
    \right)} \right]$$](../images/516210_1_En_7_Chapter/516210_1_En_7_Chapter_TeX_Equ2.png)(2)和![$$L_{D}
    \left( {\phi ,\theta } \right) = \frac{1}{m}\mathop \sum \limits_{I = 1}^{m} \left[
    {\log \left( {D_{\phi } \left( {x^{l} } \right)} \right) + log\left( {1 - \left(
    {D_{\phi } \left( {g^{l} } \right)} \right)} \right)} \right]$$](../images/516210_1_En_7_Chapter/516210_1_En_7_Chapter_TeX_Equ3.png)(3)
- en: where m is the batch size description and *g*^l is the description of the quantum
    generator data samples.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，m 是批量大小的描述，*g*^l 是量子生成器数据样本的描述。
- en: With the usage of QGANs, we can effectively load distributions of random probability
    into the quantum data state within polynomial time, which can be utilized for
    use in banking and financial sectors on other quantum algorithms such as QAE.
    To ensure the QGAN optimal performance, the probability distribution for the generator
    initialization must be properly set. Further studies on other distributions were
    released to demonstrate the effectiveness of QGAN in the research with application
    in quantum finance.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 利用 QGAN，我们可以在多项式时间内有效地将随机概率分布加载到量子数据状态中，这可以用于银行和金融领域中的其他量子算法，如 QAE。为确保 QGAN
    的最佳性能，必须适当设置生成器初始化的概率分布。进一步的研究发布了其他分布，以展示 QGAN 在量子金融研究中的有效性及应用。
- en: 4.2 Option Pricing with QGAN^([2](#Fn2))
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 使用 QGAN 进行期权定价^([2](#Fn2))
- en: Options are financial derivatives giving the purchaser the right to purchase
    or sell an asset that is under the buyer's agreed price and date. The price of
    an option, called the premium, consists of a number of variables and it is really
    important to price options properly. The Black–Scholes model, the Monte-Carlo
    Simulating, and the Binomial Price Option are some of the models widely used to
    estimate options [[27](#CR27)]. These theories have wide margins for errors due
    to their value being derived from other assets. The pricing theory of options
    is primarily aimed at determining the probability of exercising options at maturity.
    Stock price, exercise price, volatility rate, and expiry time are typical variables
    used to enter into mathematical models to calculate the option price accurately.
    A stock's underlying option is a Call Option, which gives the holder the right
    to buy the stock at a certain price within a specific time period, and a Put Option
    allows the holder to sell the stock at a defined price within a given time period.
    This section will be further discussed the work performed by a team of IBM researchers,
    based on European call options that can be modelled at maturity only and that
    are modelled and analytically computed by Black–Scholes. They presented a method
    for pricing options and option portfolios, and they have suggested a way to implement
    it using quantum circuits.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 期权是金融衍生品，赋予购买者在约定价格和日期下购买或出售资产的权利。期权的价格，称为期权费，由多个变量组成，正确定价期权非常重要。Black–Scholes
    模型、蒙特卡洛模拟和二叉树期权价格模型是广泛用于估计期权的模型之一 [[27](#CR27)]。这些理论存在很大的误差范围，因为它们的价值是从其他资产衍生出来的。期权定价理论主要旨在确定到期时执行期权的概率。股票价格、行权价格、波动率和到期时间是用于输入数学模型以准确计算期权价格的典型变量。一种股票的基础期权是看涨期权，它赋予持有者在特定时间段内以某一价格购买股票的权利，而看跌期权允许持有者在特定时间段内以规定价格出售股票。本节将进一步讨论由
    IBM 研究人员团队执行的工作，该工作基于只能在到期时建模的欧式看涨期权，并由 Black–Scholes 进行模拟和分析计算。他们提出了一种定价期权和期权组合的方法，并建议使用量子电路来实现它。
- en: The dependent variables of the option are e underlying asset price distribution
    (S[T]), the option's maturity (*T*), and the payoff function of options (*f(S*[*T*]*)*).
    The Black–Scholes model is built on the assumption that the spot price of a maturing
    ST for a European calling option is normally distributed [[28](#CR28)]. QGAN can
    therefore be trained on log-normal distribution, and the output can also be utilized
    as an uncertainty model for option. As follows, a quantum circuit can be constructed
    that loads the uncertainty model. The circuit output is read using Eq. ([1](#Equ1)).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 期权的相关变量包括标的资产价格分布（S[T]）、期权的到期时间（*T*）以及期权的支付函数（*f(S*[*T*]*)*）。Black–Scholes 模型建立在这样一个假设上，即欧式看涨期权到期时的标的价格
    ST 服从正态分布 [[28](#CR28)]。因此，量子生成对抗网络（QGAN）可以在对数正态分布上进行训练，并且其输出也可以作为期权的不确定性模型。接下来，可以构建一个量子电路来加载这个不确定性模型。电路的输出通过方程式 ([1](#Equ1))
    进行读取。
- en: Quantum Amplitude Estimation (QAE) can be used in association with the trained
    uncertainty model to predict the expected value of the payoff function of an option.
    Quantum Amplitude Assessment (QAE) is a simple but powerful quantum method that,
    when used appropriately, is capable of providing high-speed solutions for problems
    that traditionally use Monte Carlo simulation [[22](#CR22), [28](#CR28)–[30](#CR30)].
    However, it's expected that, in general, a universal fault-tolerant quantum computer
    would be required to get a quadratic speed-up compared to the conventional Monte
    Carlo simulations. However, the cost of standard portfolios in the financial sector
    requires more powerful quantum hardware than the current generation of quantum
    computers, capable of executing more complex quantum circuits with more qubits.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 量子振幅估计（QAE）可以与训练有素的不确定性模型结合使用，以预测期权的支付函数的期望值。量子振幅评估（QAE）是一种简单但强大的量子方法，当适当使用时，能够为传统上使用蒙特卡罗模拟的问题提供高速解决方案[[22](#CR22),
    [28](#CR28)–[30](#CR30)]。然而，一般来说，预计需要通用容错量子计算机，以与传统蒙特卡罗模拟相比获得二次加速。然而，在金融行业中，标准投资组合的成本需要比当前一代量子计算机更强大的量子硬件，能够执行更复杂的量子电路，具有更多的量子比特。
- en: 5 Conclusion
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: In this chapter, we began our journey from the basic concepts behind the field
    of classical machine learning and its various types which are relevant in the
    machine learning industry nowadays. Then we focused our attention on the fundamentals
    of quantum machine learning models where variational circuits composed of parameterized
    circuits are used and have better expressive power than the classical neural networks
    for learning features. Apart from this, we saw a use case of the variational algorithm
    for molecular simulation using the VQE algorithm. We then build upon the quantum
    machine learning concepts to learn more about quantum generative adversarial networks
    which are the most basic form of quantum generative modelling and utilize the
    variational circuits for the construction of its generator and discriminator components
    as well as uses quantum gradients for the optimization of its adversarial objective
    function. Finally, we explored 3 important use cases of QGAN’s including small
    molecule drug discovery, loading of random distributions, and option pricing for
    financial applications. Moreover, another application of quantum machine learning
    is for processing natural languages, and in this work, we hope to extend our work
    on quantum natural language processing.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们从经典机器学习领域背后的基本概念开始了我们的旅程，以及在当前机器学习行业中相关的各种类型。然后，我们将注意力集中在量子机器学习模型的基础上，其中使用了由参数化电路组成的变分电路，并且比经典神经网络具有更好的表达能力来学习特征。除此之外，我们看到了使用VQE算法进行分子模拟的变分算法的用例。然后，我们基于量子机器学习的概念，了解了更多关于量子生成对抗网络的知识，这是量子生成建模的最基本形式，并利用变分电路构建其生成器和判别器组件，并使用量子梯度优化其对抗目标函数。最后，我们探讨了QGAN的3个重要用例，包括小分子药物发现、随机分布的加载以及金融应用中的期权定价。此外，量子机器学习的另一个应用是处理自然语言，在这项工作中，我们希望扩展我们在量子自然语言处理方面的工作。
