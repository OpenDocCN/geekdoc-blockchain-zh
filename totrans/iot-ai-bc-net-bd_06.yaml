- en: © Nishith Pathak and Anurag Bhandari 2018Nishith Pathak and Anurag BhandariIoT,
    AI, and Blockchain for .NET[https://doi.org/10.1007/978-1-4842-3709-0_6](A458845_1_En_6_Chapter.html)
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: © 2018年 Nishith Pathak 和 Anurag Bhandari Nishith Pathak 和 Anurag Bhandari IoT、AI
    和区块链用于 .NET [https://doi.org/10.1007/978-1-4842-3709-0_6](A458845_1_En_6_Chapter.html)
- en: 6. Building Smarter Applications Using Cognitive APIs
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6. 使用认知 API 构建更智能的应用程序
- en: 'Nishith Pathak^(1 ) and Anurag Bhandari²(1)Kotdwara, Dist. Pauri Garhwal, India(2)Jalandhar,
    Punjab, IndiaThe famous saying “Rome wasn’t built in a day” is so true about Microsoft
    cognitive services. Each service is exposed as a RESTful API by abstracting years
    and decades of experience, complex algorithms, deep neural networks, fuzzy logic,
    and research from the Microsoft research team. In Chapter [4](A458845_1_En_4_Chapter.html),
    you were introduced to Microsoft Cognitive Services. You also learned how cognitive
    services are different from traditional programming systems. Later in Chapter
    [4](A458845_1_En_4_Chapter.html), you got a sneak preview of all the Microsoft
    Cognitive Services API that Microsoft has produced.Chapter [5](A458845_1_En_5_Chapter.html)
    continued the journey of cognitive services by covering the prerequisites of creating
    Cognitive Services and setting up a development environment. You also got familiar
    with using your first cognitive applications in Visual Studio and recognized the
    power of the Computer Vision API.Welcome to this chapter. In this chapter, we
    extend Cognitive Services by applying them to the smart hospital use case that
    we introduced in Chapter [1](A458845_1_En_1_Chapter.html). As you now know, Microsoft
    Cognitive Services are broadly classified into six main categories, and each of
    them has 4-5 services, which leads to about 29 services while writing these books.
    Each of the Cognitive Services can be used in our smart hospital Asclepius Consortium.
    We will go through some of the most powerful ways of using cognitive services,
    especially around NLU, speech, and using the Face API, and apply them to the Asclepius
    hospital example.At the end of chapter, you’ll:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'Nishith Pathak^(1 ) 和 Anurag Bhandari² (1)印度，Pauri Garhwal 市，Kotdwara (2)印度，旁遮普邦，朱兰达拉著名的说法“罗马不是一天建成的”对于微软认知服务确实如此。每项服务都暴露为
    RESTful API，通过将来自微软研究团队的数十年经验、复杂算法、深度神经网络、模糊逻辑和研究抽象化。在[第 4 章](A458845_1_En_4_Chapter.html)，你被介绍了微软认知服务。你也学到了认知服务与传统编程系统的区别。稍后在[第
    4 章](A458845_1_En_4_Chapter.html)，你会预览到微软已经生产的所有 Microsoft 认知服务 API。[第 5 章](A458845_1_En_5_Chapter.html)继续探讨认知服务的旅程，涵盖了创建认知服务和设置开发环境的先决条件。你还熟悉了在
    Visual Studio 中使用你的第一个认知应用程序，并认识到了计算机视觉 API 的强大功能。欢迎来到本章。在本章中，我们通过将它们应用到我们在[第
    1 章](A458845_1_En_1_Chapter.html)中介绍的智能医院用例来扩展认知服务。正如你现在所知道的，微软认知服务被广泛分类为六大类别，每个类别都有
    4-5 个服务，这导致写这些书时大约有 29 个服务。我们将介绍如何使用认知服务的一些最强大的方式，特别是围绕 NLU、语音以及使用 Face API，并将它们应用到
    Asclepius 医院的示例中。在本章的结尾，你将:'
- en: Understand some of the powerful ways to apply cognitive services
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解一些应用认知服务的强大方式
- en: Understand natural language understanding (NLU) and LUIS
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解自然语言理解（NLU）和 LUIS
- en: Develop, test, host, and manage the LUIS application for the smart hospital
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为智能医院开发、测试、托管和管理 LUIS 应用程序
- en: Interact with the Speech API
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与语音 API 进行交互
- en: Use the Speech API to convert speech to text and text to speech
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用语音 API 将语音转换为文本和文本转换为语音
- en: Use face detection and recognition in hospital scenarios
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在医院场景中使用人脸检测和识别
- en: The Asclepius Consortium is a chain of hospitals that deal with almost every
    kind of disease. As part of their offering, they have the Dr. Checkup mobile application
    that provides natural language functionality in series of applications. This includes
    a mobile application that serves not only to maintain history, records, and payment
    transfers, but also helps user perform basic diagnosis by providing symptoms.
    This helps patients not only take quick action but understand the complexity of
    diseases, as shown in Figure [6-1](#Fig1).![A458845_1_En_6_Fig1_HTML.jpg](A458845_1_En_6_Fig1_HTML.jpg)Figure
    6-1The Dr. Checkup app provides a basic diagnosisOnce the disease is identified,
    patients can schedule an appointment with a specific specialist/doctor, as shown
    in Figure [6-2](#Fig2).![A458845_1_En_6_Fig2_HTML.jpg](A458845_1_En_6_Fig2_HTML.jpg)Figure
    6-2Dr. Checkup is scheduling an appointment with a doctor after chatting with
    a patientAsclepius Consortium also uses the same NLU techniques of scheduling
    appointments in their frontend teller machines.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Asclepius 联盟是一家涉及几乎所有类型疾病的医院连锁机构。作为他们提供的一部分，他们有一个名为 Dr. Checkup 的移动应用程序，提供一系列应用程序中的自然语言功能。这包括一个移动应用程序，不仅用于维护历史记录和付款转账，而且通过提供症状帮助用户进行基本诊断。这不仅帮助患者迅速采取行动，还帮助他们理解疾病的复杂性，如图
    [6-1](#Fig1) 所示。![A458845_1_En_6_Fig1_HTML.jpg](A458845_1_En_6_Fig1_HTML.jpg)图
    6-1 Dr. Checkup 应用提供基本诊断一旦疾病被识别出来，患者可以安排与特定专家/医生的预约，如图 [6-2](#Fig2) 所示。![A458845_1_En_6_Fig2_HTML.jpg](A458845_1_En_6_Fig2_HTML.jpg)图
    6-2 Dr. Checkup 与患者聊天后安排与医生的预约 Asclepius 联盟还在其前端柜员机中使用相同的 NLU 技术来安排预约。
- en: Microsoft’s Mission and NLU
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微软的使命和自然语言理解
- en: 'Microsoft’s earlier mission was to have desktop computers in every home. Microsoft
    has been very successful in achieving that in most of the Western world. Recently
    Microsoft revised their mission to “Empowering every person and every organization
    on the planet to achieve more”. This new mission from Microsoft is more human
    in nature compared to previously being more technological. The supreme goal of
    artificial intelligence has always been to serve humanity. In order for AI to
    serve humanity, it should be able to understand humans. As a first step, AI should
    understand and process the languages that humans speak.As more and more intelligent
    systems are devised, it is important for these systems to understand human languages,
    interpret the meanings, and then take appropriate actions wherever necessary.
    This domain of interpreting human languages is called Natural Language Understanding
    (NLU). NLU is the ability of a machine to convert natural language text to a form
    that the computer can understand. In other words, it’s the ability to extract
    the meaning from the sentence. This enables the system to understand the “what”
    question of the language.Take the use case in Chapter [4](A458845_1_En_4_Chapter.html)
    where a person is asking an intelligent system questions like the following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 微软早期的使命是让每个家庭都拥有台式电脑。微软在实现这一目标方面取得了非常成功的成绩，覆盖了大部分西方世界。最近，微软修改了他们的使命为“赋能地球上的每个个人和组织，让他们取得更多成就”。与以前更加技术化相比，微软的这一新使命更加人性化。人工智能的最高目标一直是为人类服务。为了让人工智能为人类服务，它应该能够理解人类。作为第一步，人工智能应该能够理解和处理人类所说的语言。随着越来越多的智能系统的设计，这些系统理解人类语言、解释含义，然后在必要时采取适当的行动变得越来越重要。这个解释人类语言的领域被称为自然语言理解（NLU）。NLU
    是机器将自然语言文本转换为计算机能够理解的形式的能力。换句话说，它是从句子中提取含义的能力。这使系统能够理解语言的“什么”问题。接下来以第 [4](A458845_1_En_4_Chapter.html)
    章的用例为例，其中一个人正在向智能系统提问，问题如下：
- en: “How does my schedule look today?
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “今天的日程安排如何？
- en: Now this question can be asked in a variety of ways. Some of themWhat’s my schedule
    for the day?Are there a lot of meetings in the office?How busy is my calendar
    for today?To humans, it is immediately clear that these sentences are a person’s
    way of inquiring about her schedule for the day. For a machine, it may not be
    clear. In fact, creating an NLU engine has been one of the more complex problems
    to solve. There is variety of factors, but the main issues is that there is no
    one algorithm to resolve it. Moreover, training a machine to understand grammar,
    rules, and slang is difficult. Thanks to the advent of deep learning, we can now
    achieve great precision of language understanding by training the engine with
    thousands of utterances, create a pattern recognition based on those examples,
    and then constantly improve on it to identify formal and informal rules of language
    understanding.Based on this NLU theory, various commercial offerings exist and
    are based on the intent-entity schema that we briefly discussed in Chapter [4](A458845_1_En_4_Chapter.html).
    Intent helps in understanding the intention of the user behind the question being
    asked. If you look at these examples, there were multiple ways of asking same
    questions, but the intention was the same—get me the schedule for that day. Once
    we know the right intent, it is then straightforward for the system to respond
    with a correct answer.To identify the right intention, NLU systems are also trained
    to recognize certain keywords. These keywords are called entities. In our previous
    examples, to get a schedule from a calendar, you often need require person’s name
    and date. Each of these can be marked as entities. It is important to understand
    that entities are optional and not all sentences may be accompanied by them. There
    is also a good chance that a sentence may have more than one entity as well. We
    are going to discuss identifying intents and entities later in the chapter.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这个问题可以以多种方式提出。其中一些是：什么是我今天的日程安排？办公室有很多会议吗？我的日历今天很忙吗？对于人类来说，这些句子立即清楚地表明了一个人询问她今天日程的方式。对于机器来说，可能不太清楚。事实上，创建一个自然语言理解引擎是一个比较复杂的问题之一。有各种各样的因素，但主要问题是没有一个算法可以解决它。此外，训练机器理解语法、规则和俚语是困难的。由于深度学习的出现，我们现在可以通过用成千上万个话语训练引擎，创建一个基于这些例子的模式识别，然后不断改进它来识别语言理解的正式和非正式规则，从而达到语言理解的极高精度。基于这个自然语言理解理论，存在各种商业产品，并且基于我们在第[4](A458845_1_En_4_Chapter.html)章中简要讨论的意图-实体架构。意图有助于理解用户在提问时的意图。如果你看这些例子，有多种方式提出相同的问题，但意图是相同的——给我那一天的日程安排。一旦我们知道了正确的意图，系统就可以直接用正确的答案来回应。为了识别正确的意图，自然语言理解系统还经过训练来识别某些关键词。这些关键词称为实体。在我们之前的例子中，要从日历中获取日程，通常需要人的姓名和日期。每个实体都可以标记出来。重要的是要理解，实体是可选的，并非所有句子都可能有实体。句子可能还有更多的实体。我们将在本章后面讨论识别意图和实体。
- en: Language Understanding Intelligent Service (LUIS)
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语言理解智能服务（LUIS）
- en: The Language Understanding Intelligent Service aka LUIS is Microsoft’s NLU cloud
    service and is part of the cognitive suite discussed in Chapter [4](A458845_1_En_4_Chapter.html).
    It is important to understand that LUIS shouldn’t be treated as a full-fledged
    software application for your end user. LUIS only replaces the NLU component from
    the overall stack. It’s an NLU engine that handles NLU implementation by abstracting
    the inner machine learning model’s complexity. Your frontend still can be a website,
    chatbot, or any application ranging from a graphical to conversational user interface.
    In our Asclepius use case, the frontend is mobile application (Dr. Checkup). Before
    we open LUIS and start working, it is important to understand the underpinnings
    of LUIS that require deep expertise in design. Let’s look at the behind the scenes
    aspects of LUIS.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 语言理解智能服务，又称为 LUIS，是微软的 NLU 云服务，是第 [4](A458845_1_En_4_Chapter.html) 章讨论的认知套件的一部分。重要的是要理解，LUIS
    不应被视为最终用户的完整软件应用程序。LUIS 只是替换整体堆栈中的 NLU 组件。它是一个处理 NLU 实现的 NLU 引擎，通过抽象内部机器学习模型的复杂性。您的前端仍然可以是网站、聊天机器人或任何从图形到对话用户界面的应用程序。在我们的
    Asclepius 用例中，前端是移动应用程序（Dr. Checkup）。在打开 LUIS 并开始工作之前，了解需要深入设计专业知识的 LUIS 的基础是很重要的。让我们看看
    LUIS 的幕后方面。
- en: Designing on LUIS
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 LUIS 上设计
- en: The LUIS framework is just like a clean slate that’s been trained on a few built-in
    entities. As a first step, it is important to design the LUIS application in an
    effective manner. Designing a LUIS application requires a profound understanding
    of the problems that your software is trying to solve. For example, our use case
    of the smart hospital requires LUIS to be used to converse with patients to book
    an appointment with a doctor or to talk with the hospital chatbot to detect whether
    a doctor’s attention is really required. There are no strict guidelines or rules
    to follow while implementing LUIS. However, based on our experiences while interacting
    with LUIS and another NLU system, we came up with some high-level guidelines.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: LUIS 框架就像一个干净的板，已经训练了一些内置实体。作为第一步，设计LUIS 应用程序是非常重要的。设计 LUIS 应用程序需要对软件试图解决的问题有深刻的理解。例如，我们的智能医院用例需要使用
    LUIS 与患者交流，预约医生的约会，或者与医院聊天机器人交谈，以检测是否真的需要医生的关注。在实施 LUIS 时没有严格的指导方针或规则。然而，根据我们与
    LUIS 和另一个 NLU 系统互动的经验，我们提出了一些高级指导原则。
- en: Design Guidelines for Using LUIS
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 LUIS 的设计指南
- en: 'The LUIS application should have the right intent and entities for this smart
    healthcare use case. There are many ways to identify the right intent and entities.
    We propose the following design principles for achieving effective identification:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 智能医疗用例中，LUIS 应具有正确的意图和实体。有许多方法可以识别正确的意图和实体。我们提出以下设计原则以实现有效的识别：
- en: Plan your scope first. It is very important to plan the scope and narrow it
    down to what’s inside the scope of LUIS. Clear identification of the scope is
    the first step in successfully achieving delivery of LUIS implementation. We recommend
    you keep the scope of applying LUIS limited to a few tasks or goals.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先规划您的范围。规划范围并将其缩小到 LUIS 范围内非常重要。明确确定范围是成功实现 LUIS 实现交付的第一步。我们建议您将应用 LUIS 的范围限制在少数任务或目标中。
- en: Use a prebuilt domain (if possible). Once the scope is finalized, you are aware
    now of the use case or domain that LUIS is going to solve. LUIS also comes with
    some prebuilt domains that have a set of entities and intents previously defined.
    These prebuilt domains are also pre-trained and are ready to use. Use prebuilt
    domain whenever you can. If your requirement is achieved with prebuilt intents
    or entities, choose them before creating a new one. You can always customize the
    prebuilt domains. You should always try to pick at least one of the prebuilt domains
    and entities along, even if you also have to create a few new ones to suit your
    requirements.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用预构建的领域（如果可能）。一旦确定了范围，您现在了解了 LUIS 将要解决的用例或领域。LUIS 还附带了一些预构建领域，其中包含一组以前定义的实体和意图。这些预构建领域也经过了预训练，并且可以立即使用。如果可能的话，请尽量使用预构建领域。如果您的需求可以通过预构建的意图或实体实现，请在创建新的之前选择它们。您始终可以自定义预构建领域。即使您必须创建一些新的来满足您的需求，您也应该始终尝试挑选至少一个预构建的领域和实体。
- en: Identify the tasks that your application is going to perform. Once a domain
    is identified, list the tasks that your application is going to perform. These
    tasks identify the intention of the end user to access your application. As you
    may have guessed, create each task as an intent. It is important to break tasks
    appropriately so that you don’t have tasks that are non-specific. The more tasks
    you have, the more rigorous the training is.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定您的应用程序将执行的任务。一旦确定了领域，列出您的应用程序将执行的任务。这些任务确定了最终用户访问您的应用程序的意图。正如你可能已经猜到的，将每个任务创建为一个意图。适当地分解任务非常重要，这样您就不会有不具体的任务。您拥有的任务越多，培训就越严格。
- en: Identify additional information required for tasks. Not all tasks are straightforward.
    Most of them require some additional information. This additional information
    are called entities. Entities complement the intents for identifying specific
    tasks. You can think of entities as variables of your application that are required
    to store and pass information to your client application.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定任务所需的额外信息。并非所有任务都是直截了当的。其中大多数任务都需要一些额外的信息。这些额外的信息称为实体。实体为识别特定任务的意图补充。您可以将实体视为应用程序的变量，这些变量需要存储并传递信息给客户端应用程序。
- en: Training is a key. At the core, LUIS accepts textual inputs. These inputs are
    called utterances. LUIS needs to be trained extensively on these utterances before
    the LUIS model will really understand future utterances. The more example utterances
    you have, the better the model. In order to identify various utterances, it’s
    better to collect phrases that you expect the user would type and identify different
    ways through which the same questions can be asked. If your application must deal
    with multiple similar use cases, there's a good chance LUIS will get confused
    with the lack of sufficient training for each of the similar use cases. Despite
    your training, it is not safe to assume that LUIS will respond with absolute accuracy.
    LUIS is based on the active machine learning model, which ensures that the LUIS
    model keeps on learning and enhancing the model in time. In fact, LUIS keeps track
    of all utterances for which it was unable to predict an intent with high confidence.
    You will find such utterances under the “Suggested Utterances” section on an intent’s
    page. Use this option to appropriately label utterances and confirm to LUIS whether
    it was right or wrong. LUIS training is a continuous process, until you find suggested
    utterances sections showing no suggestions.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 培训至关重要。在核心层面，LUIS 接受文本输入。这些输入称为话语。在 LUIS 真正理解未来话语之前，需要对这些话语进行大量训练。拥有的示例话语越多，模型就越好。为了识别各种话语，最好收集您期望用户键入的短语，并确定可以提出相同问题的不同方式。如果您的应用程序必须处理多个类似的用例，LUIS
    有可能因为对每个相似用例的训练不足而感到困惑。尽管进行了培训，但不安全地假设 LUIS 会以绝对准确性做出回应是不明智的。LUIS 基于主动机器学习模型，这确保了
    LUIS 模型会持续学习和增强模型的时间。事实上，LUIS 会跟踪所有无法以高置信度预测意图的话语。您将在意图页面的“建议的话语”部分找到这些话语。使用此选项适当地标记话语，并向
    LUIS 确认它是否正确或错误。LUIS 培训是一个持续的过程，直到找不到建议的话语部分不再提供建议为止。
- en: Plan Your Scope First
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 首先规划您的范围
- en: The high-level sequence diagram for this mobile application and frontend teller
    is shown in Figure [6-3](#Fig3).![A458845_1_En_6_Fig3_HTML.jpg](A458845_1_En_6_Fig3_HTML.jpg)Figure
    6-3The high-level interactions between various actors while booking appointments
    or during initial diagnosisHere are the stepwise interactions as well.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 此移动应用程序和前端柜员机的高级序列图如图[6-3](#Fig3)所示。![A458845_1_En_6_Fig3_HTML.jpg](A458845_1_En_6_Fig3_HTML.jpg)图6-3各方在预约或初步诊断期间的高级互动步骤也在此处列出。
- en: 1.The patient asks, either through a mobile application or the frontend teller
    machine (either through message or voice), to talk with Dr. Checkup.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1.患者通过移动应用程序或前端柜员机（通过短信或语音）请求与查康医生交谈。
- en: 2.If the patient submits the query through voice, the mobile app/frontend teller
    machine uses the Microsoft Speech API to convert the voice into text.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2.如果患者通过语音提交查询，则移动应用程序/前端柜员机将使用 Microsoft Speech API 将语音转换为文本。
- en: 3.The application then passes the text to the LUIS app to determine the intent
    of the question asked.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3.然后，应用程序将文本传递给 LUIS 应用程序，以确定所提问的意图。
- en: 4.LUIS performs its NLU analysis and returns its predictions for intent and
    entity. The result is returned as JSON back to the application.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4.LUIS 进行其自然语言理解分析，并返回其对意图和实体的预测。结果作为 JSON 返回到应用程序。
- en: 5.The application checks for top scoring intents in the returned JSON and decides
    on the desired action. The action can be scheduling an appointment or providing
    a basic diagnosis. If action is scheduling an appointment, it checks with a doctor’s
    calendar and sets the appointment. For a basic diagnosis, it talks with the databases
    by passing the intent and entity combination received.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 5.应用程序在返回的 JSON 中检查得分最高的意图，并决定所需的操作。操作可以是安排约会或提供基本诊断。如果操作是安排约会，则检查医生的日历并设置约会。对于基本诊断，它通过传递接收到的意图和实体组合与数据库交流。
- en: 6.The database has a predefined set of answers stored for the combination of
    intent and entity. The answer is retrieved and sent back to the mobile application.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 6.数据库中存储了预定义的答案，针对意图和实体的组合。答案被检索并发送回移动应用程序。
- en: 7.The application displays the desired result to the patient, either through
    text or voice.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 7.应用程序通过文本或语音向患者显示所需的结果。
- en: In these scenarios and applications, NLU plays a vital role in the implementation.
    Before we delve more into other aspects, let us first look at how to identify
    intents and entities.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些场景和应用中，自然语言理解在实施中起着至关重要的作用。在我们深入探讨其他方面之前，让我们首先看看如何识别意图和实体。
- en: Identifying Intents and Entities
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 识别意图和实体
- en: Once the scope is finalized, the next step is to identify the intents and entities.
    Let’s take the case of early diagnosis. What do you expect from the end user?
    Apart from the name, age, and gender details, you expect the user to list his
    symptoms so that, based on some general set of rules, an early diagnosis can be
    provided. Now the user can provide these symptoms in a simple sentence or in a
    couple of sentences. Figure [6-4](#Fig4) shows some of the examples of how someone
    can provide symptoms.![A458845_1_En_6_Fig4_HTML.jpg](A458845_1_En_6_Fig4_HTML.jpg)Figure
    6-4Some of the ways that users can share their symptomsIf you look these examples,
    they all are being requested for the early diagnosis intent. Most of these early
    diagnosis sentences are matched with various entities, like body part and symptom.
    Each body part and symptom can be replaced with some body parts or with symptoms.
    For the first example, you can have the following:![A458845_1_En_6_Figa_HTML.jpg](A458845_1_En_6_Figa_HTML.jpg)Of
    course, this list is not exhaustive and you may need to work on creating a more
    complete list. Let’s take another use case of scheduling an appointment with the
    doctor. What do you need to schedule a doctor appointment? Essentially, you need
    the type of doctor (gynecologist, dentist, cardiologist, and so on), the potential
    date, and optionally a specific time range, before blocking the time of the doctor.
    Figure [6-5](#Fig5) shows some of the ways you can schedule your appointment.![A458845_1_En_6_Fig5_HTML.jpg](A458845_1_En_6_Fig5_HTML.jpg)Figure
    6-5Some ways to schedule an appointment with a doctorThese examples are for setting
    an appointment with the doctor and have the entity doctortype associated with
    them. There are times when the user specifies the intent but doesn’t provide an
    entity. Then it’s up to the application logic to decide on the next step. You
    can check back with the user or even proceed to process while assuming some default
    value. Consider this example:I want to see a doctorThe user wants to schedule
    an appointment with a doctor, but doesn’t specify the doctor’s name or even the
    date and time. In this scenario, you can set the default type for the entity.
    In this case, it can be a physician for example and the appointment time can be
    the next available slot.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦范围确定，下一步是确定意图和实体。让我们以早期诊断为例。您期望终端用户提供什么？除了姓名、年龄和性别详细信息外，您期望用户列出他的症状，以便根据一些一般性规则提供早期诊断。现在用户可以用一个简单的句子或几个句子提供这些症状。图[6-4](#Fig4)展示了某些用户如何提供症状的示例。![A458845_1_En_6_Fig4_HTML.jpg](A458845_1_En_6_Fig4_HTML.jpg)图6-4用户提供症状的一些方式如果您看这些例子，它们都是为了早期诊断意图而请求的。大多数这些早期诊断句子与各种实体匹配，如身体部位和症状。每个身体部位和症状都可以用一些身体部位或症状来替换。对于第一个例子，您可以有以下内容：![A458845_1_En_6_Figa_HTML.jpg](A458845_1_En_6_Figa_HTML.jpg)当然，这个列表不是详尽无遗的，您可能需要努力创建一个更完整的列表。让我们再来看一个与医生预约挂号有关的用例。您需要什么来安排医生预约？基本上，您需要医生的类型（妇科医生、牙科医生、心脏病专家等）、可能的日期，以及可选的特定时间范围，在将医生的时间锁定之前。图[6-5](#Fig5)展示了您可以安排预约的一些方式。![A458845_1_En_6_Fig5_HTML.jpg](A458845_1_En_6_Fig5_HTML.jpg)图6-5安排与医生预约的一些方式这些示例是用于与医生预约的，并与实体医生类型相关联。有时用户指定了意图，但没有提供实体。然后，由应用程序逻辑来决定下一步。您可以回头询问用户，甚至假定一些默认值并继续处理。考虑这个例子：我想看医生用户想预约看医生，但没有指定医生的姓名，甚至日期和时间。在这种情况下，您可以为实体设置默认类型。在这种情况下，例如可以是医生，而约会时间可以是下一个可用的时段。
- en: Creating a Data Dictionary for LUIS
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为LUIS创建数据字典
- en: As you know by now, LUIS doesn’t perform any calculations or logic. It only
    extract meaning from utterances by extracting intents and entities from them.
    As a good design process, it helps to create a data dictionary before you open
    LUIS and start working on it. The data dictionary is more like a bible of metadata
    that stores utterances, along with its associated intents and entities. You can
    use it as a design document for your NLU. This is also helpful, as through this
    dictionary, you can determine the count of intents and entities to be created.
    Table [6-1](#Tab1) shows a good way to create three columns of a data dictionary
    for the LUIS application.Table 6-1The Data Dictionary Sample for Dr. Checkup
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您现在所知，LUIS不执行任何计算或逻辑。它只是从话语中提取意图和实体的含义。作为一个良好的设计过程，帮助您在打开LUIS并开始工作之前创建一个数据字典。数据字典更像是一个存储话语及其相关意图和实体的元数据的圣经。您可以将其用作您的NLU的设计文档。这也是有帮助的，因为通过这个字典，您可以确定要创建的意图和实体的数量。表[6-1](#Tab1)显示了用于LUIS应用程序的数据字典的三列的良好方法。表6-1用于Dr.
    Checkup的数据字典示例
- en: '| Utterances | Intent | Entity |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 话语 | 意图 | 实体 |'
- en: '| :-- | :-- | :-- |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- | :-- |'
- en: '| Schedule an appointment with the physician tomorrow before 5 PM | scheduleAppointment
    | DoctorType = physician,datetime = tomorrow,AppointmentTime::StartTime = AppointmentTime::EndTime
    = 5 PM |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 在明天下午5点之前与医生预约 | scheduleAppointment | 医生类型 = 医师, 日期时间 = 明天, 预约时间::开始时间 =
    预约时间::结束时间 = 下午5点 |'
- en: '| Pain in abdomen | checkCondition | Symptom = PainBody part = abdomen |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 腹痛 | checkCondition | 症状 = 腹痛身体部位 = 腹部 |'
- en: '| Feverish with loud cough | checkCondition | Symptom = feverishBody Part =
    Loud Cough |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 发烧伴有大声咳嗽 | checkCondition | 症状 = 发烧身体部位 = 大声咳嗽 |'
- en: '| Set an appointment with orthopedist | scheduleAppointment | Doctor type =
    orthopedist |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 与骨科医生预约 | scheduleAppointment | 医生类型 = 骨科医生 |'
- en: This table is just an example, but it would be wise to create it as Excel sheet
    and use it as a design document for your LUIS application.TipThe data dictionary
    shown in Table [6-1](#Tab1) is a basic dictionary to get started. You can extend
    it and make it more usable. For instance, add an Answer column that provides a
    message about what answer would be returned to the user. You can also use this
    data dictionary to create test use cases.Identifying intent and entities is the
    one of the most important tasks. Once the intents and entities are identified,
    the next task is to create these entities and intents on LUIS. Before you create
    entities in LUIS, you need to grab a subscription key for LUIS.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表只是一个示例，但将其创建为Excel表格并将其用作LUIS应用程序的设计文档是明智的。提示表[6-1](#Tab1)中显示的数据字典是一个基本的字典，可以帮助您入门。您可以扩展它并使其更可用。例如，添加一个答案列，提供有关将向用户返回什么答案的消息。您还可以使用此数据字典创建测试用例。识别意图和实体是最重要的任务之一。一旦识别出意图和实体，下一个任务就是在LUIS中创建这些实体和意图。在您在LUIS中创建实体之前，您需要获取LUIS的订阅密钥。
- en: Getting a Subscription Key for LUIS
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取LUIS的订阅密钥
- en: Chapter [5](A458845_1_En_5_Chapter.html) described in detail how to create an
    account in Azure Portal and get the subscription key for the Vision API. You can
    use the same account to get a subscription key for LUIS. Open Azure Portal and,
    from the left side menu, choose New ➤ AI + Cognitive Services. Click on Language
    Understanding, as shown in Figure [6-6](#Fig6).![A458845_1_En_6_Fig6_HTML.jpg](A458845_1_En_6_Fig6_HTML.jpg)Figure
    6-6A screenshot of the Azure Service Portal after selecting the new option from
    the menuFill out the form with an appropriate subscription, pricing tier, and
    resource, as shown in Figure [6-7](#Fig7). You may want to get started with the
    free tier (F0), as we discussed in the previous chapter. Click on Create.![A458845_1_En_6_Fig7_HTML.jpg](A458845_1_En_6_Fig7_HTML.jpg)Figure
    6-7Filling in the form for creating a LUIS subscription keyOnce this is submitted,
    it will take some time to get the account validated and then created. You can
    then go back to the dashboard after receiving notification on it. Click on your
    LUIS account in the dashboard and get the keys to take it forward, as shown Figure
    [6-8](#Fig8).![A458845_1_En_6_Fig8_HTML.jpg](A458845_1_En_6_Fig8_HTML.jpg)Figure
    6-8The LUIS subscription keys are created in the Azure Portal
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 章节 [5](A458845_1_En_5_Chapter.html) 详细描述了如何在 Azure 门户中创建帐户并获取 Vision API 的订阅密钥。您可以使用相同的帐户获取
    LUIS 的订阅密钥。打开 Azure 门户，从左侧菜单中选择 New ➤ AI + Cognitive Services。点击 Language Understanding，如图
    [6-6](#Fig6) 所示。![A458845_1_En_6_Fig6_HTML.jpg](A458845_1_En_6_Fig6_HTML.jpg)图
    6-6选择新选项后的 Azure 服务门户的截图填写表格，选择适当的订阅、定价层和资源，如图 [6-7](#Fig7) 所示。您可能希望从免费层（F0）开始，正如我们在前一章中讨论的那样。点击
    Create。![A458845_1_En_6_Fig7_HTML.jpg](A458845_1_En_6_Fig7_HTML.jpg)图 6-7填写创建
    LUIS 订阅密钥的表格一旦提交，将需要一些时间来验证并创建帐户。在收到通知后，您可以返回仪表板。在仪表板中点击您的 LUIS 帐户，并获取密钥以继续，如图
    [6-8](#Fig8) 所示。![A458845_1_En_6_Fig8_HTML.jpg](A458845_1_En_6_Fig8_HTML.jpg)图
    6-8在 Azure 门户中创建 LUIS 订阅密钥
- en: Apply the Subscription
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 应用订阅
- en: Now you have everything ready, so the first task is to add the newly created
    subscription keys to LUIS.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经准备好了一切，所以第一项任务是将新创建的订阅密钥添加到 LUIS 中。
- en: 1.Open the LUIS site from [https://luis.ai](https://luis.ai) .
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1.从 [https://luis.ai](https://luis.ai) 打开 LUIS 网站。
- en: 2.Log in through the same Microsoft account that you used in the Azure Portal.
    While writing the book, LUIS asks for accepting license and grants LUIS permission
    to access the Microsoft account.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2.通过在 Azure 门户中使用相同的 Microsoft 帐户登录。在编写本书时，LUIS 要求接受许可协议，并授予 LUIS 访问 Microsoft
    帐户的权限。
- en: 3.Click OK. You are now on the LUIS dashboard page. If this is the first time
    you have logged in, you will see the MyApps section empty.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3.点击确定。您现在位于 LUIS 仪表板页面。如果这是您第一次登录，您将看到 MyApps 部分为空。
- en: 4.Click on Create New App to create a new app and specify name, culture, and
    optional description, as shown in Figure [6-9](#Fig9). Click Done. You can provide
    your own name and culture as per your logic.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“创建新应用”以创建一个新应用，并指定名称、文化和可选描述，如[图6-9](#Fig9)所示。点击“完成”。你可以根据自己的逻辑提供自己的名称和文化。
- en: '![A458845_1_En_6_Fig9_HTML.jpg](A458845_1_En_6_Fig9_HTML.jpg)Figure 6-9Creating
    a new application in LUISCongratulations, you have quickly created an application.
    Now it’s time to add your subscription keys to the application before creating
    intents and entities.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '![A458845_1_En_6_Fig9_HTML.jpg](A458845_1_En_6_Fig9_HTML.jpg)图6-9在LUIS中创建新应用恭喜，您已经快速创建了一个应用程序。现在是在创建意图和实体之前向应用程序添加您的订阅密钥的时候了。'
- en: Applying the Subscription Key in LUIS
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在LUIS中应用订阅密钥
- en: As you click Done previously, you are redirected to the application’s page.
    If not, click on Asclepius NLU from the MyApps section.Click on Publish and scroll
    down to the “Resource and Keys” section. Click on Add Keys and select the tenant,
    Azure subscription, and then LUIS account, as shown in Figure [6-10](#Fig10).
    Tenant represents the Azure active subscription ID of the client or of your organization.![A458845_1_En_6_Fig10_HTML.jpg](A458845_1_En_6_Fig10_HTML.jpg)Figure
    6-10Assigning a LUIS key to the appIt’s time now to add intents and entities.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前点击“完成”后，您将被重定向到应用程序页面。如果没有，请从“我的应用程序”部分点击Asclepius NLU。点击“发布”并滚动到“资源和密钥”部分。点击“添加密钥”并选择租户、Azure订阅，然后选择LUIS帐户，如[图6-10](#Fig10)所示。租户代表客户或您组织的Azure活动订阅ID。![A458845_1_En_6_Fig10_HTML.jpg](A458845_1_En_6_Fig10_HTML.jpg)图6-10向应用程序分配LUIS密钥现在是时候添加意图和实体了。
- en: Adding Intent and Entities
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 添加意图和实体
- en: Adding intents and entities is very straightforward. To add a new intent, from
    the left sidebar go to the Intents page. If this is the first time you have been
    on this page, you won’t have any intents created. Keep your data dictionary handy.
    Now click on Create New Intent, specify the first entry of the intent from the
    data dictionary as the intent name, and click Done. The first column of your data
    dictionary also lists the sample utterances. Start adding sample utterances as
    shown previously. After adding the initial utterances, click the Save button to
    save your changes. Hover over the word Psychiatrist in the Just Added utterance
    to see it surrounded by square brackets. Clicking on the word will give you the
    option to either label it as an existing entity or as a new entity. Create an
    entity called Doctor type. Figure [6-11](#Fig11) shows how the scheduleAppointment
    intent will look once you have committed the initial utterances.![A458845_1_En_6_Fig11_HTML.jpg](A458845_1_En_6_Fig11_HTML.jpg)Figure
    6-11The ScheduleAppointment intent screenshot with a few utterancesRepeat this
    process for all the intents, entities, and utterances created in the data dictionary.
    You should now train, test, and publish the LUIS as an endpoint, which can be
    used by the mobile application.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 添加意图和实体非常简单。要添加新意图，请从左侧边栏转到意图页面。如果这是您第一次进入此页面，则不会有任何已创建的意图。保持您的数据字典方便。现在点击“创建新意图”，将数据字典中意图的第一个条目指定为意图名称，然后点击“完成”。您的数据字典的第一列还列出了示例话语。按照先前显示的方式开始添加示例话语。在添加了初始话语后，点击“保存”按钮以保存您的更改。将鼠标悬停在刚添加的话语中的“精神科医生”一词上，以查看其被方括号括起来的情况。点击该词将为您提供将其标记为现有实体或新实体的选项。创建一个名为Doctor的实体类型。图[6-11](#Fig11)显示了一旦您提交了初始话语，scheduleAppointment意图将会是什么样子。![A458845_1_En_6_Fig11_HTML.jpg](A458845_1_En_6_Fig11_HTML.jpg)图6-11显示了带有几个话语的ScheduleAppointment意图屏幕截图。重复此过程，针对数据字典中创建的所有意图、实体和话语。现在，您应该训练、测试和发布LUIS作为终端点，以供移动应用程序使用。
- en: Training and Testing LUIS
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练和测试LUIS
- en: One of the reasons we followed this process was to ensure that all the intents
    have some sample utterances. If an intent doesn’t have an utterance, you can’t
    train the application. Hover over the Train button. You will see the message “App
    has untrained changes”. Click Train on the top right to train the app. By training,
    you ensure that LUIS is creating a generalized model with utterances and will
    be able to identify intents and entities. Once the training process is successfully
    complete, your Train button should have a green notification bar mentioning this
    fact. You can now hover the Train button. You will get the message “App up to
    date”.LUIS also provides a testing interface so the user can test the application.
    Click on the Test button to open the Test slide-out page and start interactive
    testing. Provide some utterances other than what you have used in training to
    see whether the results come in as expected or not. Your testing slide also contains
    the inspect panel to inspect LUIS results and change the top scoring intent, as
    shown in Figure [6-12](#Fig12).![A458845_1_En_6_Fig12_HTML.jpg](A458845_1_En_6_Fig12_HTML.jpg)Figure
    6-12The LUIS test and inspect screen to inspect the LUIS result and change the
    top scoring intentYou will realize soon that not all tests yield the desired result.
    Initially, apart from getting a positive output from LUIS, you may also end up
    getting different intents for your test utterances, or even getting the right
    intent without an entity. Both require rigorous training. It can come through
    either through your training utterance or through the production application.
    For your application to use it, you need to push it to the production endpoint
    so you can get an HTTP endpoint, which can be used to call your LUIS app.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遵循这个流程的一个原因是确保所有意图都有一些示例话语。如果一个意图没有话语，那么就无法训练应用程序。将鼠标悬停在“训练”按钮上。你会看到消息“应用程序有未训练的更改”。点击右上角的“训练”按钮来训练应用程序。通过训练，你可以确保
    LUIS 正在创建一个带有话语的泛化模型，并且能够识别意图和实体。一旦训练过程成功完成，你的“训练”按钮应该有一个绿色的通知栏来提醒这一事实。现在你可以将鼠标悬停在“训练”按钮上。你会得到消息“应用程序是最新的”。
- en: Publishing LUIS App
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 发布 LUIS 应用程序
- en: The endpoint is nothing but a web service to access a LUIS app. The endpoint
    receives an utterance via a query string parameter and returns a JSON output with
    a corresponding intent-entities breakdown. When you are publishing for the first
    time, an endpoint URL is generated for you based on your application’s ID and
    the subscription key. This URL remains constant throughout the lifetime of your
    LUIS app.For creating a production endpoint, click on Publish on the top left.
    Select Production from the Publish to dropdown. If you want your JSON endpoint
    to include all predicted scores, check the Include All Predicted Intent Scores
    option. Click on Publish to Production Slot as shown in Figure [6-13](#Fig13).
    After publishing, you will get the endpoint.![A458845_1_En_6_Fig13_HTML.jpg](A458845_1_En_6_Fig13_HTML.jpg)Figure
    6-13Publishing the LUIS app to get an endpoint
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 终结点实际上是一个用于访问 LUIS 应用的 Web 服务。 终结点通过查询字符串参数接收一个话语，并返回一个 JSON 输出，其中包含相应的意图-实体分解。
    当您首次发布时，会根据您的应用程序 ID 和订阅密钥为您生成一个终结点 URL。 这个 URL 在您的 LUIS 应用程序的整个生命周期中保持不变。要创建一个生产终结点，请点击左上角的发布。
    从“发布到”下拉菜单中选择“生产”。 如果您希望您的 JSON 终结点包含所有预测的分数，请选中“包含所有预测的意图分数”选项。 单击“发布到生产槽”如图
    [6-13](#Fig13) 所示。 发布后，您将获得终结点。![A458845_1_En_6_Fig13_HTML.jpg](A458845_1_En_6_Fig13_HTML.jpg)图
    6-13发布 LUIS 应用程序以获取终结点
- en: Using a LUIS Endpoint
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 LUIS 终结点
- en: 'Using a LUIS endpoint is easy. You just need to call the HTTP endpoint created
    in the earlier section and pass your query with parameter q. If the endpoint is
    correct, you start getting the response in JSON, as shown in the following code:{  "query":
    "can you set appointment for dentist",  "topScoringIntent": {    "intent": "ScheduleAppointment",    "score":
    0.999998569  },  "intents": [    {      "intent": "ScheduleAppointment",      "score":
    0.999998569    },    {      "intent": "GetCondition",      "score": 0.0250619985    }],  "entities":
    []}You now understand the essence of training. The more training there is, the
    higher the confidence score. Our frontend teller and mobile application uses this
    endpoint and takes the first confidence score to talk to our database, which in
    turns returns the actual answer to be displayed to the user. Apart from the mobile
    device and the frontend teller UI, they also have the additional work to maintain
    the state of the user. LUIS supports a limited set of dialog management but, at
    the time this book was written, dialog management support hasn’t been so flexible,
    so we urge your software application to maintain it. Our frontend application
    also caters to interaction with voice users. Therefore, let’s look at how to implement
    speech in our application.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '使用 LUIS 端点很容易。您只需调用前一节中创建的 HTTP 端点，并将带有参数 q 的查询传递进去。如果端点正确，您将开始收到 JSON 格式的响应，如下面的代码所示：{  "query":
    "can you set appointment for dentist",  "topScoringIntent": {    "intent": "ScheduleAppointment",    "score":
    0.999998569  },  "intents": [    {      "intent": "ScheduleAppointment",      "score":
    0.999998569    },    {      "intent": "GetCondition",      "score": 0.0250619985    }],  "entities":
    []}现在您已经理解了训练的本质。训练次数越多，置信度分数就越高。我们的前端窗口和移动应用程序使用此端点，并采用第一个置信度分数与我们的数据库进行交流，然后返回实际要显示给用户的答案。除了移动设备和前端窗口
    UI 外，它们还有额外的工作要维护用户的状态。LUIS 支持有限的对话管理，但是在撰写本书时，对话管理支持并不那么灵活，因此我们建议您的软件应用程序来维护它。我们的前端应用程序还支持与语音用户的交互。因此，让我们看看如何在我们的应用程序中实现语音交互。'
- en: Interaction with Speech
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语音交互
- en: There are many new devices coming up almost every morning. Gone are those days
    where we just expect our devices to understand some set of commands and take actions
    on them. Interaction with these devices has also been changed drastically in the
    last decade. Among all of them, speech has been one of the most powerful, and
    it is of course a natural way for interaction with the users. Consider the personal
    assistants like Cortana, Siri, or even smart voices controlling cars—almost all
    of them have the natural interaction of speech. The Asclepius chains of hospitals
    have patients coming from various fields and they also want their frontend teller
    machine, along with mobile devices, to have speech interaction capabilities.Broadly
    speaking, speech interactions used in the Asclepius mobile and frontend teller
    applications must convert speech into text or vice versa. Traditionally, implementing
    speech in the application has been always been a difficult job. Thanks to the
    Microsoft Cognitive Bing Speech API, which provides the easiest way to enhance
    your application with speech-driven scenarios. The Speech API provides ease of
    use by abstracting all the complexity of speech algorithms and presenting an easy-to-use
    REST API.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: Getting Started with Bing Speech API
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Bing Speech API has various implementations of the Speech API to suit customer
    requirements. Requirements are accomplished by using Speech Recognition and Speech
    Synthesis. Speech recognition, aka speech to text, allows you to handle spoken
    words from your users in your application using a recognition engine and convert
    the words to text. Speak Synthesis, also known as Text to Speech (TTS), allows
    you to speak words or phrases back to the users through a speech synthesis engine.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Speech to Text
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Bing Text to Speech API  provides these features in an easy-to-use REST
    API. Like all other Microsoft Cognitive APIs, all interactions are done through
    HTTP POST. All calls go through these APIs, which are hosted on a Azure Cloud
    server. You need to follow these steps to use the Bing Speech API for text to
    speech.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Bing 文本转语音 API 在易于使用的 REST API 中提供这些功能。与所有其他 Microsoft 认知 API 一样，所有交互都通过 HTTP
    POST 完成。所有调用都通过托管在 Azure 云服务器上的这些 API 进行。您需要按照以下步骤使用 Bing 语音 API 进行文本转语音。
- en: 1.Get a JSON Web Token (JWT) by calling the token service.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1. 调用令牌服务获取 JSON Web 令牌（JWT）。
- en: 2.Put the JWT token in the header and call the Bing Speech API.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2. 将 JWT 令牌放入标头并调用 Bing 语音 API。
- en: 3.Parse the text.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3. 解析文本。
- en: Getting the JWT Token
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取 JWT 令牌
- en: 'All calls to the Microsoft Cognitive Services API require authentication before
    actually using the service. Unlike other Cognitive Services, which just require
    a subscription key to be passed, the Bing Speech API also requires an access token,
    also called a JWT token, before it’s called. access_token is the JWT token passed
    as a base64 string in the speech request header. To obtain the JWT token, users
    need to send a POST message to the token service and pass the subscription key
    as shown here:POST https://api.cognitive.microsoft.com/sts/v1.0/issueToken HTTP/1.1Host:
    api.cognitive.microsoft.comOcp-Apim-Subscription-Key: 000000000000000000000000000000000The
    following code shows you how to use this in the frontend teller ASP.NET application:private
    GUID instanceID; public async Task<string> GetTextFromAudio (Stream audiostream)        {            var
    requestUri = @"https://speech.platform.bing.com/recognize?scenarios=smd&appid=D4D52672-91D7-4C74-8AD8-42B1D98141A5&locale=en-US&device.os=
    WindowsOS&version=3.0&format=json&instanceid=instanceID3&requestid=" + Guid.NewGuid();            using
    (var client = new HttpClient())            {                var token = this.getValidToken();                client.DefaultRequestHeaders.Add("Authorization",
    "Bearer" + token);                using (var binaryContent = new ByteArrayContent(StreamToBytes(audiostream)))                {                    binaryContent.Headers.TryAddWithoutValidation("content-type",
    "audio/wav; codec=\"audio/pcm\"; samplerate=18000");                    var response
    = await client.PostAsync(requestUri, binaryContent);                    var responseString
    = await response.Content.ReadAsStringAsync();                    dynamic data
    = JsonConvert.DeserializeObject(responseString);                    return data.header.name;                }            }private
    const int TokenExpiryInSeconds = 600;private string Token;private void getValidToken()        {            this.token
    = GetNewToken();            this.timer?.Dispose();            this.timer = new
    Timer(                x => this. getValidToken(),                null,//Specify
    that token should run after 9 mins                TimeSpan.FromSeconds(TokenExpiryInSeconds).Subtract(TimeSpan.FromMinutes(1)),       TimeSpan.FromMilliseconds(-1));  //
    Indicates that this function will only run once        }private static string
    GetNewToken ()        {            using (var client = new HttpClient())            {                client.DefaultRequestHeaders.Add("Ocp-Apim-Subscription-Key",
    ApiKey);                var response = client.PostAsync("https://api.cognitive.microsoft.com/sts/v1.0/issueToken",
    null).Result;                return response.Content.ReadAsStringAsync().Result;            }        }'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 所有对微软认知服务 API 的调用在实际使用服务之前都需要进行身份验证。与其他认知服务不同，Bing 语音 API 还需要在调用之前传递访问令牌，也称为
    JWT 令牌。access_token 是作为 base64 字符串传递到语音请求头中的 JWT 令牌。要获取 JWT 令牌，用户需要向令牌服务发送 POST
    消息，并像这样传递订阅密钥：
- en: Code Walkthrough
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码演示
- en: 'As an experienced developer, you might have immediately observed that the essence
    of the code for calling speech to text lies in the GetTextFromAudio method. Here
    is the step-by-step procedure for this code:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名经验丰富的开发者，您可能立即注意到调用语音转文本的关键代码在于 GetTextFromAudio 方法。以下是此代码的逐步操作过程：
- en: 1.Create a URL pointing to the speech endpoint with a necessary parameter. Ensure
    each parameter is been used once, otherwise, you end up getting an HTTP 400 error.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1.创建指向语音端点的 URL，并带有必要的参数。确保每个参数仅被使用一次，否则会导致 HTTP 400 错误。
- en: 2.Call the getValidToken method to get the JWT token. In order to ensure utmost
    security, each JWT token is valid for only 10 minutes. Therefore, tokens need
    to be refreshed on or before 10 minutes to ensure they are always valid. Calling
    the Speech API with an invalid token results in an error. GetValidToken shows
    a mechanism to achieve it. You are also free to use your own method. Internally,
    the GetValidToken method calls the getNewToken method to get the JWT token.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2.调用 getValidToken 方法获取 JWT 令牌。为了确保最高安全性，每个 JWT 令牌仅有效 10 分钟。因此，需要在 10 分钟之前或之后刷新令牌，以确保它们始终有效。使用无效令牌调用语音
    API 将导致错误。GetValidToken 显示了实现此目标的一种方法。您也可以自由使用自己的方法。在内部，GetValidToken 方法调用 getNewToken
    方法以获取 JWT 令牌。
- en: 3.Pass the valid JWT token as an authorization header prefixed with the string
    Bearer.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3.将有效的 JWT 令牌作为授权头的前缀字符串 Bearer 传递。
- en: 4.Convert the audio being passed from analog to digital by using codecs.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4.使用编解码器将传递的音频从模拟转换为数字化。
- en: 5.Call the Speech API asynchronously and get the JSON data.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 5.异步调用语音 API 并获取 JSON 数据。
- en: 6.Deserialize JSON to a .NET object for further use.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 6.将 JSON 反序列化为 .NET 对象以供进一步使用。
- en: Congratulations! You now know how to convert any speech to text with just a
    few lines of code. Let’s also learn how to convert text to speech as well.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 祝贺！现在您已经知道如何仅用几行代码将任何语音转换为文本。我们还学习如何将文本转换为语音。
- en: Text to Speech
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文本转语音
- en: Text-to-speech conversion  follows nearly the same pattern of speech-to-text
    conversion. Let’s look at the code first before going through the code walkthrough:private
    string GenerateSsml(string locale, string gender, string name, string text){    var
    ssmlDoc = new XDocument(                        new XElement("speak",                            new
    XAttribute("version", "1.0"),                            new XAttribute(XNamespace.Xml
    + "lang", "en-US"),                            new XElement("voice",                                new
    XAttribute(XNamespace.Xml + "lang", locale),                                new
    XAttribute(XNamespace.Xml + "gender", gender),                                new
    XAttribute("name", name),                                text)));    return ssmlDoc.ToString();}Public
    void ConvertTexttoSpeech(string text){String ssml = this. GenerateSsml("en-US","
    Female","TexttoSpeech",text)byte[] TTSAudio = this.convertTextToSpeech(ssml);SoundPlayer
    player = new SoundPlayer(new MemoryStream(TTSAudio));player.PlaySync();}private
    byte[] convertTextToSpeech(string ssml){    var token = this.getValidToken();    var
    client = new RestClient("https://speech.platform.bing.com/synthesize");    var
    request = new RestRequest(Method.POST);    request.AddHeader("authorization",
    "Bearer" + token);    request.AddHeader("x-search-clientid", "8ae9b9546ebb49c98c1b8816b85779a1");    request.AddHeader("x-search-appid",
    "1d51d9fa3c1d4aa7bd4421a5d974aff9");    request.AddHeader("x-microsoft-outputformat",
    "riff-16khz-16bit-mono-pcm");    request.AddHeader("user-agent", "MyCoolApp");    request.AddHeader("content-type",
    "application/ssml+xml");    request.AddParameter("application/ssml+xml", ssml,
    ParameterType.RequestBody);    IRestResponse response = client.Execute(request);    return
    response.RawBytes;}
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 文本转语音转换几乎遵循与语音转文本相同的模式。在进行代码演练之前，让我们先看一下代码：
- en: Code Walkthrough
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码演练
- en: 'Here are the steps to convert text to speech:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 将文本转换为语音的步骤如下：
- en: 1.Create a SSML markup for the text to be converted into speech by calling the
    generateSSML method.Note Speech Synthesis Markup Language (SSML) is a common standard
    way to represent speech in XML format . It is part of W3C specification. SSML
    provides a uniform way of creating speech-based markup text. Check the official
    spec for complete SSML syntax at [https://www.w3.org/TR/speech-synthesis](https://www.w3.org/TR/speech-synthesis)
    .
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用 generateSSML 方法创建要转换为语音的文本的 SSML 标记。注意：语音合成标记语言（SSML）是一种用 XML 格式表示语音的常见标准方式。它是
    W3C 规范的一部分。SSML 提供了一种创建基于语音的标记文本的统一方式。请查阅官方规范以获取完整的 SSML 语法，网址为 [https://www.w3.org/TR/speech-synthesis](https://www.w3.org/TR/speech-synthesis)
    。
- en: 2.Call the Text to Speech API. You first need to get a valid token. For that,
    you can reuse the getValidToken() method shown in the speech-to-text code.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用 Text to Speech API。首先需要获取有效的令牌。为此，可以重用语音转文本代码中展示的 getValidToken() 方法。
- en: 3.Make a POST request to  [https://speech.platform.bing.com/synthesize](https://speech.platform.bing.com/synthesize)
    to get a byte array of the audio sent back as a response by the Text to Speech
    API. There are various ways to make POST requests. We use a popular third-party
    HTTP library called RestSharp. Easy installation of RestSharp in Visual Studio
    is supported via NuGet.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 利用 RestSharp 这个流行的第三方 HTTP 库，向 [https://speech.platform.bing.com/synthesize](https://speech.platform.bing.com/synthesize)
    发送 POST 请求，以获取由 Text to Speech API 作为响应返回的音频的字节数组。在 Visual Studio 中，可以通过 NuGet
    方便地安装 RestSharp。
- en: 4.Use a SoundPlayer class, a built-in .NET class, to play audio files and streams,
    in order to convert a byte array into speech. SoundPlayer is a built-in .NET class
    that plays audio files and streams. The format of this audio file is determined
    by the value of the x-Microsoft-outputformat header. As SoundPlayer only supports
    WAV audio files, use riff-16khz-16bit-mono-pcm as the value for the outputformat
    header.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用内置的 .NET 类 SoundPlayer 来播放音频文件和流，将字节数组转换为语音。SoundPlayer 是一个内置的 .NET 类，用于播放音频文件和流。该音频文件的格式由
    x-Microsoft-outputformat 标头的值确定。由于 SoundPlayer 仅支持 WAV 音频文件，因此将 riff-16khz-16bit-mono-pcm
    用作 outputformat 标头的值。
- en: Identifying and Recognizing Faces
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 识别和识别面部。
- en: Like any smart hospital, Asclepius has a very tight surveillance system. Asclepius
    consortium  is also very careful about the number of people visiting patients.
    The Asclepius surveillance system monitors inventory warehouse, restricts only
    a limited set of doctors and nurses into security and warehouse zones, and even
    with the attending patients. This smart digital action helps restrict unwanted
    people from entering buy raising the alarm when a security breach is attempted.
    Asclepius also has an automated attendance system, which doesn’t require the user
    to carry an identity card or any device. As soon as the employee enters the hospital,
    she is identified from the CCTV camera and her attendance is registered. Her time
    in and out of the system is also being monitored. All rooms and bays have digital
    identification mechanism for allowing only authorized people to enter rooms. This
    all has been achieved through the use of various cognitive technologies, especially
    the Face API.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 像任何智能医院一样，Asclepius 拥有非常严格的监控系统。Asclepius 联合体对访问病人的人数也非常谨慎。Asclepius 的监控系统监视库存仓库，限制只有一小部分医生和护士可以进入安全和仓库区域，甚至与病人一起。这种智能数字行动有助于通过在尝试安全漏洞时发出警报来限制不受欢迎的人员进入。Asclepius
    还拥有自动考勤系统，不需要用户携带身份证或任何设备。员工进入医院后，她就会被从闭路电视摄像头中识别出来，并且她的考勤已经注册。她进出系统的时间也在监控之中。所有的房间和区域都有数字识别机制，只允许授权人员进入房间。所有这些都是通过使用各种认知技术实现的，特别是
    Face API。
- en: What Does the Face API Work?
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面部 API 是如何工作的？
- en: Face API at a high level helps in detecting, identifying, verifying, and recognizing
    faces. It also can be used to get more insights about a face. Face detection and
    identification is not a new concept. It’s been used across academia, government
    institutions, and industries for decades in one form or another. The Face API
    extends it by bringing years of Microsoft research into face detection and recognition
    in a simple-to-use API.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 面部 API 在高层次上帮助检测、识别、验证和识别面部。它还可以用于获取有关面部的更多见解。面部检测和识别并不是一个新概念。它在学术界、政府机构和各行各业已经有数十年的历史了。Face
    API 将 Microsoft 多年的面部检测和识别研究融入了一个易于使用的 API 中，从而扩展了它。
- en: How Does Asclepius Achieve Strong Surveillance?
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Asclepius如何实现强大的监控？
- en: Asclepius  has created various security groups to cater their security. Each
    hospital employee and person are added to one of those known groups (Visitors,
    Regular, Patients, Doctors, Vendors, Admin). By default, any unknown people are
    tagged as part of the Visitors group. All patients are tagged under the Patients
    group. All the doctors belong to the Doctors group and some of the doctors and
    hospital employees belong to the Admin group, which has access to all the bays.
    With the help of smart CCTV cameras, images are captured live via frames. Only
    authorized people from certain people groups will get access to certain rooms,
    as shown in Figure [6-14](#Fig14). The same process  is followed to identify employees
    from people entering the office.![A458845_1_En_6_Fig14_HTML.jpg](A458845_1_En_6_Fig14_HTML.jpg)Figure
    6-14How Asclepius consortium  is using face recognition to recognize people and
    open the door for them
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Asclepius 创建了各种安全组，以满足他们的安全需求。每个医院员工和个人都被添加到这些已知组中之一（访客、普通员工、患者、医生、供应商、管理员）。默认情况下，任何未知人员都被标记为访客组的一部分。所有患者都被标记为患者组的成员。所有医生都属于医生组，而一些医生和医院员工属于管理员组，可以访问所有房间。借助智能闭路电视摄像头，图像通过帧实时捕获。只有来自特定人员组的授权人员才能访问特定房间，如图
    [6-14](#Fig14) 所示。同样的过程也用于识别进入办公室的员工和访客。![A458845_1_En_6_Fig14_HTML.jpg](A458845_1_En_6_Fig14_HTML.jpg)图
    6-14 Asclepius 联盟如何使用人脸识别来识别人员并为他们打开门
- en: Getting Keys for the Face API
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取 Face API 的密钥
- en: As with all cognitive services, you must first get a subscription key for the
    Face API via the Azure Portal.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有认知服务一样，您必须首先通过 Azure 门户获取 Face API 的订阅密钥。
- en: 1.Go to the Azure Portal ➤ AI + Cognitive service blade.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1.转到 Azure 门户 ➤ AI + 认知服务刀片。
- en: 2.Select the API type as Face API.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2.选择 API 类型为 Face API。
- en: 3.Fill out the location, pricing tier, and resource group, and then click Create
    to create a subscription.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3.填写位置、定价层和资源组，然后单击“创建”以创建订阅。
- en: Make sure the subscription key for the Face API is handy. You’ll need it soon.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 确保 Face API 的订阅密钥随手可得。您很快会需要它。
- en: Creating a Person and Person Group
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建一个人员和人员组
- en: 'Follow these steps to attain face identification and verification:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤进行面部识别和验证：
- en: 1.Create a Person group.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1.创建一个人员组。
- en: 2.Create a person.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2.创建一个人员。
- en: 3.Add faces to the person.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3.为人员添加面部特征。
- en: 4.Train the Person group.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4.训练人员组。
- en: 'Once these tasks are achieved, the Person group can be used to authenticate
    and authorize people. While doing any face identification, you need to set the
    scope. The Person group determines the overall scope of the face identification.
    Each Person group contains one or more people. For example, only the Admin Person
    group has authority to access all security inventory. The Person group contains
    many people and each person internally contains multiple face images to get it
    trained, as shown in Figure [6-15](#Fig15).![A458845_1_En_6_Fig15_HTML.png](A458845_1_En_6_Fig15_HTML.png)Figure
    6-15The correlation between the Person group and a personAs shown in Figure [6-15](#Fig15),
    John, Marc, and Ken are part of the Admin Person group. Likewise, Asclepius has
    other person groups that handle authentication and authorization for other tasks.
    For example, the Regular Person group is for all the regular employees in the
    hospital. The Regular Person group is used to handle the automated attendance
    process by monitoring and validating all people entering the hospital using a
    secured bay.Creating a Person group profile is a straightforward and easy process.
    You need to provide an HTTP PUT API, which is available at https://[location].api.cognitive.microsoft.com/face/v1.0/persongroups/,
    by passing the Person group name and the subscription key of the Face API that
    you created earlier.PUT https://westcentralus.api.cognitive.microsoft.com/face/v1.0/persongroups/Admin
    HTTP/1.1Host: westcentralus.api.cognitive.microsoft.comContent-Type: application/jsonOcp-Apim-Subscription-Key:
    000000000000000000000000000000000000000000000000If you call the API with a valid
    subscription key and your person name is unique, you will get successful response
    200 with an empty response body. Ensure that all the Face APIs only support application/json.Once
    all the groups are added, the next step is to add a person to these groups. Adding
    a person is also an easy task. You need to call a https://[location].api.cognitive.microsoft.com/face/v1.0/persongroups/{personGroupId}/persons
    where the location needs to be replaced with the location used while getting the
    Face API and persongroupid needs to be replaced with the Person Group name in
    which this person needs to be added. The Person name to be created needs to be
    part of the JSON body request. For example, the following code shows how to add
    Nishith to the Admin group created previously:POST https://westus.api.cognitive.microsoft.com/face/v1.0/persongroups/admin/persons
    HTTP/1.1Host: westus.api.cognitive.microsoft.comContent-Type: application/jsonOcp-Apim-Subscription-Key:
    00000000000000000000000000000000{    "name":"Nishith",    "userData":"User-provided
    data attached to the person"}Successful calls create a unique person ID with JSON
    response shown here:Pragma: no-cacheapim-request-id: 845a9a5f-9c4f-4f96-a126-04f2916a602dStrict-Transport-Security:
    max-age=31536000; includeSubDomains; preloadx-content-type-options: nosniffCache-Control:
    no-cacheDate: Sun, 31 Dec 2017 11:26:35 GMTX-AspNet-Version: 4.0.30319X-Powered-By:
    ASP.NETContent-Length: 51Content-Type: application/json; charset=utf-8Expires:
    -1{  "personId": "91ec6844-2be9-46d9-bc7f-c4d2deab166e"}Each person is identified
    by his or her unique person ID. So now for future reference, Nishith would be
    referred as person ID 91ec6844-2be9-46d9-bc7f-c4d2deab166e. In order to call a
    successful person creation, you need to ensure that you are within the limit of
    creating a person and the person group for that subscription. The following table
    shows the limitation of each subscription.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '一旦完成这些任务，就可以使用Person组来验证和授权人员。在进行任何人脸识别时，您需要设置范围。Person组确定了人脸识别的整体范围。每个Person组包含一个或多个人。例如，只有Admin
    Person组才有权限访问所有安全清单。Person组包含许多人，每个人内部包含多张面部图像以进行训练，如图[6-15](#Fig15)所示。![A458845_1_En_6_Fig15_HTML.png](A458845_1_En_6_Fig15_HTML.png)图6-15
    Person组与人员之间的相关性如图[6-15](#Fig15)所示，John、Marc和Ken是Admin Person组的一部分。同样，Asclepius有其他处理其他任务的人员组。例如，Regular
    Person组适用于医院所有常规员工。Regular Person组用于通过监控和验证所有进入医院的人员来处理自动考勤过程。创建Person组配置文件是一个简单而轻松的过程。您需要提供一个HTTP
    PUT API，该API可在https://[location].api.cognitive.microsoft.com/face/v1.0/persongroups/处获得，通过传递之前创建的Face
    API的Person组名称和订阅密钥。PUT https://westcentralus.api.cognitive.microsoft.com/face/v1.0/persongroups/Admin
    HTTP/1.1Host: westcentralus.api.cognitive.microsoft.comContent-Type: application/jsonOcp-Apim-Subscription-Key:
    000000000000000000000000000000000000000000000000如果您使用有效的订阅密钥调用API，并且您的人名是唯一的，您将收到一个空的响应体的成功响应200。确保所有Face
    API只支持application/json。一旦所有组都添加完毕，下一步就是将人员添加到这些组中。添加人员也是一项简单的任务。您需要调用一个https://[location].api.cognitive.microsoft.com/face/v1.0/persongroups/{personGroupId}/persons，其中位置需要替换为在获取Face
    API时使用的位置，并且persongroupid需要替换为要将此人添加到的Person组名称。要创建的Person名称需要成为JSON body请求的一部分。例如，以下代码显示了如何将Nishith添加到之前创建的Admin组中：POST
    https://westus.api.cognitive.microsoft.com/face/v1.0/persongroups/admin/persons
    HTTP/1.1Host: westus.api.cognitive.microsoft.comContent-Type: application/jsonOcp-Apim-Subscription-Key:
    00000000000000000000000000000000{    "name":"Nishith",    "userData":"User-provided
    data attached to the person"}成功调用会创建一个带有以下JSON响应的唯一人员ID：Pragma: no-cacheapim-request-id:
    845a9a5f-9c4f-4f96-a126-04f2916a602dStrict-Transport-Security: max-age=31536000;
    includeSubDomains; preloadx-content-type-options: nosniffCache-Control: no-cacheDate:
    Sun, 31 Dec 2017 11:26:35 GMTX-AspNet-Version: 4.0.30319X-Powered-By: ASP.NETContent-Length:
    51Content-Type: application/json; charset=utf-8Expires: -1{  "personId": "91ec6844-2be9-46d9-bc7f-c4d2deab166e"}每个人都通过其唯一的person
    ID来识别。因此，现在以后参考Nishith将被称为person ID 91ec6844-2be9-46d9-bc7f-c4d2deab166e。为了调用成功的人员创建，您需要确保您在为该订阅创建人员和人员组的限制范围内。以下表格显示了每个订阅的限制。'
- en: '| Tier | Person per Person Group | Persons per Subscription |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 层 | 每人每组 | 每订阅的人数 |'
- en: '| :-- | :-- | :-- |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- | :-- |'
- en: '| Free Tier | 1K | 1K |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 免费层 | 1K | 1K |'
- en: '| S0 | 10K | 1M |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| S0 | 10K | 1M |'
- en: If you exceed the limit, you will get the QuotaExceeded error. While creating
    a person, you didn’t provide any faces.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果超过限制，将收到 QuotaExceeded 错误。在创建人物时，您没有提供任何脸。
- en: Add Faces
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 添加人脸
- en: 'In order to add faces, call https://[location].api.cognitive.microsoft.com/face/v1.0/persongroups/{personGroupId}/persons/{personId}
    via an HTTP Post. Be sure to replace the location, persongroupid, and person ID
    with the appropriate values. Pass the image as an URL in the application body.
    For example, use the following code to add Nishith’s image to the Nishith Person
    in the Admin group:POST https://westus.api.cognitive.microsoft.com/face/v1.0/persongroups/admin/persons/91ec6844-2be9-46d9-bc7f-c4d2deab166e/persistedFaces
    HTTP/1.1Host: westus.api.cognitive.microsoft.comContent-Type: application/jsonOcp-Apim-Subscription-Key:
    00000000000000000000000000000000{    "url":" https://pbs.twimg.com/media/DReABwzW4AAv7hL.jpg"}A
    successful call with this URL will result in returning a persisted face ID:Pragma:
    no-cacheapim-request-id: 7e5f7e9d-4ad1-4cd4-a1df-ec81f4f37d33Strict-Transport-Security:
    max-age=31536000; includeSubDomains; preloadx-content-type-options: nosniffCache-Control:
    no-cacheDate: Mon, 01 Jan 2018 09:55:08 GMTX-AspNet-Version: 4.0.30319X-Powered-By:
    ASP.NETContent-Length: 58Content-Type: application/json; charset=utf-8Expires:
    -1{  "persistedFaceId": "185e9d95-d52b-4bd9-b6a9-f512c4dbd5a2"}Make sure the image
    is an URL and is specified in the request body; your application should be Internet
    accessible. Only files having extensions of JPEG, PNG, GIF, and BMP are supported
    and each image should not be more than 4MB. Each person can have multiple faces
    so efficient training can be done. You can tag up to 248 faces per person.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '为了添加人脸，通过 HTTP Post 调用 https://[location].api.cognitive.microsoft.com/face/v1.0/persongroups/{personGroupId}/persons/{personId}。请确保用正确的值替换位置、persongroupid
    和 person ID。将图像作为 URL 传递到应用程序主体中。例如，使用以下代码将 Nishith 的图像添加到 Admin 组中的 Nishith 人物：POST
    https://westus.api.cognitive.microsoft.com/face/v1.0/persongroups/admin/persons/91ec6844-2be9-46d9-bc7f-c4d2deab166e/persistedFaces
    HTTP/1.1Host: westus.api.cognitive.microsoft.comContent-Type: application/jsonOcp-Apim-Subscription-Key:
    00000000000000000000000000000000{    "url":" https://pbs.twimg.com/media/DReABwzW4AAv7hL.jpg"}成功调用此
    URL 将返回一个持续的人脸 ID:Pragma: no-cacheapim-request-id: 7e5f7e9d-4ad1-4cd4-a1df-ec81f4f37d33Strict-Transport-Security:
    max-age=31536000; includeSubDomains; preloadx-content-type-options: nosniffCache-Control:
    no-cacheDate: Mon, 01 Jan 2018 09:55:08 GMTX-AspNet-Version: 4.0.30319X-Powered-By:
    ASP.NETContent-Length: 58Content-Type: application/json; charset=utf-8Expires:
    -1{  "persistedFaceId": "185e9d95-d52b-4bd9-b6a9-f512c4dbd5a2"}确保图像是一个 URL，并在请求体中指定；您的应用程序应该是可访问互联网的。仅支持扩展名为
    JPEG、PNG、GIF 和 BMP 的文件，每个图像不应超过 4MB。每个人可以有多张脸，因此可以进行高效的训练。您可以为每个人标记最多 248 张脸。'
- en: Training Is the Key
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练是关键
- en: 'More training results in better accuracy. We must now train the Person group.
    Any changes to the faces would require training the Person group again before
    using it to identify faces. In order to train the Person group, give an HTTP POST
    call to https://[location].api.cognitive.microsoft.com/face/v1.0/persongroups/[persongroupname]/train
    and pass the subscription key. Replace the persongroupname and location appropriately.
    For example, to train the Admin Person group, the HTTP request would be:POST https://westus.api.cognitive.microsoft.com/face/v1.0/persongroups/admin/train
    HTTP/1.1Host: westus.api.cognitive.microsoft.comOcp-Apim-Subscription-Key: 00000000000000000000000000000000A
    successful call to the API would result in Empty JSON.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '更多的训练会带来更好的准确性。现在我们必须训练人员组。任何对面部的更改都需要在使用它来识别面部之前再次训练人员组。为了训练人员组，请向 https://[location].api.cognitive.microsoft.com/face/v1.0/persongroups/[persongroupname]/train
    发送 HTTP POST 调用，并传递订阅密钥。适当地替换 persongroupname 和 location。例如，要训练 Admin 人员组，HTTP
    请求将是：POST https://westus.api.cognitive.microsoft.com/face/v1.0/persongroups/admin/train
    HTTP/1.1Host: westus.api.cognitive.microsoft.comOcp-Apim-Subscription-Key: 00000000000000000000000000000000对
    API 的成功调用将导致空的 JSON。'
- en: Using the Face API for Authentication
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用面部 API 进行身份验证
- en: 'Once a person and the Person group are trained, the Face API can then be used
    to authenticate or identify a face from an unknown Person group. As mentioned,
    all the bays and rooms of Asclepius have digital entrance mechanisms that are
    supported by Smart CCTV cameras. The digital locks are tied to one or more Person
    groups. Door locks are only open when the system authenticates and authorizes
    a person as being part of the Person group.As and when a new person tries to enter
    a room, the CCTV camera first calls the Face Detect API by passing the captured
    image from CCTV to detect human faces in the image, which also returns face IDs
    for those faces. Those face IDs are then been passed to the Face Identify API
    to test it against person groups. When the Face Identify API returns a confidence
    score of more than .9, the door opens. The system also tracks the time spent in
    that room as well.To call the Face Detect API for the image being captured, use
    the URL [https://westus.api.cognitive.microsoft.com/face/v1.0/detect?returnFaceId=true&returnFaceLandmarks=false](https://westus.api.cognitive.microsoft.com/face/v1.0/detect%3FreturnFaceId=true%26returnFaceLandmarks=false)
    . Then pass the subscription key as the header and the image being captured from
    the CCTV camera as part of the JSON request body. For example:POST https://westus.api.cognitive.microsoft.com/face/v1.0/detect?returnFaceId=true&returnFaceLandmarks=false
    HTTP/1.1Host: westus.api.cognitive.microsoft.comContent-Type: application/jsonOcp-Apim-Subscription-Key:
    00000000000000000000000000000000{    "url":"https://asclepius.com/media/DReABwzW4AAv7hL.jpg"}The
    response will return an array of face entries in JSON, along with face ID, as
    shown in this code.Pragma: no-cacheapim-request-id: b6a209c3-fd26-422c-8baa-99b54e827d86Strict-Transport-Security:
    max-age=31536000; includeSubDomains; preloadx-content-type-options: nosniffCache-Control:
    no-cacheDate: Mon, 01 Jan 2018 10:35:37 GMTX-AspNet-Version: 4.0.30319X-Powered-By:
    ASP.NETContent-Length: 113Content-Type: application/json; charset=utf-8Expires:
    -1[{  "faceId": "1e685d67-43b9-470f-8c06-e9b0cd5d6584",  "faceRectangle": {    "top":
    134,    "left": 525,    "width": 74,    "height": 74  }}]In this code, a face
    is returned along with the face ID. Use the face ID and pass it to the Face Identify
    API, as shown in the following code, to validate whether the face ID captured
    is part of the Person group that’s authorized to enter the bay:POST https://westus.api.cognitive.microsoft.com/face/v1.0/identify
    HTTP/1.1Host: westus.api.cognitive.microsoft.comContent-Type: application/jsonOcp-Apim-Subscription-Key:
    00000000000000000000000000000000{        "personGroupId":"admin",    "faceIds":[        "1e685d67-43b9-470f-8c06-e9b0cd5d6584"        ],    "maxNumOfCandidatesReturned":4,    "confidenceThreshold":
    0.9}In this code, the confidenceThreshold parameter is set to .9, which acts as
    a confidence score for determining the identity of a person. ConfidenceThreshold
    is an optional parameter and should have a value between O and 1\. With proper
    subscription, it returns the result as a JSON API:Pragma: no-cacheapim-request-id:
    de275faf-1cdf-4476-b19f-6466ebdbcbeaStrict-Transport-Security: max-age=31536000;
    includeSubDomains; preloadx-content-type-options: nosniffCache-Control: no-cacheDate:
    Mon, 01 Jan 2018 10:45:48 GMTX-AspNet-Version: 4.0.30319X-Powered-By: ASP.NETContent-Length:
    135Content-Type: application/json; charset=utf-8Expires: -1[{  "faceId": "1e685d67-43b9-470f-8c06-e9b0cd5d6584",  "candidates":
    [{    "personId": "91ec6844-2be9-46d9-bc7f-c4d2deab166e",    "confidence": 1.0  }]}]In
    this code, the face is being detected with 100% accuracy, so the digital door
    opens.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '一旦一个人和人群被训练，Face API 就可以用来验证或识别来自未知人员组的脸。 如前所述，Asclepius 的所有湾和房间都有由智能闭路电视摄像机支持的数字入口机制。
    数字锁与一个或多个人员组相关联。 只有在系统对一个人进行身份验证和授权为人员组的一部分时，门锁才会打开。当新的人试图进入一个房间时，闭路电视摄像机首先通过将来自闭路电视摄像机的捕获图像传递给
    Face Detect API 来检测图像中的人脸，该 API 还返回这些人脸的面部 ID。 然后，这些面部 ID 被传递给 Face Identify API
    以测试其是否与人员组匹配。 当 Face Identify API 返回大于 0.9 的置信度分数时，门打开。 系统还跟踪在该房间内的时间。要调用 Face
    Detect API 来捕获图像，使用 URL [https://westus.api.cognitive.microsoft.com/face/v1.0/detect?returnFaceId=true&returnFaceLandmarks=false](https://westus.api.cognitive.microsoft.com/face/v1.0/detect%3FreturnFaceId=true%26returnFaceLandmarks=false)
    。 然后，将订阅密钥作为标头和来自闭路电视摄像机捕获的图像作为 JSON 请求正文的一部分。 例如：POST https://westus.api.cognitive.microsoft.com/face/v1.0/detect?returnFaceId=true&returnFaceLandmarks=false
    HTTP/1.1Host: westus.api.cognitive.microsoft.comContent-Type: application/jsonOcp-Apim-Subscription-Key:
    00000000000000000000000000000000{    "url":"https://asclepius.com/media/DReABwzW4AAv7hL.jpg"}响应将返回一个包含
    JSON 中的面部条目数组，以及面部 ID，如此代码所示。Pragma: no-cacheapim-request-id: b6a209c3-fd26-422c-8baa-99b54e827d86Strict-Transport-Security:
    max-age=31536000; includeSubDomains; preloadx-content-type-options: nosniffCache-Control:
    no-cacheDate: Mon, 01 Jan 2018 10:35:37 GMTX-AspNet-Version: 4.0.30319X-Powered-By:
    ASP.NETContent-Length: 113Content-Type: application/json; charset=utf-8Expires:
    -1[{  "faceId": "1e685d67-43b9-470f-8c06-e9b0cd5d6584",  "faceRectangle": {    "top":
    134,    "left": 525,    "width": 74,    "height": 74  }}]在此代码中，返回了一个面部以及面部 ID。
    使用面部 ID 并将其传递给 Face Identify API，如下面的代码所示，以验证捕获的面部 ID 是否属于授权进入湾的 Person 组的一部分：POST
    https://westus.api.cognitive.microsoft.com/face/v1.0/identify HTTP/1.1Host: westus.api.cognitive.microsoft.comContent-Type:
    application/jsonOcp-Apim-Subscription-Key: 00000000000000000000000000000000{        "personGroupId":"admin",    "faceIds":[        "1e685d67-43b9-470f-8c06-e9b0cd5d6584"        ],    "maxNumOfCandidatesReturned":4,    "confidenceThreshold":
    0.9}在此代码中，confidenceThreshold 参数设置为 .9，它充当确定人员身份的置信度分数。 ConfidenceThreshold 是一个可选参数，应该具有介于
    0 和 1 之间的值。 使用适当的订阅，它将以 JSON API 的形式返回结果：Pragma: no-cacheapim-request-id: de275faf-1cdf-4476-b19f-6466ebdbcbeaStrict-Transport-Security:
    max-age=31536000; includeSubDomains; preloadx-content-type-options: nosniffCache-Control:
    no-cacheDate: Mon, 01 Jan 2018 10:45:48 GMTX-AspNet-Version: 4.0.30319X-Powered-By:
    ASP.NETContent-Length: 135Content-Type: application/json; charset=utf-8Expires:
    -1[{  "faceId": "1e685d67-43b9-470f-8c06-e9b0cd5d6584",  "candidates": [{    "personId":
    "91ec6844-2be9-46d9-bc7f-c4d2deab166e",    "confidence": 1.0  }]}]在此代码中，面部被 100%
    准确地检测到，因此数字门打开。'
- en: Your Assignment
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As part of their digital strategy to make video processing more powerful, Asclepius
    is planning to use surveillance to get more useful insights. It plans to achieve
    this by getting powerful insights through the video streaming, all of which is
    possible through the use of Video AI. Video content has been developing at such
    a rapid pace that manual processing or creating manual video surveillance system
    doesn’t work. The need of the hour is to get a surveillance system that monitors
    the video, takes immediate actions, and generates insights to help serve the need.
    Asclepius Consortium plans to handle queries like the following:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: How many patients and people came into the hospital yesterday?
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Were the patients happy after consulting with the doctor?
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who entered or attempted to enter the secured inventory warehouse?
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are all the products and tools taken out of inventory?
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we respond to critical and severe patients 24X7?
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can we monitor people activity and ensure that people get proper support whenever
    and wherever required?
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When did Dr. John (for example) enter the hospital and where is he currently?
    Or when was the patient named Mike last attended to?
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can we identify instruments, doctors, and other inventory objects?
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HintWe discussed Video AI briefly in Chapter [4](A458845_1_En_4_Chapter.html),
    but essentially Video AI helps in processing videos, generating insights such
    as the face recognition and tracking, detecting voice activity, performing sentiment
    analysis, detecting scenes, and much more. You need a couple of APIs of Video
    AI to do this. You need an Index API to index, a Search API to do a search, a
    Visual Insights API to get insights, and then the Streaming API to do the actual
    streaming. This is achieved by discovering content in the video and generating
    insights. To learn more about it, visit [https://Vi.microsoft.com](https://vi.microsoft.com)
    . At the time this book was written, Video Indexer is in preview mode.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Recap
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, you learned about some of the powerful ways to use Microsoft
    Cognitive Services and apply them to the Asclepius hospital example. You got an
    in-depth understanding about LUIS and learned how to create, train, test, and
    publish a LUIS application. You also learned how to convert text to speech and
    speech to text by calling the Speech API. Later in the chapter, you learned how
    to use the Face API to identify and recognize faces and to create a strong surveillance
    system.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，您学习了如何利用微软认知服务的一些强大方法，并将它们应用到Asclepius医院的示例中。您深入了解了LUIS，并学会了如何创建、训练、测试和发布LUIS应用程序。您还学会了如何通过调用语音API将文本转换为语音和语音转换为文本。在本章的后面，您学会了如何使用Face
    API来识别和识别人脸，并创建一个强大的监控系统。
