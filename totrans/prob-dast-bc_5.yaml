- en: <hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '[Part III](contents.xhtml#rpart3)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Probabilistic Data Structures: An Overview](contents.xhtml#rpart3)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: </hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: <hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '[9](contents.xhtml#rchapter9)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Introduction to Probabilistic Data Structures](contents.xhtml#rchapter9)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: </hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '[9.1 Need of Probabilistic Data Structures](contents.xhtml#rsec9_1)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is an exponential increase in the generation of data since last few years.
    This heavy data growth poses a challenge for industry and academia for storage
    and query processing. While analyzing logs for huge data sets, it is required
    to perform different query operations, such as counting unique items, computing
    frequency of a data item, searching any item in a set, etc. Additionally, we need
    to probe more complex datasets, such as images, videos, web pages, etc. Clearly,
    in order to process such query operations on data, it is essential to store data
    in computer memory. Tapes, hard disk, solid state drives are different types of
    memory available for a computing system. However, these different types of memory
    have different characteristics as presented in [Fig. 9.1](12chap_09.xhtml#fig9_1).
    For example, hard disks are mechanical devices and they are slow to access as
    compared to main memory integrated on a semiconductor chip which makes querying
    from database in hard disk time consuming. Hence, for a query, a processor has
    to every time access the hard disk for the data it requires which clearly would
    be a slow operation. Also, disk access proves costly as compared to the main memory
    (that's why a GB of main memory is much costlier than a GB of hard drive).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1](../images/fig9_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 9.1**'
  prefs: []
  type: TYPE_NORMAL
- en: Computer memory hierarchy.
  prefs: []
  type: TYPE_NORMAL
- en: Besides, a process needs to be in the main memory in order to get executed so,
    it has to get swapped in from secondary memory to main memory as depicted in [Fig.
    9.2](#fig9_2). Simultaneously, for a developer, main memory is easy to use as
    creating an array, linked list, or set in main memory is easy as compared to writing
    files in or out by using a Hadoop database or Apache Solr in secondary storage.
    These upcoming big data technologies are oftenly used in providing accurate analysis
    and decision making. These technologies provide distributed data storage and parallel
    processing. Although the distributed database Hadoop with a heavy processing engine
    (Spark, MapReduce) is good with batch processing framework where the aim is to
    improve job throughput rather than handling speed of access issue. Notably, the
    batch processing of data doesn't impose any time constraints so, it can be stored
    on disk and queries can be processed in batches. Additionally, the popular approach
    of using SQL for processing queries on database in secondary storage results in
    high space complexity. For instance, Powerdrill is a column oriented data storage
    approach that faces the challenge of high memory and computational overhead for
    large datasets. However, streaming data requires real-time processing with a minimal
    delay which is possible with improved speed of access. Moreover, streaming data
    requires processing in a single pass. So, it is always better to work more in
    main memory for real-time processing of streaming data along with processing data
    in a single pass. Subsequently, the growing size of databases and applications
    dataset demands a compact data structure in order to get managed and handled properly.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2](../images/fig9_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 9.2**'
  prefs: []
  type: TYPE_NORMAL
- en: Memory management via swapping.
  prefs: []
  type: TYPE_NORMAL
- en: The current scenario of data generation has resulted in the release of new applications
    that need to deal with a huge volume of data. Conventional algorithms assumption
    of fitting data in main memory fails when dealing with such a huge amount of data.
    In this context, streaming algorithms (that process data in one or a few passes
    while consuming a limited amount of storage and time) are getting popular among
    researchers.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, in order to fix above mentioned issue, deterministic data structures,
    such as hash tables, array, binary search tree fail to deal with large data sets
    as it is difficult to accommodate large streaming data into memory at once. The
    conventional data structures can't go on the further side of linear processing.
    Moreover, for large dataset, a polynomial running time complexity served by deterministic
    data structures is not beneficial. Also, 3 V's (volume, variety, and velocity)
    of data demands real-time analysis and processing. Additionally, complexity of
    data and noise in data is not defined. As size of data is not known in prior,
    one can't predict the memory requirements for storing data. Therefore, there is
    a need for an effective data structure that can support quick response time and
    efficient storage space in the main memory. To address these challenges, probabilistic
    data structures (PDS) are used recently by many researchers and programmers.
  prefs: []
  type: TYPE_NORMAL
- en: 'PDS allows performing basic query operation on data in the main memory itself.
    The use case of PDS is to process big data that does not fit inside the main memory.
    PDS are used for query operations, such as membership check, frequency check,
    similarity check, and cardinality check. Low memory requirements and good processing
    speed are the two unique properties of PDS. Nevertheless, the working of PDS is
    highly dependent on cryptographic hashing functions that enable randomness and
    flexibility in inserting data. Hash functions when applied on large data sets
    summarize it in a compact form which dramatically reduces storage requirements
    and its behavior is hard to predict. Here, also cryptographic hash functions have
    to satisfy three main requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Work factor: In order to defend brute force, hash function should be computationally
    expensive.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sticky state: It is impossible to create a state with a plausible input pattern.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Diffusion: The associated output bit of hash function should be complex function
    of each input bit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cryptographic hash functions are further categorized into keyed hash functions
    and unkeyed hash functions. A keyed hash function involves a secret key whereas,
    for a unkeyed hash function, the key is known to everyone. A keyed hash function
    is used for message authentication code (MAC).
  prefs: []
  type: TYPE_NORMAL
- en: Notably, PDS's are based on unkeyed hash function. With this insight, the nature
    of this data structure is randomized because of randomly selected hash functions.
    Also, in most cases, it is not important to know which item from the set has been
    matched, sometimes it is necessary to know only whether a match has bee made or
    not. Hence, only signatures of the items can be stored instead of the value. Over
    and above, PDS does not result in same structure every time for the same series
    of operations. Hence, PDS are also known as sketching data structures [[116](bib.xhtml#ch00-bib-116)].
    Notably, inaccuracy with a specific structure is expected with PDS. However, they
    have a constant query processing time and can be easily parallelized (as hashes
    have independent property) to be used for real-time data processing for a quick
    response. The coming sections will discuss the membership query, cardinality estimation,
    similarity search, and frequency estimation PDS in detail along with their Python
    implementation. Refer to [Fig. 9.3](#fig9_3) for taxonomy of PDS.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3](../images/fig9_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 9.3**'
  prefs: []
  type: TYPE_NORMAL
- en: Taxonomy of PDS.
  prefs: []
  type: TYPE_NORMAL
- en: Due to minimized memory requirements PDS are useful for big data and streaming
    data applications.
  prefs: []
  type: TYPE_NORMAL
- en: '[9.2 Deterministic Data Structures vs. Probabilistic Data Structures](contents.xhtml#rsec9_2)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: IT professionals came across different deterministic data structures, for example,
    Array, hash tables, etc. However, with these in-memory conventional data structures
    operations such as insert, search, delete are performed with specific key value.
    These data structures results in deterministic (accurate) results. In contrast
    to this, results of operation in case of PDS could be probabilistic which implies
    results are approximate and not always definite. Notably, a conventional data
    structure can perform all set of operations that a PDS can do but only for small
    data sets. However, if data set is too large to fit into memory, conventional
    data structure fails for that case. Additionally, for streaming applications which
    demands data processing in one go, it is difficult to handle with conventional
    data structures. [Table 9.1](#tab9_1) presents difference between deterministic
    data structures and probabilistic data structures.
  prefs: []
  type: TYPE_NORMAL
- en: '**TABLE 9.1**'
  prefs: []
  type: TYPE_NORMAL
- en: Difference between deterministic and probabilistic data structures.
  prefs: []
  type: TYPE_NORMAL
- en: '| Deterministic data structures | Probabilistic data structures |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| No false positives are generated | False positives are generated while query
    processing |'
  prefs: []
  type: TYPE_TB
- en: '| Provides optimal path | Provides good path instead of optimal |'
  prefs: []
  type: TYPE_TB
- en: '| Not necessarily make use of hash functions | These data structures strictly
    uses hash function to process queries |'
  prefs: []
  type: TYPE_TB
- en: '| Stores data in actual format | Stores signatures of data instead of actual
    data |'
  prefs: []
  type: TYPE_TB
- en: '| Uses more memory over PDS | Uses much less memory over traditional data structures
    |'
  prefs: []
  type: TYPE_TB
- en: '| Process queries in linear, sublinear, quadratic, factorial etc. time | Only
    process queries in constant time |'
  prefs: []
  type: TYPE_TB
- en: '| Error free results are generated | Error in results are expected. However,
    errors rates have sppecific structure |'
  prefs: []
  type: TYPE_TB
- en: '| Used when complete accuracy is required | Used when speed and low memory
    is required over exact accuracy |'
  prefs: []
  type: TYPE_TB
- en: '| Stores data in inact form | Transform non-uniform distributed data to uniformly
    distributed data |'
  prefs: []
  type: TYPE_TB
- en: '| Example: Array, linked list | Example: Bloom filter, HLL |'
  prefs: []
  type: TYPE_TB
- en: '[9.3 Probabilistic Data Structures Applications](contents.xhtml#rsec9_3)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To build effective applications, one practice is an efficient use of data structure.
    Infact choosing a good data structure is a sign of good programmer. Any application
    involving large scale business can make use of PDS. Analyzing big data set, statistical
    analysis, mining huge data set are some use-cases of PDS. For instance, to check
    whether a particular item on Amazon is available for order or not. However, applications
    of PDS are not only limited to computer science field but also used in various
    filed. For example, in classification of DNA sequences into novel or already known
    genome.
  prefs: []
  type: TYPE_NORMAL
- en: Duplication of data blocks is defined when more than one file share common data
    or when same data occurs at more than one place in a given file. Comparing each
    file with all other files involves heavy processing. PDS helps to solve this problem
    by storing fingerprint of data blocks rather than storing original data and matching
    hashes for finding duplicate files [[71](bib.xhtml#ch00-bib-71)].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DDoS attack is defined when a particular machine is flooded by an attacker so
    that it may not be accessed by user when required. This demand needs for monitoring
    network traffic. One solution is to analyze destination IP address of IP packet
    and if counter value of any IP address exceeds predefined threshold that address
    is considered as suspicious. PDS can help analyzing these packets with less memory
    and constant time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, filtering of personal e-mail can be eased with PDS as spam detection
    system involves a big database having e-mail signatures [[216](bib.xhtml#ch00-bib-216)].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Growth in network traffic demands the need for network monitoring and traffic
    engineering. To operate efficiently, data centers, and PDS sketches for tasks,
    such as heavy hitter detection, traffic matrix estimation, traffic pattern detection
    etc. PDS sketches have proved to minimize the computation cost for information
    collection in the network [[137](bib.xhtml#ch00-bib-137)].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cardinality estimation PDS is used to check how many unique IP addresses views
    an article on any particular site.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PDS are also used for DNA sequences that involve categorization of sequence
    as novel or already existing genome. Sequencing implies calculating the right
    order of base pair in a DNA segment. Also, PDS are used for analyzing co-relation
    in DNA sequencing [[109](bib.xhtml#ch00-bib-109)].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A worth mentioning application of PDS is to find all elements in data set with
    a frequency greater than a predefined number. Such a characteristic of PDS is
    used to detect heavy hitter for a website.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Likewise, PDS can be used for an application of spell check having 350000 dictionary
    words in the memory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9.4 Probabilistic Data Structure Challenges](contents.xhtml#rsec9_4)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PDS optimizes algorithm performance by using fixed or sublinear memory and by
    providing constant execution time. However, the biggest challenge faced by PDS
    is that they can't provide exact answers and shows some probability of error.
    However, this error can be controlled with a trade-off with resources of PDS.
    Hence, for cases where reduced accuracy is unacceptable (such as- bank account,
    military applications) use of PDS is not recommended. Nevertheless, for cases
    (such as- recommending a movie, counting unique visitors, preventing DDoS attack)
    where cost of relatively small mistakes is low, PDS can be recommended.
  prefs: []
  type: TYPE_NORMAL
- en: Activity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Multiple Choice Questions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Which of the following memory has slowest speed of access?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Registers
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Main memory
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Hard disk
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Tape storage
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the requirements for a cryptographic hash function?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: One-way
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Work factor
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Diffusion
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: All of the above
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: In keyed hash function, key is known to everyone.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'False'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following memory has maximum ease of use?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Registers
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Main memory
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Hard disk
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Tape storage
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of following statement about PDS is false?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: PDS are also known as sketching data structure
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: PDS ae also know as deterministic data structure
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Results of PDS operations have some error
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Bloom filter is an example of PDS
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Which of the following is an example of cardinality estimation PDS?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: HyperLogLog
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: BF
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Skiplist
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Minhashing
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following is an example of membership query PDS?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Cuckoo filter
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Minhashing
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Simhashing
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: LogLog
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following is an example of frequency query PDS?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Cuckoo filter
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: CMS
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Simhashing
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: LogLog
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: PDS are useful for big data and streaming data applications
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'False'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following is an example of PDS?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Detecting DDoS attack
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Spell checker
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Monitoring IP traffic
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: All of the above
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 1\. d  2\. d  3\. b  4\. a  5\. b  6\. a  7\. a  8\. b  9\. a  10\. d
  prefs: []
  type: TYPE_NORMAL
- en: <hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '[10](contents.xhtml#rchapter10)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Membership Query Probabilistic Data Structures](contents.xhtml#rchapter10)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: </hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '[10.1 Membership Query Probabilistic Data Structures](contents.xhtml#rsec10_1)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Oftentimes while processing streaming IoT data, searching for a particular item
    is required with minimum latency and space. The aim of membership query probabilistic
    data structures (MSQ PDS) is to check the presence of an element *x* in a large
    set <math alttext="" display="inline"><mrow><mo stretchy="false">(</mo><mi>S</mi><mo
    stretchy="false">)</mo></mrow></math> of elements. The membership query operation
    using a linked list, array or a balanced binary tree requires a memory space linear
    to the size of set *S*. Hash table also has a larger size so, the memory it takes
    will also be larger. On the other hand, MSQ PDS are getting popular for handling
    queries of big data and streaming applications as these data structures consume
    less memory. Also, MSQ PDS provides constant query time. In order to provide optimized
    space efficiency, as opposed to storing the entire set of data, MSQ PDS stores
    summarized form of data using hashing. [Table 10.1](#tab10_1) represents a comparison
    in space and time complexity for membership query operation in different data
    structures. Insertion and deletion (for some specific MSQ PDS) are the operations
    that are supported by MSQ PDS.
  prefs: []
  type: TYPE_NORMAL
- en: '**TABLE 10.1**'
  prefs: []
  type: TYPE_NORMAL
- en: Space and time complexity for searching in different data structures
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Linear DS | Non-linear DS | Hashing DS | Probabilistic DS |'
  prefs: []
  type: TYPE_TB
- en: '| Example: | Array, Linked list | Graph, BST | Hash Tables | BF, QF, Skiplist
    |'
  prefs: []
  type: TYPE_TB
- en: '| Space Complexity | <math alttext="" display="inline"><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></math> | <math
    alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math> | <math alttext="" display="inline"><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></math> | <math
    alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>m</mi><mo
    stretchy="false">)</mo></mrow></math> |'
  prefs: []
  type: TYPE_TB
- en: '| Search Time | <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math> | <math alttext="" display="inline"><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo stretchy="false">)</mo></mrow></math>
    | <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo
    stretchy="false">)</mo></mrow></math> | <math alttext="" display="inline"><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></math> |'
  prefs: []
  type: TYPE_TB
- en: '*n*: data size, *m*: PDS size (*m* ¡ ¡ *n*), *k*: number of hash function,
    DS: Data structures, BST: Binary search trees'
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, a predictable error is expected while using MSQ PDS. However,
    here errors are managed under a predefined marginal threshold with a trade-off
    between accuracy and storage requirements. Bloom Filter, quotient filter, and
    skiplist are popularly used PDS under this category which will be discussed further
    in this chapter. Moreover, the popularity of Bloom filter resulted in its various
    variants with some extra capability which is not supported by standard Bloom filter.
    However, being a part of error prone approach, bloom filter, and quotient filter
    return results with false positive on membership query whereas skip list doesn't
    return any error.
  prefs: []
  type: TYPE_NORMAL
- en: False positive implies that even if an element is not present in the set, query
    result may output true whereas false negative implies that for the presence of
    an element query results in negative results. The difference between false positive
    and false negative has been represented in [Fig. 10.1](13chap_10.xhtml#fig10_1).
    Additionally, the precision and recall value for the model can be computed from
    Eqs. 10.1 and 10.2 respectively where precision describes how accurate the calculated
    results are out of total positive predictions and recall depicts the proportion
    of correctly identified actual positive. The next topic discusses the concept
    of Bloom filter.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1](../images/fig10_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 10.1.**'
  prefs: []
  type: TYPE_NORMAL
- en: False positive vs. false negative.
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mfrac><mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>p</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi></mrow><mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>p</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mo>+</mo><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mi>p</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi></mrow></mfrac></mrow></mtd></mtr></mtable></mrow></math>(10.1)
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>p</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi></mrow><mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>p</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mo>+</mo><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>g</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi></mrow></mfrac></mrow></mtd></mtr></mtable></mrow></math>(10.2)
  prefs: []
  type: TYPE_NORMAL
- en: '[10.2 Bloom Filter and its Variants](contents.xhtml#rsec10_2)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The concept of BF was introduced by Burton H. Bloom back in 1970 [[46](bib.xhtml#ch00-bib-46)].
    BF resides inside the main memory and with BF its fast to check MSQ. Insertion
    and lookup are the two operations supported by standard BF. However, lookup operation
    of standard BF occasionally results in false positive but never in false negative.
    Apparently, BF should be used in cases where a bit of false positive can be accepted.
  prefs: []
  type: TYPE_NORMAL
- en: '[10.2.1 Structure of Bloom filter](contents.xhtml#rsec10_2_1)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'BF is an array of *m* bits having index from 0 to m-1 as represented in [Fig.
    10.2](13chap_10.xhtml#fig10_2). A single bit is used to represent each entry in
    the filter, i.e., 0 or 1\. Along with this, BF employs *k* different independent
    and uniform hash functions. Instead of storing the data itself, BF utilizes hashing
    to store hashes of the data in a compact form. However, employed hash functions
    should have fast speed. The number of hash functions can be from 1 to *m*. The
    bits of BF are all initialized to zero. It first performs multiple times <math
    alttext="" display="inline"><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></math>
    hashing on each data item and then stores its hash value in the array of size
    *m*. Clearly, with an increase in the number of hash functions, the speed of BF
    gets slow. Notably, searching time complexity with BF is independent of the size
    of array and stored number of elements. For a fixed error rate, both insertion
    and lookup operations serve constant time complexity that is proportional to the
    number of hash functions used. Hence, by encoding information in a bit vector,
    BF can compactly represent a data and can be transmitted with a low bandwidth
    requirement. Despite proving quite beneficial, there are some disadvantages of
    BF which are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, deletion is not supported by BF as resetting bits to 0 can introduce
    false negatives (the reseted bit might represent other element entry in the BF).
    However, the entire BF can be deleted once in a while with reset function. Although,
    there are various instances of BF which support deletion by keeping a record of
    variable count in memory, for example, Counting BF [[79](bib.xhtml#ch00-bib-79)],
    Deletable BF [[165](bib.xhtml#ch00-bib-165)] etc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Poor scaling out of main memory as in secondary memory use of multiple hash
    functions requires many random access to the disk.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BF can not be resized dynamically.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inability to compute frequency count of each element. It can only check presence
    of any element.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.2](../images/fig10_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 10.2.**'
  prefs: []
  type: TYPE_NORMAL
- en: Representation of Bloom filter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Insertion and membership query operations of BF are described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: To insert an element *x*, first apply *k* hash functions to the element *x*
    and the position corresponding to <math alttext="" display="inline"><mrow><mi>h</mi><mi>i</mi><mo
    stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>...</mn><mo>,</mo><mi>k</mi><mo
    stretchy="false">)</mo></mrow></math> is set to 1 if already not set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To check membership of an element *x*, pass the element *x* through *k* hash
    functions to get *k* array positions. If any of the bit corresponding to these
    positions is zero, then the element is definitely not in the set otherwise, it
    might be present. Also, it is probable that even if all *k* corresponding positions
    are 1, element might not be present into the set (false positive). While designing
    BF, one of the aims of developers is to design filter with very less false positive
    rate. However, false negative never happens for BF.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, consider a case where BF is 10 bit long with three hash functions
    ( <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo>,</mo><msub><mi>h</mi><mn>2</mn></msub><mo>,</mo><msub><mi>h</mi><mn>3</mn></msub></mrow></math>)
    where <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo>=</mo><mi>x</mi><mi>m</mi><mi>o</mi><mi>d</mi><mn>6</mn></mrow></math>,
    <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>2</mn></msub><mo>=</mo><mo
    stretchy="false">(</mo><mi>x</mi><mi>m</mi><mi>o</mi><mi>d</mi><mn>4</mn><mo stretchy="false">)</mo><mi>m</mi><mi>o</mi><mi>d</mi><mn>6</mn></mrow></math>
    and <math alttext="" display="inline"><mrow><mi>h</mi><mn>3</mn><mo>=</mo><mo
    stretchy="false">(</mo><mn>2</mn><mo>*</mo><mi>x</mi><mo stretchy="false">)</mo><mi>m</mi><mi>o</mi><mi>d</mi><mn>6</mn></mrow></math>.
    To insert an element 11, pass the key (*11*) through all hash functions which
    results in 3 indices, i.e, <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo>=</mo><mn>5</mn><mo>,</mo><msub><mi>h</mi><mn>2</mn></msub><mo>=</mo><mn>3</mn><mo>,</mo><msub><mi>h</mi><mn>3</mn></msub><mo>=</mo><mn>4</mn></mrow></math>
    and set these three resulting positions to 1\. Similarly to insert element 3,
    positions 0, 3 will be set to 1 as represented in [Fig. 10.3](#fig10_3). However,
    membership query for key *5* returns definitely not in the set as positions corresponding
    to hash function <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>2</mn></msub></mrow></math>
    is zero (See [Fig. 10.4](13chap_10.xhtml#fig10_4)). The lookup operation for element
    12 will result in false positive as 12 is not present in the set but position
    corresponding to all three hash functions, (i.e., 0, 0, 0) are set to 1 whereas
    for element 5, the scenario represents true positive. Simultaneously, [Fig. 10.5](13chap_10.xhtml#fig10_5)
    represents deletion and it could be observed that deletion of element 3 from the
    introduces false negative for element 11.
  prefs: []
  type: TYPE_NORMAL
- en: '**Union and intersection of standard BF**'
  prefs: []
  type: TYPE_NORMAL
- en: 'BF also support operation of union and intersection algebraic operations. Suppose
    *BF(X)* and *BF(Y)* are two BFs that use same size of filter and hash functions.
    Then, intersection and union operation between *BF(X)* and *BF(Y)* is given by:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>B</mi><mi>F</mi><mo stretchy="false">(</mo><mi>A</mi><mo>∩</mo><mi>B</mi><mo
    stretchy="false">)</mo><mo>=</mo><mi>B</mi><mi>F</mi><mo stretchy="false">(</mo><mi>A</mi><mo
    stretchy="false">)</mo><mo>∩</mo><mi>B</mi><mi>F</mi><mo stretchy="false">(</mo><mi>B</mi><mo
    stretchy="false">)</mo></mrow></mtd></mtr></mtable></mrow></math>(10.3)
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>B</mi><mi>F</mi><mo stretchy="false">(</mo><mi>A</mi><mo>∪</mo><mi>B</mi><mo
    stretchy="false">)</mo><mo>=</mo><mi>B</mi><mi>F</mi><mo stretchy="false">(</mo><mi>A</mi><mo
    stretchy="false">)</mo><mo>∪</mo><mi>B</mi><mi>F</mi><mo stretchy="false">(</mo><mi>B</mi><mo
    stretchy="false">)</mo></mrow></mtd></mtr></mtable></mrow></math>(10.4)
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3](../images/fig10_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 10.3.**'
  prefs: []
  type: TYPE_NORMAL
- en: Insertion in BF.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4](../images/fig10_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 10.4.**'
  prefs: []
  type: TYPE_NORMAL
- en: Lookup in BF.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.5](../images/fig10_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 10.5.**'
  prefs: []
  type: TYPE_NORMAL
- en: Deletion in BF.
  prefs: []
  type: TYPE_NORMAL
- en: '**Applications of BF**'
  prefs: []
  type: TYPE_NORMAL
- en: Yahoo mail use BF to compactly represent users contact list so that it gets
    easily fitted in browser cache memory. The use of BF avoids round trip to back
    end server for checking whether e-mail address of the sender is already present
    in contact list or not.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BF is utilized by youtube to assure that recommended videos for a user doesnot
    match user's watch history.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: URL shortener uses BF to ensure unique URLs are generated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tinder deploys BF to filter out repeats for right swipes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache HBase, Postgress databases are using BF to check if a particular record
    exists or not and in case of positive results, records will be fetched from memory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Facebook uses BF for one-hit-wonder. One-hit-wonder is used for the sites which
    get lots of traffic. It basically checks events that happen once and never again.
    So, BF can be used to probe if a particular web page has been visited before or
    not. If somebody visits the site only once, not much content and complicated computations
    will be served. In another case if somebody visits a website more often, more
    personalized content will be served. To realize this process, a BF is employed
    and visitors are checked against BF. In case of positive results, site will serve
    expensive content and for negative results, cached version is served.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quora the famous place to ask questions uses BF to filter out stories that users
    have seen before.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BF supports spell checkers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BF is widely used for forwarding and routing of packets among different nodes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bioinformatics [[108](bib.xhtml#ch00-bib-108)].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prevention of DDoS attack by inserting BF with entries of malicious IP addresses.
    [[161](bib.xhtml#ch00-bib-161)]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False Positive Probability in BF:**'
  prefs: []
  type: TYPE_NORMAL
- en: Clearly, the false positive rate is dependent on the number of 1's in the filter
    and on the count of hash functions.
  prefs: []
  type: TYPE_NORMAL
- en: Probability of a element passed to hash function and setting of a bit is given
    by <math alttext="" display="inline"><mrow><mfrac><mn>1</mn><mi>m</mi></mfrac></mrow></math>
    and probability of not setting a bit (probability of getting false positive) is
    given by Eq. 10.5
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>P</mi><mo>=</mo><mn>1</mn><mo>−</mo><mfrac><mn>1</mn><mi>m</mi></mfrac></mrow></mtd></mtr></mtable></mrow></math>(10.5)
  prefs: []
  type: TYPE_NORMAL
- en: As an element is passed through *k* hash functions. So, probability that an
    arbitrary bit is not set after mapping an element to *k* corresponding positions.
    is given by Eq. 10.6
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>P</mi><mo>=</mo><msup><mrow><mfenced close=")" open="("><mrow><mn>1</mn><mo>−</mo><mfrac><mn>1</mn><mi>m</mi></mfrac></mrow></mfenced></mrow><mi>k</mi></msup></mrow></mtd></mtr></mtable></mrow></math>(10.6)
  prefs: []
  type: TYPE_NORMAL
- en: Now, for *n* insertions, probability that an arbitrary bit is not set after
    feeding through *k* hash functions is given by Eq. 10.7
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>P</mi><mo>=</mo><msup><mrow><mfenced close=")" open="("><mrow><mn>1</mn><mo>−</mo><mfrac><mn>1</mn><mi>m</mi></mfrac></mrow></mfenced></mrow><mrow><mi>k</mi><mi>n</mi></mrow></msup></mrow></mtd></mtr></mtable></mrow></math>(10.7)
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, false positive rate (FPR) happens when a bit is falsely set to
    high. Hence, the probability of an arbitrary bit being set is given by Eq. 10.8
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>P</mi><mo>=</mo><mn>1</mn><mo>−</mo><msup><mrow><mfenced
    close=")" open="("><mrow><mn>1</mn><mo>−</mo><mfrac><mn>1</mn><mi>m</mi></mfrac></mrow></mfenced></mrow><mrow><mi>k</mi><mi>n</mi></mrow></msup></mrow></mtd></mtr></mtable></mrow></math>(10.8)
  prefs: []
  type: TYPE_NORMAL
- en: A new element is passed through *k* hash functions. Therefore, for *k* hash
    functions, Eq. 10.8 can be manipulated to give Eq. 10.9
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>P</mi><mo>=</mo><msup><mrow><mfenced close=")" open="("><mrow><mn>1</mn><mo>−</mo><msup><mi>e</mi><mrow><mfrac><mrow><mo>−</mo><mi>k</mi><mi>n</mi></mrow><mi>m</mi></mfrac></mrow></msup></mrow></mfenced></mrow><mi>k</mi></msup></mrow></mtd></mtr></mtable></mrow></math>(10.9)
  prefs: []
  type: TYPE_NORMAL
- en: It is clear from Eq. 10.9 that FPR is a function of *k, m* and *n*. Incrementing
    the total number of elements and decrementing filter size, lead to increase in
    the FPR. However, by incrementing *k*, FPR gets reduced. Unfortunately, the computational
    complexity of system gets increased by increasing value of *k*. Also, if value
    of *m* is set as <math alttext="" display="inline"><mi>∞</mi></math>, error rate
    tends to 0 whereas if value of *m* is 1, in this case error rate tends to 0 which
    implies 100% chance of getting error. To achieve minimum FPR, for a constant value
    of *m* and *n* for the optimum value of *k* is computed as depicted in Eq. 10.10\.
    Hence, for a given *k, m* needs to be linearly increased with *n* to have a fixed
    FPR.
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><msub><mi>k</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub><mo>=</mo><mi>l</mi><mi>n</mi><mo
    stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo><mfrac><mi>m</mi><mi>n</mi></mfrac><mo>=</mo><mn>0.7</mn><mfrac><mi>m</mi><mi>n</mi></mfrac></mrow></mtd></mtr></mtable></mrow></math>(10.10)
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, by fixing a accepted target FPR *(p)* and utilizing optimal value
    of *k*, the size of filter *m* can be computed as:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>P</mi><mo>=</mo><msup><mrow><mfenced close=")" open="("><mrow><mn>1</mn><mo>−</mo><msup><mi>e</mi><mrow><mfrac><mrow><mo
    stretchy="false">(</mo><mo>−</mo><mi>l</mi><mi>n</mi><mo stretchy="false">(</mo><mn>2</mn><mo
    stretchy="false">)</mo><mfrac><mi>m</mi><mi>n</mi></mfrac><mo stretchy="false">)</mo><mi>n</mi></mrow><mi>m</mi></mfrac></mrow></msup></mrow></mfenced></mrow><mrow><mi>l</mi><mi>n</mi><mo
    stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo><mfrac><mi>m</mi><mi>n</mi></mfrac></mrow></msup></mrow></mtd></mtr></mtable></mrow></math>(10.11)
  prefs: []
  type: TYPE_NORMAL
- en: which further results in
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>m</mi><mo>=</mo><mo>−</mo><mfrac><mrow><mi>n</mi><mi>l</mi><mi>n</mi><mo
    stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><mrow><msup><mrow><mo
    stretchy="false">(</mo><mi>l</mi><mi>n</mi><mo stretchy="false">(</mo><mn>2</mn><mo
    stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mn>2</mn></msup></mrow></mfrac></mrow></mtd></mtr></mtable></mrow></math>(10.12)
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, from Eq. 10.12, the optimal bits required per elements can be computed
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mfrac><mi>m</mi><mi>n</mi></mfrac><mo>=</mo><mo>−</mo><mfrac><mrow><mi>n</mi><mi>l</mi><mi>n</mi><mo
    stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><mrow><mi>l</mi><mi>n</mi><mn>2</mn></mrow></mfrac><mo>≈</mo><mo>−</mo><mn>1.44</mn><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mi>p</mi></mrow></mtd></mtr></mtable></mrow></math>(10.13)
  prefs: []
  type: TYPE_NORMAL
- en: The graph presented in [Fig. 10.6](13chap_10.xhtml#fig10_6) plots the change
    in FPR against filter size for 10M elements [[41](bib.xhtml#ch00-bib-41)]. It
    can be observed that rate of false positive decreases with an increase in filter
    size. For a single hash function to achieve *p* less than 0.01 size of filter
    needs to be 100 times size of total elements, whereas choosing *k = 5* can provide
    the same in 100M.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.6](../images/fig10_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 10.6.**'
  prefs: []
  type: TYPE_NORMAL
- en: False positive rate vs. size of array [[41](bib.xhtml#ch00-bib-41)].
  prefs: []
  type: TYPE_NORMAL
- en: '[10.2.2 Implementation of BF in Python](contents.xhtml#rsec10_2_2)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![](../images/list10_1.jpg)![](../images/list10_2.jpg)![](../images/list10_3.jpg)![](../images/list10_4a.jpg)![](../images/list10_4b.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[10.2.3 Variants of BF](contents.xhtml#rsec10_2_3)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some popular variants of BF are discussed as follows and their comparison is
    presented in [Table 10.3](#tab10_3).
  prefs: []
  type: TYPE_NORMAL
- en: '**TABLE 10.2**'
  prefs: []
  type: TYPE_NORMAL
- en: Case when 8 bits per elements are used for compression.
  prefs: []
  type: TYPE_NORMAL
- en: '| Array bits per element | <math alttext="" display="inline"><mrow><mfrac><mi>m</mi><mi>n</mi></mfrac></mrow></math>
    | 8 | 14 | 92 |'
  prefs: []
  type: TYPE_TB
- en: '| Transmission bits per element | <math alttext="" display="inline"><mrow><mfrac><mi>z</mi><mi>n</mi></mfrac></mrow></math>
    | 8 | 7.293 | 7.293 |'
  prefs: []
  type: TYPE_TB
- en: '| Hash function | k | 6 | 2 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| False positive rate | P | 0.0216 | 0.0177 | 0.0108 |'
  prefs: []
  type: TYPE_TB
- en: '*n*: data size, *m*: BFsize *k*: number of hash function, *z*: desired compressed
    size'
  prefs: []
  type: TYPE_NORMAL
- en: '**TABLE 10.3**'
  prefs: []
  type: TYPE_NORMAL
- en: Comparison between different BF variants.
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 10.3](../images/tab10_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[10.2.3.1 Counting BF](contents.xhtml#rsec10_2_3_1)'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As discussed earlier, deletion in standard BF requires a bit to be reset from
    1 to 0 which may lead to the occurrence of false negative as a single arbitrary
    bit may represent multiple elements. As a solution to this problem, counting BF
    was designed by authors in [[79](bib.xhtml#ch00-bib-79)] for exchanging information
    related to web cache among various proxies over the Internet.
  prefs: []
  type: TYPE_NORMAL
- en: Notably, the increase in web usage has effected fetch latency in the network.
    In this context, distributed proxy server improves latency by maintaining a web
    cache memory of each other proxy server information which allows for access of
    desired page from neighbor cache nearer to client instead of accessing from original
    web source. Web cache sharing can be benefited a lot from BF as total message
    exchange are quadratic in the total number of proxies. The advantage of web caching
    is to lower down the unnecessary bandwidth consumption because of increasing Internet
    request. In this process, each proxy server is employed with a compact and summarized
    information of other proxies cached documents. Web proxy servers periodically
    construct BF with their current cache entries and broadcast it to the network.
    For a cache miss, proxy server probes BF for cache hit in other proxies. Queries
    are then sent to the proxies with positive results. The false positive probabilities
    are compensated by reduction in bandwidth consumption as BF refrains the transfer
    of full list of URL cache summaries. The concept of distributed web caching is
    represented in [Fig. 10.7](13chap_10.xhtml#fig10_7).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.7](../images/fig10_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 10.7.**'
  prefs: []
  type: TYPE_NORMAL
- en: Distributed web caching.
  prefs: []
  type: TYPE_NORMAL
- en: Here, in counting BF, rather than using a single bit for representing each entry
    in the filter, a fixed size counter value is used to track the count of element
    hashed to that position. In order to avoid counter overflow, poison approximation
    suggests 4 bits per counter for majority of applications. Instead of just checking
    the presence of an element, counting BF is used to check the occurrence of elements
    for *θ* or more times where *θ* implies count threshold. For instance, if *θ*=2
    for one hit wonder case it implies one hit or two hits for a particular event.
    Similar to standard BF, counting BF also generates false positive. However, unlike
    standard BF, counting BF can lead to false negative if a never inserted element
    is tried to be removed from the filter. The parameters *m*, *n*, *k* are also
    defined same as in standard BF. However, counting BF results in wastage of space
    as reported in [[51](bib.xhtml#ch00-bib-51)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Initially, all bits in this filter are zero. Operations supported by couting
    BF are described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Insertion: To insert an element, pass it through *k* hash functions and *k*
    counters corresponding to these hash functions are incremented by one. To explain
    this concept, consider a BF with 3 hash functions, i.e., <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo>,</mo><msub><mi>h</mi><mn>2</mn></msub><mo>,</mo><msub><mi>h</mi><mn>3</mn></msub></mrow></math>)
    where <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo>=</mo><mi>x</mi><mi>m</mi><mi>o</mi><mi>d</mi><mn>10</mn></mrow></math>,
    <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>2</mn></msub><mo>=</mo><mo
    stretchy="false">(</mo><mn>2</mn><mi>x</mi><mo>+</mo><mn>3</mn><mo stretchy="false">)</mo><mi>m</mi><mi>o</mi><mi>d</mi><mn>10</mn></mrow></math>,
    <math alttext="" display="inline"><mrow><mi>h</mi><mn>3</mn><mo>=</mo><mo stretchy="false">(</mo><mn>2</mn><mo>*</mo><mi>x</mi><mo
    stretchy="false">)</mo><mi>m</mi><mi>o</mi><mi>d</mi><mn>10</mn></mrow></math>,
    and *x* represents number to be inserted. The insertion of elements 9, 15, 8 are
    represented in [Fig. 10.8](13chap_10.xhtml#fig10_8). The hash index corresponding
    to each element is:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo
    stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo><mo>=</mo><mn>9</mn><mo>,</mo><msub><mi>h</mi><mn>2</mn></msub><mo
    stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>,</mo><msub><mi>h</mi><mn>3</mn></msub><mo
    stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo><mo>=</mo><mn>8</mn></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo
    stretchy="false">(</mo><mn>15</mn><mo stretchy="false">)</mo><mo>=</mo><mn>5</mn><mo>,</mo><msub><mi>h</mi><mn>2</mn></msub><mo
    stretchy="false">(</mo><mn>15</mn><mo stretchy="false">)</mo><mo>=</mo><mn>3</mn><mo>,</mo><msub><mi>h</mi><mn>3</mn></msub><mo
    stretchy="false">(</mo><mn>15</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo
    stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo><mo>=</mo><mn>8</mn><mo>,</mo><msub><mi>h</mi><mn>2</mn></msub><mo
    stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo><mo>=</mo><mn>9</mn><mo>,</mo><msub><mi>h</mi><mn>3</mn></msub><mo
    stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo><mo>=</mo><mn>6</mn></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.8](../images/fig10_8.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '**FIGURE 10.8.**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Insertion in Counting BF.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Lookup: While membership query for an element, feed the element to *k* hash
    functions. If any bit mapped to these corresponding locations is zero, it implies
    that element is definitely not in the set otherwise, it may be present. The membership
    query for element 9 and 15 results in true positive whereas for element 13 a false
    positive is reported as represented in [Fig. 10.9](13chap_10.xhtml#fig10_9) (
    <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo stretchy="false">(</mo><mn>13</mn><mo
    stretchy="false">)</mo><mo>=</mo><mn>5</mn><mo>,</mo><msub><mi>h</mi><mn>2</mn></msub><mo
    stretchy="false">(</mo><mn>13</mn><mo stretchy="false">)</mo><mo>=</mo><mn>3</mn><mo>,</mo><msub><mi>h</mi><mn>3</mn></msub><mo
    stretchy="false">(</mo><mn>13</mn><mo stretchy="false">)</mo><mo>=</mo><mn>4</mn></mrow></math>).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.9](../images/fig10_9.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '**FIGURE 10.9.**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Lookup in Counting BF.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Deletion: To delete an element simply decrement the counter value of the corresponding
    location by one as represented in [Fig. 10.10](13chap_10.xhtml#fig10_10) for element
    8\. In addition to this, [Fig. 10.11](13chap_10.xhtml#fig10_11) represent case
    where element 13 which is never added to the filter is deleted and subsequently
    membership query for element 8 results in a false negative. Nevertheless, counting
    BF supports deletion but its space cannot be extended on demand [[92](bib.xhtml#ch00-bib-92)].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.10](../images/fig10_10.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '**FIGURE 10.10.**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Deletion in Counting BF.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.11](../images/fig10_11.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '**FIGURE 10.11.**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Understanding false negative for Counting BF.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Counting overflow is however an disadvantage of counting BF. If an counter value
    reaches <math alttext="" display="inline"><mrow><msup><mn>2</mn><mi>w</mi></msup><mo>−</mo><mn>1</mn></mrow></math>,
    (where w represents width of the counter), it cannot be incremented after this
    point. Counting BF also supports the same applications as described for standard
    BF. Differently, a Counting BF can be incorporated in place of BF to allow deletion
    of least recently used web information from web cache. A worth application of
    counting BF is to detect DDoS attacks by setting an approximate count on access
    of given webpage in a short timespan.
  prefs: []
  type: TYPE_NORMAL
- en: '[10.2.3.2 Compressed BF](contents.xhtml#rsec10_2_3_2)'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The intension behind the introduction of compressed BF [[146](bib.xhtml#ch00-bib-146)]
    is to enable BF to be passed as a message among different network nodes. Compression
    is an effective technique to reduce transmission size and compressing a BF can
    improve network performance. Arithmetic coding is however recommended by authors
    for fast compression process. Clearly, here developers are concerned for optimizing
    transmission size in a network with heavy network traffic. Along with reducing
    bits to be broadcasted, false positive rate and lookup cost also get reduced.
    Unfortunately, compression and decompression increase processing costs. Here,
    hash function is not optimized for *m* and *n* rather for transmission size (which
    is not necessarily *m* but a compressed array). However, false positive probability
    is targeted to minimize after compression.
  prefs: []
  type: TYPE_NORMAL
- en: In standard BF, the main concern of the developers is to minimize the probability
    of false positive by manipulating *k* for a fixed value of *m* and *n*. The standard
    BF is optimized for <math alttext="" display="inline"><mrow><msub><mi>k</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub><mo>=</mo><mi>l</mi><mi>n</mi><mo
    stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo><mfrac><mi>m</mi><mi>n</mi></mfrac><mo>=</mo><mn>0.7</mn><mfrac><mi>m</mi><mi>n</mi></mfrac></mrow></math>
    when each bit position has <math alttext="" display="inline"><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></math>
    probability of being set as 0 or 1\. Although, in compressed BF, *k* is selected
    so that the probability of each array entry being 1 if <math alttext="" display="inline"><mrow><mfrac><mn>1</mn><mn>3</mn></mfrac></mrow></math>.
    Hence, resulting unbalanced filter will contain <math alttext="" display="inline"><mrow><mfrac><mn>1</mn><mn>3</mn></mfrac></mrow></math>
    1's and <math alttext="" display="inline"><mrow><mfrac><mn>2</mn><mn>3</mn></mfrac></mrow></math>
    0's so that it is easy to compress. This feature is leveraged to compress *m*
    bit array and to suppress its transmission size. To achieve this, reduced number
    of hash functions are employed for large filter size so that less bits than standard
    BF are transmitted in the network with low FPR. Specifically, with same number
    of bits to transfer, compressed BF achieves lower FPR over standard BF. Notably,
    the FPR is lower down to <math alttext="" display="inline"><mrow><msup><mrow><mn>0.5</mn></mrow><mrow><mo
    stretchy="false">(</mo><mi>z</mi><mo>/</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msup></mrow></math>,
    where *z* is the array size after compression. Here, authors have concluded that
    with the increase in size of filter it is possible to minimize the use of hash
    functions. [Table 10.2](#tab10_2) shows the result when 8 bits per element are
    used for transmission, i.e., <math alttext="" display="inline"><mrow><mfrac><mi>z</mi><mi>n</mi></mfrac><mo>=</mo><mn>8</mn></mrow></math>
    Similar to standard BF, completely random hash functions are used and deletion
    of elements is not possible. Also, a large value of *w* can lead to space wastage
    due to number of unused zeros. Hence, deciding the right value of *w* is a complex
    trade-off that depends on type of application and distribution of data. Moreover,
    other variants of BF such as counting BF can be benefited from this compression.
    At the receiving node, BF is decompressed. Clearly, this filter still demands
    larger memory space at the endpoints. Specifically, compressed BF is utilized
    in P2P sharing among distributed nodes. However, lightweight nodes with few computing
    powers and memory resources may fail for this complicated algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: '[10.2.3.3 Spectral BF](contents.xhtml#rsec10_2_3_3)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unfortunately, standard BF doesn't support multiset, i.e., it doesn't allow
    query for multiplicities of an element if an element is repeating more than once
    in a set. In 2003, spectral BF [[65](bib.xhtml#ch00-bib-65)] was designed specifically
    to support multiset and preferred to be used for streaming data. In fact spectral
    BF is an optimized extension of counting BF. The term spectral signifies that
    the multiplicities of element are supported within a requested spectrum. Improved
    lookup, enhanced accuracy and support of deletion are the reasons for adopting
    spectral BF over standard BF. Similar to counting BF, a *m* counter array is used
    rather than a bit vector. All the counters are initialized to zero. However, the
    usage of counter instead of single bit increases up the space requirements. Along
    with insertion and lookup operations, spectral BF supports deletion as well. The
    time complexity for all these operations is constant, i.e., <math alttext="" display="inline"><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math>. Handling
    ad-hoc iceberg queries, spectral Bloomjoins, providing fast aggressive index are
    some of the use cases of spectral BF. Ad-hoc iceberg queries perform queries for
    a threshold specified at query time and return a small portion of data. The facility
    of spectral Bloomjoins reduces the common rounds for remote databases sites while
    performing joins in order to minimize complexity and network usage. Moreover,
    spectral BF is used for scenarios that demands an index on a relation for frequency
    count queries, for instance, bifocal sampling. Spectral BF employs two scheme
    for its operations, i.e., minimal increase and recurring minimum. The former is
    suited for insertion and lookup whereas the later can support deletion as well.
    For sequence that requires insertions and lookup only, minimal increase shows
    improved performance over recurring minimum. <math alttext="" display="inline"><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo><mo>+</mo><mi>O</mi><mo
    stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo><mo>+</mo><mi>N</mi></mrow></math>
    is the total space requirement for this data structure where *N* is the overall
    length of array and *m* is the number of unique elements inserted into array.
    Now, we will discuss the two spectral BF scheme one by one.
  prefs: []
  type: TYPE_NORMAL
- en: '**Minimal Increase**: This scheme is based on key insight that minimal counter
    has the most appropriate results for *k* counter positions corresponding to *k*
    hash functions as other items could also be hashed to same locations in large
    datasets. With this insight, for a increment operation, only minimal valued counter
    are incremented and rest are kept intact. For a multiset *S*, say <math alttext=""
    display="inline"><mrow><msub><mi>f</mi><mi>x</mi></msub></mrow></math> be the
    frequency of element *x* in the set.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Insertion: While inserting an element, positions corresponding to *k* hash
    functions are calculated and only minimal valued counter value is incremented
    by 1\. Consider a spectral BF with *10* counter values and *3* hash functions,
    i.e., <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo>=</mo><mi>x</mi><mi>m</mi><mi>o</mi><mi>d</mi><mn>10</mn></mrow></math>,
    <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>2</mn></msub><mo>=</mo><mo
    stretchy="false">(</mo><mn>2</mn><mi>x</mi><mo>+</mo><mn>3</mn><mo stretchy="false">)</mo><mi>m</mi><mi>o</mi><mi>d</mi><mn>10</mn></mrow></math>,
    <math alttext="" display="inline"><mrow><mi>h</mi><mn>3</mn><mo>=</mo><mo stretchy="false">(</mo><mn>2</mn><mo>*</mo><mi>x</mi><mo
    stretchy="false">)</mo><mi>m</mi><mi>o</mi><mi>d</mi><mn>10</mn></mrow></math>.
    [Fig. 10.12](13chap_10.xhtml#fig10_12) represents insertion with minimal increase
    scheme. Here, element 9, 15, 8, 9, 8, 9 are inserted in series and while insertion
    only minimal counter value is incremented by 1\. For instance, while inserting
    element 8 for the first time, hash functions returned 8, 9, 6 as array location
    which has data 1, 1, 0 respectively. So while inserting 8, only value at location
    6, i.e., 0 is incremented. However, for second time insertion of element 9, hash
    functions returned 9, 1, 8 locations which has value 1, 1, 1\. As all three places
    have same counter values, so all get incremented by 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Frequency query: A frequency count query for element *x* returns <math alttext=""
    display="inline"><mrow><msub><mi>f</mi><mi>x</mi></msub></mrow></math>. After
    feeding through *k* hash function, return the minimum value among the *k* locations.
    [Fig. 10.13](13chap_10.xhtml#fig10_13) represents lookup operation with minimal
    increase scheme. Here, query for element 8 returned 2 as location corresponding
    to hash functions, i.e., 8, 9, 6 has value 3, 3, 2 respectively and minimum of
    them which is 2 is returned for frequency query result. Also, query for element
    13 returned 1 despite the fact it is not present in the set which is clearly a
    false positive.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deletion: Deletion is not preferable while using minimal increase. As all counter
    values are not incremented while inserting an element (only minimal counter values
    are incremented) so, the deletion operation may result in false negative. [Fig.
    10.14](13chap_10.xhtml#fig10_14) represents occurrence of false negative while
    performing deletion in spectral BF. Deletion of element 9 will decrement the counter
    value of locations 9, 1, 8 by 1 and consequently frequency query for element 8
    will return 1 which should be actually 2 as elements as 2 occurrences.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.12](../images/fig10_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 10.12.**'
  prefs: []
  type: TYPE_NORMAL
- en: Insertion in spectral BF following minimal increase scheme.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.13](../images/fig10_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 10.13.**'
  prefs: []
  type: TYPE_NORMAL
- en: Lookup operation in spectral BF following minimal increase scheme.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.14](../images/fig10_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 10.14.**'
  prefs: []
  type: TYPE_NORMAL
- en: Deletion operation in spectral BF following minimal increase scheme.
  prefs: []
  type: TYPE_NORMAL
- en: '**Recurring Minimum:** Recurring Minimum employs two different spectral BF''s,
    primary (F1), secondary (F2). The key logic for recurring minimum is that elements
    facing errors while querying have less chances for recurring minima counter values.
    Here, the items with recurring minima counter values corresponding to *k* hash
    functions are maintained in primary spectral BF whereas elements with unique minimum
    counter values are maintained in secondary spectral BF. Hence, the secondary BF
    stores elements which faces higher error rates. Nevertheless, hashing twice into
    BF in case of unique minimum makes recurring minimum a complex method. Operations
    supported by recurring minimum scheme is discussed as follows.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Insertion: To insert an item *x*, increment the corresponding *k* counters
    in primary BF. Next, check whether element *x* has recurring minimum counter value,
    if so continue the counter value process. Otherwise, if *x* has single minimum
    counter value, check for *x* in secondary BF and increment counter. If not found
    there, insert *x* to secondary Spectral BF with a value equal to minimal counter
    value retrieved from primary BF.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Frequency query: To query an element, first probe primary BF and check if an
    element has recurring minimum then return minimum counter value. Otherwise search
    in secondary BF and the minimum counter value from secondary BF is returned if
    value is greater than zero, if not minimum counter value from primary BF is returned.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deletion: To delete an element, first delete the counter value by 1 in primary
    SBF. Also, if it has single minimum, decrement its counter value in secondary
    BF as well. Due to the reason that an element is inserted both to primary and
    secondary BF, false negative can never happen.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10.2.3.4 Deletable Bloom Filter (DBF)](contents.xhtml#rsec10_2_3_4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Deletable BF (DBF) [[165](bib.xhtml#ch00-bib-165)] was introduced to solve
    the problem of false negatives that happens while deleting elements in counting
    BF. However, instead of employing a counter array like counting BF, a bit array
    of *m* bits is used. The key insight behind DBF is that it tries to locate the
    bit region where collision while inserting an element can take place and deletion
    can only be done in collision free area. Here a bit array of *m* bits is divided
    into *r* region and each region should contain <math alttext="" display="inline"><mrow><mfrac><mrow><msup><mi>m</mi><mo>′</mo></msup></mrow><mi>r</mi></mfrac></mrow></math>
    bits each where <math alttext="" display="inline"><mrow><msup><mi>m</mi><mo>′</mo></msup><mo>=</mo><mi>m</mi><mo>−</mo><mi>r</mi></mrow></math>.
    At the starting of *m* bit array, a collision bitmap of size *r* is kept to code
    and these *r* bits are initialized to 0\. 1 in collision bitmap is marked for
    a collision prone area whereas zero represents a collision free region. A key
    question while designing BF is to choose the value of *r* as this value decides
    the capability of a BF to remove elements and FPR. The false positive probability
    for DBF is calculated as:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>P</mi><mo>=</mo><msup><mrow><mfenced close="]" open="["><mrow><mn>1</mn><mo>−</mo><msup><mrow><mfenced
    close=")" open="("><mrow><mn>1</mn><mo>−</mo><mfrac><mn>1</mn><mrow><mi>m</mi><mo>−</mo><mi>r</mi></mrow></mfrac></mrow></mfenced></mrow><mrow><mi>k</mi><mo>*</mo><mi>n</mi></mrow></msup></mrow></mfenced></mrow><mi>k</mi></msup></mrow></mtd></mtr></mtable></mrow></math>(10.14)
  prefs: []
  type: TYPE_NORMAL
- en: 'where, *n* is the total number of elements to be inserted. Operations supported
    by DBF are described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Insertion: To insert an element, the *k* positions corresponding to *k* hash
    functions are set to 1\. If any cell among *k* locations is found to be already
    1, it represents case of collision and in response to this collision, the bit
    corresponding to the region where collision happened in collision bitmap is set
    to 1\. [Fig. 10.15](13chap_10.xhtml#fig10_15) represents insertion in DBF. Here,
    element 15, 9, 8, 4 are inserted in series with 3 hash functions as: <math alttext=""
    display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo>=</mo><mi>x</mi><mi>m</mi><mi>o</mi><mi>d</mi><mn>11</mn></mrow></math>,
    <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>2</mn></msub><mo>=</mo><mo
    stretchy="false">(</mo><mn>2</mn><mi>x</mi><mo>+</mo><mn>3</mn><mo stretchy="false">)</mo><mi>m</mi><mi>o</mi><mi>d</mi><mn>11</mn></mrow></math>,
    <math alttext="" display="inline"><mrow><mi>h</mi><mn>3</mn><mo>=</mo><mo stretchy="false">(</mo><mn>2</mn><mo>*</mo><mi>x</mi><mo
    stretchy="false">)</mo><mi>m</mi><mi>o</mi><mi>d</mi><mn>11</mn></mrow></math>.
    For element 9, no collision is detected whereas for element 8, collision is detected
    at 8th location in region 3\. So, the corresponding bit in the collision bitmap
    is set to 1\. Similarly, for element 4, collision happens in region 1, 2, and
    3 so these same positions in collision bitmap are set to 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.15](../images/fig10_15.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '**FIGURE 10.15.**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Insertion operation in deletable BF.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Lookup query: To query an element, pass the element in question through *k*
    hash functions and if any of *k* location is 0, the element is not in set otherwise
    it might be present.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deletion: To delete, among *k* computed hashed locations, reset only those
    bits that lie in collision free zone. If all *k* bits corresponding to hash functions
    are located in collision prone area, then the element is non-deletable. Hence,
    the deletion of an element is only possible if atleast any one bit among *k* can
    be reset to 0\. This way false negative are avoided but false positives are still
    possible. [Fig. 10.16](13chap_10.xhtml#fig10_16) represents deletion for DBF.
    As shown in the figure element 15 cannot be deleted because corresponding hashed
    locations, i.e., 4, 0, 8 all lies in collision prone area whereas element 9 is
    successfully deleted as among corresponding hashed locations 9th, 10th location
    lies in collision free area.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.16](../images/fig10_16.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '**FIGURE 10.16.**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Deletion operation in DBF.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[10.2.3.5 Stable BF](contents.xhtml#rsec10_2_3_5)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unfortunately, the count of zero in BF decreases with time and there reaches
    a point when all the queries are answered as probably in the set. The reason behind
    introduction of SBF is to eliminate duplicates in the streaming data and to evict
    stale data before error reaches a pre-defined threshold value. Stable BF creates
    space for more recent items as this data is of more importance than the stale
    one. Similar to counting BF, an array of *d*-bit counters is used here and all
    counters are initialized to 0\. So, maximum counter value can reach <math alttext=""
    display="inline"><mrow><msup><mn>2</mn><mi>d</mi></msup><mo>−</mo><mn>1</mn></mrow></math>.
    To deal with stale data, Stable BF evicts stale data to create space for new data.
    Query processing, URL crawling, monitoring distinct IP addresses, graph processing
    are some of the applications of Stable BF.
  prefs: []
  type: TYPE_NORMAL
- en: 'Insertion: To insert an item, pass it through *k* hash functions. After some
    point when the number of zeros becomes constant, update Stable BF. To update,
    randomly *p* counter value is decremented by 1\. After this step, all *k* computed
    hash locations are set to a maximum value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Checking duplicacy: To check duplicate value, query and check whether *k* hashed
    cells is hashed to 0 or 1\. For a case where any cell returns 0, there is no duplicate
    item in te set otherwise duplicacy exist. However, randomly setting bits to 0
    may result in false negative. Here, false negative is defined as a situation when
    query for duplicate item is answered as distinct. Also, false negative is dependent
    on input data distribution. For the elements that don''t have predecessor, the
    chances of false negative are zero.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moreover, Stable BF guarantees a tight upper bound on FPR while introducing
    false negative due to randomly eviction of stale information. Setting *p=0* and
    *d=1*, Stable BF behaves as SBF. [Fig. 10.17](13chap_10.xhtml#fig10_17) represents
    a case for *p=2* and *d=3*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.17](../images/fig10_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 10.17.**'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Stable BF.
  prefs: []
  type: TYPE_NORMAL
- en: '[10.2.3.6 Retouched Bloom Filter (RBF)](contents.xhtml#rsec10_2_3_6)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One approach to reduce false positive is by increasing the size of bit vector.
    However, this approach can lead to increased memory usage. Another BF variant
    to decrease FPR from the filter is introduced by Donnet *et al.* [[73](bib.xhtml#ch00-bib-73)]
    and named as RBF. This filter also enhances flexibility of the system. Here, false
    positives that are more troublesome over others are tried to be removed from the
    filter. However, this approach introduces random false negatives. False negatives
    are compensated with the advantage that more concerning false positives are handled.
    Here the false positives are tried to be identified after the construction of
    BF but before it has been used. Retouched BF randomly removes some false positive
    with a trade-off against introducing some false negatives. Notably, false negatives
    doesn't happen in standard BF.
  prefs: []
  type: TYPE_NORMAL
- en: RBF works by resetting some chosen bits in bit vector to 0 in order to reduce
    FPR. This process of RBF is named as bit clearing process. Clearly, for an element
    if any position corresponding to *k* hash functions are reset to 0 in bit clearing
    process, it will result in false negative. The bit clearing process can be randomized
    or selective. The results of RBF are concluded on a metric *χ*. If the value of
    this metric is greater than 1, it implies that removed false positive proportion
    is higher over generated false negative proportion whereas a value lesser than
    1 represents that removed false positive proportion is lower than generated false
    negative.
  prefs: []
  type: TYPE_NORMAL
- en: 'Randomized Bit clearing RBF: In random bit clearing process, randomly some
    bits are reset to 0, despite of the logic whether these bits are reset to 0\.
    For randomized bit clearing process, it is observed that value of *χ* is calculated
    as 1 which implies that overall error rate for the system is maintained.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Selective bit clearing RBF: Unlike randomized bit clearing, only those bits
    are reset to zero, that contributes to false positive. Selective clearing process
    has 4 algorithms to proceed which are discussed as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Random selection: The first one is random selection that doesn''t demand any
    intelligence for selective clearing process. Here, unlike randomized bit clearing
    process instead of resetting random bits in bit vector, only a bit among *k* available
    can be reset. Here, only one bit is reset that is related with false positive
    of troublesome keys.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Minimum false negative selection: Here, aim is to reduce the probability of
    occurrence of false negative that are generated with selective clearing process.
    This is processed by setting locally a counting vector that stores quantity of
    recorded elements. This algorithm considers possibility of hash collision in the
    bit vector among the hashed key of the element belonging to a set. The disadvantage
    with this algorithm is over estimation.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Maximum false positive selection: This algorithm aims to remove maximum false
    positive. For every troublesome key to eliminate that was not previously deleted,
    among *k* hashed, chose the position to be reseted that decreaments the number
    of false positive.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ratio selection: The last algorithm is ratio selection which is a combination
    of minimum false negative selection and maximum false positive selection algorithm.
    This also aims to minimizes the generated false negatives and to maximize the
    removal of false positives.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Selective clearing process decreases the false positive rate at a greater degree
    than increase in generated false positive numbers. Clearly, RBF incurs extra processing
    cost of key removal and this cost is a multiple of RBF parameters such as- number
    of hash functions. For further details and involved mathematics user may refer
    to [[73](bib.xhtml#ch00-bib-73)].
  prefs: []
  type: TYPE_NORMAL
- en: '[10.2.3.7 Dynamic Bloom Filter](contents.xhtml#rsec10_2_3_7)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As previously mentioned that BFs are not good for dynamic set, i.e., set whose
    size changes over time. Static set cannot perform operations of addition and deletion
    operation with standard BF. BF only works well for sets whose size is known in
    advance. Moreover, in BF target FPR threshold is computed after knowing the size
    of total elements. Specifically for applications that does not have any information
    about upper bound on cardinality of sets, it is difficult to decide BF size. In
    case, the number of elements exceeds the threshold of set size, SBF becomes quite
    unsuccessful because of occurrence of too many false positives. Moreover, for
    the distributed application scenario, all nodes on the network have to adopt similar
    configuration with an aim to achieve interoperability of standard BF among nodes.
    To handle such a case, nodes reconstruct their BF if cardinality size of even
    any one node exceeds the threshold value. For most stand alone applications, that
    have prior information about upper bound on total number of elements for a dynamic
    set, a larger space than known upperbound is allocated so that all items can be
    represented. However, this approach reduces the space efficiency of standard BF.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a solution to this problem of standard BF, dynamic BF was introduced. For
    stand alone applications, dynamic BF can insert an item on demand. For distributed
    applications, dynamic BF handles interoperability issues among nodes as it consumes
    a suitable memory in order to reduce unnecessary waste and transmission overhead.
    Also, it controls rate of false match probability at an acceptable level even
    with an increasing number of elements. Here, in dynamic BF, the false positive
    probability is referred to as false match probability. Notably, dynamic BF can
    support static set as well. Here, a BF is called “active” if false probability
    rate is below a predefined upperbound, otherwise it is referred as full. A dynamic
    BF comprises of *s* homogeneous standard BFs. The *s* is initialized with value
    1 and it is in active state. The insertion of elements can only be done in an
    active BF and a new BF is appended after the previous active BF gets full. [Fig.
    10.18](13chap_10.xhtml#fig10_18) represents the data structure of dynamic BF.
    Let *NR* is the count of elements added to BF. Nevertheless, the dynamic BF is
    initialized with upper bound on false match probability of dynamic BF, max value
    of *s*, upper bound on false positive rate of standard BF, filter size *m* of
    each standard BF, the capacity *C* that is maximum number of items to be stored
    in one standard BF. To create a dynamic BF, initialize one standard BF with the
    above mentioned parameters. The operations supported by dynamic BF is discussed
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Insertion: To insert an element, first locate active BF from given dynamic
    BF. If the current BF is not active, the next BF is employed as new active BF
    and value of *s* is incremented by one. Pass the element through *k* hash functions
    and insert the element in current active BF. Next increment the value of *NR*
    by 1 for current BF. After multiple insertions, when number of elements exceeds
    capacity threshold *c*, i.e., *NR <math alttext="" display="inline"><mo>></mo></math>*
    c, a new BF is appended and this newly created BF is referred to as active BF.
    At a time only one BF is active and rest are inactive. The time complexity for
    the insertion operation is <math alttext="" display="inline"><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></math>.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lookup query: To search an item, pass the item through *k* hash functions.
    If any of the BF stored in dynamic BF returned true, the element might be present
    into set otherwise if all BFs returned false, element is definitely not present
    into set. The time complexity for the lookup query is <math alttext="" display="inline"><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mi>k</mi><mo>*</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></math>.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deletion: Deletion in dynamic BF is somehow difficult. To delete, first check
    for the presence of an element in dynamic BF using lookup query operation discussed
    above. If the element is not present, deletion of element will be rejected. If
    the lookup query results are positive for a single BF, reset the corresponding
    *k* bits to 0 otherwise if multiple BFs returned 1, then dynamic BF don''t delete
    the element in order to prevent occurrence of false negatives. The time complexity
    of the deletion operation is <math alttext="" display="inline"><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mi>k</mi><mo>*</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></math>.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.18](../images/fig10_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 10.18.**'
  prefs: []
  type: TYPE_NORMAL
- en: Data structure of dynamic BF.
  prefs: []
  type: TYPE_NORMAL
- en: '[10.2.3.8 Cuckoo Filter](contents.xhtml#rsec10_2_3_8)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Similar to BF, cuckoo filter [[78](bib.xhtml#ch00-bib-78)] provides fast membership
    query with great space efficiency. Additionally, cuckoo filter supports deletion,
    limited counting with same space complexity. Cuckoo filter is based on the concept
    of cuckoo hashing. Cuckoo hashing is known for its excellence in handling collisions
    for hashing based data structures. In cuckoo hashing, a cuckoo hash table is employed
    which comprises an array of buckets and an item is supposed to be inserted Here,
    two hash functions each for a table is used. Each item is hashed with two different
    hash functions and each hash function indexes into a bucket. The item is stored
    in any of the two buckets. The item is first tried to be stored in the first bucket
    if there is nothing stored there otherwise the item is stored in the second bucket
    if the corresponding location in the second bucket is empty. In case if the second
    bucket is not empty, then item stored in the second bucket is evicted and reinserted
    in alternate hash index. Next, the element is placed in empty location. Clearly,
    this procedure faces the problem of displacing the older key. If alternate hash
    location of older key is empty, it is quite easy to relocate otherwise older key
    has to displace another key. This process is repeated till an empty bucket is
    found. If this situation leads to a cycle, completely new hash functions are selected
    and the whole data structure is reconstructed again. Hence, the amortized complexity
    for insertion is *O(1)*. The query procedure probes both buckets to check item's
    presence. [Fig. 10.19](13chap_10.xhtml#fig10_19) represents the insertion of element
    20, 50, 53, 75, 100, 67, 105, 3, 36, 39 in sequence.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.19](../images/fig10_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 10.19.**'
  prefs: []
  type: TYPE_NORMAL
- en: Insertion in cuckoo hashing.
  prefs: []
  type: TYPE_NORMAL
- en: 'A cuckoo filter is determined by its fingerprint and bucket size. For example,
    a *(3,5)* filter implies 3 bit length filter and each bucket can store 5 fingerprints.
    It is concluded that cuckoo filter consumes less space than standard BF if target
    FPR is less than 3%. The membership query performance of cuckoo filter is better
    than standard BF even when 95% space of the filter is consumed. However, storing
    only fingerprint instead of actual item prevents insertion using standard cuckoo
    hashing. Here, the existing fingerprint has to be relocated to an alternate position
    instead of actual items. The operations of cuckoo filter are described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Insertion: Here, the question is how to restore and rehash the original items
    for locating to alternate location? To deal with this problem, cuckoo filter employs
    ”partial key cuckoo hashing” to find item''s alternate location from its fingerprint.
    Here, for an item *x*, the index for two hash buckets is calculated as: <math
    alttext="" display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo stretchy="false">(</mo><mi>x</mi><mo
    stretchy="false">)</mo><mo>=</mo><mi>h</mi><mi>a</mi><mi>s</mi><mi>h</mi><mo stretchy="false">(</mo><mi>x</mi><mo
    stretchy="false">)</mo></mrow></math> and <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>2</mn></msub><mo>=</mo><msub><mi>h</mi><mn>1</mn></msub><mo
    stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>h</mi><mi>a</mi><mi>s</mi><mi>h</mi><mo
    stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo
    stretchy="false">)</mo></mrow></math>. By using XOR operation it is ensured that
    <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo stretchy="false">(</mo><mi>x</mi><mo
    stretchy="false">)</mo></mrow></math> can be computed using <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>2</mn></msub><mo
    stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></math> and
    fingerprint of *x*. Thus to relocate a key from either of the location calculated
    by <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo
    stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></math> or
    <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>x</mi><mo
    stretchy="false">)</mo></mrow></math> the alternate location is computed by <math
    alttext="" display="inline"><mrow><mi>j</mi><mo>=</mo><mi>i</mi><mo>⊕</mo><mi>h</mi><mi>a</mi><mi>s</mi><mi>h</mi><mo
    stretchy="false">(</mo><mi>f</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo
    stretchy="false">)</mo></mrow></math> where, *i* is the index location of bucket
    where item is originally stored and *j* is the index of alternate bucket. With
    this process, original value of item *x* is not required. Consider a cuckoo filter
    with two entries per 10 buckets as shown in [Fig. 10.20](13chap_10.xhtml#fig10_20).
    To compute index location for item *x* use <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo>=</mo><mi>h</mi><mi>a</mi><mi>s</mi><mi>h</mi><mo
    stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></math> and
    <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>2</mn></msub><mo>=</mo><msub><mi>i</mi><mn>1</mn></msub><mo>⊕</mo><mi>h</mi><mi>a</mi><mi>s</mi><mi>h</mi><mo
    stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo></mrow></math>. Say
    <math alttext="" display="inline"><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow></math>
    and <math alttext="" display="inline"><mrow><msub><mi>i</mi><mn>2</mn></msub></mrow></math>
    are the indices computed from these hash functions. This example uses shift fold
    method to compute fingerprint <math alttext="" display="inline"><mrow><mo stretchy="false">(</mo><mi>f</mi><mo
    stretchy="false">)</mo></mrow></math> for item *x* and hash of *x* is computed
    by *xmod*10\. To handle a collision, randomly pick <math alttext="" display="inline"><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow></math>
    or <math alttext="" display="inline"><mrow><msub><mi>i</mi><mn>2</mn></msub></mrow></math>
    (say *i*) and displace fingerprint at bucket *i* to alternate bucket *j* using
    the formula <math alttext="" display="inline"><mrow><mi>j</mi><mo>=</mo><mi>i</mi><mo>⊕</mo><mi>h</mi><mi>a</mi><mi>s</mi><mi>h</mi><mo
    stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo
    stretchy="false">)</mo></mrow></math>. Following case may exist while inserting:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Case1: Insert(131)*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (a)Use shift fold method to compute fingerprint *f*, *f*= 13+1 = 14.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: (b)<math alttext="" display="inline"><mrow><msub><mi>i</mi><mn>1</mn></msub><mo
    stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></math> = <math
    alttext="" display="inline"><mrow><mi>h</mi><mi>a</mi><mi>s</mi><mi>h</mi><mo
    stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></math> = <math
    alttext="" display="inline"><mrow><mi>h</mi><mi>a</mi><mi>s</mi><mi>h</mi><mo
    stretchy="false">(</mo><mn>131</mn><mo stretchy="false">)</mo></mrow></math> =
    131*mod*10 =1
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: (c)<math alttext="" display="inline"><mrow><msub><mi>i</mi><mn>2</mn></msub><mo
    stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>⊕</mo><mo
    stretchy="false">(</mo><mi>h</mi><mi>a</mi><mi>s</mi><mi>h</mi><mo stretchy="false">(</mo><mn>14</mn><mo
    stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>⊕</mo><mo
    stretchy="false">(</mo><mn>14</mn><mi>m</mi><mi>o</mi><mi>d</mi><mn>10</mn><mo
    stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>⊕</mo><mn>4</mn><mo>=</mo><mn>5</mn></mrow></math>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: (d)As index 1 is available, insert *f* at the same location.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Case 2: Insert(1111)*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (a)<math alttext="" display="inline"><mrow><mi>f</mi><mo stretchy="false">(</mo><mn>1111</mn><mo
    stretchy="false">)</mo><mo>=</mo><mn>11</mn><mo>+</mo><mn>11</mn><mo>=</mo><mn>22</mn></mrow></math>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: (b)<math alttext="" display="inline"><mrow><msub><mi>i</mi><mn>1</mn></msub><mo
    stretchy="false">(</mo><mn>1111</mn><mo stretchy="false">)</mo><mo>=</mo><mn>1111</mn><mi>m</mi><mi>o</mi><mi>d</mi><mn>10</mn><mo>=</mo><mn>1</mn></mrow></math>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: (c)<math alttext="" display="inline"><mrow><msub><mi>i</mi><mn>2</mn></msub><mo
    stretchy="false">(</mo><mn>3333</mn><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>⊕</mo><mo
    stretchy="false">(</mo><mn>22</mn><mi>m</mi><mi>o</mi><mi>d</mi><mn>10</mn><mo
    stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>⊕</mo><mn>2</mn><mo>=</mo><mn>3</mn></mrow></math>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: (d)As, both indices 1 and 5 are occupied, this represent collision case.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: (e)Randomly pick <math alttext="" display="inline"><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow></math>
    or <math alttext="" display="inline"><mrow><msub><mi>i</mi><mn>2</mn></msub></mrow></math>
    and displace the fingerprint from selected location to other bucket. Suppose <math
    alttext="" display="inline"><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow></math>
    is selected, then <math alttext="" display="inline"><mrow><mi>j</mi><mo>=</mo><msub><mi>i</mi><mn>1</mn></msub><mo>⊕</mo><mi>h</mi><mi>a</mi><mi>s</mi><mi>h</mi><mo
    stretchy="false">(</mo><mi>f</mi><mo stretchy="false">[</mo><msub><mi>i</mi><mn>2</mn></msub><mo
    stretchy="false">]</mo><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>⊕</mo><mo
    stretchy="false">(</mo><mi>h</mi><mi>a</mi><mi>s</mi><mi>h</mi><mo stretchy="false">(</mo><mi>f</mi><mo
    stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo
    stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>⊕</mo><mo stretchy="false">(</mo><mi>h</mi><mi>a</mi><mi>s</mi><mi>h</mi><mo
    stretchy="false">(</mo><mn>14</mn><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>⊕</mo><mn>4</mn><mo>=</mo><mn>5</mn></mrow></math>.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.20](../images/fig10_20.jpg)'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_IMG
- en: '**FIGURE 10.20.**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Insertion in cuckoo filter.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Lookup: For an item *x*, first compute fingerprint of *x* and two indices for
    the bucket. Next, read the content of these two locations. If there is match then
    filter returns true otherwise false. This way false negatives are avoided as there
    are no overflows. False positives can happen if two elements have same fingerprint
    and also hash indices are same. Clearly, this process has <math alttext="" display="inline"><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math> time
    complexity. However, FPR becomes high when filter gets full.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deletion: To delete an item, first follow the same procedure of lookup query
    for the element to be deleted. If there is no match, deletion is not possible,
    otherwise if there is a match, simply delete the copy of that fingerprint from
    the bucket. To avoid ”false deletion”, the entry of the element is not cleared.
    With this insight, false positive nature of the filter is unchanged after deletion.
    This process takes <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo
    stretchy="false">)</mo></mrow></math> time complexity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, unlike cuckoo hashing rather than storing original value, only fingerprints
    are stored in filter. Each element is stored in a *f* bit fingerprint. The space
    consumed by cuckoo filter is given by Eq. 10.15 where, *ϵ* specifies FPR, *α*
    is the maximum capacity of filter and *B* is the number of entries per bucket.
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mfrac><mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo
    stretchy="false">(</mo><mfrac><mn>1</mn><mi mathvariant="normal">ϵ</mi></mfrac><mo
    stretchy="false">)</mo><mo>+</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo
    stretchy="false">(</mo><mn>2</mn><mi>B</mi><mo stretchy="false">)</mo></mrow><mi>α</mi></mfrac></mrow></mtd></mtr></mtable></mrow></math>(10.15)
  prefs: []
  type: TYPE_NORMAL
- en: '[10.2.3.9 Hierarchical BF](contents.xhtml#rsec10_2_3_9)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In network terms, attribution is defined as a process of finding source and
    destination of some traffic. However, sometimes this process is difficult due
    to lack of logging mechanism for example, attacker may spoof address by using
    a zombie machine. Hierarchical BF facilitates the process of payload attribution
    where with a given payload, aim is to identify the sender or receiver of the given
    payload. This could be beneficial to detect certain security attacks, such as
    DDoS, spoofing. Shanmugasundarm et al. [[168](bib.xhtml#ch00-bib-168)] basically
    extended BF in order to support substring matching. As an advantage, this algorithm
    even does not require full packet for attribution, only a significant portion
    is enough. Along with this, the algorithm requires low storage requirements and
    also it ensures the privacy of data by simply storing hashes of payload rather
    than actual payloads.
  prefs: []
  type: TYPE_NORMAL
- en: Here, payload of each packet of length *p* is first divided into set of *q*
    multiple blocks of size *s*. Each block is appended with its offset value. Next,
    each block with its offset value is hashed and inserted into standard BF. This
    data structure is named as block based BF with offset as shown in [Fig. 10.21](13chap_10.xhtml#fig10_21).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.21](../images/fig10_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 10.21.**'
  prefs: []
  type: TYPE_NORMAL
- en: Hierarchical BF.
  prefs: []
  type: TYPE_NORMAL
- en: '[10.2.3.10 Stochastic Fair Blue](contents.xhtml#rsec10_2_3_10)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although authors do not define this data structure as a variant of BF but it
    has a lot in similar to working of BF. Stochastic Fair Blue (SFB) [[81](bib.xhtml#ch00-bib-81)]
    is a technique that uses counting BF along with blue algorithm. The authors proposed
    this scheme in order to solve TCP's congestion control problem. It detects heavy
    hitters to enhance the forwarding speed of multicast packets. SFB uses *N*k* bins,
    where *k* is the number of levels with each having *N* bins along with *k* hash
    functions. Also, each bin associates a dropping/marking probability <math alttext=""
    display="inline"><mrow><msub><mi>p</mi><mi>m</mi></msub></mrow></math>. For each
    incoming packet, apply *k* hash functions to its connection ID (source-destination
    address pair, source-destination port pair, and protocol) and increments corresponding
    bin locations. If account of packets hashed to a bin goes above the maximum size
    of bin, then increment <math alttext="" display="inline"><mrow><msub><mi>p</mi><mi>m</mi></msub></mrow></math>
    with a value <math alttext="" display="inline"><mrow><msub><mi>δ</mi><mn>1</mn></msub></mrow></math>
    for the bin; otherwise decrement by a value <math alttext="" display="inline"><mrow><msub><mi>δ</mi><mn>2</mn></msub></mrow></math>
    in case the link is idle. A packet is placed in heavy hitter list if the value
    of <math alttext="" display="inline"><mrow><msub><mi>p</mi><mi>m</mi></msub></mrow></math>
    reaches to 1\. In order to reduce FPR, authors have used the idea of conservative
    update. For a packet, extract <math alttext="" display="inline"><mrow><msub><mi>p</mi><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow></math>
    among corresponding *k* hash locations. Now, a packet is marked as heavy hitter
    if <math alttext="" display="inline"><mrow><msub><mi>p</mi><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow></math>
    and is then dropped. So, with BF heavy hitters can easily be detected with less
    space and less number of operation for each packet.
  prefs: []
  type: TYPE_NORMAL
- en: '[Fig. 10.22](13chap_10.xhtml#fig10_22) represents an example of stochastic
    fair blue. As shown, packet <math alttext="" display="inline"><mrow><msub><mi>p</mi><mi>x</mi></msub></mrow></math>
    higher up <math alttext="" display="inline"><mrow><msub><mi>p</mi><mi>m</mi></msub></mrow></math>
    of all bins it is mapped into. However, packet <math alttext="" display="inline"><mrow><msub><mi>p</mi><mi>y</mi></msub></mrow></math>
    may map in the same bin as heavy hitter flow in a level but in other levels, it
    maps into normal bin. As <math alttext="" display="inline"><mrow><msub><mi>p</mi><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow></math>
    for packet <math alttext="" display="inline"><mrow><msub><mi>p</mi><mi>y</mi></msub></mrow></math>
    is <math alttext="" display="inline"><mrow><mn>0.2</mn><mtext>\textless</mtext><mn>1</mn></mrow></math>,
    it is identified as normal flow whereas <math alttext="" display="inline"><mrow><msub><mi>p</mi><mi>x</mi></msub></mrow></math>
    is marked as heavy hitter.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.22](../images/fig10_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 10.22.**'
  prefs: []
  type: TYPE_NORMAL
- en: Stochastic fair blue example.
  prefs: []
  type: TYPE_NORMAL
- en: '[10.3 Quotient Filter](contents.xhtml#rsec10_3)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After BF, Quotient Filter (QF) [[40](bib.xhtml#ch00-bib-40)] is popular among
    programmers for checking approximate membership queries (AMQ), i.e., it also checks
    whether an element belongs to a set or not. QF is a cache friendly scheme based
    on quotienting technique [[120](bib.xhtml#ch00-bib-120)] that even provides scalability
    outside the main memory. Similar to BF, the membership query result answers ”probably
    in the set” or ”definitely not in the set” as QF also generates false positive
    errors. Increasing filter size can significantly reduce error probability of query
    whereas inserting more elements into the set can increase the false positive rates.
    However, no false negatives are generated for any query results. A typical use
    case of AMQ QF is in database tables stored on disk. Any access to the database
    stored on disk will first check QF for the particular key. If the filter returns
    positive results, the disk will be accessed otherwise not.
  prefs: []
  type: TYPE_NORMAL
- en: BF only provides beneficial when it is stored in the main memory. When BF size
    gets too large its performance significantly reduces. Another option is to store
    BF on disk but this approach requires too many random access to the disk because
    of the usage of multiple hash functions. Also, this approach will perform multiple
    input output operations. Moreover, in-memory buffering technique fails in providing
    scalability if BF size is much larger than in-memory buffer size. QF on the other
    hand, stores elements data really close to each other so as to avoid multiple
    random access. With this insight, QF uses a single hash function and provides
    ways to tackle high collision probability. However, the size consumed by QF is
    20% larger than BF.
  prefs: []
  type: TYPE_NORMAL
- en: 'The QF is quite fascinated by the concept of hash tables where instead of storing
    actual elements, hashes of the element along with some meta data bits are stored.
    The additional meta data bits are used to handle collisions. Insertion, lookup,
    deletion, merging, resizing are the operations supported by QF. To perform QF
    operations, first pass the element *x* through a single hash function that in
    return generates *p* bit fingerprint. The fingerprint is further partitioned into
    two parts: remainder part which has *r* least significant bits and quotient part
    which has *q* most significant bits. The employed hash tables have a total of
    <math alttext="" display="inline"><mrow><msup><mn>2</mn><mi>q</mi></msup></mrow></math>
    slots and the remainder part for any element is stored in location indexed by
    the quotient. Hard collision happens if different valued elements hash similar
    fingerprint whereas soft collision happens if two different value fingerprints
    have same quotient but different remainder.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose a element *k* generate fingerprint *kf*, and after partition lets its
    remainder be *KR* and its quotient be *KQ*. If *KR* is stored exactly at slot
    *KQ*, the slot is termed as canonical slot. For a soft collision, *KR* is stored
    at next available slot to the right of location *KQ* in sorted order. Insertion
    algorithm makes sure that all fingerprints with same quotient bits are stored
    contagiously and such a set forms a run. It may also be possible that runs first
    fingerprint may not get stored in its canonical slot as it may get shifted with
    already stored remainder of some different quotient. A run having its first fingerprint
    stored in canonical slot refers to the start of the cluster. A cluster may comprise
    more than one run which ends at an empty slot or start of some other cluster.
    Along with elements fingerprint, three additional bits are stored in the slot
    as shown in [Fig. 10.23](13chap_10.xhtml#fig10_23). These bits are explained as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*is_occupied*: If this bit is set, it implies that this slot is the canonical
    slot for some inserted element in the filter. It may be possible that the key
    is not stored in its canonical slot but stored somewhere else in the filter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*is_continuation*: If this bit is set, it implies that slot is occupied with
    some remainder but definitively not the first remainder of the run.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*is_shifted*: If this bit is set, it implies that slot is holding a remainder
    that is not in its canonical slot.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, with metadata bits, QF consumes 20% more space than BF (but less than
    counting BF) for the same data size. Also, throughput of lookup operation slows
    down 3 times. The only way false positive can happen is when there is a hard collision
    and its probability is given as: <math alttext="" display="inline"><mrow><mn>1</mn><mo>−</mo><msup><mi>e</mi><mrow><mfrac><mrow><mo>−</mo><mi>α</mi></mrow><mrow><msup><mn>2</mn><mi>r</mi></msup></mrow></mfrac></mrow></msup></mrow></math>,
    where *α* is load factor defined as the fraction of total elements and number
    of slots. When a new element is inserted, its slot is marked occupied and additional
    bits are updated accordingly. The significance of different combination of additional
    bits are specified in [Table 10.4](#tab10_4). Operations of QF are discussed as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.23](../images/fig10_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 10.23.**'
  prefs: []
  type: TYPE_NORMAL
- en: Structure of QF.
  prefs: []
  type: TYPE_NORMAL
- en: '**TABLE 10.4**'
  prefs: []
  type: TYPE_NORMAL
- en: Significance of possible combination of metadata bits.
  prefs: []
  type: TYPE_NORMAL
- en: '| 1 | 2 | 3 | Interpretation |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0 | 0 | This Slot is empty |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0 | 1 | This is start of run and remainder has been shifted from its
    canonical slot. |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1 | 0 | This combination is not used. |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1 | 1 | This remainder is not first remainder in a run and also it has
    been shifted from its canonical slot |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0 | 0 | This is first remainder in run that too in canonical slot. |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0 | 1 | This is holding first remainder in run that has been shifted
    from its canonical slot. In addition, the run meant for this slot exists that
    has been shifted right. |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 0 | This combination is not used |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 1 | This remainder is not first remainder in a run that has been
    shifted from its canonical slot. In addition, the run meant for this slot exists
    that has been shifted right. |'
  prefs: []
  type: TYPE_TB
- en: '1: is_occupied, 2: is_continuation, 3: is_shifted'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lookup**: To query any element *k* follow the following steps.'
  prefs: []
  type: TYPE_NORMAL
- en: Hash the key to generate its fingerprint *kH*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, partition *kH* into quotient *kQ* and remainder *kR*. Clearly, canonical
    slot for element *k* is *kQ*. If canonical slot has all metadata bits as false,
    it implies slot is not occupied. Hence, the element is definitively not present
    in the set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If *kQ* is occupied, then locate the run for *k*. As it is previously mentioned,
    remainder with same quotient are stored contagiously and it forms a run. The first
    in a run might not be present in canonical slot, if entire run has been shifted
    right by some another run in left. So, to locate quotient run, first locate start
    of the cluster and then find number of run to skip in a cluster to reach run for
    *kR*. For this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scan left for locating start of the cluster. If *is_shifted* for slots to the
    left of *kQ* is false, it implies start of the cluster.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Scan right to keep track of running count that counts number of runs to skip
    in order to reach quotient run. The slots to the left of *kQ* with *is_occupied*
    set implies another run to be skipped. For each value of *is_occupied* as 1, increment
    the running count and decrement one if *is_continuation* is clear (implies start
    of another run) until running count reaches zero. When the value of running count
    becomes zero it implies that quotient run has been reached.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, remainder corresponding to the run with *kR* is compared. If matches,
    the element *k* is probably present in the set otherwise definitely not in the
    filter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Insertion:**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Pass the element *k* to be inserted through the hash function to compute its
    fingerprint. First, ensure that the key is not already inserted in filter by using
    lookup procedure described above. If not inserted already, then follow the next
    step.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the elements are inserted in a run, it is always done in sorted order.
    The element remainder may have to shift right in any slot even when they belong
    to same run and update the metadata bits accordingly. However, this shifting does
    not change the value of *is_occupied* bit.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a remainder is inserted at the starting of already existing run, this causes
    any previous remainder to be shifted to next available slot in right and in response
    set its *is_continuation* bit. The *is_shifted* also has to be reset in case remainder
    is shifted.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For understanding QF, consider an example with quotient size 4 and remainder
    size 28\. Let the employed hash function generates a hash of 32 bit. First, element
    *144, 133, 4033* are added into QF as represented in [Fig. 10.24](13chap_10.xhtml#fig10_24)
    (a). Insertion for all 3 elements is done in canonical slot as these slots are
    not occupied.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.24](../images/fig10_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 10.24.**'
  prefs: []
  type: TYPE_NORMAL
- en: Insertion of elements in QF.
  prefs: []
  type: TYPE_NORMAL
- en: Next, element 9999 is added. The canonical slot for this element is already
    occupied. It is observed that *is_shift* and *is_continuation* bit is not set
    which implies it is beginning of cluster and also runs start. The remainder for
    element 999 is greater than that of element 144, so it should be stored to the
    right of element 144, i.e., slot 2 and set its *is_shifted* and *is_continuation*
    bit. The change in QF after insertion of element 9999 is reflected in [Fig. 10.24](13chap_10.xhtml#fig10_24)
    (b).
  prefs: []
  type: TYPE_NORMAL
- en: Next, element 14023 is to be added. Since slot 2 is already in use but its *is_occupied*
    bit is 0\. So, element 14023 has to be stored to next available slot to the right,
    i.e., slot 3 and set *is_shifted* bit for slot 3\. Also, set *is_occupied* bit
    for slot 2 as it is a canonical slot for element 14023\. The state of QF after
    insertion of element 14023 is represented in [Fig. 10.24](13chap_10.xhtml#fig10_24)
    (c).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, element 55 is added into QF which after passing through hash function
    generates 0*x*10000001\. Since the canonical slot 1 is not free. The *is_shifted*
    and *is_continuation* bit value for slot 1 is 0 which implies it is beginning
    of the cluster and also it is runs start. The remainder for element 55 is smaller
    than remainder of element 144\. So, the existing remainder in slot 1 should be
    shifted right to slot 2 and accordingly set the *is_continuation* and *is_shifted*
    bit. The state of the QF after insertion of element 55 is represented in [Fig.
    10.24](13chap_10.xhtml#fig10_24) (d).
  prefs: []
  type: TYPE_NORMAL
- en: Now, consider lookup query for element 4045\. Say *f(4045)* = 733433CD. As the
    canonical slot 7 is occupied. The value of *is_occupied*, *is_continuation* and
    *is_shifted* infers that it is start of the cluster as well as start of run. See
    [Fig. 10.24](13chap_10.xhtml#fig10_24) (d). The next slot to the right, i.e.,
    8 is empty which infers that slot 7 itself is a start and end of a run. Next,
    the remainder for element 4045 is compared with existing remainder in slot 7\.
    As the match for two values failed, so the element is definitely not present.
  prefs: []
  type: TYPE_NORMAL
- en: Next, consider the case for querying 133 whose fingerprint value is 48921258\.
    It can be observed that slot 4 is already occupied. Also, the value of its *is_shifted*
    bit is 1 which implies that the element corresponding to the current remainder
    has been stored in its canonical slot and is shifted. The value 1 for *is_canonical*
    slot represents that run for which this slot is a canonical slot exists but has
    been shifted to the right. For locating start of the cluster, scan left from slot
    4 and look for *is_shifted* as false, which is found to be slot 1\. So, slot 1
    indicates start of the cluster. Next, locate quotient run, for this scan to the
    left from slot 4 and check for *is_occupied*. If the value of *is_occupied* bit
    is 1 it implies another run to be skipped. There are 3 such slots, i.e., 1, 2
    and 4 which indicate that run for element 4033 is third run in the cluster. The
    start of current run and end of previous run is detected by *is_continuation*
    bit being false. The first run is at index 1, second at index 4, and third is
    at index 5\. Hence, index 5 is the quotient run for element 4033\. Now, compare
    the remainder stored in quotient run that starts at index 5 with the remainder
    of the element in question. However, there is only one slot in that run. So, compare
    the remainder of the element 4033 with existing remainder at slot 5\. As there
    is a match, so it is concluded that element 4033 is probably in the set.
  prefs: []
  type: TYPE_NORMAL
- en: '**Algorithm 1** Quotienting technique'
  prefs: []
  type: TYPE_NORMAL
- en: '**Input:** Fingerprint f'
  prefs: []
  type: TYPE_NORMAL
- en: '**Output:** Quotient f[q] and remainder f[r]'
  prefs: []
  type: TYPE_NORMAL
- en: '1: f[r]←f mod 2^r'
  prefs: []
  type: TYPE_NORMAL
- en: '2: **2:** return f[q], f[r]'
  prefs: []
  type: TYPE_NORMAL
- en: '**Algorithm 2** To find the run'
  prefs: []
  type: TYPE_NORMAL
- en: '**Input:** Canonical bucket index f[q]'
  prefs: []
  type: TYPE_NORMAL
- en: '1: i ← f[q]'
  prefs: []
  type: TYPE_NORMAL
- en: '2: **while** QF[i].is_shifted=1 **do**'
  prefs: []
  type: TYPE_NORMAL
- en: 3:i←i−1
  prefs: []
  type: TYPE_NORMAL
- en: '4: **end while**'
  prefs: []
  type: TYPE_NORMAL
- en: '5: run[start]← i'
  prefs: []
  type: TYPE_NORMAL
- en: '6: **while** i≠f[q] **do**'
  prefs: []
  type: TYPE_NORMAL
- en: 7:**repeat**
  prefs: []
  type: TYPE_NORMAL
- en: 8:run[start]← runstart+1
  prefs: []
  type: TYPE_NORMAL
- en: 9:**until** QF[run[start]].is_continuation ≠1
  prefs: []
  type: TYPE_NORMAL
- en: 10:**repeat**
  prefs: []
  type: TYPE_NORMAL
- en: 11:i←i+1
  prefs: []
  type: TYPE_NORMAL
- en: 12:**until** QF[i].is_occupied=1
  prefs: []
  type: TYPE_NORMAL
- en: '13: **end while**'
  prefs: []
  type: TYPE_NORMAL
- en: '14: run[end]←run[start]'
  prefs: []
  type: TYPE_NORMAL
- en: '15: **repeat**'
  prefs: []
  type: TYPE_NORMAL
- en: 16:run[end]← run[end]+1
  prefs: []
  type: TYPE_NORMAL
- en: '17: **until** QF[runend].is_continuation ≠1'
  prefs: []
  type: TYPE_NORMAL
- en: '18: **Return** run[start], run[end]'
  prefs: []
  type: TYPE_NORMAL
- en: '**Algorithm 3** To test element in QF'
  prefs: []
  type: TYPE_NORMAL
- en: '**Input**: Element *x*, hash function *h*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Output: True for positive and false for negative result**'
  prefs: []
  type: TYPE_NORMAL
- en: '1: f←h(x) f[q], f[r]←f'
  prefs: []
  type: TYPE_NORMAL
- en: '2: **if** QF[fq.is_occupied≠1 ] **then**'
  prefs: []
  type: TYPE_NORMAL
- en: 3:return False
  prefs: []
  type: TYPE_NORMAL
- en: '4: **else**'
  prefs: []
  type: TYPE_NORMAL
- en: 5:run[start], run[end]← **Find(f[q])**
  prefs: []
  type: TYPE_NORMAL
- en: 6:**for** i← run[start] to runend **do**
  prefs: []
  type: TYPE_NORMAL
- en: 7:**if** QF[i] =f[r] **then**
  prefs: []
  type: TYPE_NORMAL
- en: 8:return True
  prefs: []
  type: TYPE_NORMAL
- en: 9:**end if**
  prefs: []
  type: TYPE_NORMAL
- en: 10:**end for**
  prefs: []
  type: TYPE_NORMAL
- en: 11:Return False
  prefs: []
  type: TYPE_NORMAL
- en: '12: **end if**'
  prefs: []
  type: TYPE_NORMAL
- en: '[10.4 Skip List](contents.xhtml#rsec10_4)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Skip list follows a linked list alike structure. However, the worst case time
    complexity for a search operation in linked list in <math alttext="" display="inline"><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></math> as
    the list is linearly traversed while searching whereas for a skip list it is <math
    alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math>. For a set *S* of unique elements, skip
    list is defined as sequence of linked list *S0*, *S1*, *S2*, …….., *Sh*. The lower
    list (base list) has height 0 and this list is supposed to contain all elements
    of set *S* in non-decreasing order. Also, each list *Sl <math alttext="" display="inline"><mrow><mo
    stretchy="false">(</mo><mi>l</mi><mo>=</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>......</mn><mo>,</mo><mi>h</mi><mo
    stretchy="false">)</mo></mrow></math>* contains special items <math alttext=""
    display="inline"><mrow><mo>−</mo><mi>∞</mi></mrow></math> and <math alttext=""
    display="inline"><mrow><mo>+</mo><mi>∞</mi></mrow></math>. Each successive linked
    list in a series accommodate subset of elements from immediate previous list and
    the way subset of elements is chosen defines the type of linked list i.e., deterministic
    or probabilistic. Any element is inserted into new layer from immediate previous
    layer with a probability *p*. For probabilistic (or randomized) skip list, random
    coin flips are used to construct each higher level of elements whereas in deterministic
    (or perfect) skip list each higher level consists of <math alttext="" display="inline"><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></math>
    of elements from immediate lower list. In probabilistic skiplist, each element
    is added to the next level with probability of <math alttext="" display="inline"><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></math>.
    As this chapter is all about PDS, so for the sake of brevity the main focus is
    on probabilistic type skip list. Unlike other data structures, skip list does
    not use hashing still, it is considered as probabilistic data structure as it
    is based on concept of probability to construct subsequent layer above original
    layer of skip list. The name of data structure skip list is defended as higher
    level skips some elements from lower list. The operations of skip list are defined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Searching: To start searching an item *i*, start from top lists left most item,
    i.e., <math alttext="" display="inline"><mrow><mo>−</mo><mi>∞</mi></mrow></math>
    in every case. At any current position say *p*, compare item *i* to be searched
    with with the item to the immediate right of *p* and store that element in a new
    variable say *v*, i.e., <math alttext="" display="inline"><mrow><mi>v</mi><mo>←</mo><mo
    stretchy="false">(</mo><mi>E</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">(</mo><mi>p</mi><mo
    stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></math>
    and follow:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If <math alttext="" display="inline"><mrow><mi>i</mi><mo>=</mo><mi>v</mi></mrow></math>,
    return *v*.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Otherwise if ( <math alttext="" display="inline"><mrow><mi>i</mi><mtext>\textgreater</mtext><mi>v</mi></mrow></math>),
    then move a single step towards right and if <math alttext="" display="inline"><mrow><mi>i</mi><mtext>\textless</mtext><mi>v</mi></mrow></math>,
    move a single step down and compare it to its immediate rightmost item. Repeat
    the same process until there is no option to go down which concludes that item
    is not in list.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The search procedure for element 80 is represented in [Fig. 10.25](13chap_10.xhtml#fig10_25).
    For *n* elements, the search time complexity for skip list is <math alttext=""
    display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math> as at each level, number of items are cut
    down to half.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.25](../images/fig10_25.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '**FIGURE 10.25.**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Searching in skip list.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Insertion: To insert an item follow the following steps:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First follow the search algorithm to locate the position of the element at the
    bottom level.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, toss a biased coin more than one time till a tail is encountered. Observe
    the count of coin showing head before a tail is encountered. Store this number
    in a variable say *x*.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If the value of *x=0*, add the item only at the bottom level, i.e., <math alttext=""
    display="inline"><mrow><msub><mi>S</mi><mn>0</mn></msub></mrow></math>. Otherwise
    if <math alttext="" display="inline"><mrow><mi>x</mi><mo>≥</mo><mi>h</mi></mrow></math>,
    add additional new levels <math alttext="" display="inline"><mrow><msub><mi>S</mi><mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>S</mi><mrow><mi>h</mi><mo>+</mo><mn>2</mn></mrow></msub><mo>,</mo><mn>...</mn><mo>,</mo><msub><mi>S</mi><mrow><mi>x</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow></math>
    at the top of level *Sh* that only contains two special keys, ı.e., - <math alttext=""
    display="inline"><mi>∞</mi></math>, + <math alttext="" display="inline"><mi>∞</mi></math>
    and element *i*.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For *n* elements, the time complexity for inserting an element is <math alttext=""
    display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math>. Insertion of element 85 with value of *x
    =1* is presented in [Fig. 10.26](13chap_10.xhtml#fig10_26).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.26](../images/fig10_26.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '**FIGURE 10.26.**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Insertion in skip list.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Deletion: To delete an item *i*, follow the following steps'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First search for *i*, using search algorithm described above and locate the
    position *p0, p1,………, ph* for item *i*.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Remove the element from list at levels *S0, S1,………, Sh* corresponding to the
    positions *p0, p1,………, ph*.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The time complexity for deletion operation is <math alttext="" display="inline"><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo stretchy="false">)</mo></mrow></math>
    for *n* elements. The deletion for element 87 is represented in [Fig. 10.27](13chap_10.xhtml#fig10_27).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.27](../images/fig10_27.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '**FIGURE 10.27.**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Deletion in skip list.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The skip list provides beneficial in case where data structures need to be accessed
    concurrently. For example, skip list is used in designing highly scalable concurrent
    priority queue for heavy scale microprocessors [[171](bib.xhtml#ch00-bib-171)].
    Similarly, skip list is used to implement lock free dictionaries for a shared
    object in pre-emptive and concurrent environments in large scale multi-processors
    [[181](bib.xhtml#ch00-bib-181)]. Skip list implement a non-blocking (lock-free)
    algorithm for shared object which ensures that regardless of contention, atleast
    one operation will be active.
  prefs: []
  type: TYPE_NORMAL
- en: '[10.4.1 Skiplist implementation in Python](contents.xhtml#rsec10_4_1)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: First, we will define a skip list node where each node is inked by a list of
    pointers to immediate next node.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/list10_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Next, we will define a skip list
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/list10_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: To perform search, insert and delete operation it is important to define a update
    function that will start searching from top most level and passes the list of
    any level till an element larger than element in question is found. Then, next
    level is explored and the process is repeated as discussed above.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/list10_7.jpg)![](../images/list10_8.jpg)![](../images/list10_9.jpg)![](../images/list10_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Activity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Multiple Choice Questions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Which of the following does not fall in the category of membership query PDS?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: BF
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Min Hash
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: QF
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Skip list
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: In standard bloom filter, what is the search complexity for *k* hash functions,
    *m* filter size and *n* total elements to be inserted ?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>k</mi><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo>+</mo><mi>k</mi><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>m</mi><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following bloom filter does not support false negative?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Counting BF
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Spectral BF
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Deletable BF
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: None of the above
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following is an advantage of counting BF over standard BF?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Less space requirements
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Counting BF never support false positive
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Counting BF never support false negative
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Counting bloom filter support deletion
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following mentioned bloom filter does not support deletion?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Counting BF
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Deletable BF
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Scalable BF
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Dynamic BF
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the time complexity for deletion operation in a skip list having *n*
    elements?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><msup><mi>n</mi><mn>2</mn></msup></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo>+</mo><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which among the following is not a meta-data bit for QF?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>i</mi><mi>s</mi><mo>_</mo><mi>o</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>p</mi><mi>i</mi><mi>e</mi><mi>d</mi></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>i</mi><mi>s</mi><mo>_</mo><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>n</mi><mi>u</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>i</mi><mi>s</mi><mo>_</mo><mi>s</mi><mi>e</mi><mi>t</mi></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>i</mi><mi>s</mi><mo>_</mo><mi>s</mi><mi>h</mi><mi>i</mi><mi>f</mi><mi>t</mi><mi>e</mi><mi>d</mi></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'QF is preferred over BF because:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: QF consumes less space over BF
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: QF is cache friendly whereas a BF is not
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: BF provides scalability outside main memory whereas QF does not
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: None of the above
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 1\. b  2\. a  3\. c  4\. d  5\. c  6\. a  7\. c  8\. c
  prefs: []
  type: TYPE_NORMAL
- en: <hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '[11](contents.xhtml#rchapter11)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Cardinality Estimation Probabilistic Data Structures](contents.xhtml#rchapter11)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: </hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '[11.1 Introduction](contents.xhtml#rsec11_1)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next category of PDS is for cardinality estimation that is popularly used
    in query processing and data base design. Database models uses algorithms of cardinality
    estimation to compute selectivity of a predicate. Linear counting, LogLog, HyperLogLog
    are some of the algorithms that falls under this category. The aim of such a PDS
    is to count number of unique elements of a set where duplicates are present. For
    instance, for a set <math alttext="" display="inline"><mrow><mi>S</mi><mo>=</mo><mo
    stretchy="false">[</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>3</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>3</mn><mo>,</mo><mn>4</mn><mo
    stretchy="false">]</mo></mrow></math> the cardinality os the set is 4\. An important
    use case for such PDS is to compute number of unique visitors for a particular
    website. As per data given by, from May 2019 to Sep 2019, the total visit on Amazon
    web page is 2.22 B. If we believe that every 10th visitor was unique, the cardinality
    of such case is 222 million. Notable, with linear space requirements, cardinality
    estimation is difficult to achieve for any of deterministic data strictures. To
    compute cardinality estimation, a simple way is to first arrange sets element
    in ascending order. Next, apply linear scan on set S to eliminate duplicates.
    If we use merge sort, the cardinality of set S having *n* elements can be computed
    in <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math> disc access with <math alttext="" display="inline"><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math> extra
    space and hence this approach is inefficient. Another way to compute cardinality
    is by using a hash table data structure where hashes of elements are stored in
    hash table and cardinality is computed by total number of keys in hash table.
    Obviously, hashing has advantage of removing duplicates without sorting and hence
    require a single scan. However, for huge data set, hashing proves bad as it is
    difficult to fit the large has table in main memory. The time complexity for this
    approach is <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math> with <math alttext="" display="inline"><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></math> extra
    space. Hence, with the traditional deterministic approaches, the query processing
    on increasing volume of data can only be processed in linear memory space.
  prefs: []
  type: TYPE_NORMAL
- en: PDS using probabilistic techniques estimates cardinality with low space requirements
    and linear time. Cardinality estimation PDS are also based on hashing. However,
    different from simple hashing, these data structure doesn't store values of elements
    in the hash table. Cardinality estimation using PDS can be done regardless of
    type of data and it can also be distributed over parallel machines with less communication
    overhead.
  prefs: []
  type: TYPE_NORMAL
- en: '[11.2 Linear Counting](contents.xhtml#rsec11_2)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As a first attempt to compute cardinality with probabilistic approach, authors
    in [[213](bib.xhtml#ch00-bib-213)] introduced linear counting algorithm. Instead
    of storing actual element, linear counting simply set a bit corresponding to the
    element in the hash table. As it may be possible that, two records might collide
    to same location, so computed count might not be exact. Hence, cardinality is
    approximated that is computed from occupancy ratio of hash table. For a set having
    120 million elements, computing cardinality with linear counting approach requires
    1.25 MB of main memory, 1000 disk access, and 1% error rate. Linear counting offers
    a two step process for computing cardinality which are described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Linear counting employs a hash table of size *m* in main memory along with a
    hash function. Every entry of hash table is initialized to 0\. To each incoming
    item, a hash function is applied and the corresponding index in hash table is
    set to 1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, count of blank entries (,i.e., 0) is noted. Lets call this number *x*.
    Then analyze the fraction of empty bits ( <math alttext="" display="inline"><mrow><mo
    stretchy="false">(</mo><msub><mi>V</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow></math>)
    by taking fraction of *x* and *m*. Final estimated cardinality is computed by
    putting value in the following equation:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mover accent="true"><mi>n</mi><mo>^</mo></mover><mo>≈</mo><mo>−</mo><mi>m</mi><mi>l</mi><mi>n</mi><msub><mi>V</mi><mi>N</mi></msub></mrow></mtd></mtr></mtable></mrow></math>(11.1)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: where, *n* is computed estimated cardinality.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The time complexity of linear counting algorithm is *O(n)* where, *n* is the
    total count of elements in set *S*. The accuracy in results of linear counting
    algorithm is dependent on load factor. Here, load factor is defined as fraction
    of unique elements and hash table size. A higher value of load factor decreases
    the accuracy of results and lower the value of load factor, higher is the result
    accuracy. Hence, if the hash table size is very small compared to total number
    of elements, it can lead to high risk of collisions. Otherwise if hash table size
    is large enough the risk of collision reduces but it will consume more space,
    Authors have concluded that for a load factor greater than 1, linear counting
    produces 1% of error. The expected relative error for estimated cardinality <math
    alttext="" display="inline"><mover accent="true"><mi>n</mi><mo>^</mo></mover></math>
    for a given multiset with *N* unique elements is given by Eq. 11.3\. The variable
    *t* represents load factor ( <math alttext="" display="inline"><mrow><mfrac><mi>N</mi><mi>m</mi></mfrac></mrow></math>).
    The relative error signifies, on an average what percentage of estimated cardinality
    <math alttext="" display="inline"><mover accent="true"><mi>n</mi><mo>^</mo></mover></math>
    is miscalculated and is given by.
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mfrac><mrow><mo stretchy="false">(</mo><msup><mi>e</mi><mi>t</mi></msup><mo>−</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo
    stretchy="false">)</mo></mrow><mrow><mn>2</mn><mi>N</mi></mrow></mfrac></mrow></mtd></mtr></mtable></mrow></math>(11.2)
  prefs: []
  type: TYPE_NORMAL
- en: The hash table size is also influenced by standard error. The standard error
    is described as standard deviation of <math alttext="" display="inline"><mrow><mfrac><mrow><mover
    accent="true"><mo stretchy="false">(</mo><mo>^</mo></mover><mi>n</mi><mo stretchy="false">)</mo></mrow><mi>N</mi></mfrac></mrow></math>
    and is calculated by following equation.
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><msqrt><mi>m</mi></msqrt><mfrac><mrow><msup><mrow><mo
    stretchy="false">(</mo><msup><mi>e</mi><mi>t</mi></msup><mo>−</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo
    stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup></mrow><mi>N</mi></mfrac></mrow></mtd></mtr></mtable></mrow></math>(11.3)
  prefs: []
  type: TYPE_NORMAL
- en: Although in order to use this method, count of unique items should be known
    in prior so as to allocate a hash table of appropriate size. Clearly, linear counting
    approach is faster than traditional approach but it fails to produce accurate
    results. Hence use case for this data structure is for applications where 100%
    accuracy is not required. Nevertheless authors in [[38](bib.xhtml#ch00-bib-38)]
    suggested not to use linear counting algorithm for database relations whose cardinality
    is greater than 20 million because of extremely large table size. that provides
    more accurate results with less storage requirements. As a better solution, LogLog
    and HyperLogLog algorithms are also available.
  prefs: []
  type: TYPE_NORMAL
- en: Lets understand linear counting with an example. Suppose <math alttext="" display="inline"><mrow><mi>m</mi><mo>=</mo><mn>16</mn></mrow></math>
    and hash function is based on modular hashing, i.e., <math alttext="" display="inline"><mrow><mi>h</mi><mo
    stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mi>k</mi><mo>+</mo><mn>2</mn><mo
    stretchy="false">)</mo><mi>m</mi><mi>o</mi><mi>d</mi><mn>16</mn></mrow></math>
    where *k* is the key to be inserted. Let set *S* contains total of 10 elements,
    i.e., <math alttext="" display="inline"><mrow><mi>S</mi><mo>=</mo><mn>4</mn><mo>,</mo><mn>34</mn><mo>,</mo><mn>6</mn><mo>,</mo><mn>4</mn><mo>,</mo><mn>14</mn><mo>,</mo><mn>36</mn><mo>,</mo><mn>6</mn><mo>,</mo><mn>7</mn><mo>,</mo><mn>0</mn><mo>,</mo><mn>7</mn></mrow></math>.
    Notably, cardinality of this set is 7\. Pass these elements through hash function
    and set the corresponding bit to 1\. The resulting state of hash table after passing
    these elements is represented ?? as <math alttext="" display="inline"><mrow><mi>h</mi><mo
    stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo><mo>=</mo><mn>6</mn><mo>,</mo><mi>h</mi><mo
    stretchy="false">(</mo><mn>34</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn><mo>,</mo><mi>h</mi><mo
    stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo><mo>=</mo><mn>8</mn><mo>,</mo><mi>h</mi><mo
    stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo><mo>=</mo><mn>6</mn><mo>,</mo><mi>h</mi><mo
    stretchy="false">(</mo><mn>14</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn><mo>,</mo><mi>h</mi><mo
    stretchy="false">(</mo><mn>36</mn><mo stretchy="false">)</mo><mo>=</mo><mn>2</mn><mo>,</mo><mi>h</mi><mo
    stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo><mo>=</mo><mn>8</mn><mo>,</mo><mi>h</mi><mo
    stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo><mo>=</mo><mn>9</mn><mo>,</mo><mi>h</mi><mo
    stretchy="false">(</mo><mn>0</mn><mo stretchy="false">)</mo><mo>=</mo><mn>2</mn><mi>a</mi><mi>n</mi><mi>d</mi><mi>h</mi><mo
    stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo><mo>=</mo><mn>9</mn></mrow></math>.
    In this case value of *x* is 11, load factor is <math alttext="" display="inline"><mrow><mfrac><mn>7</mn><mrow><mn>16</mn></mrow></mfrac></mrow></math>
    and consequently value of ( <math alttext="" display="inline"><mrow><mo stretchy="false">(</mo><msub><mi>V</mi><mi>n</mi></msub><mo
    stretchy="false">)</mo></mrow></math>) <math alttext="" display="inline"><mrow><mfrac><mrow><mn>11</mn></mrow><mrow><mn>16</mn></mrow></mfrac></mrow></math>
    which is equal to 0.6875\. To get final estimated cardinality, put the value of
    ( <math alttext="" display="inline"><mrow><mo stretchy="false">(</mo><msub><mi>V</mi><mi>n</mi></msub><mo
    stretchy="false">)</mo></mrow></math>) in Eq. 11.1 which results in <math alttext=""
    display="inline"><mrow><mover accent="true"><mi>n</mi><mo>^</mo></mover><mo>≈</mo><mo>−</mo><mn>16</mn><mo>*</mo><mi>l</mi><mi>n</mi><mo
    stretchy="false">(</mo><mn>0.6875</mn><mo stretchy="false">)</mo></mrow></math>
    which on solving gives 5.99 ≈ 6\. Due to collisions, estimated count is 6 whereas
    actual cardinality is 7\. This whole example is represented in [Fig. 11.1](#fig11_1)
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1](../images/fig11_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 11.1.**'
  prefs: []
  type: TYPE_NORMAL
- en: Example of linear counting algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/list11_1a.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[11.2.1 Implemtation code of linear counting](contents.xhtml#rsec11_2_1)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Python implemented code for linear counting is described as follows. Here,
    first a dataset is defined that takes 300 numbers between 0 and 20\. Next, we
    check number of unique values in dataset using len() function. The depicts that
    with increase in mapsize, load factor decreases and cardinality estimation generates
    more accurate results.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/list11_1b.jpg)![](../images/list11_1c.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[11.3 LogLog](contents.xhtml#rsec11_3)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Linear counting still consumes O(n) space which is linear space consumption.
    In this context, LogLog was introduced in [[74](bib.xhtml#ch00-bib-74)] which
    provides solution to cardinality estimation for large datasets. This algorithm
    uses memory in order of <math alttext="" display="inline"><mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo
    stretchy="false">(</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo
    stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></math>
    where, *N* is upper bound on number of unique items. In order to count, <math
    alttext="" display="inline"><mrow><msup><mn>2</mn><mrow><mn>32</mn></mrow></msup></mrow></math>
    (4 billion) distinct items, this algorithms only requires <math alttext="" display="inline"><mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo
    stretchy="false">(</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo
    stretchy="false">(</mo><msup><mn>2</mn><mrow><mn>32</mn></mrow></msup><mo stretchy="false">)</mo><mo
    stretchy="false">)</mo><mo>=</mo><mn>5</mn></mrow></math> bits of space. To understand
    the concept of LogLog, take an analogy: Suppose two friends Tom and Jerry went
    to a conference and there they decided to bet on who interacted with most strangers.
    So, they started keeping a counter of people they are interacting with. However
    counting as such can be a tedious task. So for next conference instead of just
    counting, they started writing their names on paper. This way it is better to
    count unique people rather than getting confused with total number of conversations.
    However, roaming around with a pen and a paper is not really easy. So, Tom came
    up with an alternative, rather than noting down names of persons, hey decided
    to ask last 6 digits of their contact number and the one with longest sequence
    of leading zeros in last 6 digits of contact number will be declared as winner.
    For example, a contact number of a person is 988866336, so longest sequence here
    is 0 as there are no leading zeros and if contact number is 00639, so longest
    sequence becomes 2\. Clearly if either Tom or Jerry interacts to a few people,
    probability of getting longest leading zeros is either 0 or 1\. As the number
    of people they interacted becomes large, chances of getting a leading zero sequence
    increases to being 3 or 4\. To get a value 6 for longest zero sequence, either
    of them had interacted with thousand of people to get someone with 00000 as their
    last 6 digits of contact number.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Same concept is applied to LogLog algorithm. Here unique elements are counted
    in large set by hashing each element and then recording longest sequence of zeros
    for each element. LogLog employs a hash table having *m* entries or buckets along
    with a single hash function. Notably, with increase in value of *m*, average error
    rate decreases. As output of hash function is of fixed length, insertion of elements
    has time complexity of O(1). A step by step explanation of estimating cardinality
    with LogLog is described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: For each incoming item, compute a fixed length hash of each item.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Divide the hash obtained from previous step into two parts. First *k* bits signifies
    the index to a bucket and from the remaining sequence longest zero sequence is
    noted and the value of longest zero sequence is stored in that particular bucket.
    For instance, for a hash table of 16 buckets, a fixed length (10 bit) hash obtained
    is 1010 001001 and there are total of 16 buckets. So, first 4 bits tells about
    index of the bucket and from remaining bis longest zero sequence is noted, i.e.,
    2 is stored at location 10th.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each hash obtained, only the largest value of longest string of leading
    zero so far is stored in each bucket.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lets say R1, R2,………, Rm denotes entries in the hash table. The final cardinality
    of the set can be computed by taking arithmetic mean of entries in hash table.
    To reduce the effect of outliers and to minimize variance, rather than taking
    average, mean is calculated. Hence, LogLog improves accuracy by storing multiple
    estimates and then averaging the results. So, final cardinality of the set can
    be computed as:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>E</mi><mi>s</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>d</mi><mi>c</mi><mi>a</mi><mi>r</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>l</mi><mi>i</mi><mi>t</mi><mi>y</mi><mo>=</mo><mn>0.79402</mn><mo>*</mo><mi>m</mi><mo>*</mo><msup><mn>2</mn><mrow><mfrac><mrow><mstyle
    displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mrow><msub><mi>R</mi><mi>j</mi></msub></mrow></mstyle></mrow><mi>m</mi></mfrac></mrow></msup></mrow></mtd></mtr></mtable></mrow></math>(11.4)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Taking *m* buckets basically simulates as different *m* hash functions are taken.
    The standard error of LogLog algorithm is given out to be <math alttext="" display="inline"><mrow><mfrac><mrow><mn>1.30</mn></mrow><mrow><mi>s</mi><mi>q</mi><mi>r</mi><mi>t</mi><mo
    stretchy="false">(</mo><mi>M</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow></math>
    where, *m* signifies total bucket entries. Hence for a bucket with 2048 entries
    and each entry having S bits, an error of 2.5% is expected. The hash table can
    estimate cardinality till 227\. The clear insight of LogLog is that it is less
    likely for a number to start with a long string of zeros (probability of a number
    having 10 leading zeros is less however not rare). Although LogLog algorithm is
    not suitable for small cardinality and it can only work with sets having large
    cardinality. Also, it is required to decode a prior upper bound on the total items
    to be inserted so that hash table can be chosen. Lets take example of LogLog where
    <math alttext="" display="inline"><mrow><mi>m</mi><mo>=</mo><mn>16</mn></mrow></math>,
    index for any bucket takes 4 bits. This example counts unique visitors for a website.
    Refer to [Fig. 11.2](#fig11_2) After inserting 4 elements estimated cardinality
    is <math alttext="" display="inline"><mrow><mn>0.79402</mn><mo>*</mo><mn>16</mn><mo>*</mo><msup><mn>2</mn><mrow><mfrac><mn>6</mn><mrow><mn>16</mn></mrow></mfrac></mrow></msup><mo>≈</mo><mn>16.47</mn></mrow></math>.
    Clearly due to insertion of few elements, results of this algorithm are calculated
    wrong. However, for large cardinality algorithm will generate more accurate results.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2](../images/fig11_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 11.2.**'
  prefs: []
  type: TYPE_NORMAL
- en: LogLog example.
  prefs: []
  type: TYPE_NORMAL
- en: '[11.3.1 Implementation of LogLog in Python](contents.xhtml#rsec11_3_1)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![](../images/list11_2a.jpg)![](../images/list11_2b.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[11.4 HyperLogLog](contents.xhtml#rsec11_4)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: HyperLogLog (HLL) is most popular probabilistic algorithm that computes distinct
    items in a multiset. Rather than exact, HLL computes approximates in low storage
    requirements. HLL [[82](bib.xhtml#ch00-bib-82)] is an improved version of LogLog
    in two ways.
  prefs: []
  type: TYPE_NORMAL
- en: 'The insertion of any element in HLL has almost same procedure as discussed
    for LogLog. Different from LogLog, while combining buckets in step 4th, rather
    than using arithmetic mean, harmonic mean of the values in the bucket are taken.
    The sequential implementation of HLL is represented in [Fig. 11.3](#fig11_3) This
    is to decrement the effect of uncommon high max-leading zero count in the same
    bucket. Harmonic mean helps to ignore values that approaches towards infinity.
    Hence, it reduces the impact of exponentiating a noisy number and improves accuracy
    of cardinality estimation. HLL further reduces the effect of outliers to improve
    the accuracy of estimation by removing out the largest value before averaging.
    The estimated cardinality from HLL is given by:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>E</mi><mo>=</mo><msub><mi>α</mi><mi>m</mi></msub><mo>.</mo><mi>m</mi><mfrac><mi>m</mi><mrow><mfenced
    close=")" open="("><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mrow><msup><mn>2</mn><mrow><mo>−</mo><msup><mi>R</mi><mi>j</mi></msup></mrow></msup></mrow></mstyle></mrow></mfenced></mrow></mfrac></mrow></mtd></mtr></mtable></mrow></math>(11.5)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.3](../images/fig11_3.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '**FIGURE 11.3.**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Sequential implementation of HLL.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: where, *α* is a constant whose value is chosen as per the number of buckets.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: HLL makes correction for extreme cases, i.e., when all buckets are not occupied
    and when buckets are almost full and hash collisions causes underestimates. If
    the calculated estimation *E* is less than <math alttext="" display="inline"><mrow><mn>2.5</mn><mo>*</mo><mi>m</mi></mrow></math>
    and there are some buckets that has zero value for maximum leading zero, then
    the final cardinality in this case is replaced with
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><msub><mi>E</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub><mo>=</mo><mo>−</mo><mi>m</mi><mo>*</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo
    stretchy="false">(</mo><mfrac><mi>V</mi><mi>m</mi></mfrac><mo stretchy="false">)</mo></mrow></mtd></mtr></mtable></mrow></math>(11.6)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'where, *V* is the count of bucket with zero value for maximum leading zero.
    Whereas for big cardinalities that approaches the total size of hash table, i.e.,
    for <math alttext="" display="inline"><mrow><mi>E</mi><mo>></mo><mfrac><mrow><msup><mn>2</mn><mi>m</mi></msup></mrow><mrow><mn>30</mn></mrow></mfrac></mrow></math>,
    the final cardinality is computed as:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><msub><mi>E</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub><mo>=</mo><mo>−</mo><msup><mn>2</mn><mi>m</mi></msup><mi>l</mi><mi>o</mi><mi>g</mi><mo
    stretchy="false">(</mo><mn>1</mn><mo>−</mo><mfrac><mi>E</mi><mrow><msup><mn>2</mn><mi>m</mi></msup></mrow></mfrac><mo
    stretchy="false">)</mo></mrow></mtd></mtr></mtable></mrow></math>(11.7)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Along with this, HLL supports merge operation that simply applies union of two
    HLL's and this function returns the maximum value from each pair of buckets, i.e.,
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>H</mi><mi>L</mi><msub><mi>L</mi><mrow><mi>u</mi><mi>n</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub><mo
    stretchy="false">[</mo><mi>j</mi><mo stretchy="false">]</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo
    stretchy="false">(</mo><mi>H</mi><mi>L</mi><msub><mi>L</mi><mn>1</mn></msub><mo
    stretchy="false">[</mo><mi>j</mi><mo stretchy="false">]</mo><mo>,</mo><mi>H</mi><mi>L</mi><msub><mi>L</mi><mn>2</mn></msub><mo
    stretchy="false">[</mo><mi>j</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo></mrow></mtd></mtr></mtable></mrow></math>(11.8)
  prefs: []
  type: TYPE_NORMAL
- en: where, *j* varies from 1 to *m*. One of thee reason that HLL is more popular
    over LogLog because for the same count of items, HLL results in better accuracy
    when compared to LogLog. The Standard error rate of HLL is described as <math
    alttext="" display="inline"><mrow><mfrac><mrow><mn>1.04</mn></mrow><mrow><mi>s</mi><mi>q</mi><mi>r</mi><mi>t</mi><mo
    stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow></math>,
    where *m* is the number of buckets used. For instance, redis software use 16348
    registers by default, so in order to implement HLL, it returns the standard error
    of 0.81%. Original HLL still returns large error for small cardinality but with
    little improvements, it can manage very small range cardinality to large range
    cardinality.
  prefs: []
  type: TYPE_NORMAL
- en: Take an example that counts the number of unique users who visited a website
    so far. Suppose there are 16 buckets which imply that addressing a bucket requires
    4 bits. As shown in [Fig. 11.4](#fig11_4), for every IP address, first pass it
    through a HLL hash function that returns 16 bit fixed number. First four bits
    determine bucket number and from remaining bits count of leading zeros are extracted
    but only record of maximum number of leading zeros is kept and rest others are
    ignored. Similarly, for other IP addresses, the same process is repeated. To get
    the final cardinality, the harmonic mean of count column is taken. After inserting
    4 different IP addresses the estimated cardinality can be computed as <math alttext=""
    display="inline"><mrow><mfrac><mrow><mn>0.673</mn><mo>*</mo><mn>16</mn><mo>*</mo><mn>16</mn></mrow><mrow><msup><mn>2</mn><mrow><mo>−</mo><mn>2</mn></mrow></msup><mo>+</mo><msup><mn>2</mn><mrow><mo>−</mo><mn>4</mn></mrow></msup></mrow></mfrac><mo>≈</mo><mn>551</mn></mrow></math>
    which is obviously not equal to 4 because for small cardinalities the HLL results
    shows strong bias. However, for large carnalities this algorithm works fine.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.4](../images/fig11_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 11.4.**'
  prefs: []
  type: TYPE_NORMAL
- en: HLL example.
  prefs: []
  type: TYPE_NORMAL
- en: '[11.4.1 Implementation of HLL in Python](contents.xhtml#rsec11_4_1)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![](../images/list11_3a.jpg)![](../images/list11_3b.jpg)![](../images/list11_4.jpg)![](../images/list11_5a.jpg)![](../images/list11_5b.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Activity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Multiple Choice Questions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: What is the time complexity for linear counting algorithm for *n* number of
    total elements
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the time complexity for insertion operation of LogLog algorithm with
    a hash table of size *m*?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>m</mi><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>m</mi><mn>2</mn></msup><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: None of the above
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For a hash table of size 32\. How many bits are reserved for index field and
    longest zero sequence field ?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 6,25
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 5,27
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 16,16
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 10,22
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: HLL stands for?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: HydroLogLog
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: HyperLogLog
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Hyperloglinear
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Hyperlinearlinear
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the space requirement for LogLog data structure with *N* as upper bound
    on number of unique elements?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo
    stretchy="false">(</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo
    stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>l</mi><mi>o</mi><msup><mi>g</mi><mn>2</mn></msup><mo
    stretchy="false">(</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo
    stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo
    stretchy="false">(</mo><mi>l</mi><mi>o</mi><msup><mi>g</mi><mn>2</mn></msup><mo
    stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>l</mi><mi>o</mi><msup><mi>g</mi><mn>2</mn></msup><mo
    stretchy="false">(</mo><mi>l</mi><mi>o</mi><msup><mi>g</mi><mn>2</mn></msup><mo
    stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To count, <math alttext="" display="inline"><mrow><msup><mn>2</mn><mrow><mn>32</mn></mrow></msup></mrow></math>
    (4 billion) distinct items, LogLog algorithms only requires?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 5 bits
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 10 bits
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 32 bits
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: None of these
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 1\. a  2\. b  3\. c  4\. b  5\. a  6\. a
  prefs: []
  type: TYPE_NORMAL
- en: <hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '[12](contents.xhtml#rchapter12)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Frequency Count Query Probabilistic Data Structures](contents.xhtml#rchapter12)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: </hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '[12.1 Introduction](contents.xhtml#rsec12_1)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This category concerns for estimating the count of a particular items in a set.
    For example, search engine uses frequency estimators for extracting frequently
    searched queries and network routers uses them for locating common source and
    destination addresses. One proposed solution to this randomly extract a sample
    from the set that shows properties of complete set. However, achieving true randomness
    is a quite unfavorable task. So, sampling also is not a useful solution to our
    problem. Also with hash tables, memory requirement becomes high (linear space
    requirements) as more items are added. Majority algorithm [[52](bib.xhtml#ch00-bib-52)]
    and Misra-Gries [[144](bib.xhtml#ch00-bib-144)] algorithms are two popular deterministic
    algorithms to solve frequency count problem. One of the effective way is to adopt
    approximation based queries for streaming data. In this context, an trending data
    structure is “Sketch” which based on summary based approach performs approximation
    queries. Sketch algorithms based on approximation and randomization are space
    and time efficient solutions in this context. Sketches refer to a category of
    algorithm that portrays a large set of data by a compact summary that is much
    smaller than actual data size [[89](bib.xhtml#ch00-bib-89)]. Machine learning,
    NLP, security are some important area where variants of sketches are being used
    [[203](bib.xhtml#ch00-bib-203)]. Sketches also solves problems faced by sampling
    technique and supports parallelization in practice. Parallelization in sketches
    implies that it can be implemented independently on different parts of data and
    further combines these parts that results in consistent aggregate. In short, parallelization
    imposes a straightforward divide and conquer approach for problems that faces
    scalability challenge. Moreover, sketches possess sub-linear asymptotic computational
    complexity which results in low computational power and storage. The algorithm
    under this category is characterized by two parameters, i.e., *ϵ* and *δ* where
    *ϵ* (accuracy parameter)describes the maximum affordable error in frequency estimation
    results with a maximum probability of *δ* (confidence parameter). These two parameters
    can be tuned as per available space. Also, for sketches error could be over-estimation,
    underestimation or a combination of both while estimating frequency.
  prefs: []
  type: TYPE_NORMAL
- en: '[12.2 Count-Min Sketch](contents.xhtml#rsec12_2)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Count-Min Sketch (CMS) [[66](bib.xhtml#ch00-bib-66)] is most popularly available
    sketch data structure for executing frequency count queries. Specifically, this
    data structure serves efficient query processing on streaming data. CMS uses a
    compressed represent of data in order to guarantee low storage requirements. Similar
    to hash table, CMS employs a table with *w* width and depth *d*. While designing
    the sketch, the parameters *w* and *d* are fixed. The table is all initialized
    to zero. Different from hash table, rather than using a single hash function,
    for each row of table a different hash function is used, i.e., a total of *d*
    pairwise independent hash functions are used as shown in [Fig. 12.1](#fig12_1).
    Pairwise independence constructs a universal hash family that results in minimum
    collision [[113](bib.xhtml#ch00-bib-113)]. Hash functions from universal families
    are those classes having less collision probability. The hash functions should
    be chosen such that they spread out the incoming items so as to attain high accuracy.
    Each of hash function takes the incoming element and maps it to corresponding
    column within range of 1,2,3,…..,*w*. CMS consumes only sub-linear space with
    an disadvantage of over-counting because of hash collisions. Linear space complexity
    implies that with increase in data size, memory consumption also increases with
    a direct relationship between the two. Sub-linear on the other hand does not consumes
    equal memory to the data. It however consumes less than or half of the memory
    as compared to data as shown in [Fig. 12.2](#fig12_2). The operations supported
    by CMS are described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.1](../images/fig12_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 12.1.**'
  prefs: []
  type: TYPE_NORMAL
- en: Structure of CMS.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.2](../images/fig12_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 12.2.**'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding sub-linear space requirements.
  prefs: []
  type: TYPE_NORMAL
- en: 'Update(i, c): This function updates frequency of any incoming element *i* by
    a count *c*. To each incoming element, all *d* hash functions are applied and
    corresponding location between <math alttext="" display="inline"><mrow><mn>1</mn><mo>−</mo><mi>w</mi></mrow></math>
    to each hash function is updated by adding a value *c* to the existing value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Estimate(i): This function computes the frequency of an element *i* in a set.
    First locate the locations corresponding to *d* hash functions. Finally the frequency
    count for element *i* is the minimum value out of the *d* obtained locations.
    As hash functions are used, there are chances that different element may collide
    on same cell. Thus by selecting minimum value, closest accurate results are fetched
    for frequency queries. Clearly, the results from a CMS may overestimate but never
    underestimate. Notably, CMS performs counting first and then computes minimum,
    thus named count-min sketch.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Delete(i, c): To delete element *i* from the set, simply decrement the d corresponding
    locations in each row by a count *c*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Notably, the frequency estimation of CMS is somewhat similar to counting BF.
    Like other PDS, CMS use-cases are beneficial for application that does not care
    about exact frequency count of the element. Database query planning, finding heavy
    hitters in traffic monitoring, NLP, compressed sensing, joint-size estimations
    are some of the promising use-cases of frequency query estimation PDS. CMS also
    supports parallelization as here sub sketches can be merged by taking sum of tables.
    However, two sketches can only be merged if they are constructed using same value
    of *w* and *d* along with same hash functions. Moreover, CMS enables approximate
    addition of any summable value that supports a monoid. One of the disadvantage
    of CMS is that it shows behavior biased estimation of true frequency count of
    a number. Count-min-log sketch, count-min-mean sketch are some of the most recent
    improvements over CMS. Clearly, for any item *i*, actual frequency ( <math alttext=""
    display="inline"><mrow><msub><mi>f</mi><mi>i</mi></msub></mrow></math>) is always
    less than or equal to estimated frequency ( <math alttext="" display="inline"><mrow><msub><mover
    accent="true"><mi>f</mi><mo>^</mo></mover><mi>i</mi></msub></mrow></math>). For
    a sketch of size *w*d*, setting <math alttext="" display="inline"><mrow><mi>w</mi><mo>=</mo><mfrac><mn>2</mn><mi>ϵ</mi></mfrac></mrow></math>
    and <math alttext="" display="inline"><mrow><mi>d</mi><mo>=</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo
    stretchy="true">(</mo><mfrac><mn>1</mn><mi>δ</mi></mfrac><mo stretchy="true">)</mo></mrow></math>
    ensures that estimate operation can exceed actual frequency by atmost <math alttext=""
    display="inline"><mrow><mi>ϵ</mi><mi>N</mi></mrow></math> ( <math alttext="" display="inline"><mrow><msub><mover
    accent="true"><mi>f</mi><mo>^</mo></mover><mi>i</mi></msub><mo>≤</mo><msub><mi>f</mi><mi>i</mi></msub><mo>+</mo><mi>ϵ</mi><mi>N</mi></mrow></math>)
    with atleast probability <math alttext="" display="inline"><mrow><mn>1</mn><mo>−</mo><mi>δ</mi></mrow></math>.
    Effect of changing values of *w* and *d* is represented in [Table 12.1](#tab12_1).
    Hence cardinality estimation for size *N* has atmost of <math alttext="" display="inline"><mrow><mfrac><mrow><mn>2</mn><mi>N</mi></mrow><mi>w</mi></mfrac></mrow></math>
    error with atleast probability of <math alttext="" display="inline"><mrow><mn>1</mn><mo>−</mo><msup><mrow><mo
    stretchy="true">(</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="true">)</mo></mrow><mi>d</mi></msup></mrow></math>.
    Space consumed by CMS is O( <math alttext="" display="inline"><mrow><mfrac><mn>1</mn><mi>ϵ</mi></mfrac><mi>l</mi><mi>o</mi><mi>g</mi><mfrac><mn>1</mn><mi>δ</mi></mfrac></mrow></math>)
    and time taken by update and estimate is given by: <math alttext="" display="inline"><mrow><mi>O</mi><mo
    stretchy="true">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mfrac><mn>1</mn><mi>δ</mi></mfrac><mo
    stretchy="true">)</mo><mo>=</mo><mi>O</mi><mo stretchy="true">(</mo><mi>d</mi><mo
    stretchy="true">)</mo></mrow></math>. CMS also supports deletion by decrementing
    the corresponding hash location.'
  prefs: []
  type: TYPE_NORMAL
- en: '**TABLE 12.1**'
  prefs: []
  type: TYPE_NORMAL
- en: Effects of change in parameters for CMS.
  prefs: []
  type: TYPE_NORMAL
- en: '| Parameter | Increase | Decrease |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| w |'
  prefs: []
  type: TYPE_TB
- en: High Accuracy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More memory requirement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| • Relatively more error rate |'
  prefs: []
  type: TYPE_TB
- en: '| d |'
  prefs: []
  type: TYPE_TB
- en: Updates will be processed at low speed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Less false positive rate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More memory Requirements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Less time in updating data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Less memory requirements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: One of the major applications of CMS includes monitoring Heavy hitters. Heavy
    hitters are defined with respect to a threshold *ϕ* and if count of any item frequency
    is equal to or greater than *ϕ*, then that item may be regarded as a heavy hitter.
    Schechter *et al.* [[167](bib.xhtml#ch00-bib-167)] proposed an approach that identifies
    most popular passwords in order to prevent statistical-guessing attacks. Here,
    the main contribution of the authors is to deprive an attacker of guessing most
    popular passwords by not letting any of the passwords to get common. CMS gives
    better results when combined with BF. Gupta *et al.* [[94](bib.xhtml#ch00-bib-94)]
    presented an Intrusion Detection System model that works on PDS. To check whether
    a node is suspicious or not from a list of suspicious nodes, all incoming node
    are passed through a BF, followed by a CMS to count frequency of hits by a particular
    node if BF returns true.
  prefs: []
  type: TYPE_NORMAL
- en: Lets understand CMS with a example. Consider a 2-D table where value of <math
    alttext="" display="inline"><mrow><mi>w</mi><mo>=</mo><mn>6</mn></mrow></math>
    and <math alttext="" display="inline"><mrow><mi>d</mi><mo>=</mo><mn>4</mn></mrow></math>,
    i.e., 4 hash functions will be used and each row will have 6 buckets. Consider
    <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo>=</mo><mi>i</mi><mi>m</mi><mi>o</mi><mi>d</mi><mn>6</mn></mrow></math>,
    <math alttext="" display="inline"><mrow><mi>h</mi><mn>2</mn><mo>=</mo><mo stretchy="true">(</mo><mn>2</mn><mo>*</mo><mi>i</mi><mo
    stretchy="true">)</mo><mi>m</mi><mi>o</mi><mi>d</mi><mn>6</mn></mrow></math>,
    <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>3</mn></msub><mo>=</mo><mo
    stretchy="true">(</mo><mi>i</mi><mi>m</mi><mi>o</mi><mi>d</mi><mn>3</mn><mo stretchy="true">)</mo><mi>m</mi><mi>o</mi><mi>d</mi><mn>6</mn></mrow></math>
    and <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>4</mn></msub><mo>=</mo><mo
    stretchy="true">(</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>3</mn><mo stretchy="true">)</mo><mi>m</mi><mi>o</mi><mi>d</mi><mn>6</mn></mrow></math>.
    All 24 locations are initialized to zero. Each incoming element is passed through
    all 4 hash functions and corresponding positions are incremented by their given
    count. The series of operation update(12,1), update(5,2), update (16,1), update(6,1)
    is shown in [Fig. 12.3](#fig12_3). The results of element 12, 5, 16, 6 after passing
    through given hash function is shown in [Table 12.2](#tab12_2). The query operation
    Estimate(6) has been shown in [Fig. 12.4](#fig12_4) and query operation Estimate(12)
    has been represented in [Fig. 12.5](#fig12_5). For element 6, the estimate query
    return true result whereas for element 12, it shows an case of over-estimate.
    Last, the deletion of element 6 by a count 1 is shown in [Fig 12.6](#fig12_6).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3](../images/fig12_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 12.3.**'
  prefs: []
  type: TYPE_NORMAL
- en: Update operation in CMS.
  prefs: []
  type: TYPE_NORMAL
- en: '**TABLE 12.2**'
  prefs: []
  type: TYPE_NORMAL
- en: Results of elements after passing through hash functions.
  prefs: []
  type: TYPE_NORMAL
- en: '| Element | *h*[1] | *h*[2] | *h*[3] | *h*[4] |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | 0 | 0 | 0 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 5 | 4 | 2 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | 4 | 2 | 1 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 0 | 0 | 0 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '![Figure 12.4](../images/fig12_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 12.4.**'
  prefs: []
  type: TYPE_NORMAL
- en: Estimate operation in CMS.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.5](../images/fig12_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 12.5.**'
  prefs: []
  type: TYPE_NORMAL
- en: Estimate operation in CMS representing over-estimate.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.6](../images/fig12_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 12.6.**'
  prefs: []
  type: TYPE_NORMAL
- en: Estimate operation in CMS representing over-estimate.
  prefs: []
  type: TYPE_NORMAL
- en: '[12.2.1 Implementation of CMS with Python](contents.xhtml#rsec12_2_1)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![](../images/list12_1a.jpg)![](../images/list12_1b.jpg)![](../images/list12_2a.jpg)![](../images/list12_2b.jpg)![](../images/list12_3.jpg)![](../images/list12_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[12.2.2 Count-mean-min-sketch](contents.xhtml#rsec12_2_2)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To deal with biasness generated by CMS, authors of [[70](bib.xhtml#ch00-bib-70)],
    introduced a variant of CMS called count-mean-min (CMM). Authors have pointed
    out that due to property that a counter of CMS is touched by many elements so,
    an error is expected. Here, the authors characterize this error as noise. Notably,
    the CMS outputs the least noise counter In CMM, the authors aim to estimate the
    noise generated by each counter. To estimate noise from counters, note the values
    of other counters in a row that are not touched by element in question. Here,
    it is assumed that each element is mapped uniformly and randomly for all rows
    of the table. The value in each counter that is not touched by element is an independent
    random variable and follows the same distribution pattern as noise. The structure
    and updation procedure of CMM is similar to CMS. Here also a 2-D table (w*d) is
    employed that uses the same hash function (h0, h1, …., hd-1\. However, the estimation
    procedure of CMM is different from CMS. Rather than returning the minimum value
    from *d* counters, the estimated noise from these *d* counters is deducted and
    median of residues is returned. To compute noise in each *d* counters of a row,
    take average off all other counters in any row *i* except for the counters in
    any row *i*. Hence, the estimated noise for a counter is given by Eq.:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mfrac><mrow><mi>N</mi><mo>−</mo><mi>C</mi><mi>M</mi><mo
    stretchy="false">[</mo><mi>i</mi><mo>,</mo><msub><mi>h</mi><mi>i</mi></msub><mo
    stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><mrow><mi>w</mi><mo>−</mo><mn>1</mn></mrow></mfrac></mrow></mtd></mtr></mtable></mrow></math>(12.1)
  prefs: []
  type: TYPE_NORMAL
- en: where, *N* is stream size,
  prefs: []
  type: TYPE_NORMAL
- en: '*CM[i, hi(q)]* is the counter for element *q* in row *i* and *i= o,1,…., d-1*,'
  prefs: []
  type: TYPE_NORMAL
- en: '*w* = sketch width'
  prefs: []
  type: TYPE_NORMAL
- en: '*q* = Element in question'
  prefs: []
  type: TYPE_NORMAL
- en: 'This algorithm may also overestimate and the estimate count is given by median
    of:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>C</mi><mi>M</mi><mo stretchy="false">[</mo><mi>i</mi><mo>,</mo><msub><mi>h</mi><mi>i</mi></msub><mo
    stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>−</mo><mfrac><mrow><mi>N</mi><mo>−</mo><mi>C</mi><mi>M</mi><mo
    stretchy="false">[</mo><mi>i</mi><mo>,</mo><msub><mi>h</mi><mi>i</mi></msub><mo
    stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><mrow><mi>w</mi><mo>−</mo><mn>1</mn></mrow></mfrac></mrow></mtd></mtr></mtable></mrow></math>(12.2)
  prefs: []
  type: TYPE_NORMAL
- en: for all *i* rows.
  prefs: []
  type: TYPE_NORMAL
- en: '[12.3 Count-sketch](contents.xhtml#rsec12_3)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Count-sketch is almost similar to CMS and it provides an estimate of frequency
    for any individual item. Actually, authors [[62](bib.xhtml#ch00-bib-62)] of count-sketch
    designed it to keep approximate count of highest frequency items in a stream.
    The difference between CMS and count-sketch two comes in the estimation process
    and in the nature of guaranteed accuracy for frequency estimate. Authors have
    proved that proposed algorithm is better than the sampling algorithm. Count sketch
    also employs a 2-D table of size *w*d* in size which is interpreted as array of
    *d* hash tables with each having *w* buckets. Different from CMS, rather than
    using a single hash function, two hash functions (*h and g*) are being used for
    each row of count sketch. Each hash functions <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo>,</mo><msub><mi>h</mi><mn>2</mn></msub><mo>,</mo><mn>......</mn><mo>,</mo><msub><mi>h</mi><mi>d</mi></msub></mrow></math>
    maps from *1,2,….,w* whereas <math alttext="" display="inline"><mrow><msub><mi>s</mi><mn>1</mn></msub><mo>,</mo><msub><mi>s</mi><mn>2</mn></msub><mo>,</mo><mn>..........</mn><mo>,</mo><msub><mi>s</mi><mi>d</mi></msub></mrow></math>
    maps to -1, +1, i.e., either +1 or -1\. The operations supported by count-sketch
    are discussed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Update(q, c): This operation updates an item *q* with count *c* to the count-sketch.
    For each hash table of array, compute the state of updated sketch as:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>s</mi><mi>k</mi><mi>e</mi><mi>t</mi><mi>c</mi><mi>h</mi><mo
    stretchy="false">[</mo><mi>k</mi><mo>,</mo><msub><mi>h</mi><mi>i</mi></msub><mo
    stretchy="false">[</mo><mi>q</mi><mo stretchy="false">]</mo><mo stretchy="false">]</mo><mo>=</mo><mi>s</mi><mi>k</mi><mi>e</mi><mi>t</mi><mi>c</mi><mi>h</mi><mo
    stretchy="false">[</mo><mi>k</mi><mo>,</mo><msub><mi>h</mi><mi>i</mi></msub><mo
    stretchy="false">[</mo><mi>q</mi><mo stretchy="false">]</mo><mo stretchy="false">]</mo><mo>+</mo><mi>c</mi><mo>*</mo><msub><mi>s</mi><mi>i</mi></msub><mo
    stretchy="false">[</mo><mi>q</mi><mo stretchy="false">]</mo><mi>w</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi>e</mi><mo>></mo><mi>i</mi><mo>∈</mo><mo
    stretchy="false">[</mo><mn>1</mn><mo>,</mo><mi>d</mi><mo stretchy="false">]</mo><mo>></mo><mi>a</mi><mi>n</mi><mi>d</mi><mo>></mo><mn>1</mn><mo><</mo><mi>k</mi><mo><</mo><mi>d</mi><mo>.</mo></mrow></mtd></mtr></mtable></mrow></math>(12.3)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Introducing <math alttext="" display="inline"><mrow><mo>±</mo><mn>1</mn></mrow></math>
    can be helpful in better estimation for element *q* as it can better handle collision
    among elements. However, if an element *q* collides with multiple frequent elements,
    it wont result in good estimate for element *q* but in case of collision with
    infrequent elements impact of <math alttext="" display="inline"><mrow><mo>±</mo><mn>1</mn></mrow></math>
    is positive.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Estimate(q): This operation find the approximate count of element *q* in sketch.
    To execute the operation take median of <math alttext="" display="inline"><mrow><mi>s</mi><mi>k</mi><mi>e</mi><mi>t</mi><mi>c</mi><mi>h</mi><mo
    stretchy="true">[</mo><mi>k</mi><mo>,</mo><msub><mi>h</mi><mi>k</mi></msub><mo
    stretchy="true">[</mo><mi>q</mi><mo stretchy="true">]</mo><mo>.</mo><msub><mi>s</mi><mi>k</mi></msub><mo
    stretchy="true">[</mo><mi>q</mi><mo stretchy="true">]</mo><mo stretchy="true">]</mo></mrow></math>
    where, <math alttext="" display="inline"><mrow><mi>i</mi><mo>∈</mo><mo>[</mo><mn>1</mn><mo>,</mo><mi>d</mi><mo>]</mo></mrow></math>
    and <math alttext="" display="inline"><mrow><mn>1</mn><mo>≤</mo><mi>k</mi><mo>≤</mo><mi>d</mi></mrow></math>.
    Authors have proved in results that the median is comparatively robust over mean.
    Moreover, mean is sensitive to the outliers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, the authors have not mentioned about delete operation anywhere in the
    base paper of count-sketch. Space consumed by Count-Sketch is <math alttext=""
    display="inline"><mrow><mi>O</mi><mo stretchy="true">(</mo><mfrac><mn>1</mn><mrow><msup><mi>ϵ</mi><mn>2</mn></msup></mrow></mfrac><mi>l</mi><mi>o</mi><mi>g</mi><mfrac><mn>1</mn><mi>δ</mi></mfrac><mo
    stretchy="true">)</mo></mrow></math>. However, authors have ignored the space
    requirement of actual storage of elements from stream. Also, etting <math alttext=""
    display="inline"><mrow><mi>w</mi><mo>=</mo><mfrac><mn>2</mn><mrow><msup><mi>ϵ</mi><mn>2</mn></msup></mrow></mfrac></mrow></math>
    and <math alttext="" display="inline"><mrow><mi>d</mi><mo>=</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo
    stretchy="true">(</mo><mfrac><mn>4</mn><mi>δ</mi></mfrac><mo stretchy="true">)</mo></mrow></math>
    achieves atmost error of <math alttext="" display="inline"><mrow><mi>ϵ</mi><mi>N</mi></mrow></math>
    with atleast probability of <math alttext="" display="inline"><mrow><mn>1</mn><mo>−</mo><mi>δ</mi></mrow></math>
    where *N* is stream size. Notably, this algorithm generates overestimates as well
    as underestimate for a query.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take an example to understand count-sketch more clearly. Consider a table
    with <math alttext="" display="inline"><mrow><mi>w</mi><mo>=</mo><mn>6</mn></mrow></math>
    and <math alttext="" display="inline"><mrow><mi>d</mi><mo>=</mo><mn>4</mn></mrow></math>.
    The value of the hash function for each hash table is <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>1</mn></msub><mo>=</mo><mi>i</mi><mi>m</mi><mi>o</mi><mi>d</mi><mn>6</mn></mrow></math>,
    <math alttext="" display="inline"><mrow><mi>h</mi><mn>2</mn><mo>=</mo><mo stretchy="true">(</mo><mn>2</mn><mo>*</mo><mi>i</mi><mo
    stretchy="true">)</mo><mi>m</mi><mi>o</mi><mi>d</mi><mn>6</mn></mrow></math>,
    <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>3</mn></msub><mo>=</mo><mo
    stretchy="true">(</mo><mi>i</mi><mi>m</mi><mi>o</mi><mi>d</mi><mn>3</mn><mo stretchy="true">)</mo><mi>m</mi><mi>o</mi><mi>d</mi><mn>6</mn></mrow></math>
    and <math alttext="" display="inline"><mrow><msub><mi>h</mi><mn>4</mn></msub><mo>=</mo><mo
    stretchy="true">(</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>3</mn><mo stretchy="true">)</mo><mi>m</mi><mi>o</mi><mi>d</mi><mn>6</mn></mrow></math>
    and *g*1,*g*2 generate either <math alttext="" display="inline"><mrow><mo>−</mo><mn>1</mn></mrow></math>
    or <math alttext="" display="inline"><mrow><mo>+</mo><mn>1</mn></mrow></math>
    randomly for any incoming item. The result of elements after passing through hash
    function *h* and *g* is represented in [Table 12.3](#tab12_3). The operation <math
    alttext="" display="inline"><mrow><mi>u</mi><mi>p</mi><mi>d</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo
    stretchy="true">(</mo><mn>12</mn><mo>,</mo><mn>1</mn><mo stretchy="true">)</mo></mrow></math>,
    <math alttext="" display="inline"><mrow><mi>u</mi><mi>p</mi><mi>d</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo
    stretchy="true">(</mo><mn>5</mn><mo>,</mo><mn>2</mn><mo stretchy="true">)</mo></mrow></math>,
    <math alttext="" display="inline"><mrow><mi>u</mi><mi>p</mi><mi>d</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo
    stretchy="true">(</mo><mn>16</mn><mo>,</mo><mn>1</mn><mo stretchy="true">)</mo></mrow></math>
    and <math alttext="" display="inline"><mrow><mi>u</mi><mi>p</mi><mi>d</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo
    stretchy="true">(</mo><mn>6</mn><mo>,</mo><mn>1</mn><mo stretchy="true">)</mo></mrow></math>
    in series has been represented in [Figs. 12.7](#fig12_7). Similarly, the operations
    <math alttext="" display="inline"><mrow><mi>e</mi><mi>s</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo
    stretchy="true">(</mo><mn>5</mn><mo stretchy="true">)</mo></mrow></math> and <math
    alttext="" display="inline"><mrow><mi>e</mi><mi>s</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo
    stretchy="true">(</mo><mn>12</mn><mo stretchy="true">)</mo></mrow></math> have
    been represented in [Fig. 12.8](#fig12_8) and [12.9](#fig12_9) respectively. It
    is clear from [Fig. 12.9](#fig12_9) that the query for element 12 results in over-estimation.
    Notably, the estimation query for count-sketch may result in under-estimation
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: '**TABLE 12.3**'
  prefs: []
  type: TYPE_NORMAL
- en: Results of elements after passing through two hash functions *h* and *g*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 12.3](../images/tab12_3.jpg)![Figure 12.7](../images/fig12_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 12.7.**'
  prefs: []
  type: TYPE_NORMAL
- en: Update operation in Count-sketch.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.8](../images/fig12_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 12.8.**'
  prefs: []
  type: TYPE_NORMAL
- en: Estimate operation in count-sketch.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.9](../images/fig12_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 12.9.**'
  prefs: []
  type: TYPE_NORMAL
- en: Estimate operation in count-sketch representing over-estimate.
  prefs: []
  type: TYPE_NORMAL
- en: '[12.4 Count-Min with Conservative Update Sketch](contents.xhtml#rsec12_4)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The main logic behind the conservative update is “Minimal Increase” which only
    increment count with the minimum amount required to ensure that accuracy of the
    estimate remains. Counservative update (CU) can be applied to Count-Min-sketch
    and also to spectral BF. CM-CU sketch was introduced by authors of [[76](bib.xhtml#ch00-bib-76)]
    with an aim to reduce the false positive error in the result. Specifically, the
    authors of [[88](bib.xhtml#ch00-bib-88)] concluded that CMS with conservative
    update minimizes the over-estimation error by a factor of 1.5\. Similar to CMS,
    CM-CU also uses a 2-D table of size <math alttext="" display="inline"><mrow><mi>w</mi><mo>*</mo><mi>d</mi></mrow></math>
    where, *w* is the width and *d* is the depth of the table. Also, *k* hash functions
    equal to the depth of the table are used. For any incoming item, only the count
    by minimal amount will be incremented. However, the CM-CU sketch does not support
    deletion. The operations that are supported by CM-CU sketch are discussed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Update (*q, c*): This operation adds an element *q* with count *c* to the sketch.
    To perform this operation, first, compute the approximate frequency of the element
    *q* from the existing state of the sketch by using the <math alttext="" display="inline"><mrow><mi>E</mi><mi>s</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo
    stretchy="true">(</mo><mi>q</mi><mo stretchy="true">)</mo></mrow></math> procedure
    explained for CMS, (i.e., by taking a minimum of the values returned from values
    indexed by *d* hash functions. Let''s call this value <math alttext="" display="inline"><mrow><msub><mi>f</mi><mi>q</mi></msub></mrow></math>.
    Next, compare the values at *k* locations corresponding to *k* hash functions.
    Here, in CMS, the values at *k* locations are only incremented if the existing
    value in the sketch is less than <math alttext="" display="inline"><mrow><msub><mi>f</mi><mi>q</mi></msub><mo>+</mo><mn>1</mn></mrow></math>,
    otherwise, the value won''t get changed. This type of conditional updation ensures
    that unnecessary updation and reduces over-estimation error. In order to update
    *q* with the count, *c* first compute <math alttext="" display="inline"><mrow><msub><mi>f</mi><mi>q</mi></msub></mrow></math>
    using:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><msub><mi>f</mi><mi>q</mi></msub><mo>=</mo><mi>m</mi><mi>i</mi><msub><mi>n</mi><mi>k</mi></msub><mo>></mo><mi>s</mi><mi>k</mi><mi>e</mi><mi>t</mi><mi>c</mi><mi>h</mi><mo
    stretchy="false">[</mo><mi>k</mi><mo>,</mo><msub><mi>h</mi><mi>k</mi></msub><mo
    stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>></mo><mo>∀</mo><mo>></mo><mn>1</mn><mo>≤</mo><mi>k</mi><mo>≤</mo><mi>d</mi></mrow></mtd></mtr></mtable></mrow></math>(12.4)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'and update the count according o following equation:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>s</mi><mi>k</mi><mi>e</mi><mi>t</mi><mi>c</mi><mi>h</mi><mo
    stretchy="false">[</mo><mi>k</mi><mo>,</mo><msub><mi>h</mi><mi>k</mi></msub><mo
    stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>←</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo>{</mo><mi>s</mi><mi>k</mi><mi>e</mi><mi>t</mi><mi>c</mi><mi>h</mi><mo
    stretchy="false">[</mo><mi>k</mi><mo>,</mo><msub><mi>h</mi><mi>k</mi></msub><mo
    stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>,</mo><msub><mi>f</mi><mi>q</mi></msub><mo>+</mo><mi>c</mi><mo>}</mo></mrow></mtd></mtr></mtable></mrow></math>(12.5)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Estimate(q)*: It follows the same procedure *Estimate(q)* as explained for
    CMS in [section 12.2](#sec12_2).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The example for update operation has been represented in [Fig. 12.10](#fig12_10).
    Here, the operations <math alttext="" display="inline"><mrow><mi>u</mi><mi>p</mi><mi>d</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo
    stretchy="true">(</mo><mn>12</mn><mo>,</mo><mn>1</mn><mo stretchy="true">)</mo></mrow></math>,
    <math alttext="" display="inline"><mrow><mi>u</mi><mi>p</mi><mi>d</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo
    stretchy="true">(</mo><mn>5</mn><mo>,</mo><mn>2</mn><mo stretchy="true">)</mo></mrow></math>,
    <math alttext="" display="inline"><mrow><mi>u</mi><mi>p</mi><mi>d</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo
    stretchy="true">(</mo><mn>16</mn><mo>,</mo><mn>1</mn><mo stretchy="true">)</mo></mrow></math>,
    <math alttext="" display="inline"><mrow><mi>u</mi><mi>p</mi><mi>d</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo
    stretchy="true">(</mo><mn>6</mn><mo>,</mo><mn>1</mn><mo stretchy="true">)</mo></mrow></math>
    in shown in series. The hash outputs for all these element has been shown in [Table
    12.2](#tab12_2). Similarly the operation Estimate(6) has been shown in [Fig. 12.11](#fig12_11).
    Experiments concluded that error rate is proportional to <math alttext="" display="inline"><mrow><mfrac><mn>1</mn><mi>M</mi></mfrac></mrow></math>
    where *M* is the available memory.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.10](../images/fig12_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 12.10.**'
  prefs: []
  type: TYPE_NORMAL
- en: Update operation in CM-CU sketch.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.11](../images/fig12_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 12.11.**'
  prefs: []
  type: TYPE_NORMAL
- en: Estimate operation in CM-CU sketch.
  prefs: []
  type: TYPE_NORMAL
- en: Activity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Multiple Choice Questions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: What is the main idea behind count-min with conservative update?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Minimal increase
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Minimal decrease
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Maximal increase
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Maximal decrease
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: If a sketch employs a table of size <math alttext="" display="inline"><mrow><mi>t</mi><mo>*</mo><mi>b</mi></mrow></math>
    where *t* is number of rows and *b* is the number of columns, then how many hash
    functions are required in order to implement CMS?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="true">(</mo><mi>t</mi><mo>+</mo><mi>b</mi><mo
    stretchy="true">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="true">(</mo><mi>b</mi><mo
    stretchy="true">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="true">(</mo><mi>t</mi><mo
    stretchy="true">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="true">(</mo><mi>t</mi><mo>*</mo><mi>b</mi><mo
    stretchy="true">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which measure of central tendency is used in order to execute query by count-sketch
    ?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mode
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Median
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Average
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Range
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the impact on error rate with increase in width of 2-D array of CMS
    ?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Error rate will become high
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Error rate will get reduced
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Error could be high or low
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: No relation between error rate and width of table
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following mentioned BF does not support deletion?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Counting BF
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: DBF
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Stable BF
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Compressed BF
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which among the following is the deterministic algorithm for frequency estimation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: CMS
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: HLL
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Majority algorithm
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: All of the above
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the time complexity for updation operation in CMS?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="true">(</mo><mi>d</mi><mo
    stretchy="true">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="true">(</mo><mi>w</mi><mo
    stretchy="true">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="true">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>d</mi><mo
    stretchy="true">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>i</mi><mi>s</mi><mo>_</mo><mi>s</mi><mi>h</mi><mi>i</mi><mi>f</mi><mi>t</mi><mi>e</mi><mi>d</mi></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the space requirement for CMS?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Linear
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Sub-linear
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Super-linear
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: logarithmic
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 1\. a  2\. b  3\. b  4\. b  5\. c  6\. c  7\. a  8\. b
  prefs: []
  type: TYPE_NORMAL
- en: <hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '[13](contents.xhtml#rchapter13)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Approximate Similarity Search Query Probabilistic Data Structures](contents.xhtml#rchapter13)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: </hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '[13.1 Introduction](contents.xhtml#rsec13_1)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Large datasets generated from a system may contain duplicates or near duplicates.
    Applying brute force technique to probe all possible combination can give exact
    nearest neighbor match, but this way is no scalable. Over and above, the traditional
    cluster analysis techniques (e.g., k-nearest neighbor) take quadratic or cubic
    time which seems unpractical for large datasets. Moreover, tree structure methods,
    such as- kd-trees, BDD trees etc. demands enough space and time as these methods
    compare given query with each record while searching to identify similar records
    [[83](bib.xhtml#ch00-bib-83)], [[106](bib.xhtml#ch00-bib-106)]. Hence, there is
    a demand for efficient similarity search method that can solve desired queries
    in low cost. To address this problem, researchers proposed using approximation
    techniques for high dimensional similarity search.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data structure under this category approximates similarity search for high
    dimensional data. Sometimes, similarity search is also referred to as approximate
    nearest neighbor search or proximity search. In such type of problem, different
    features of interest e.g., text document, images are treated as points and a distance
    metric is used to identify similarity between two objects. The similarity search
    measure maps a pair of set to a similarity score in range [0,1]. Specifically,
    the aim here is to find duplicates or cluster of similar points in high dimensional
    attribute space. The use-cases for approximate similarity search includes finding
    similarity between web pages in the Internet, locating similar image or audio/video
    files, data deduplication, identifying plagiarism cases, identify variations in
    malware family etc. Mathematically, the problem is defined as: For a query *q*,
    the aim is to locate item *x* such that <math alttext="" display="inline"><mrow><mtext>dis</mtext><mo>(</mo><mi>q</mi><mo>,</mo><mi>x</mi><mo>)</mo><mo>≤</mo><mo>(</mo><mn>1</mn><mo>+</mo><mi>ϵ</mi><mo>)</mo><mi>d</mi><mi>i</mi><mi>s</mi><msup><mrow><mo
    stretchy="false">(</mo><mi>q</mi><mo>,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mo>∗</mo></msup></mrow></math>
    where, *ϵ* is the at most estimated expected error [[212](bib.xhtml#ch00-bib-212)].'
  prefs: []
  type: TYPE_NORMAL
- en: The fundamentals of approximate similarity also rely on hashing as hashing converts
    the data points to a low dimensional representation. Hash table lookup and fast
    distance approximation are two techniques of hashing to perform approximate nearest
    neighbor search. The former method uses a hash table as data structure that is
    comprised of buckets. Each item *x* is hashed to a bucket <math alttext="" display="inline"><mrow><mi>h</mi><mo
    stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></math>. However,
    different from conventional hashing algorithm, here hash table aims to maximize
    probability of neighbor item collision. In contrast, the later computes the distance
    between given query and hash code of the reference item. Subsequently, the reference
    item having smallest distance are the candidates of nearest neighbor. Next, we
    will present the different types of approximate similarity search PDS.
  prefs: []
  type: TYPE_NORMAL
- en: '[13.2 Minhashing](contents.xhtml#rsec13_2)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Andrie Border introduced minhashing to detect duplicacy in web pages of AltaVista
    search engine [[53](bib.xhtml#ch00-bib-53)], [[54](bib.xhtml#ch00-bib-54)]. Minhash
    is based on the jaccard similarity notion to identify similarity between two sets.
    Jaccard similarity for two sets is the ratio of intersection to the union of two
    sets and is given by:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="block"><mrow><mtable columnalign="left"><mtr columnalign="left"><mtd
    columnalign="left"><mrow><mi>J</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>S</mi><mn>1</mn></msub><mo>,</mo><msub><mi>S</mi><mn>2</mn></msub><mo
    stretchy="false">)</mo><mo>=</mo><mo>|</mo><msub><mi>S</mi><mn>1</mn></msub><mo>∩</mo><msub><mi>S</mi><mn>2</mn></msub><mo>|</mo><mo>/</mo><mo>|</mo><msub><mi>S</mi><mn>1</mn></msub><mo>∪</mo><msub><mi>S</mi><mn>2</mn></msub><mo>|</mo><mo>.</mo></mrow></mtd></mtr></mtable></mrow></math>(13.1)
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, take two small sets, <math alttext="" display="inline"><mrow><mi>s</mi><mi>e</mi><mi>t</mi><mi>A</mi><mo>=</mo><mn>10</mn><mo>,</mo><mn>113</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>55</mn><mo>,</mo><mn>12</mn></mrow></math>
    and <math alttext="" display="inline"><mrow><mi>s</mi><mi>e</mi><mi>t</mi><mi>B</mi><mo>=</mo><mn>10</mn><mo>,</mo><mn>3</mn><mo>,</mo><mn>56</mn><mo>,</mo><mn>7</mn><mo>,</mo><mn>9</mn></mrow></math>.
    It can be noticed that there are 2 items in common between sets and there are
    total of 10 unique items in two sets. Therefore, the set A and B have a jaccard
    similarity of <math alttext="" display="inline"><mrow><mfrac><mn>2</mn><mn>9</mn></mfrac></mrow></math>.
    Although computing intersection and union between two set is an expensive operation.
    However, to compute similarity between documents, documents can also be represented
    as sets. Shingling is one of the popular way to convert a document into set. *k*-shingles
    is defined as set of all possible *k* size non repeatable substrings of the given
    document. A document with *n* words, having set of *k*-shingles consumes <math
    alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>k</mi><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math> space. Suppose a document is made up of
    a small sentence “Clustering large number of binary program is a difficult task”.
    So, 5 word long shingles are:'
  prefs: []
  type: TYPE_NORMAL
- en: Clustering large number of binary
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: large number of binary program
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: number of binary program is
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: of binary program is a
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: binary program is a difficult
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: program is a difficult task
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Therefore, the document as a set is: (“Clustering large number of binary”,
    “large number of binary program”, “number of binary program is”, “of binary program
    is a”, “binary program is a difficult”, “program is a difficult task”). Time complexity
    to compute jaccard similarity is <math alttext="" display="inline"><mrow><mi>O</mi><mo
    stretchy="false">(</mo><msub><mi>n</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow></math>
    as there are total of <math alttext="" display="inline"><mrow><mfrac><mrow><mi>n</mi><mo
    stretchy="false">(</mo><mi>n</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><mn>2</mn></mfrac></mrow></math>
    comparisons.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, the large collection of set can also be represented by a single boolean
    matrix. To represent set as boolean matrix, rows of the matrix contain elements
    of universal set whereas column of the matrix contains all sets. The entry in
    row *r* and column *c* is 1 if and only if set of row *r* is a member of column
    *c*, otherwise the entry is zero. In this case, column similarity is the jaccard
    similarity of the set having rows with column value 1\. To understand this, consider
    three columns C1, C2, C3 with values: From [Table 13.1](#tab13_1) <math alttext=""
    display="inline"><mrow><mi>S</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><msub><mi>C</mi><mn>1</mn></msub><mo>,</mo><msub><mi>C</mi><mn>2</mn></msub><mo
    stretchy="false">)</mo><mo>=</mo><mfrac><mn>2</mn><mn>5</mn></mfrac></mrow></math>
    as there are two rows in column C1 and C2 where both entries 1\. Therefore, intersection
    of set that column C1 and C2 represent is 2\. Also, there are rows where atleast
    one column has 1\. So, the union of represented set is 5\. Hence, the jaccard
    similarity is <math alttext="" display="inline"><mrow><mfrac><mn>2</mn><mn>5</mn></mfrac></mrow></math>
    which is 40%. Similarly, <math alttext="" display="inline"><mrow><mi>S</mi><mi>i</mi><mi>m</mi><mo
    stretchy="false">(</mo><msub><mi>C</mi><mn>1</mn></msub><mo>,</mo><msub><mi>C</mi><mn>3</mn></msub><mo
    stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>5</mn></mfrac></mrow></math>.
    Notably, this matrix is not sparse and calculating jaccard similarity for this
    case is quite simple. However, with this representation the resultant matrix is
    sparse, i.e., it has more zeros than one which is a overhead for the memory. From
    [Table 13.1](#tab13_1) <math alttext="" display="inline"><mrow><mi>S</mi><mi>i</mi><mi>m</mi><mo
    stretchy="false">(</mo><msub><mi>C</mi><mn>1</mn></msub><mo>,</mo><msub><mi>C</mi><mn>2</mn></msub><mo
    stretchy="false">)</mo><mo>=</mo><mfrac><mn>2</mn><mn>5</mn></mfrac></mrow></math>
    as there are wo rows in column C1 and C2 where both entries 1\. Therefore, intersection
    of set that column C1 and C2 represent is 2\. Also, there are rows where atleast
    one column has 1\. So, the union of represented set is 5\. Hence, the jaccard
    similarity is <math alttext="" display="inline"><mrow><mfrac><mn>2</mn><mn>5</mn></mfrac></mrow></math>
    which is 40%. Similarly, <math alttext="" display="inline"><mrow><mi>S</mi><mi>i</mi><mi>m</mi><mo
    stretchy="false">(</mo><msub><mi>C</mi><mn>1</mn></msub><mo>,</mo><msub><mi>C</mi><mn>3</mn></msub><mo
    stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>5</mn></mfrac></mrow></math>.
    Notably, this matrix is not sparse and calculating jaccard similarity for this
    case is quite simple. However, with this representation the resultant matrix is
    sparse, i.e., it has more zeros than one which is a overhead for the memory. Minhash
    algorithm provides a way for fast approximation to jaccard similarity of two sets.
    In order to implement minhashing, for each set minhash signature is computed and
    saved in signature matrix. The computed minhash signature has a fixed length and
    it is independent to the size of set. Signature matrix of minhash is made up of
    *h* rows that signifies number of hash functions and *c* columns which is equal
    to total number of sets. The signature matrix is useful as it provides almost
    same similarity as that of boolean matrix but with quite less storage space.'
  prefs: []
  type: TYPE_NORMAL
- en: '**TABLE 13.1**'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding minhashing.
  prefs: []
  type: TYPE_NORMAL
- en: '| C1 | C2 | C3 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: Randomly permute rows.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute minhash value, <math alttext="" display="inline"><mrow><mi>M</mi><mi>H</mi><mo
    stretchy="false">(</mo><mi>C</mi><mo stretchy="false">)</mo></mrow></math> =index
    of first row (after permutation) with 1 in column *C*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, use multiple independent hash function and create a signature for
    each column so that signature matrix has *h* rows. These minhash functions are
    selected once and same set of minhash functions is applied to each column. Notably,
    large matrix produce less errors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sim(C1, C2)= Sim(Sig(C1), Sig(C2), i.e., similarity between two sets is fraction
    of permutations where minhash value agree.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lets understand this concept with an example. Consider a input matrix with
    5 columns and 7 rows as shown in [Fig. 13.1](#fig13_1). These columns are permuted
    thrice in order P1, P2, P3\. So, resultant signature matrix has 3 rows (each corresponding
    to one permutation) and 5 column. The minhash value for permutation 1 has value
    <math alttext="" display="inline"><mrow><mn>2</mn><mo>−</mo><mn>1</mn><mo>−</mo><mn>2</mn><mo>−</mo><mn>3</mn><mo>−</mo><mn>4</mn></mrow></math>
    for each 5 column respectively and the reason is discussed as follows: The row
    5 is first in order and row 4 is second and so on. Clearly, row 5 has 1 in second
    column and hence column second has got its first minhash value, next row 4 is
    analyzed. As row 4 has 1 for columns 1 and 3 and neither of these column has been
    assigned a value yet. So, both of these columns get a value of 2 in signature
    matrix. Next, row 2 is scanned and it has 1 for columns 2 and 4\. As, column 2
    is already having a minhash value, so only column 4 will get a value of 3 in signature
    matrix. Similarly, column 5 gets value 4\. Notably, we have discovered minhash
    value for each column so there is no point of moving further.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.1](../images/fig13_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 13.1.**'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding minhashing.
  prefs: []
  type: TYPE_NORMAL
- en: '**Surprising property**'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we consider all possible permutations of the rows then it is observed that:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>P</mi><mo stretchy="false">[</mo><mi>M</mi><mi>H</mi><mo
    stretchy="false">(</mo><msub><mi>C</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mi>M</mi><mi>H</mi><mo
    stretchy="false">(</mo><msub><mi>C</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo
    stretchy="false">]</mo><mo>=</mo><mi>J</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>C</mi><mn>1</mn></msub><mo>,</mo><msub><mi>C</mi><mn>2</mn></msub><mo
    stretchy="false">)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, with large dataset, its difficult to pick random permutation.
    Moreover, representing random permutations for large entries require huge amount
    of space. Also, accessing rows in order of any of these permutations requires
    many disc access to get each row which is clearly time consuming.
  prefs: []
  type: TYPE_NORMAL
- en: Lets look at a better implementation of minhashing. The idea is to simulate
    permutations without actually permuting rows. Here in this implementation, a normal
    hash function <math alttext="" display="inline"><mrow><mo stretchy="false">(</mo><mi>h</mi><mo
    stretchy="false">)</mo></mrow></math> for each minhash function is chosen that
    hashes integer to some bucket. We assume that position of row *r* in the permutation
    is <math alttext="" display="inline"><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>r</mi><mo
    stretchy="false">)</mo></mrow></math>. Following steps are taken to obtain a signature
    matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Rather than permuting rows, pick some number of ordinary hash functions, one
    corresponding to each minhash function we want to simulate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each column *C* and each hash function <math alttext="" display="inline"><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow></math>,
    keep a slot <math alttext="" display="inline"><mrow><mi>M</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>c</mi><mo
    stretchy="false">)</mo></mrow></math>. For example, number of slots is <math alttext=""
    display="inline"><mrow><mn>100</mn><mo>*</mo><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>c</mi><mi>o</mi><mi>l</mi><mi>u</mi><mi>m</mi><mi>n</mi><mi>s</mi></mrow></math>.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Initialize all slots <math alttext="" display="inline"><mrow><mi>M</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>c</mi><mo
    stretchy="false">)</mo></mrow></math> to infinity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To compute minhash signature, <math alttext="" display="inline"><mrow><mi>M</mi><mo
    stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>c</mi><mo stretchy="false">)</mo></mrow></math>
    should alwayz contain the smallest value of <math alttext="" display="inline"><mrow><msub><mi>h</mi><mi>i</mi></msub><mo
    stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></math> for
    those column *C* has 1 in row *r*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Algorithm 4** Minhash algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm for above discussed method has been shown in algorithm 4.
  prefs: []
  type: TYPE_NORMAL
- en: '1: **for** each row r **do**'
  prefs: []
  type: TYPE_NORMAL
- en: 2:**for** each hash function **do**
  prefs: []
  type: TYPE_NORMAL
- en: 3:compute <math alttext="" display="inline"><mrow><msub><mi>h</mi><mi>i</mi></msub><mo
    stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></math>;
  prefs: []
  type: TYPE_NORMAL
- en: 4:**for** each column c **do**
  prefs: []
  type: TYPE_NORMAL
- en: 5:**if** c has 1 in row r **then**
  prefs: []
  type: TYPE_NORMAL
- en: 6:**for** each hash function <math alttext="" display="inline"><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow></math>
    **do**
  prefs: []
  type: TYPE_NORMAL
- en: 7:**if** hi(r) ¡ M(i,c) **then** M(i,c) ← hi(r);
  prefs: []
  type: TYPE_NORMAL
- en: 8:**end if**
  prefs: []
  type: TYPE_NORMAL
- en: 9:**end for**
  prefs: []
  type: TYPE_NORMAL
- en: 10:**end if**
  prefs: []
  type: TYPE_NORMAL
- en: 11:**end for**
  prefs: []
  type: TYPE_NORMAL
- en: 12:**end for**
  prefs: []
  type: TYPE_NORMAL
- en: '13: **end for**'
  prefs: []
  type: TYPE_NORMAL
- en: This implementation is fast as well as uses fixed memory footprint. Although
    signature matrix consumes comparatively less space to represent document signature
    but it still takes <math alttext="" display="inline"><mrow><mfenced close=")"
    open="("><mtable><mtr><mtd><mi>n</mi></mtd></mtr><mtr><mtd><mn>2</mn></mtd></mtr></mtable></mfenced><mo
    stretchy="false">(</mo><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo
    stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></math> approximate time
    for finding similar pair of comparison. To understand this concept with example,
    consider a matrix with 2 columns and 5 rows as represented in [Fig. 13.2](#fig13_2).
    Two hash functions are used here, i.e., <math alttext="" display="inline"><mrow><mi>h</mi><mo
    stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi><mi>m</mi><mi>o</mi><mi>d</mi><mn>5</mn></mrow></math>
    and <math alttext="" display="inline"><mrow><mi>g</mi><mo stretchy="false">(</mo><mi>x</mi><mo
    stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mn>2</mn><mi>x</mi><mo>+</mo><mn>1</mn><mo
    stretchy="false">)</mo><mi>m</mi><mi>o</mi><mi>d</mi><mn>5</mn></mrow></math>.
    Hence, final signature matrix will be of length 2.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.2](../images/fig13_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 13.2.**'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding minhashing.
  prefs: []
  type: TYPE_NORMAL
- en: Initially all slots are infinity. The first row has 1 for column 1 and 0 in
    column 2\. So, both of the component for column 2 has not changed and it remains
    infinity but first column value will get changed to values of <math alttext=""
    display="inline"><mrow><mi>h</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math>
    and <math alttext="" display="inline"><mrow><mi>g</mi><mo stretchy="false">(</mo><mn>1</mn><mo
    stretchy="false">)</mo></mrow></math> i.e., 1 and 3\. Now, consider second row
    where both columns has 1 and <math alttext="" display="inline"><mrow><mi>h</mi><mo
    stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo><mo>=</mo><mn>2</mn></mrow></math>
    and <math alttext="" display="inline"><mrow><mi>g</mi><mo stretchy="false">(</mo><mn>2</mn><mo
    stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow></math>. Simply for column 2,
    infinity values are replaced with hash values whereas for column 1 <math alttext=""
    display="inline"><mrow><mi>h</mi><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo><mo>></mo><mi>h</mi><mo
    stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math> so,
    this value will not changed and <math alttext="" display="inline"><mrow><mi>g</mi><mo
    stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo><mo><</mo><mi>g</mi><mo
    stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math> so,
    second component here will get changed to 0\. As minhash function uses minimum
    value encountered for each hash function. Hence, the name minhash is defendable.
    Likewise, other rows are observed and final signature matrix for both columns
    are shown in [Fig. 13.2](#fig13_2). Code 13.4 presents Python implementation using
    built-in hash function and *h* bitwise XOR masks for doing hashing.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/list13_1.jpg)![](../images/list13_2a.jpg)![](../images/list13_2b.jpg)![](../images/list13_2c.jpg)![](../images/list13_3a.jpg)![](../images/list13_3b.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[13.3 Locality Sensitive Hashing](contents.xhtml#rsec13_3)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Locality Sensitive Hashing (LSH) aims to find nearest data points to the given
    query. Here, also hash tables are utilized to find close enough match. Detecting
    plagiarism, classifiaction by topic, recommendation systems, entity resolution,
    genome-wide association study, audio-video fingerprinting, etc. are some of the
    key areas where LSH is used. The idea that LSH uses is “repurpose collisions”
    which states rather than avoiding collisions, make collisions happen for nearly
    data points. So, in LSH nearby or close enough data points are made to be fall
    in same bucket and distant data points in different buckets. More formally, the
    algorithm selects a hash family *H* and this hash family is locality sensitive
    if:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>P</mi><mi>r</mi><mo stretchy="false">[</mo><mi>h</mi><mo
    stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mi>h</mi><mo
    stretchy="false">(</mo><mi>B</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow></math>
    is high if *A* is close enough to *B*
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>P</mi><mi>r</mi><mo stretchy="false">[</mo><mi>h</mi><mo
    stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mi>h</mi><mo
    stretchy="false">(</mo><mi>B</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow></math>
    is low if *A* is far away from *B*
  prefs: []
  type: TYPE_NORMAL
- en: LSH is an idea of hashing items many times and comparing only those that fall
    into same bucket even atleast once. However, LSH doesn't guarantee to provide
    exact answers but they give a good approximation. In order to implement LSH,
  prefs: []
  type: TYPE_NORMAL
- en: First step is to perform shingling on the set of given documents.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second step is to perform minhashing that outputs short integer representation
    of sets in form of signatures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Notably, minhashing converts large sets to short signatures using hashing, while
    preserving similarity whereas LSH further finds pairs of signature that are likely
    to be similar.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Third step is to perform locality sensitive hashing that aims to find a small
    list of candidate pairs of signatures that are only evaluated for similarity check.
    Rather than probing all pair of a set for similarity check, only a list of candidate
    pairs are evaluated. To the minhash signature matrix, columns are hashed to different
    buckets using several hash functions and the documents that hashes to same bucket
    even for once are referred to as candidate pair.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rather than detecting completely similar documents, LSH finds similarity greater
    than *t* between documents. So, two columns C1 and C2 of min-hash signatures matrix
    are candidate pairs if their signatures agree for atleast fraction *t* of their
    signatures of rows. to perform hashing of a single column,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: First partition signature matrix into *b* bands, having *r* rows per band.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Hash each band of each column in any of *k* buckets. For better efficiency,
    take *k* as large as possible.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify the candidate pair that hashes to same bucket for atleast 1 band.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*b* and *r* should be selected to achieve most similar pairs and few non-similar
    pairs and also to eliminate false positives and false negatives. The more insight
    on choosing *b* and *r* is discussed next.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The concept of band partition and hash function computation of one band is represented
    in [Fig. 13.3](#fig13_3) and [13.4](#fig13_4).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Finally, main memory is accessed to test whether candidate pairs have really
    similar signatures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 13.3](../images/fig13_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 13.3.**'
  prefs: []
  type: TYPE_NORMAL
- en: Band partition in LSH.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.4](../images/fig13_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**FIGURE 13.4.**'
  prefs: []
  type: TYPE_NORMAL
- en: Hash function for one band.
  prefs: []
  type: TYPE_NORMAL
- en: Observation
  prefs: []
  type: TYPE_NORMAL
- en: For a 100 row signature matrix, if we choose 25 bands of 4 signature per band
    then there is higher probability for two given documents to fall in same hash
    buckets as the two documents will be hashed 20 times (one for each band) and only
    few signatures are getting compared in each band, i.e., only 5 as compared to
    another case with 10 bands of 10 signatures per band. Hence, there is higher chance
    for false positives if higher number of bands are selected. In contrast, chances
    of false negatives increases if we chose a lower value of number of bands.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose there are 100,000 column and 100 rows in signature matrix which implies
    size of signature matrix is 100*100000\. Lets assume number of bands chosen are
    20 with 5 signature per band. To understand existence of false positives and false
    negatives consider two cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Case 1**'
  prefs: []
  type: TYPE_NORMAL
- en: Assume similarity threshold to be 80%, i.e., we want to retrieve all documents
    that are 80%similar pairs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Probability that two columns C1, C2 are identical in one particular band: <math
    alttext="" display="inline"><mrow><msup><mrow><mo stretchy="false">(</mo><mn>0.8</mn><mo
    stretchy="false">)</mo></mrow><mn>5</mn></msup><mo>=</mo><mn>0.32768</mn></mrow></math>.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Probability that two columns C1, C2 are not identical in any of the 20 bands:
    <math alttext="" display="inline"><mrow><msup><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mn>0.328</mn><mo
    stretchy="false">)</mo></mrow><mrow><mn>20</mn></mrow></msup><mo>=</mo><mn>0.00035</mn></mrow></math>.
    which implies about <math alttext="" display="inline"><mrow><mfrac><mn>1</mn><mrow><mn>3000</mn></mrow></mfrac></mrow></math>
    th of truly 80% similar sets are false negatives.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Case 2**'
  prefs: []
  type: TYPE_NORMAL
- en: Take another case for two documents to be 40% similar.
  prefs: []
  type: TYPE_NORMAL
- en: 'Probability that two columns C1, C2 are identical in one particular band: <math
    alttext="" display="inline"><mrow><msup><mrow><mo stretchy="false">(</mo><mn>0.4</mn><mo
    stretchy="false">)</mo></mrow><mn>5</mn></msup><mo>=</mo><mn>0.01</mn></mrow></math>.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, probability that two columns C1, C2 are identical in atleast one of 20
    bands: <math alttext="" display="inline"><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mo
    stretchy="false">(</mo><mn>1</mn><mo>−</mo><mn>0.01</mn><mo stretchy="false">)</mo><mo
    stretchy="false">)</mo><mo>=</mo><mn>0.19</mn></mrow></math>. which implies that
    there is about 20% probability of false positives.'
  prefs: []
  type: TYPE_NORMAL
- en: Therefor *b* and *r* should be selected to achieve minimum rate of false positives
    and false negatives.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/list13_4a.jpg)![](../images/list13_4b.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[13.3.1 Simhash](contents.xhtml#rsec13_3_1)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Simhash is a variant of LSH and unlike typical cryptographic algorithm, simhash
    also tries to maximize the probability of collision for almost similar item [[62](bib.xhtml#ch00-bib-62)].
    It was proposed by Moses Chankar in order to detect near duplicate documents.
    Simhashing is based on the concept of sign random projection [[34](bib.xhtml#ch00-bib-34)].
    It basically reduces dimensionality of data and maps highly dimensional data to
    *f*-bit fingerprint (*f* is very small generated from hashing).
  prefs: []
  type: TYPE_NORMAL
- en: 'Simhash fingerprint is usally generated from any feature of document. The document
    feature is generally *k*-word shingles or frequency of word. To compute simhash
    fingerprint, follow the steps below:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate the features of documents.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Select a hash size *f* (8,16, 32.. etc.) and maintain a *f*-dimensional vector
    *V* and initialize all dimensions of vector to 0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hash each feature to *f*-bit hash value (These unique f-bits of each feature
    increments/decrements the final *f* value of vector).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For each unique *f*-bit hash value:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>i</mi><mi>f</mi><mi>b</mi><mi>i</mi><msub><mi>t</mi><mi>i</mi></msub><mi>o</mi><mi>f</mi><mi>h</mi><mi>a</mi><mi>s</mi><mi>h</mi><mi>i</mi><mi>s</mi><mi>s</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>n</mi><mo>,</mo><mi>a</mi><mi>d</mi><mi>d</mi><mn>1</mn><mi>t</mi><mi>o</mi><mi>f</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>l</mi><mi>f</mi><mo>−</mo><mi>b</mi><mi>i</mi><mi>t</mi><mi>v</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>o</mi><mi>r</mi><mo
    stretchy="false">(</mo><mi>V</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*elsifbitiofhashisnotset*,*substract*1*fromV[i]*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Final simhash bit vector has
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>b</mi><mi>i</mi><msub><mi>t</mi><mi>i</mi></msub></mrow></math>
    as 1 if <math alttext="" display="inline"><mrow><mi>V</mi><mo>[</mo><mi>i</mi><mo>]</mo><mo>></mo><mn>0</mn></mrow></math>
    and 0 otherwise.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For example, take a sentence “Data Structures”.
  prefs: []
  type: TYPE_NORMAL
- en: First, convert all higher case word to lower case word and divide into 3- word
    shingles, i.e., ‘dat’, ‘ata’, ‘tas’, ‘ast’, ‘str’, ‘tru’, ‘ruc’, ‘uct’, ‘ctu’,
    ‘tur’, ‘ure’, ‘res’.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hash each shingle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>d</mi><mi>a</mi><mi>t</mi><mo
    stretchy="false">)</mo><mo>=</mo><mn>10110000</mn></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>a</mi><mi>t</mi><mi>a</mi><mo
    stretchy="false">)</mo><mo>=</mo><mn>10100001</mn></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>t</mi><mi>a</mi><mi>s</mi><mo
    stretchy="false">)</mo><mo>=</mo><mn>10110010</mn></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>a</mi><mi>s</mi><mi>t</mi><mo
    stretchy="false">)</mo><mo>=</mo><mn>01100011</mn></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>s</mi><mi>t</mi><mi>r</mi><mo
    stretchy="false">)</mo><mo>=</mo><mn>10110100</mn></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>t</mi><mi>r</mi><mi>u</mi><mo
    stretchy="false">)</mo><mo>=</mo><mn>00100101</mn></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>r</mi><mi>u</mi><mi>c</mi><mo
    stretchy="false">)</mo><mo>=</mo><mn>10110110</mn></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>u</mi><mi>c</mi><mi>t</mi><mo
    stretchy="false">)</mo><mo>=</mo><mn>10111000</mn></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>t</mi><mi>u</mi><mi>r</mi><mo
    stretchy="false">)</mo><mo>=</mo><mn>01101001</mn></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>u</mi><mi>r</mi><mi>e</mi><mo
    stretchy="false">)</mo><mo>=</mo><mn>10111010</mn></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>r</mi><mi>e</mi><mi>s</mi><mo
    stretchy="false">)</mo><mo>=</mo><mn>01101011</mn></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*if <math alttext="" display="inline"><mrow><mi>s</mi><mi>h</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>l</mi><mi>e</mi><mo>.</mo><mi>h</mi><mo
    stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo>=</mo><mo>=</mo><mn>1</mn></mrow></math>*,
    *V[i]* is incremented by 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*if <math alttext="" display="inline"><mrow><mi>s</mi><mi>h</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>l</mi><mi>e</mi><mo>.</mo><mi>h</mi><mo
    stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo>=</mo><mo>=</mo><mn>0</mn></mrow></math>*,
    *V[i]* = is decremented by 1'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The *V* vector is represented by [Fig. 13.5](#fig13_5).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 13.5](../images/fig13_5.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '**FIGURE 13.5.**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Simhash example.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To compute final simhash fingerprint:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: if <math alttext="" display="inline"><mrow><mi>V</mi><mo>[</mo><mi>i</mi><mo>]</mo><mo>></mo><mn>0</mn></mrow></math>,
    *simhash[i]* = 1
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: else *simhash[i]*= 0
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: So, simhash fingerprint is <math alttext="" display="inline"><mrow><mo stretchy="false">(</mo><mn>10110000</mn><mo
    stretchy="false">)</mo></mrow></math>.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To detect similarity of document *d* with a given set of document. One solution
    is to take hamming distance of simhash fingerprint of fingerprint of *d* with
    all other documents simhash fingerprint value. However, with growing problem size
    this method is not efficient. In another approach, rather than comparing all simhash
    bits of document *d* with all bits in simhash value of document set, only compare
    some specific bit position. If they matches, only then hamming distance of two
    simhash fingerprint is computed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Activity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Multiple Choice Questions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Which one of the following is not a type of similarity search PDS?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Minhash
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Maxhash
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: LSH
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Simhash
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The space consumed by set of k-shingles with total of *n* words in a documents
    is?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>k</mi><mn>2</mn></msup><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>k</mi><mo>+</mo><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>3</mn></msup><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>k</mi><mo>*</mo><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The time consumed by signature matrix for comparing similar pairs is?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mfenced close=")" open="("><mtable><mtr><mtd><mi>n</mi></mtd></mtr><mtr><mtd><mn>2</mn></mtd></mtr></mtable></mfenced><mo
    stretchy="false">(</mo><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo
    stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>4</mn></msup><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: In general, probability of signature not to agree on any of the bands for two
    columns C1 and C2 is given by ?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><msup><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msup><mi>s</mi><mi>b</mi></msup><mo
    stretchy="false">)</mo></mrow><mi>r</mi></msup></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><msup><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msup><mi>s</mi><mi>b</mi></msup><mo
    stretchy="false">)</mo></mrow><mi>r</mi></msup></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><msup><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msup><mi>r</mi><mi>s</mi></msup><mo
    stretchy="false">)</mo></mrow><mi>b</mi></msup></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><msup><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msup><mi>b</mi><mi>r</mi></msup><mo
    stretchy="false">)</mo></mrow><mi>s</mi></msup></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which among the following is not a distance metric ?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Euclidean distance
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Hamming distance
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Cosine distance
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Signature distance
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the time complexity to compute jaccard similarity for *n* given document?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>3</mn></msup><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="" display="inline"><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo
    stretchy="false">)</mo></mrow></math>
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Higher number of bands in LSH implies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Lower false positives
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Higher false negatives
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Higher false positive
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Lower false negatives
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Locality sensitive hashing generates:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: False positives only
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: False negatives only
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Both false positives and false negatives
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Neither of false positive and false negatives
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
