- en: CHAPTER 9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Life 3.0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Among pines and dunes at the edge of a peninsula overlooking Monterey Bay stand
    the historic rustic stone buildings of Asilomar. Once a YWCA camp, and still without
    televisions or landlines in its guest rooms, this retreat is separated by an eighty-mile
    drive from Silicon Valley. Here in early January 2017 many of the leading researchers
    and luminaries of the information age secretly gathered under the auspices of
    the Foundational Questions Institute, directed by the MIT physicist Max Tegmark
    and supported by tens of millions of dollars from Elon Musk and Skype’s co-founder
    Jaan Tallinn.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most prominent participants were the bright lights of Google: Larry Page,
    Eric Schmidt, Ray Kurzweil, Demis Hassabis, and Peter Norvig, along with former
    Googler Andrew Ng, later of Baidu and Stanford. Also there was Facebook’s Yann
    LeCun, an innovator in deep-learning math and a protégé of Google’s Geoffrey Hinton.
    A tenured contingent consisted of the technologist Stuart Russell, the philosopher
    David Chalmers, the catastrophe theorist Nick Bostrom, the nanotech prophet Eric
    Drexler, the cosmologist Lawrence Krauss, the economist Erik Brynjolfsson, and
    the “Singularitarian” Vernor Vinge, along with scores of other celebrity scientists.[¹](notes.html#ch09note-1)'
  prefs: []
  type: TYPE_NORMAL
- en: They gathered at Asilomar preparing to alert the world to the dire threat posed
    by . . . well, by themselves—Silicon Valley. Their computer technology, advanced
    AI, and machine learning—acclaimed in hundreds of press releases as the Valley’s
    principal activity and hope for the future, with names such as TensorFlow, DeepMind,
    Machine Learning, Google Brain, and the Singularity—had gained such power and
    momentum that it was now deemed nothing less than a menace to mankind.
  prefs: []
  type: TYPE_NORMAL
- en: 'In 1965 I. J. Good, whom Turing taught to play Go at Bletchley Park while they
    worked on cracking the Enigma cipher, penned the first (and still the pithiest)
    warning:'
  prefs: []
  type: TYPE_NORMAL
- en: Let an ultra-intelligent machine be defined as a machine that can far surpass
    all the intellectual activities of any man however clever. Since the design of
    machines is one of those intellectual activities, an ultra-intelligent machine
    could design even better machines. There would unquestionably be an “intelligence
    explosion” and the intelligence of man would be left far behind.[²](notes.html#ch09note-2)
  prefs: []
  type: TYPE_NORMAL
- en: '“Thus,” Good declared, “the first ultra-intelligent machine is the last invention
    that man need ever make, provided that it is docile enough to tell us how to keep
    it under control.”[³](notes.html#ch09note-3) The message of the Asilomar experts
    was that keeping it under control is still an unsolvable problem. When a new supreme
    intelligence emerges, it is hard to see how an inferior human intelligence can
    govern it. As Musk put it, “It’s potentially more dangerous than nukes.”[⁴](notes.html#ch09note-4)
    Stephen Hawking pronounced: “The development of full artificial intelligence could
    spell the end of the human race.”[⁵](notes.html#ch09note-5)'
  prefs: []
  type: TYPE_NORMAL
- en: Tegmark explains why a “breakout,” in which the machines take over the commanding
    heights of the society and economy, is almost inevitable. When Homo sapiens came
    along, after all, the Neanderthals had a hard time, and virtually all animals
    were subdued. The lucky ones became pets, the unlucky lunch.
  prefs: []
  type: TYPE_NORMAL
- en: Asilomar was unveiling an industry on the march across the second half of Kurzweil’s
    exponential chessboard.[⁶](notes.html#ch09note-6) Everyone should watch out. New
    robotic kings would be popping up all over the board. “For any process whose power
    grows at a rate proportional to its current power,” explained Tegmark, “its power
    will keep doubling at regular intervals, in ultimately exponential explosions.”[⁷](notes.html#ch09note-7)
    To the Googleplex intellectuals, mathematics is essentially a doomsday machine.
  prefs: []
  type: TYPE_NORMAL
- en: Another possibility is that blather like this, which reveals the grandiose fatuity
    of contemporary “genius,” could discredit the prevailing system of the world.
  prefs: []
  type: TYPE_NORMAL
- en: 'Cynics—and there are some on the fringes of the AI shrine—might consider this
    secret meeting an ingenious publicity campaign for Silicon Valley’s most touted
    products. It was certainly a splendid sendoff for Tegmark’s tome, Life 3.0: Being
    Human in the Age of Artificial Intelligence, and a rousing launch for his Future
    of Life Institute. Secret meetings, particularly if packed with hundreds of famously
    loquacious celebrities, tend to generate far more attention than public ones do,
    and this summit was no exception.'
  prefs: []
  type: TYPE_NORMAL
- en: What tribute to one’s transformative brilliance could be more thrillling than
    the warning that your inventions threaten to attain consciousness and reduce human
    beings to patronized pets? The Asilomar Statement of AI Principles, signed by
    eight thousand scientists, representing a 97 percent consensus—including a passel
    of Nobel laureates and Hawking—echoed the billowy affirmations of Google’s own
    “Do No Evil” precepts and the statement of principles of Burning Man. “Superintelligence
    should only be developed in the service of widely shared ethical ideals, and for
    the benefit of all humanity rather than one state or organization. . . . An arms
    race in lethal autonomous weapons should be avoided.” One wonders what the 3 percent
    of dissenters had to say.
  prefs: []
  type: TYPE_NORMAL
- en: All in all, however, the statement was a bland summation of the new Silicon
    Valley system of the world, in which human beings are no longer the supreme intelligence
    or the significant inventors. Even new laws of physics, according to Tegmark,
    will have to come from AI. “Given that a super-intelligent computer has the potential
    to dramatically supersede human understanding of computer security, even to the
    point of discovering more fundamental laws of physics than we know today, it’s
    likely that if it breaks out, we’ll have no idea how it happened. Rather it will
    seem like a Harry Houdini breakout act, indistinguishable from pure magic.”[⁸](notes.html#ch09note-8)
  prefs: []
  type: TYPE_NORMAL
- en: 'The advocates of super-AI believe that it can propel human intelligence out
    into the cosmos in the form of silicon digital devices, escaping the limits of
    space exploration by vulnerable carbon-based human beings. Ultimately the breakout
    will sweep into the galaxy, with the intelligent machines contriving ever more
    powerful rockets bearing ever more miraculous minds and bionic bodies. Tegmark
    speculates about what that will look like: “after spending billions of years as
    an almost negligibly small perturbation on an indifferent lifeless cosmos, life
    suddenly explodes onto the cosmic arena as a spherical blast wave expanding near
    the speed of light, never slowing down, and igniting everything in its path with
    the spark of life.”[⁹](notes.html#ch09note-9) In Tegmark’s new creation story,
    digital machines become the dominant form of life.'
  prefs: []
  type: TYPE_NORMAL
- en: In the face of this new revelation from Silicon Valley, I decided to consult
    the most experienced and sophisticated of the Asilomar attendees, Ray Kurzweil,
    who for the past five years has been director of engineering at Google. Despite
    his reputation as one of the most extreme figures in the movement, I knew him
    to be an equable and undismayed master of the technology. When I asked him about
    Tegmark, he seemed somewhat abashed, as if he knew that this line of thought from
    his alma mater, MIT, was not going as he might have wished.
  prefs: []
  type: TYPE_NORMAL
- en: Kurzweil has been studying and fashioning forms of artificial intelligence ever
    since he was a fourteen-year-old prodigy-protégé of MIT’s Marvin Minsky, a career
    that encompasses the entire history of the field. In late 2017, Kurzweil confided
    that he has been consulting his mentor for new insights on the fast developing
    technology. With a mischievous twinkle in his eye, he said he was surprised to
    discover that Minsky has become more articulate and responsive recently—perhaps
    surprising in view of the inconvenience of his death two years ago.
  prefs: []
  type: TYPE_NORMAL
- en: Conducting what he calls a “semantic search” of all ten of Minsky’s compendious
    books—that is, searching for specific associative meanings rather than blind “key
    words”—Kurzweil was able to get answers instantly from the deceased AI legend.
    Kurzweil has used the same program to explore his own works and rediscover insights
    that had slipped away over time, presumably displaced in memory by the newer concepts
    of his semantics program. If you have Gmail on your smartphone, you have seen
    the fruits of Kurzweil’s semantic breakthroughs in the three proposed responses
    underneath each new email you receive.
  prefs: []
  type: TYPE_NORMAL
- en: To the more intoxicated of the Asilomar congregants, semantic search is a “super-human”
    capability, surpassing a search by sequence of words, which can fail if the words
    are not recalled exactly. By rendering each word as a cluster of synonyms and
    associations in longer sequences up a hierarchy of meanings, Kurzweil’s “semantic
    search” operates as a vast computer acceleration of a cumbersome human perusal
    of a pile of texts.
  prefs: []
  type: TYPE_NORMAL
- en: As Kurzweil acknowledges, semantic search is an “extension of human intelligence”
    rather than a replacement for it. A human being reinforced by AI prosthetics is
    less likely, not more likely, to be ambushed by a usurper digital machine. Semantic
    search delays the machine-learning eschaton.
  prefs: []
  type: TYPE_NORMAL
- en: Also at Google in late October 2017, the DeepMind program launched yet another
    iteration of the AlphaGo program, which, you may recall, repeatedly defeated Lee
    Sedol, the five-time world champion Go player. The tree search in AlphaGo evaluated
    positions and selected moves using deep neural networks trained by immersion in
    records of human expert moves and by reinforcement from self-play. The blog Kurzweil.ai
    now reports a new iteration of AlphaGo based solely on reinforcement learning,
    without direct human input beyond the rules of the game and the reward structure
    of the program.
  prefs: []
  type: TYPE_NORMAL
- en: In a form of “generic adversarial program,” AlphaGo plays against itself and
    becomes its own teacher. “Starting tabula rasa,” the Google paper concludes, “our
    new program AlphaGo Zero achieved superhuman performance, winning 100–0 against
    the previously published, champion-defeating AlphaGo.”[^(10)](notes.html#ch09note-10)
  prefs: []
  type: TYPE_NORMAL
- en: The claim of “superhuman performance” seemed rather overwrought to me. Outperforming
    unaided human beings is what machines—from a 3D printer to a plow—are supposed
    to do. Otherwise we wouldn’t build them. A deterministic problem with few constraints—a
    galactic field to plow—Go is perfectly suited to a super-fast computer. Functioning
    at millions of iterations per second, the machine soon reduces all human games
    of Go ever played to an infinitesimal subset of its own experience. It may be
    said to “discover” millions of solutions beyond human reach just as a space probe
    may “discover” regions of space beyond human ken. But speed of iteration is not
    the same as intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: Because Go is a game of pure strategy without differentiated pieces like chess,
    a computer can exhaust the solutions more efficiently than in chess, with its
    smaller solution space. The Asilomar eschatologists miss the difference between
    computing-speed and intelligence, between programmable machines and programmers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Tegmark makes the case as well as it can be made that the attainments of AI
    programs—“Watson” the quiz-show winner and occasionally superior medical diagnostician;
    Big Blue the chess champion; Google’s DeepMind game players, which learned to
    outperform human players from scratch in dozens of electronic games; the face-recognizers;
    the natural language translators; the self-driving car programs—portend a super-intelligence
    that will someday be so superior to the human mind that we will no more comprehend
    its depths than a dog grasps the meaning of our own cerebrations. It is just a
    matter of time. Although shunning the dystopian interpretation, Kurzweil boldly
    offers a date: 2049\. Tegmark likes to quote Edward Robert Harrison: “Hydrogen,
    given enough time, turns into people.” People, given enough time, presumably turn
    into Turing machines, and Turing machines are essentially what people used to
    call “God.” He isn’t shy about the godlike powers this super-AI will have: “Whatever
    form matter is in, advanced technology can rearrange it into any desired substances
    or objects, including power plants, computers, and advanced life forms.”'
  prefs: []
  type: TYPE_NORMAL
- en: Life 3.0 and Asilomar are declarations of principles for a post-human age. The
    conclusion is that the last significant human beings are the inventors of super-intelligent
    AI. People like Hassabis, Norvig, LeCun, and Page. Pay them tribute while you
    can and hope that they will be indulgent if you sign up for their movement. Life
    3.0 is silicon-based and machine-generated.
  prefs: []
  type: TYPE_NORMAL
- en: Like everyone in the movement, from Page to Kurzweil, Tegmark is a sophisticated
    modern man who recognizes that there are many imponderables. In his book, he even
    imagines some persons being allowed to opt out of a relatively benevolent AI regime
    and set up human-only zones.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the patronizing spirit common in the field, he writes: “The small fraction
    of humans who have opted to live in these zones, effectively exist in a lower
    and more limited plane of awareness from everyone else, and have limited understanding
    of what their more intelligent fellow minds are doing in the other zones. However,
    many of them are quite happy with their lives.”'
  prefs: []
  type: TYPE_NORMAL
- en: The problem is not AI itself, which is an impressive technology with much promise
    for improving human life. What transforms “super-AI” from a technology into a
    religious cult is the assumption that the human mind is essentially a computer,
    a material machine. That assumption springs from a belief in evolution as a random
    process that has produced sub-optimal human brains, relatively crude computer
    “wetware,” which in time can be excelled in silicon.
  prefs: []
  type: TYPE_NORMAL
- en: This assumption leads to a preoccupation with the likelihood of extraterrestrial
    beings. Although Kurzweil and Tegmark are both smart enough or canny enough to
    dismiss the existence of extraterrestrial minds, most of the movement is intoxicated
    by the view that we are not alone. The usual conclusion is that intelligent life
    on other planets is so easy, so determined by material forces, that it is “inevitable.”
    Expressing this assurance is SETI, the “search for extraterrestrial intelligence,”
    a collective effort conducted on hundreds of thousands of computers around the
    globe searching through electromagnetic debris for a glint of mind elsewhere in
    the universe. Nothing has turned up in thirty-five years or so, but Yuri Milner,
    the great Russian physicist-investor, has pumped another $100 million into the
    cause in his “Breakthrough Listen” project.
  prefs: []
  type: TYPE_NORMAL
- en: All these pursuits reflect a breakdown of terrestrial intelligence. The intellectuals
    of this era are simply blind to the reality of consciousness. Consciousness is
    who we are, how we think, and how we know. It echoes with religious intuitions
    and psychological identity. It is the essence of mind as opposed to machine. It
    is the source of creativity and free will. If you don’t understand it, you may
    have a theory of computers but you do not have a notion of intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: All the AI scenarios assume the premise of AI super-intelligence with anthropomorphic
    consciousness, will, feelings, imagination, creativity, and independence. But
    in presenting every cockamamie view they can imagine, Tegmark and the other AI
    champions never come close to demonstrating that voltages, transistor gates, memory
    capacitors, and flip-flops can somehow know or learn anything, let alone become
    willful and conscious or independent of their human programmers.
  prefs: []
  type: TYPE_NORMAL
- en: The debating-point response of the super-AI proponents is that the human mind
    consists of electrical and chemical components that are unintelligent in themselves.
    But here we encounter the Gödel-Turing difficulty of self-reference. By referring
    back to their own brains, which they don’t really understand, the AI scientists
    plunge directly into the self-referential Gödel perplex. By using their own minds
    and consciousness to deny the significance of consciousness in minds, they refute
    themselves.
  prefs: []
  type: TYPE_NORMAL
- en: As Turing concluded, they need an “oracle”—a source of intelligence outside
    the system itself—and all he could say about the oracle is that it “could not
    be a machine.” Turing saw that computers repeat the uncertainties of physics that
    stem from recursive self-reference. Just as physics founders when it tries to
    use instruments made of electrons and photons to measure electrons and photons,
    artificial intelligence founders when computers use computers to explain themselves.
  prefs: []
  type: TYPE_NORMAL
- en: Consciousness and free will are self-reference without determinism. The AI experts
    want to deny it, but until they come to terms with consciousness they cannot explain
    mind. Kurzweil seems to believe that consciousness can be put to the side. His
    book How to Create a Mind is the most systematic exposition of AI and, like his
    masterpiece, The Singularity Is Near, full of original insights. But on the issue
    of consciousness both books plunge into circularity, merely asserting that when
    a machine is fully intelligent it will be recognized as conscious. Gödel smiled.
  prefs: []
  type: TYPE_NORMAL
- en: A symbol machine does not know anything. Software symbols represent phenomena
    that have been perceived consciously—known—by the outside Turing oracle, the programmer.
    This “cannot be a machine” because it supplies the assumptions and axioms and
    procedures on which the computer’s logical machine depends.
  prefs: []
  type: TYPE_NORMAL
- en: 'The blind spot of AI is that consciousness does not emerge from thought; it
    is the source of it. As Leibnitz, imagining a computer blown up to the size of
    a building, observed in the seventeenth century, inside the machine (the determinist
    scheme), you find cogs and gears but no cognition. The oracle programmer must
    be outside. How a software programmer can miss the essence of his own trade is
    a mystery, but Chesterton understood the myopia of the expert:'
  prefs: []
  type: TYPE_NORMAL
- en: The . . . argument of the expert, that the man who is trained should be the
    man who is trusted, would be absolutely unanswerable if it were really true that
    the man who studied a thing and practiced it every day went on seeing more and
    more of its significance. But he does not. He goes on seeing less and less of
    its significance.[^(11)](notes.html#ch09note-11)
  prefs: []
  type: TYPE_NORMAL
- en: The materialist superstition is a strange growth in an age of information. Writing
    from his home, which he named “Entropy House,” Shannon showed that information
    itself is measured by unexpected bits—by its surprisal. This is a form of disorder
    echoing the disorder of thermodynamic entropy. Information is surprise. A determinist
    machine is by definition free from surprise. The answers are always implicit in
    the questions. There is no entropy, nothing unexpected.
  prefs: []
  type: TYPE_NORMAL
- en: This point eludes many of the great minds of the era, who imagine that information
    is order, or, as they sometimes put it, revealing their incomprehension, negentropy.
    In both thermodynamics and information theory, entropy is disorder, not order.
    Order defines the expected bits, the redundancy. Entropy measures the unexpected
    ones and gauges the information, measured by the degrees of freedom in the message.
  prefs: []
  type: TYPE_NORMAL
- en: Gauged by the unexpected deformation of a regularity, information is neither
    fully determined nor fully random. As Shannon put it, information is stochastic,
    adapting a Greek word that means “to aim at.” It combines probabilities with skills,
    and randomness with structure. Information is maximized in a high-entropy message
    borne by a low-entropy carrier, such as the modulated code-bearing light in a
    fiber-optic line.
  prefs: []
  type: TYPE_NORMAL
- en: After von Neumann, Shannon was the most important figure in the establishment
    of the system of the world that Google now embodies. I would like to say that
    he showed the way out. But Shannon himself ended up enmeshed in the same materialist
    superstition that afflicts the Google Age. “I think man is a machine of a very
    complex sort,” he wrote, “different from a computer, i.e., different in organization.
    But it could be easily reproduced—it has about ten billion nerve cells. . . .
    And if you model each one of these with electronic equipment it will act like
    a human brain. If you take [chess master Bobby] Fischer’s head and make a model
    of that, it would play like Fischer.”
  prefs: []
  type: TYPE_NORMAL
- en: Shannon here is expressing the materialist faith. The brain consists of ten
    billion neurons governed by electrical impulses and presumably chemical reactions.
    For a devotee of materialism, this view is apodictically true; after all in the
    flat-universe theory there is nothing else present except the chemical and physical
    elements.
  prefs: []
  type: TYPE_NORMAL
- en: 'To a closer observer, as Shannon or Kurzweil understands, there is something
    else: the pattern, the design, the form, the configuration—altogether the information.
    But if you challenge the bottom-up assumption of the sufficiency of physics and
    chemistry to explain it all, he might say, “More dimensions—I have no need for
    that hypothesis.” Eclipsing consciousness, freedom of choice, and surprise, this
    faith ultimately defies information theory itself. Information depends on the
    range of freedom of choice and the surprise that can be perceived only by a conscious
    being.'
  prefs: []
  type: TYPE_NORMAL
- en: This materialist superstition keeps the entire Google generation from understanding
    mind and creation. Consciousness depends on faith—the ability to act without full
    knowledge and thus the ability to be surprised and to surprise. A machine by definition
    lacks consciousness. A machine is part of a determinist order. Lacking surprise
    or the ability to be surprised, it is self-contained and determined.
  prefs: []
  type: TYPE_NORMAL
- en: An unconscious body is simply a hermetically logical system, which as both Gödel
    and Turing proved is necessarily incomplete and in need of an “oracle.” Knowledge
    of this incompleteness is the human condition, felt intuitively and manifested
    in consciousness. The “I” emerges in the domain of faith beyond the machines of
    logic.
  prefs: []
  type: TYPE_NORMAL
- en: Real science shows that the universe is a singularity and thus a creation. Creation
    is an entropic product of a higher consciousness echoed by human consciousness.
    This higher consciousness, which throughout human history we have found it convenient
    to call God, endows human creators with the space to originate surprising things.
  prefs: []
  type: TYPE_NORMAL
- en: This is the mirrored room of cosmic thought, reflective intelligence. Consciousness
    precedes creation, the word precedes the flesh.
  prefs: []
  type: TYPE_NORMAL
- en: “The central mistake of recent digital culture,” writes Jaron Lanier, “is to
    chop up a network of individuals so finely that you end up with a mush. You then
    start to care about the abstraction of the network more than the real people who
    are networked, even though the network by itself is meaningless. Only the people
    were ever meaningful.”[^(12)](notes.html#ch09note-12)
  prefs: []
  type: TYPE_NORMAL
- en: AI cannot compete with the human intelligence that connects symbols and objects.
    AI cannot do without the human minds that provide it with symbol systems and languages;
    programs it; structures the information it absorbs in training, whether word patterns
    or pixels; provides and formulates the big data in which it finds numerical correlations;
    and sets up the goals and reward schemes and target sequences that allow it to
    iterate, optimize, and converge on a solution. Consisting of inputs cascading
    through complex sets of algorithms to produce outputs, AI cannot think at all.
  prefs: []
  type: TYPE_NORMAL
- en: Thinking is conscious, willful, imaginative, and creative. A computer running
    at gigahertz speeds and playing a deterministic game like chess or Go is only
    a machine. The idea that it is superhuman makes sense only if the abacus or calculator
    is superhuman. Artificial intelligence refers to the output of computer algorithms
    that consist of ingeniously arranged electronic elements—currents, voltages, inductances,
    and capacitances—that gain their meaning from Boolean logical schemes, tree structures,
    and “neural nets.” They achieve their utility from human languages and other symbol
    systems, including the computer languages and mathematical reasoning that program
    them.
  prefs: []
  type: TYPE_NORMAL
- en: America’s greatest philosopher, Charles Sanders Peirce, expounded this underlying
    reality when he developed his theory of signs and symbols, objects and interpreters.
    Although he wrote some 150 years ago, Peirce’s insights remain relevant to the
    latest software package or machine learning claim. In words that Turing would
    echo in describing his “oracle,” Peirce showed that symbols and objects are sterile
    without “interpretants,” who open the symbols to the reaches of imagination. Peirce’s
    “sign relation” binds object, sign, and interpreter into an irreducible triad.
    It is fundamental to any coherent theory of information that every symbol be linked
    inexorably to its object by an interpreter, a human mind. An uninterpreted symbol
    is meaningless by definition, and any philosophy that deals in such vacuities
    is sure to succumb to hidden assumptions and interpretive judgments.[^(13)](notes.html#ch09note-13)
  prefs: []
  type: TYPE_NORMAL
- en: In an industry based on substrate-independent information, materialism’s basic
    error of banishing the interpreter is deadly to the development of new technology.
    You cannot grasp the intricacies of computer science with a model of the world
    consisting of fluctuating particles any more than a model of fluctuating particles
    can illuminate the brain. Knowledge of every quark and electron in a computer
    tells you virtually nothing of what the computer is doing. To know that, you have
    to address the source code, and the source code is the ground state where human
    interpretation is imparted.
  prefs: []
  type: TYPE_NORMAL
- en: The 2017 Asilomar conference called to mind a conference held at the same place
    in February 1975, at which scientists warned about the future of technology—in
    that case, genetic engineering. They feared that experiments enabling molecular
    biologists to splice DNA from two different organisms, producing novel recombinant
    DNA molecules and chimeras, would threaten all human life. Within a decade, so
    the attendees prophesied, “scientists will be able to create new species and carry
    out the equivalent of 10 billion years of evolution in one year.”
  prefs: []
  type: TYPE_NORMAL
- en: More than four decades later, the hopes and fears of the 1975 Asilomar conference
    are nowhere near to coming true. The roots of nearly a half-century of frustration
    reach back to the meeting in Königsberg in 1930, where von Neumann met Gödel and
    launched the computer age by showing that determinist mathematics could not produce
    creative consciousness. Von Neumann stepped forward to become the oracle of the
    age we are now consummating.
  prefs: []
  type: TYPE_NORMAL
- en: Reflecting on the 1975 conference, the eminent chemist-biologist Michael Denton
    concludes, “The actual achievements of genetic engineering are rather more mundane . . .
    , a relatively trivial tinkering rather than genuine engineering, analogous to
    tuning a car engine rather than redesigning it, an exploitation of the already
    existing potential for variation which is built into all living systems. . . .
    ” Thousands of transgenic plants have been developed with results “far from the
    creation or radical reconstruction of a living organism.”[^(14)](notes.html#ch09note-14)
    All that the first Asilomar conference managed to achieve was triggering an obtuse
    paranoia about “genetically modified organisms” that hinders agricultural progress
    around the world.
  prefs: []
  type: TYPE_NORMAL
- en: That danger of paranoid politics is the chief peril that all the Deep Learners
    at the new Asilomar should have recognized.
  prefs: []
  type: TYPE_NORMAL
- en: Among the Deep Learners and Google brains at the AI Asilomar was Vitalik Buterin,
    a twenty-three-year-old college dropout with the same etiolated, wide-eared, boy-genius
    look that characterized Gödel and Turing. The assembled masters of the high-tech
    universe may have understood him about as well as the mathematicians in Königsberg
    understood the twenty-four-year-old Gödel in 1930, though the audience at Asilomar
    had advance notice of the significance of Buterin’s work.
  prefs: []
  type: TYPE_NORMAL
- en: Buterin succinctly described his company, Ethereum, launched in July 2015, as
    a “blockchain app platform.” The blockchain is an open, distributed, unhackable
    ledger devised in 2008 by the unknown person (or perhaps group) known as “Satoshi
    Nakamoto” to support his cryptocurrency, bitcoin. Buterin’s meteoric rise was
    such that soon after the Asilomar conference the central bank of Singapore announced
    that it was moving forward with an Ethereum-backed currency, and other central
    banks, including those of Canada and Russia, are investigating its potential as
    a new foundation for money transactions and smart contracts.
  prefs: []
  type: TYPE_NORMAL
- en: But Buterin’s vision for the blockchain has long been broader than cryptocurrency.
    Ethereum’s contribution, its co-founder Joe Lubin predicts, will be an Internet
    without “a single powerful entity that controls the system or controls gatekeeping
    into the system.”[^(15)](notes.html#ch09note-15) Wired magazine speculated in
    2014 that smart contracts, such as Buterin designed Ethereum to facilitate, “could
    lead to the creation of autonomous corporations—entire companies run by bots instead
    of humans.”[^(16)](notes.html#ch09note-16) If you were convening a summit of futuristic
    technologists in 2017, it would have been hard to avoid inviting the prophetic
    protagonist of Ethereum.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps Buterin, who launched Bitcoin Magazine while working as research assistant
    to the cryptographer Ian Goldberg, is the truest legatee of Shannon’s vision.
    Like Shannon he can move seamlessly between the light and dark sides of information,
    between communication and cryptography. Shannon’s information theory, like Turing’s
    computational vision, began with an understanding of codes. His first major paper,
    “A Mathematical Theory of Cryptography” (1945) proved that a perfect randomized
    one-time pad constitutes an unbreakable code, a singularity. The theory of information
    deals with a continuum between white noise (purely random) and perfect order (predictable
    and information-free). Shannon’s paper focused attention on the fertile domains
    of redundancy in between, which he dubbed “stochastic.” This region of controlled
    or bounded probability comprises the subject of communications, information codes,
    encryption, and decryption that is the heart of bitcoin, blockchain, and Ethereum.
  prefs: []
  type: TYPE_NORMAL
- en: At Asilomar, Buterin might have offered incisive recommendations for how to
    control the machine through the blockchain. But Tegmark does not mention him in
    Life 3.0. Larry Page, Elon Musk, and the paladins of Google’s DeepMind are the
    heroes. On page [236](ch20.html#page_236), though, it is suggested that a ruling
    super-intelligent AI might well invent a new cosmic cryptocurrency “in the spirit
    of bitcoin”—as if the mysterious Satoshi might have been an AI program.
  prefs: []
  type: TYPE_NORMAL
- en: The strong implication is that Buterin and his colleagues will have to take
    a back seat in the AI bandwagon, which represents the climactic technology in
    the history of human invention. The idea of a new generation of transformational
    technologists does not fit the plot line of a new eschaton.
  prefs: []
  type: TYPE_NORMAL
- en: But Google and its world are looking in the wrong direction. They are actually
    in jeopardy, not from an all-powerful artificial intelligence, but from a distributed,
    peer-to-peer revolution supporting human intelligence—the blockchain and new crypto-efflorescence.
    Buterin and his allies are dedicated to restoring data to its originators and
    incorporating it horizontally and interoperatively across the cryptocosm. Google’s
    security foibles and AI fantasies are unlikely to survive the onslaught of this
    new generation of cryptocosmic technology.
  prefs: []
  type: TYPE_NORMAL
