- en: © Springer Nature Switzerland AG 2020A. M. LangerAnalysis and Design of Next-Generation
    Software Architectures[https://doi.org/10.1007/978-3-030-36899-9_8](https://doi.org/10.1007/978-3-030-36899-9_8)
  prefs: []
  type: TYPE_NORMAL
- en: 8. Quantum Computing, AI, ML, and the Cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Arthur M. Langer^([1](#Aff2) [ ](#ContactOfAuthor2))(1)Center for Technology
    Management, Columbia University, New York, NY, USAArthur M. LangerEmail: [al261@columbia.edu](mailto:al261@columbia.edu)'
  prefs: []
  type: TYPE_NORMAL
- en: As discussed in Chap. [1](480347_1_En_1_Chapter.xhtml), quantum computing while
    not yet scalable has the potential to change the processing capabilities of computing
    especially for ML and AI processing. Without getting into the detailed hardware
    technicalities, the essential advantage of quantum is that it can evaluate many
    potential answers simultaneously (superposition) that results in improving calculation
    speeds immensely. Traditional computers behave in a sequential manner, but quantum
    allows multiple calculations to take place simultaneously and yet be related to
    the same problem. It’s like having dimensions of processing but somehow offering
    one solution. Because of this advantage, there are also disadvantages. Specifically,
    quantum provides value for certain types of computational problems. Where such
    computational algorithms are not to the advantage of quantum there is no performance
    improvement from traditional binary-based computers. The true benefit then of
    quantum computing is dealing with uncertainty problems These are also known as
    “quantum algorithms” which can solve difficult equations in many different ways.
    For example, the successful quantum algorithm called factorization created by
    Peter Shore of AT&T Bell Laboratories proved that quantum could factor large numbers
    into their prime factors in seconds compared to a classical computer that could
    almost take forever. These types of benefits tend to favor performance improvements
    in ML and AI which require large data crunching to solve or analyze complex datasets
    . One can see then that quantum is a very attractive alternative to speeding up
    computations that can provide incredible results for predictive analytic issues.
    Picture the value that quantum brings when analyzing causes of disease, or maximizing
    optimizations across sectors and use cases for smart cities, traffic systems,
    lights, meters, utilities, buildings all at the same time. Quantum allows for
    these simultaneous computations to take place and yet maintain a relationship
    with each other (called entanglement). Traditional computers would need to analyze
    each computation sequentially ultimately limiting scalability.
  prefs: []
  type: TYPE_NORMAL
- en: 8.1 Datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With enormous processing speed potential, quantum computing allows for quicker
    analysis and better integration of distributed large datasets of information.
    This is accomplished using extensive search and determinations of the patterns
    that exist in data that otherwise could not be accomplished to have an impact
    on business applications. Furthermore, quantum computers expand the potential
    to examine large databases that could be distributed across multiple network and
    machine platforms. Finally, datasets , databases , and other data structures can
    all be investigated to render correlations that provide valuable probabilities.
    As quantum evolves it can dramatically alter hardware architectures, accelerate
    the proliferation of IoT devices that may indeed result in changing the way companies
    use their data for competitive advantage.
  prefs: []
  type: TYPE_NORMAL
- en: 8.2 IoT and Quantum
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Economist’s Business Insider Intelligence (2018) has forecasted that by 2023
    consumers , companies, and governments will install 40 billion IoT devices globally.
    The result of these installations will generate massive data on a daily basis.
    The challenge for any analyst will be to understand how to approach the processing
    of this data to ultimately generate useful information and knowledge. I have already
    established the importance of IoT security. Think further of this importance as
    these IoT devices begin to generate what will likely be very sensitive information.
    Therefore, for IoT to reach its potential the confidentiality of consumer data
    must be protected and even guaranteed. Another interesting advantage of a quantum
    machine is its potential to generate secured systems using cryptography from quantum
    fed algorithms that require very large machines. These machines, as I have previously
    mentioned are typically not available to hackers. In theory, however, quantum
    cryptography should be able to generate keys that are totally random, unique,
    and incapable of being replicated. And with the speed of quantum calculations,
    a unique long key can be generated per transaction.
  prefs: []
  type: TYPE_NORMAL
- en: 8.3 AI, ML and Predictive Analytics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having established that quantum’s role is to help crunch massive amounts of
    data, the next challenge is to determine how to collect the data, store it, and
    what algorithms will be needed to obtain valuable information that can be used
    to make predictions. One must accept the fact that the voluminous data certainly
    is beyond the human capacity to derive meaningful predictive data, not to mention
    how long it might take to even if an individual could process the data!
  prefs: []
  type: TYPE_NORMAL
- en: In the past, obtaining data and analyzing it to make predictions required trained
    personnel in areas such as mathematics, statistics, and computer science. However,
    today there are now advanced APIs that can be obtained that can allow non-technical
    people to get results. So, again the analyst needs to start thinking of the data
    especially identifying what that data does and where it should reside!
  prefs: []
  type: TYPE_NORMAL
- en: 'The strategy relating to predictive analytics is quickly becoming more focused
    on the ML component of AI. The reason for this development is simple: most organizations
    likely do not know or understand the data they possess. Yes, they might know the
    business elements they store, but ML provides a whole new opportunity. For example,
    most business environments are broken down into functional units or divisions.
    Individuals that operate within these divisions are often siloed in such a way
    that they know their own data, but little about the data in other divisions that
    contain important related data that can provide value not only for their division,
    but the business overall. Thus, they do not know what to search for, because they
    know little of the opportunity. Furthermore, there is massive information that
    tends not to get stored in a way that allows for easy understanding of value.
    Transaction data updates databases which in turn is used to gather the information
    for reporting and analysis. This is particularly true for different types of transactional
    data that comes from consumers as well as data that results from their behaviors.
    Anyone who has spent time on Amazon or other consumer sites has experienced the
    application offering the consumer other opportunities based on their search behavior
    on the retail website. These behaviors are stored in the form of transactions
    and then fed into datasets that can be analyzed by machine-driven algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: 'With any new software opportunities comes dangers, and such is true with ML.
    Below are some of the setbacks that can occur:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Lack of transactions or examples that can render dependable and generalizable
    results to draw conclusions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Similar inputs can sometimes render different outputs. To have effective predictions
    there must be a clear relationship between inputs and outputs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mistakes in categorization of data is a killer. We have all seen the problems
    when a data element is not defined appropriately.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Incorrect or inappropriate example used. These are cases where certain factors
    are not considered. We see this occur when certain factors affect consumer habits
    that were not considered in the use case .
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Challenge of tagging data and then classifying all of its relationships.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '6.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implementing Natural language Processing where inputs are purely textual and
    outputs are often categorical. This challenge is how to take textual input and
    determine an output value such as positive or negative.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'There are two types of ML algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Training: learning a model from examples. This algorithm is also known as a
    learning algorithm because it examines sets of inputs and outputs and crates a
    new model based on the datasets.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.Prediction: takes an existing model with a new input and returns an output
    value as shown in Fig. [8.1](#Fig1).![../images/480347_1_En_8_Chapter/480347_1_En_8_Fig1_HTML.png](../images/480347_1_En_8_Chapter/480347_1_En_8_Fig1_HTML.png)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fig. 8.1
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Example of training to prediction algorithms
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: What occurs in Fig. [8.1](#Fig1) is a simple way of predicting a value that
    might be missing from a dataset. This can often occur from converted data from
    a legacy or earlier version of application data. By examining the new application
    data ML and establish a model that might predict what that missing element would
    have been in the old system as shown in Fig. [8.2](#Fig2).![../images/480347_1_En_8_Chapter/480347_1_En_8_Fig2_HTML.png](../images/480347_1_En_8_Chapter/480347_1_En_8_Fig2_HTML.png)
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 8.2
  prefs: []
  type: TYPE_NORMAL
- en: Updating legacy data element using ML training and prediction algorithms
  prefs: []
  type: TYPE_NORMAL
- en: Figure [8.2](#Fig2) shows that the legacy system did not store or capture a
    student’s graduation rate. In the new or replacement system, a data element was
    added to capture the student’s graduation rate. When the legacy records are converted
    ML could use a training algorithm to review the relationship between GPA Score
    and Graduation Rate to see if there is a correlation among the records in the
    new system. Should that correlation have predictability and the dataset in the
    new system is large enough, then the prediction algorithm could derive a graduation
    rate from the student’s GPA Score in the old system and calculate a Graduation
    Rate. We can see from this example that training algorithm can indirectly be used
    to create the prediction module in a sequence. The size of the dataset that would
    likely be deemed appropriate based on forms of statistics theory.
  prefs: []
  type: TYPE_NORMAL
- en: 8.4 ML in a Service Environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'ML can be designed as a service in the cloud . In this design an ML program
    and datasets can be stored on a separate and powerful server (preferably a quantum
    processor!) that could provide the necessary performance needed to deliver results
    quickly. This type of network architecture can be developed using three types
    of ML APIs according to Dorard ([2014](#CR1)) as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Specialized Prediction*: these APIs do very specific tasks like determining
    the speaking language embedded in a text. Specialized prediction APIs may often
    be available from third party libraries. Because these APIs specific but common
    they tend to be easier to implement.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Generic* *Predictor* : this API represents the training to predictor algorithm
    example shown in Fig. [8.2](#Fig2). So, there are two algorithms needed in the
    generic predictor , one to create a training model based on previous data and
    one that utilizes the training model to deal with new input. Generic predictor
    APIs are particularly effective for regression problems (algorithms that predict
    a real value).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Algorithm APIs*: these APIs, while similar to Generic Predictors are much
    more focused on a specific problem, so the parameter must be very specific. Indeed,
    think of algorithm APIs are specialty problem solvers. Should a specialize algorithm
    API not be available, then a generic API can be used by adding training data.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 8.5 Analysis ML Use Cases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An analyst can participate in ML design by providing types of use cases for
    developers. Dorard ([2014](#CR1)) provides a format to follow:'
  prefs: []
  type: TYPE_NORMAL
- en: 'WHO: who does the example concern?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DESCRIPTION: what is the context, and what are we trying to do?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'QUESTIONS ASKED: how would you write the questions that the predictive model
    should give answers to in plain English?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'TYPE OF ML PROBLEM: classification or regression?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'INPUT: what are we doing predictions on?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'FEATURES: which aspects of the inputs are we considering, and what kind of
    information do we have in their representation?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'OUTPUT: what does the predictive model return?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DATA COLLECTION: how are example input-output pairs obtained to train the predictive
    model?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'HOW PREDICTIONS ARE USED: when are predictions being made, and what do we do
    once we have them?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As one can see the analysts provides a guideline of questions to be answered
    as opposed to the answers to these questions. Clearly ML design then requires
    subject matter experts to answer these questions, or a consumer /user community
    that can define certainly the output needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Below and using Dorard’s Pricing Optimization example shows the use case with
    actual answers to the questions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'WHO: Shops, stores, and sellers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DESCRIPTION: We are introducing a new product within existing category of products
    that are already being sold, and we want to predict how we should price this new
    product; the product could be, for example, a bottle of wine in a wine shop. Or
    a new house for sales.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'QUESTIONS ASKED: “What should be the price of this new product in this given
    (and fixed) category?”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'TYPE OF ML PROBLEM: Regression.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'INPUT: Product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'FEATURES: Information about the product, specific to its category. In the wine
    bottle example, this could be the region or origin, the type of grapes, or the
    rating from a wine magazine. In the house example, this can be the number of bedrooms,
    bathrooms, the surface, the year it was built, or the type of house. We can also
    include a text description, and, when relevant, the cost to manufacture the product
    and the number of sales (total or per period of time).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'OUTPUT: Price.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DATA COLLECTION: Every time a product of the same category was sold, we log
    the price at which it went. Note that the same product might be sold several times
    (or not) and at the same or different prices, which affect the number of training
    data points.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'HOW PREDICTIONS ARE USED: We set the price of the product to the value given
    the predictive model (no need to add a margin, this is already incorporated by
    the nature of the training data). Note that if the number of sales is one of the
    features, we need to do a manual estimation of this for the new product before
    we can make a prediction on it. Besides, since prices are likely to change over
    time, it is important to frequently update the predictive model with new data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 8.6 Data Preparation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One can see that the most important aspect of ML is the quality of the data.
    To no one’s surprise it’s also the most challenging problem to solve in business.
    Many traditional companies likely have proliferations of data across multiple
    systems from the start of business computing in the early 1960s. Notwithstanding
    what companies have compiled in central systems, the amount of local data stored
    across local area network systems from the 1980s is significant. There is also
    a plethora of databases stored on PCs from desktop products like Excel, Foxpro,
    and Access to name just a few. In addition, there is rich data that is stored
    in text-based files. While the challenge seems overwhelming, progress has been
    made with the development of sophisticated natural language products that can
    specifically extract useful data from unformatted data. My point; however, is
    that analysts need to shift their focus more on analysis of data than on process
    . With the proliferation of IoT the issue of cleansing data for ML is more important
    than process analysis. Do not misunderstand my point. I am not advocating that
    process analysis is no longer necessary or important, rather that data quality
    need more attention than before. So, from an analyst perspective the data process
    should focus on the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Locate where data resides across the enterprise.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Understand the differing formats of the datasets and/or type of files systems
    where the data is stored.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Determine the meaning of each data element that comprises a file record.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Identify text-based files and see if natural language processes can aid in defining
    the data need by ML algorithms.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract the data elements that are needed for ML from various datasets .
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '6.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do a quality review based on the results of test runs on the extracted data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '7.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Automate the extract programs and implement an ML API.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Another aspect of data extract is to decide whether to place the data in a central
    repository cloud system. This objective always sounds doable on paper, but turns
    out to be an overwhelming task and often fails to achieve its objectives for a
    number of reasons. So, for now the all-powerful central database will be left
    for discussion in later chapters. The argument to merge everything has far more
    benefits and disadvantages beyond creating ML solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 8.7 Cloud
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the advent of 5G , IoT, blockchain , and potentially quantum , the cloud
    is assured to a critical part of the quest to obtain better speed, centralization,
    and security in a digital world. The challenge is how best to design the cloud
    architecture, that is, whether to have a private or public cloud or some combination.
    Further, once the infrastructure is designed there needs to be a determination
    of how applications and datasets are deployed. Obviously, there would be great
    advantage to have the cloud resident on a quantum computer to support ML and AI
    processing and improved cryptology.
  prefs: []
  type: TYPE_NORMAL
- en: There is no question that cloud is a sophisticated service-oriented architecture.
    While many analysts and designers understand the concept of cloud , many do not
    know how to maximize the configuration. Specifically, cloud should not be designed
    as a client/server hierarchical and closely coupled system. Cloud must be distributed,
    especially to support the new requirements of IoT. Therefore, cloud architecture
    must parallel IoT needs and provide independent applications in the form of functional
    primitives which will perform services independent of any given system. Figure [8.3](#Fig3)
    depicts the difference between a client/server design and a cloud distributed
    model.![../images/480347_1_En_8_Chapter/480347_1_En_8_Fig3_HTML.png](../images/480347_1_En_8_Chapter/480347_1_En_8_Fig3_HTML.png)
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 8.3
  prefs: []
  type: TYPE_NORMAL
- en: Comparison of client/server and cloud architectures
  prefs: []
  type: TYPE_NORMAL
- en: The process of transforming existing systems to a cloud environment will be
    discussed in Chap. [10](480347_1_En_10_Chapter.xhtml); however, a preview of this
    issue is provided here for better context. The first step in the transformation
    from legacy to cloud migration is to “decouple:” the data from the legacy application
    system. Applications that own their own data will not work well in a private or
    public cloud system. Once this separation is completed, analysts need to determine
    where to place applications and data on the network cloud systems. It is easier
    to replicate applications in multiple places across the network but more complicated
    with data. Have both distributed may have significant performance advantages particularly
    when it is time to determine how much data should reside on devices on the Edge.
    Obviously, distribution of datasets will be very fundamental for a blockchain
    architecture than for a more traditional client/server layout. Another issue will
    data distribution often relates to sensitivity and policy decisions. Many companies
    may be sensitive to having their data reside on a public cloud for instance. In
    most cases performance is the significant decision maker which is still affected
    by the number of read and write functions to and from databases that programs
    will perform during processing. Although many developers can use caching systems
    to improve performance, at some hardware latency will influence design decisions.
    Of course, having a quantum computer may greatly assist the latency issues depending
    on the type of processing being performed on the server. Overall, the mission
    for the analyst is to minimize input/output requests of all application programs.
    Always remember that the slowest operation on a computer remains the communication
    interaction among hardware devices. This design methodology is often known as
    designing for performance. In fact, studies have shown that overloading application
    server input output functions can deplete performance by over 80%! To address
    the latency potential, analyst should configure monitoring tools that can be used
    to alter load balances during peak processing.
  prefs: []
  type: TYPE_NORMAL
- en: Certainly, another variable in performance decisions is the role of security
    protection and its role in cloud analysis and design . I have already established
    that the world is moving to mobility , and cloud is a key part of a successful
    wireless infrastructure. However, we know with more mobility there is higher cyber
    exposure. Therefore, cloud applications should make use of “identity and access
    management.” Completing design with security in mind is critical to secure systems
    and is often very dependent on industry risk protocols such as healthcare’s “Health
    Insurance Portability and Accounting Act” or HIPAA compliance.
  prefs: []
  type: TYPE_NORMAL
- en: 8.8 Cloud Architectures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Part of a successful mobile infrastructure is designing the right cloud architecture
    which depends on the business needs, the technology service requirements, and
    the available technological capabilities like quantum . As you can imagine depending
    on these variables, there are different cloud models. According to some of the
    excerpts from Architecting Cloud Computing Solutions there are three models to
    consider: baseline, complex, and hybrid.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Baseline*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Baseline cloud computing is considered a foundational start as a beginner’s
    cloud architecture. Baseline is a tiered and layered architecture with most having
    three basic tiers: web server, application layer, and database layer. Every tier
    has some amount if data storage that can vary based on the design requirements.
    Most cloud designs have some aspects of three tiers a shown in Fig. [8.4](#Fig4).![../images/480347_1_En_8_Chapter/480347_1_En_8_Fig4_HTML.png](../images/480347_1_En_8_Chapter/480347_1_En_8_Fig4_HTML.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 8.4
  prefs: []
  type: TYPE_NORMAL
- en: Three tier baseline cloud architecture
  prefs: []
  type: TYPE_NORMAL
- en: 'Within the baseline architecture there are various configurations:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Single Server*'
  prefs: []
  type: TYPE_NORMAL
- en: This design is hosted by a single server which could be virtual or physical
    and contains the three layers described above. This architecture is not recommended
    due of its security risks because one layer can compromise another. Because this
    design is inadequate for mobile deployments, it is usually limited to work as
    an internal development machine.
  prefs: []
  type: TYPE_NORMAL
- en: '*Single Site*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This architecture has the same design as a single server except that each layer
    has its own computer instance and thus improves security, although all resources
    are still located on the same computer. There are two types of single-site architectures:
    non-redundant and redundant. Non-redundant architectures are essentially designed
    to save costs and resources but suffer from “single point of failure.” Once again,
    while this option has multiple instances it is not recommended for production.
    Figure [8.5](#Fig5) reflects this design.![../images/480347_1_En_8_Chapter/480347_1_En_8_Fig5_HTML.png](../images/480347_1_En_8_Chapter/480347_1_En_8_Fig5_HTML.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 8.5
  prefs: []
  type: TYPE_NORMAL
- en: Non-redundant three-tier architecture
  prefs: []
  type: TYPE_NORMAL
- en: Redundant architecture on the other hand provides backup for failover and recovery
    protection. Thus, redundant design offers duplicate components that eliminate
    the single point of failure as shown in Fig. [8.6](#Fig6).![../images/480347_1_En_8_Chapter/480347_1_En_8_Fig6_HTML.png](../images/480347_1_En_8_Chapter/480347_1_En_8_Fig6_HTML.png)
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 8.6
  prefs: []
  type: TYPE_NORMAL
- en: Redundant three-tier architecture
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, redundant architecture are designed more for production systems because
    there are multiple processing decision capabilities that avoid single point of
    failure.
  prefs: []
  type: TYPE_NORMAL
- en: '*Complex Cloud Architectures*'
  prefs: []
  type: TYPE_NORMAL
- en: The complex cloud architecture addresses issues of redundancy, resiliency ,
    and disaster recovery. At the core of complex cloud is the ability to monitor
    and adjust flow of traffic among multiple sites and to alternate balances appropriately
    based on usage. There are various types of complex cloud architectural designs.
  prefs: []
  type: TYPE_NORMAL
- en: 8.8.1 Multi-data Center Architecture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A data center architecture allows analysts to determine the amount of redundant
    infrastructure needed to support single-site and multi-site designs. The major
    questions for the analyst to answer are:'
  prefs: []
  type: TYPE_NORMAL
- en: How is traffic sent to one location or the other?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is one site active and the other backup or are both active?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How does fail-back to the primary site handled should a failure occur?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What changes in resiliency plans are necessary?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How is data synchronization handled before and after failover?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 8.8.2 Global Server Load Balancing (GSLB)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This architecture allows for the manipulation of DNS (Domain Name Server) information.
    The DNS is the internet’s version of a phonebook or address of the machine. Global
    server load balancing or GSLB enables pre-planned actions to occur in the event
    of a failure. While this design is effective, it is expensive and typically requires
    human interface. It is usually offered as a public cloud option for a fee. Figure [8.7](#Fig7)
    shows the GSLB configuration.![../images/480347_1_En_8_Chapter/480347_1_En_8_Fig7_HTML.png](../images/480347_1_En_8_Chapter/480347_1_En_8_Fig7_HTML.png)
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 8.7
  prefs: []
  type: TYPE_NORMAL
- en: GSLB architecture
  prefs: []
  type: TYPE_NORMAL
- en: 8.8.3 Database Resiliency
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This design offers what is called active-to-active database configuration with
    a bi-directional replication capability. This helps keep data synchronized on
    both database servers. While this design adds more complexity it also provides
    greater levels of redundancy and resiliency . Figure [8.8](#Fig8) shows the design.![../images/480347_1_En_8_Chapter/480347_1_En_8_Fig8_HTML.png](../images/480347_1_En_8_Chapter/480347_1_En_8_Fig8_HTML.png)
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 8.8
  prefs: []
  type: TYPE_NORMAL
- en: Database resiliency architecture
  prefs: []
  type: TYPE_NORMAL
- en: Another option on databases its to add caching capabilities which holds data
    in high speed memory. The caching option works on algorithms that bet that certain
    data will be requested again. If that bet works it can significantly speed up
    data access. The idea behind caching is that an application may engage in multiple
    input and output operations for a period of time with the same records. Figure [8.9](#Fig9)
    shows the addition of caching memory.![../images/480347_1_En_8_Chapter/480347_1_En_8_Fig9_HTML.png](../images/480347_1_En_8_Chapter/480347_1_En_8_Fig9_HTML.png)
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 8.9
  prefs: []
  type: TYPE_NORMAL
- en: Caching database cloud design
  prefs: []
  type: TYPE_NORMAL
- en: 8.8.4 Hybrid Cloud Architecture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Hybrid cloud is a solution that combines a private cloud with one or more public
    cloud services. Hybrid cloud provides greater flexibility because you can alter
    workloads among multiple cloud infrastructures. It also allows organizations to
    examine cost alternatives.
  prefs: []
  type: TYPE_NORMAL
- en: A hybrid cloud can certainly minimize exposure to a site failure because there
    are multiple failover options. It’s clear in many ways that the hybrid option
    certainly is attractive for the IoT/Blockchain mobile operations because of the
    redundancy and multi-location load balances that it can offer. What is always
    true with sophisticated architectures is the higher costs, although using third
    party operators for competitive choices is part of the decision-making process
    . Beyond cost and failover is flexibility. Hybrid clouds allow owners to have
    that protection in a private cloud while offering the ability to extend onto a
    public cloud for more capacity as needed. The model is depicted in Fig. [8.10](#Fig10).![../images/480347_1_En_8_Chapter/480347_1_En_8_Fig10_HTML.png](../images/480347_1_En_8_Chapter/480347_1_En_8_Fig10_HTML.png)
  prefs: []
  type: TYPE_NORMAL
- en: Fig. 8.10
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid cloud architecture
  prefs: []
  type: TYPE_NORMAL
- en: 8.9 Cloud, Edge, and Fog
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As IoT devices become widespread, organizations will need to store more data
    on devices, also known as the Edge. The edge devices and other network machines
    will need to interface with a more centralized cloud operation which have recently
    been coined Fog computing . The objective is to maximize performance and ensuring
    options for scalability especially during peak demands. Many organizations are
    considering collocating their IT infrastructure with other data centers to conserve
    costs. It is important to note that while Edge and the Cloud represent current
    alternatives, the potential rise of quantum computing certainly offers an attractive
    addition to finding ways to store and analyze the incredible explosion of valuable
    consumer data.
  prefs: []
  type: TYPE_NORMAL
- en: 8.10 Problems and Exercises
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define and describe quantum computing.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the advantages of quantum architecture?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does quantum architecture relate to AI and ML? Be specific.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the relationship between quantum and hash keys?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a dataset? Describe the different types of sets.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '6.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is predictive analytics so dependent on AI and ML?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '7.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do APIs increase performance of predictive analytics?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '8.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are some of the disadvantages of ML?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '9.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is Natural Language Processing and its relation to datasets?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '10.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define two types of ML algorithms.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '11.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the challenges when updating data elements from legacy data?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '12.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What dilemma does ML create for database normalization?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '13.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is Cloud? Why is it so essential for mobile-based architectures?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '14.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare client/server and cloud architectures.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '15.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is hybrid cloud architecture so attractive?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '16.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is Fog?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
