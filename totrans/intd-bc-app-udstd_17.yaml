- en: © The Author(s), under exclusive license to APress Media, LLC, part of Springer
    Nature 2022J. T. GeorgeIntroducing Blockchain Applications[https://doi.org/10.1007/978-1-4842-7480-4_17](https://doi.org/10.1007/978-1-4842-7480-4_17)
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: © 作者，独家授权给APress Media，LLC，属于Springer Nature 2022J. T. George引介区块链应用[https://doi.org/10.1007/978-1-4842-7480-4_17](https://doi.org/10.1007/978-1-4842-7480-4_17)
- en: 17. AI and Blockchain Monitoring Autonomous Vehicles Management Project
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 17. AI和区块链监控自主车辆管理项目
- en: Joseph Thachil George^([1](#Aff2)  )(1)Rome, Italy
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 约瑟夫·泰奇尔·乔治^([1](#Aff2)  )(1)意大利罗马
- en: The autonomous vehicle management system is the subject of this chapter. This
    entails operating a vehicle or system in a distributed environment. *Artificial
    intelligence* and message exchanges (blockchain) are both present in this scenario.
    Simultaneously, we must prevent catastrophic collapse when it comes to autonomous
    vehicle management.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 自主车辆管理系统是本章的主题。这涉及在分布式环境中操作车辆或系统。*人工智能*和消息交换（区块链）在这种情况下都存在。同时，当涉及自主车辆管理时，我们必须防止灾难性崩溃。
- en: 17.1 The Connection Between Blockchain and Artificial intelligence
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 17.1 区块链与人工智能之间的联系
- en: Blockchain and AI are two of the most popular technological developments right
    now. Scientists have been debating and researching the integration of the two
    technologies, despite the fact that their development partners and implementations
    are vastly different. A blockchain, by definition, is a distributed, decentralized,
    immutable ledger for storing encrypted data. AI, on the other hand, is the motor
    or “mind” that will enable analysis and judgment based on the acquired information^([1](#Fn1)).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 区块链和人工智能是目前两个最受欢迎的技术发展方向。尽管它们的发展伙伴和实现方式大相径庭，但科学家们一直在讨论和研究这两种技术的整合。按照定义，区块链是用于存储加密数据的分布式、去中心化、不可变的账本。而人工智能，则是根据获得的信息进行分析和判断的引擎或“大脑”^([1](#Fn1))。
- en: AI and blockchain are in a position where they can support and profit from each
    other. Because both of these technologies may affect data in various ways, combining
    them makes logical sense and potentially pushes data exploitation to new heights.
    Simultaneously, incorporating machine learning and AI into blockchain, and vice
    versa, can improve blockchain’s fundamental architecture while also enhancing
    AI’s capabilities. Blockchain could also make AI more logical and intelligible,
    allowing developers to track and comprehend why deep learning choices are made.
    The blockchain and its ledger can keep track of all the data and factors that
    go into a deep learning conclusion (see Figure [17-1](#Fig1))¹.![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig1_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig1_HTML.jpg)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能和区块链处于一种相互支持和相互受益的位置。因为这两种技术可能以各种方式影响数据，将它们结合起来在逻辑上是合理的，并且可能将数据的利用推向新的高度。同时，将机器学习和人工智能纳入区块链，反之亦然，可以改进区块链的基本架构，同时增强人工智能的能力。区块链还可以使人工智能更加逻辑和可理解，使开发人员能够跟踪和理解为什么做出深度学习选择。区块链及其分类帐可以跟踪所有数据和因素，这些数据和因素涉及到一个深度学习结论（见图
    [17-1](#Fig1)）¹。![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig1_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig1_HTML.jpg)
- en: Figure 17-1
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17-1
- en: Blockchain and AI
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 区块链和人工智能
- en: Furthermore, AI can improve blockchain efficiency considerably more effectively
    than people or even traditional technology. A glance at how blockchains are now
    operated on conventional computers demonstrates this, with a significant amount
    of computing power required to complete even basic activities^([2](#Fn2)).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，人工智能可以比人类甚至传统技术更有效地提高区块链的效率。仅仅看一下目前如何在传统计算机上操作区块链就可以证明这一点，即使是完成基本活动也需要大量的计算能力^([2](#Fn2))。
- en: 17.1.1 AI and Blockchain in Applications
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 17.1.1 应用中的人工智能和区块链
- en: The number of automobiles on the road is rising these days. As a result, preventing
    traffic accidents is a problem for society. Machine Learning (ML) techniques,
    for example, are particularly useful in improving the overall performance of the
    road safety management system. Blockchain uses consensus methods and smart contracts
    to govern communication between nodes without the need for a third-party intermediary.
    Simultaneously, AI has the potential to provide intelligent, decision-making robots
    that are comparable to human minds².
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，路上的汽车数量正在增加。因此，预防交通事故是社会面临的一个问题。例如，机器学习（ML）技术在提高道路安全管理系统的整体性能方面特别有用。区块链使用共识方法和智能合约来管理节点之间的通信，无需第三方中介。同时，人工智能有潜力提供智能的、具有人类思维能力的决策机器人²。
- en: 'Basically, we need to consider the following two aspects when we apply blockchain
    and AI for application development:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，当我们应用区块链和人工智能进行应用开发时，我们需要考虑以下两个方面：
- en: '**Monetization of data.** With consensus algorithms and smart contracts, blockchain
    manages communication among nodes without the involvement of a third-party or
    intermediary body. Additionally, blockchain technology facilitates sharing of
    information on the network, which is decentralized, secure, persistent, anonymous,
    and trustworthy.²'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decision making using AI.** Artificial Intelligence (AI) such as Machine
    Learning (ML) algorithms are very helpful for improving the performance of the
    overall vehicle safety management system.²'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 17.1.2 AI’s Role in Making Real-Time Intelligent and Decision-Making Machines
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AI technology enables machines to think for themselves without the need for
    human involvement. The AI approach is extremely careful in analyzing the collected
    data via IoT devices that have been placed within a vehicle’s driver’s cabin.
    For real-time decision-making operations in vehicles, several machine-learning
    techniques are significant.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: The system evaluates the driver’s unfit or uncomfortable state based on the
    system’s training. Then, first and foremost, it communicates with the driver.
    After that, if it detects the vehicle’s uncomfortable body expressions, it sends
    a report to the pre-programmed network. This chapter explains how to implement
    AI in vehicle system management^([3](#Fn3)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: 17.2 Blockchain for Information Sharing and Exchange
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Blockchain is critical for sharing  and transferring data across IoT device
    endpoints. It manages the wireless communication network between the various network
    control locations, systems, and servers using BC. BC is an IoT backbone technology
    that collects data and distributes it to endpoints or final nodes. As is generally
    known, BC offers IoT nodes and stakeholders with traceability, trust, privacy,
    security, and transparency when sharing information.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Blockchain allows providers and Internet firms to share data and approve interoperability
    based on customer privacy data. It also shares data sharing records in order to
    authorize data access. Data traceability is also important to guarantee that data
    exchange is legitimate, controlled, auditable, and regulated³.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: The information should be communicated among the endpoints with trust, security,
    and transparency via this blockchain system. To achieve data access permission,
    blockchain shares data sharing records. Vehicle drivers have their own private
    access control mechanisms and the ability to share or sell their data, as shown
    in Figure [17-2](#Fig2). Here, the carrier or communication service provider (CSP)
    provides benefits such as (1) no private data is sent out, (2) confirmation information
    may be verified and modified, and (3) traceable and tamper-proof information.³![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig2_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig2_HTML.jpg)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Figure 17-2
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Data transfer via blockchain technology  in the vehicle management system
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we created a project (autonomous vehicle management) that combines
    artificial intelligence and blockchain technology. The goal is to focus on artificial
    intelligence because the previous chapter talked a lot about blockchain technology.
    This is a combination of most trending technologies such as artificial intelligence,
    blockchain, and IoT. There are lots of examples in Western countries where both
    technologies are implemented in application development.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: In all Western countries, self-driving vehicles are now one of the primary axes
    of mobility development. The European Commission is dedicated to supporting any
    connected and automated mobility solutions that can help meet the previously established
    sustainability and safety goals in its smart and sustainable mobility plan.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Urban tram and train options with self-driving capabilities currently exist
    for public transportation. We may see autonomous taxis with digital car-sharing
    systems develop in the next several years, operating in limited regions. In terms
    of private transportation, the objective of producing a fully driverless car is
    still a long way off, especially in congested areas. However, in the next few
    years, automobiles with increasingly advanced autonomous driving functions will
    be available for purchase. Several cities might potentially provide the infrastructure
    needed to develop environmental digital systems that allow for the deployment
    of some autonomous driving features within a decade. Even if the change will be
    gradual, let’s expect a totally new path.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Autonomous driving is, at the moment, one of the biggest challenges facing the
    automotive world. Creating cars with artificial intelligence developed to the
    point of being able to drive without human intervention and capable of making
    fundamental decisions in a few thousandths of a second is by no means simple.
    In the test phase on the roads open to traffic, there was no shortage of accidents
    involving self-driving cars, but step by step we are arriving at increasingly
    advanced models capable of not requiring human intervention.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: 'Advantages of autonomous vehicle management include:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '**Multitasking:** The driver can devote themself to a completely different
    activity.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Safety:** Sensors and predictive algorithms will allow self-driving cars
    to assess and in some cases predict risks. Thanks to safe driving, the number
    of road accidents would decrease.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Efficiency:** Abrupt braking and sudden acceleration can be avoided, thus
    optimizing fuel consumption.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Less traffic:** Once on the road, vehicles would continuously communicate
    with each other, exchanging data on position, driving speed, and other useful
    and traffic-compliant information.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**No one excluded:** Self-driving cars can also be used by disabled people.
    In fact, they do not require particular physical skills. Just indicate the destination
    to your driverless driver and that’s it.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computers now play a crucial role in our culture. These systems are today utilized
    for a variety of applications in a variety of fields, ranging from medicine to
    avionics, this also includes the comparatively recent emerging technology called
    artificial intelligence.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Because of the new fields in which these technologies are utilized, the idea
    of “computer systems” has to be redefined. Most of these systems must meet strict
    timelines in order to complete their jobs, otherwise catastrophic repercussions
    may occur, including widespread destruction, injuries, and even fatalities.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: We refer to systems as *crucial systems* when they must adhere to strict time
    frames. When a system’s failure might be catastrophic, inflicting serious harm
    to the environment, infrastructure, or persons, we refer to it as a *safety critical
    system* .
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: 'In certain situations, these systems are used in a physical context. An automated
    automobile is an example of such a system: it consists of a computer system that
    performs the computations required to complete the given job and a physical component
    that interacts with the environment by changing both the environment’s and the
    platform’s state.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Since these systems are so widespread and yet so hazardous if they fail, meeting
    and ensuring their (typically) ultra-high reliability criteria during the design
    and development process is critical. A system’s dependability is a gauge of how
    “trustworthy” it is, or its capacity to offer accurate service.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: A breakdown is an occurrence that causes the given service to be disrupted.
    A critical system’s *dependability* is described as a collection of theoretical
    and practical indicators. Let’s look more closely at the most significant indicators.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 17.3 Dependability and Safety
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A critical system’s *dependability* is described as a collection of *quantitative*
    indicators. Here are a few of the more important ones:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '*Availability* is a metric that compares the frequency of right versus faulty
    service.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![../images/520777_1_En_17_Chapter/520777_1_En_17_Figa_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Figa_HTML.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
- en: '*Reliability* refers to a system’s capacity to deliver consistent service.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Safety* is defined as the absence of catastrophic effects in the event of
    a failure.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because safety standards necessitate a quantifiable measure, the safety of a
    system is frequently described by integrating additional metrics like the Mean
    Time to the Next Catastrophic Failure.
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![../images/520777_1_En_17_Chapter/520777_1_En_17_Figb_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Figb_HTML.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: '*Maintainability* refers to the ability to maintain and restore a system after
    it has failed. This factor has an impact on availability.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Coverage* is a metric for how effective the system’s fault-tolerance measures
    are at preventing, avoiding, or correcting problems.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A *risk* is something that threatens the system’s reliability: it’s an “event”
    that causes the system to offer erroneous service. Threats can take various forms
    and originate from a variety of places, such as incorrect specification or incorrect
    execution of a requirement, or disasters.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to system reliability, we want to make sure that the service is
    always right. A failure occurs when a service transitions from being accurate
    to being wrong. The requirement of minimizing probable transitions from a stage
    of suitable service to a stage of false service leads project deployment while
    building a critical system. (See Figure [17-3](#Fig3).)![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig3_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig3_HTML.jpg)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Figure 17-3
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Correct vs. incorrect services
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: We should differentiate between benign and catastrophic failures when assessing
    the reliability of safety-critical systems. With benign failures, the system may
    not provide the best service possible, but it will remain safe. In instances when
    these systems and people operate in close proximity, unsafe service can have disastrous
    effects such as environmental damage, disturbance of the system’s infrastructure,
    or even fatal accidents. Consider a self-driving automobile as an example. Consider
    a situation in which the automobile is traveling under “regular” conditions when
    an obstruction appears in front of it.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Despite the fact that a screeching halt and subsequent ride interruption is
    a failed state, it is considered a benign failure because nobody was injured.
    Apart from this, a scenario in which the vehicle accelerates toward a barrier
    (and eventually collides with it) is deemed a dangerous failure since the occupants
    may be seriously injured. (See Figure [17-4](#Fig4).)![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig4_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig4_HTML.jpg)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Figure 17-4
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: States
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to discover all probable failures to assess the reliability of safety-critical
    systems. The researchers used the faulty mistake failure chain, which is well-known
    among academics and policymakers alike, to accomplish their goal:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: A fault is an error with an adjudicated or speculated cause.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Error: A portion of the system’s condition might result in the failure.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Failure: The circumstance in which a mistake enters the service interface,
    causing the entire system’s service to be disrupted. (See Figure [17-5](#Fig5).)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig5_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig5_HTML.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
- en: Figure 17-5
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Fault, error, and failure
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: 'When a mistake has progressed to the point that it can no longer be corrected,
    a system’s dependability is determined by a collection of four approaches aimed
    at preventing or mitigating the impact of potential failures:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '**Fault Prevent the Occurrence:** Methods of preventing failures from occurring
    or being introduced.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fault Tolerance** **:** Methods for allowing defects to be tolerated. Even
    if a failure occurs, the system is still capable of providing proper service.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fault Rid** **:** Lowering the quantity or severity of system defects.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fault Predicting** **:** Estimating the current number, future occurrence,
    and potential effects of defects using statistical approaches. The validation
    procedure is used to assess the efficacy of the steps taken to meet a system’s
    dependability criteria.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'System requirements confirmation is a method that must be followed throughout
    the development phase, including at the start of the design process. For each
    stage of the system development process, there are a number of validation techniques
    to choose from:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '**Numerical Modeling** **:** Methods for modeling system capabilities using
    numerical models with a simple analytical solution. In other words, a quantitative
    analytic function may be used to express changes in the system. These models include
    the Sequential model and the State-Based model.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Simulation:** In a simulated environment, there is an empirical estimate
    of system reliability. This approach allows you to test if a certain fault-tolerance
    mechanism operates without causing damage to the real system.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Measurement:** Once a prototype of the system is ready, it may be monitored
    in action and the relevant metrics produced.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s important to note that these techniques aren’t mutually exclusive, and
    that all of them should be considered during the validation process.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: 'As previously mentioned, validation must take place throughout the lifecycle
    of a project, beginning with the modeling phase and continuing after implementation.
    In certain periods, some of the approaches described in this book are more appropriate:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '**Specification:** Validity is accomplished by the description of reliability
    criteria, which may be verified using numerical techniques. To identify the failure
    criteria for the system’s components, use approaches such as combinatorial designs.
    Failures are thought to be separate from each other.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Design:** It’s appropriate to use State-Based models to represent the system’s
    state space during the design phase. Markov Chains and Petri Nets are examples
    of these models.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implementation:** When the project is far enough along, it may be possible
    to build a prototype model that can be closely monitored to see how effective
    fault-tolerance approaches are in improving system dependability.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Functioning:** It is possible to test the system in a real-world setting
    after it has been installed.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 17.4 Tracking the System
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Monitoring the system is a technique that involves seeing a system operate in
    its surroundings and collecting data and evidence regarding its features. Currently,
    it’s seen to be a useful way to assess a system’s dependability, and many techniques
    to do so have been presented in the research. We use the approaches presented
    in these books in this chapter.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: 'This method seeks to continuously monitor a system in its end environment,
    ensuring that the observed behavior and performance fulfill the specific needs.
    Validation of the data acquired during the monitoring activity is required:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '**Offline:** While the system is functioning, data is gathered and saved someplace,
    then evaluated afterward.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Online** (or in real time): Data is evaluated as it is obtained. All of these
    factors must be considered while developing a monitoring strategy:'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying the system’s important events, measures, and qualities that must
    be evaluated in order to determine the system’s dependability.
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Data labeling in order to add more information to raw measurements.
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Data collection and transfer to the analysis node for processing.
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data filtering and classification based on the metrics of interest The entire
    system is referred to as target system in the description of a monitoring process.
    When the tracking activity is linked to a specific H/w or S/w or piece of the
    system, an aimed component or final application is employed. The professionals
    and academicians are full in agreement that these diametrically opposed techniques
    are effective:'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Analysis in a black-box setting.
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Analysis in a white-box setting.
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The strategy you choose is determined by how much command you have over the
    target system, particularly its inner implementations.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: A black box approach can be used when the implementations are unknown, such
    as when the ability to monitor action is performed by a third-party system. After
    defining a workload, the task is offered to the system, and its outputs are noticed.
    (See Figure [17-6](#Fig6).)![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig6_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig6_HTML.jpg)
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Figure 17-6
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Target system output processing
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: It is possible to study the target machine “on the inside” by attaching a probe
    directly to the computer and viewing the system’s intermediary outputs while it
    runs, if the internal characteristics of the target system are known and easily
    available. Because these probes are directly connected to the system’s internal
    components, they can offer considerably more information than simply observing
    the system’s outputs can.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: 'On the one side, this technique gives a lot more information on the system’s
    behavior, but it also necessitates more caution in terms of monitoring and system
    probing. These two principles, in particularly, must be followed:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '**Representativeness of choices:** In order to execute a successful monitoring
    activity, the probes should be able to get a sufficient number of relevant facts.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选择的代表性：** 为了执行成功的监控活动，探针应能够获取足够数量的相关事实。'
- en: '**No intrusiveness:** Probing must not alter the system’s behavior; otherwise,
    the acquired data will be useless.![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig7_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig7_HTML.jpg)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无侵入性：** 探测不能改变系统的行为；否则获取的数据将毫无用处。![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig7_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig7_HTML.jpg)'
- en: Figure 17-7
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图17-7
- en: Probes
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 探针
- en: Additional rationale is required in the design and development of the monitoring
    system, particularly in regard to how the probing is carried out. We can differentiate
    between the following in specific.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在监控系统的设计和开发中需要额外的理念，特别是关于探测的执行方式。我们可以具体区分以下内容。
- en: Hardware monitoring, software monitoring, and hybrid monitoring are all options.
    Because of its obvious minimal intrusiveness, a devoted hardware channel for tracking
    is the best approach to observe a system. However, as systems get more sophisticated,
    installing hardware probes becomes increasingly difficult, if not extremely difficult.
    (See Figure [17-7](#Fig7).)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件监控、软件监控和混合监控都是选择。由于其明显的最小侵入性，专用于跟踪的硬件通道是观察系统的最佳方法。然而，随着系统变得更加复杂，安装硬件探针变得越来越困难，甚至极为困难。（见图[17-7](#Fig7)。）
- en: Software probes are more powerful than hardware probes because they have access
    to more relevant data and can establish the context in which a specific output
    was created. Data extraction and measurement instructions can be included in the
    procedure, the operative system, or a new probe process can be created. In a hybrid
    technique, equipment/software probes might be utilized simultaneously, with specific
    emphasis devoted to reducing the disadvantages of each technology.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 软件探针比硬件探针更强大，因为它们可以访问更多相关数据并能建立特定输出产生的上下文。数据提取和测量指令可以包含在过程中，操作系统中，或者可以创建一个新的探针过程。在混合技术中，设备/软件探针可以同时使用，特别侧重于减少每种技术的缺点。
- en: 17.5 Motivation and Goal of This Work
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 17.5 这项工作的动机与目标
- en: A *neural network* , which is in charge of driving the automobile, is pitted
    against a system supervisor, which offers fault-tolerance mechanisms to prevent
    catastrophic failures. In relation to the effects autonomous automobiles may have
    on future system advancements, they are among the most current and promising safety
    essential technologies.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 由驾驶汽车的*神经网络*与提供容错机制以防止灾难性故障的系统监督者对抗，关于自动驾驶汽车可能对未来系统进步的影响，它们是当前和最有前景的安全关键技术之一。
- en: This type of technology typically has extremely high-capacity needs that are
    difficult to verify. Furthermore, the nature of the software architecture, which
    involves artificial intelligence and non-artificial intelligence software interacting
    with one another, makes validation much more difficult.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的技术通常具有非常高的容量需求，难以验证。此外，软件架构的性质，涉及人工智能和非人工智能软件相互作用，使验证变得更加困难。
- en: The objective of this research is to provide an experimental technique for evaluating
    the dependability of such complex systems, with an emphasis on what metrics are
    acceptable for these processes and what factors impact the analysis process. To
    exemplify the principles provided in this book, an experimental activity was undertaken
    in a realistic simulation setting.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究的目标是提供一种实验技术，用于评估这种复杂系统的可靠性，重点是什么指标对这些过程是可接受的，以及什么因素影响了分析过程。为了举例说明本书提供的原则，进行了一项在现实模拟环境中进行的实验活动。
- en: You can’t get access to a system supervisor or a trained neural network. The
    network was developed from the ground up, and the project included the creation
    of a basic system supervisor.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 你无法访问系统监督员或经过训练的神经网络。该网络是从头开始开发的，项目包括创建基本的系统监督员。
- en: It’s crucial to note that the goal of this work isn’t to provide a complete
    treatment of the argument; rather, it’s to begin a period of exploration of these
    notions and difficulties, which will need additional validation and research in
    future designs.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，这项工作的目标不是提供对论点的完整处理；相反，它是为了开始对这些概念和困难进行探索的阶段，这将需要在未来的设计中进行进一步的验证和研究。
- en: 17.6 Automotive Applications
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 17.6 汽车应用
- en: One of the popular trends this decade is self-driving cars. AI that have been
    actually trained to drive using machine learning techniques have shown that a
    computer can drive a car. However, if these systems fail, individuals might be
    hurt or killed. Simultaneously, certifying the ultra-high dependability specifications
    demanded is proving difficult. Today’s modern problems with self-driving vehicle
    safety are reviewed in this chapter.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 十年来的流行趋势之一是自动驾驶汽车。通过使用机器学习技术实际训练过的人工智能已经表明了计算机可以驾驶汽车。然而，如果这些系统失败，个人可能会受伤或丧生。与此同时，证明所需的超高可靠性规格正在变得困难。本章将审查当今自动驾驶车辆安全面临的现代问题。
- en: 17.6.1 Autonomous Cars as Cyber-Physical Systems
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 17.6.1 自主汽车作为网络物理系统
- en: A car’s ability to drive itself necessitates the use of appropriate technology
    and software. As a result, autonomous vehicles are classified as *cyber-physical
    systems* (CPSs), with the potentially devastating effects of a failure in/of these
    systems placing them in the important systems category.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 车辆自动驾驶的能力需要使用适当的技术和软件。因此，自动驾驶车辆被归类为*网络物理系统*（CPSs），这些系统的故障可能会产生灾难性的影响，将它们归类为重要系统。
- en: 'The system gathers data from various sensors to perceive and map the local
    environment. Here are some of the most significant sensors and their functions:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '**Highly accurate GPS sensors:** These sensors are useful for monitoring change
    in the status of the automobile and objects in the surroundings over time.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cameras:** Face recognition software and cameras are generally used to process
    recorded images.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lidars and Radars:** Lidars are the next step in the evolution of traditional
    radars. The information gathered from these sensors is used to map the surroundings
    and detect obstacles and objects in the vicinity of the vehicle.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These sensors’ results are integrated and sent into the car’s control system.
    Figure [17-8](#Fig8) depicts a simplified version of the software architecture.![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig8_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig8_HTML.jpg)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Figure 17-8
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: The software architecture of the system is abstracted at a high level
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Sensor data are inputs to the management system, which are divided into two
    parts. One input collects data straight from the sensors, processes it to create
    an occupancy grid1 to map the nearby region, and generates a physical model of
    the system in terms of following the appropriate path to a final stage without
    collapsing. The other input collects data from the sensors, processes it to create
    an occupancy grid1 to map the nearby area, and generates a physical model of the
    system to get the correct path to a final stage without collision.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: A car’s activities include accelerating, braking, and steering. Because of the
    importance of their job, a system supervisor is required. This system is in charge
    of detecting potential hardware faults or erroneous process control outputs for
    and, if required, executing a right action.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: The system administrator is the key part of such systems and prevents breakdown.
    Without a doubt, certain checks may be performed when data is analyzed, but the
    final decision rests with the system’s monitor, and underestimating its importance
    might have disastrous results, such as the 2018 Arizona tragedy in which a lady
    was killed by a self-driving car during a practice run.¹
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Additional examination found that the vehicle’s radar and Lidar sensors detected
    the victim around six seconds before impact, and that it took four seconds to
    infer that there was an impediment on the road requiring an emergency stop. During
    testing for “smoother rides,” however, this safety-checker was deactivated, resulting
    in tragedy.^([4](#Fn4))
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: The high complexity of these systems raises issues among specialists, including
    the need to develop a new perspective for studying and testing their safety, as
    well as the need to raise awareness about safety.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 17.7 Safety and Self-Controlled Vehicles
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The amount of automation may be split into six categories, ranging from 0 to
    5, by an SAE International proposal to categorize self-driving cars’ autonomy.
    Level 0 implies no autonomy: the car is operated only by a person; level 5 means
    that no human involvement is necessary, and the vehicle must be capable of not
    just driving safely on the road, but also avoiding catastrophic failures that
    may seriously injure people. The greater the reliability criteria for an automobile
    to be used on open streets, the more autonomous it is.⁴'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: 'Demonstrating a device’s dependability is a difficult undertaking in and of
    itself, but it becomes considerably more difficult with ultra-high dependability
    systems like these. In addition to the problem at hand, showing the dependability
    of autonomous vehicles has two additional challenges: how do you test the system
    efficiently and safely, and the presence of neural networks, and as such it is
    difficult to explain why it produced the output y given the input x.¹'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Several studies have shown that road testing vehicles is impossible. One of
    these, dubbed the RAND study, considers how many miles of driving it would take
    to demonstrate autonomous vehicles’ accuracy using traditional statistical inference,
    estimating that if autonomous vehicles’ fatality rate was 20 percentage points
    lower than humans’, it would take more than five centuries with “a fleet of 100
    driverless cars being test-driven 24/7 a day, 24/7/365 a year.”¹
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: The confirmation of ultra-high dependability criteria for safety-critical systems
    is a well-known topic in the safety literature, and autonomous cars haven’t been
    added to it. In actuality, the RAND research is just one example of the problem
    described in Littlewood & Strigini’s paper from 1993, in which the same ideas
    are examined and extended for any ultra-high dependability system.¹
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: 'The fundamental flaw in the RAND study approach is that the frequency of future
    failures cannot be anticipated only based on the observed one. Not only because
    of the quantitative findings of its impossibility, but also because this method
    is ineffective: a failure rate that was observed. This technique cannot function,
    not only because of the quantitative approaches of its impossibility, but also
    because an observed frequency failure of zero would lead to optimistic (and potentially
    dangerous) forecasts. Fortunately, as Zhao et al. demonstrate, this dilemma is
    solvable.¹'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Validating the reliability criteria of an autonomous vehicle appears to be a
    difficult challenge in and of itself. The fact that these automobiles are controlled
    by neural networks makes things much more difficult.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: The area of machine learning has seen a rise in attention in recent years, resulting
    in important scientific advancements. As a result of these advancements, autonomous
    automobiles appear to be a reality, as AIs have achieved astounding results with
    their abilities, and large businesses such as Amazon and Alibaba are investing
    even more in artificial intelligence related research. The way people interact
    with computers is changing dramatically thanks to this new wave of AI research,
    and neural networks have produced surprising results.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: While neural networks have shown promise and appear to be the only method to
    reach objectives like automated vehicles, it has been proven numerous times how
    weird a network’s forecast may become when the inputs are skewed and how wide
    the confidence level can be when the inputs are skewed. The absence of established
    standards and certifications for this sort of software, as well as the need to
    comprehend neural networks fully, has prompted worries about how reliant these
    systems may be. With advanced AI businesses lobbying for more limitations, there
    is now a growing awareness of the problem.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '17.8 Controller: The Problem with the Checker'
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The connections between the control sys and the sys admin are at the heart of
    the vehicle’s motions. The control sys, often known as the *primary factor* ,
    is the software that conducts the system’s major computations, which are required
    for the vehicle to run. To avoid catastrophic failures in this situation, fault-tolerance
    measures such as the system administrator are required. Due to high-reliability
    demands of these systems, this type of architecture is required in order to attempt
    to cover all conceivable failures. (See Figure [17-9](#Fig9).)![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig9_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig9_HTML.jpg)
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Figure 17-9
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: The system’s secure states are depicted in this diagram
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: A safe condition is one in which the control sys generates an output that doesn’t
    cause the vehicle to crash. The system’s degree of safety may be represented as
    the union of the controller’s and supervisor’s failure regions, with an overlap
    region where the supervisor is truly damaging to the system’s performance.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Consider a self-driving automobile on the road when an unexpected stumbling
    barrier arises. If the primary identifies the barriers properly, it should take
    a self-protective action to prevent going into alert mode.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: If the controller fails to detect the obstacle or detects it but continues to
    throttle, the controller is judged to have failed, and the fault features kick
    in, the controller switches from a safe to an alert state. It is now the sys administrator’s
    obligation to take remedial action to put the system into fail-safe mode. As a
    result of the failure of both elements, an administrator mistake will definitely
    force the system to fail, resulting in a failure state.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: 'The *clustering algorithm* *,* a unique table arrangement that allows visualization
    of a classification system’s performance, may be used to show the system supervisor’s
    probable actions. This is achieved by dividing the world into two categories:
    positive and negative.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: Assume we’re trying to tell the difference between white and black sheep in
    a flock. The Positive Class will be the black sheep’s class. A black sheep that
    has been identified as such is known as a True +Ve. White sheep make up the -Ve
    class, and each white sheep is a True -Ve. When a white or black sheep is misclassified,
    it is called a False Positive or False Negative¹. Actual and anticipated values
    are the two dimensions of this form of contingency table, as shown in Figure [17-10](#Fig10).![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig10_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig10_HTML.jpg)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Figure 17-10
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Matrix of perplexity table
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: We need to specify what constitutes a good and bad classification in the realm
    of self-driving automobiles. Remember that a controller “failure” was defined
    as a transition from a safe position, in which the supervisor can manage the ecosystem
    without collapsing, to an alert state, in which the system would eventually collapse
    without the administrator.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: As a result, the +ve class represents the set of events that will ultimately
    cause the controller to fail, whereas the negative class represents the set of
    events that the controller successfully controls. We’ll put the administrator’s
    choice to distinguish between safe and alert statuses to the test. To accomplish
    this, we used the following definitions for positive and negative forecasting:![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig11_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig11_HTML.jpg)
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Figure 17-11
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: True and erroneous predictions are represented graphically in the sys’s state
    space. The system’s present status is represented by dots. A blue dot indicates
    that no alert has been raised, whereas a red dot indicates that an alarm has been
    triggered by the monitor
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '**True Positive (TP):** Due to a controller failure, the system went into alert
    mode, which was correctly recognized and stopped by the controller.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**True Negative (TN):** The sys is in good working order, and the controller
    does not sound an alert.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False Positive (FB):** Although the sys is safe, the monitoring signals an
    alarm.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False Negative (FN):** The sys is on high alert, and the controller is unable
    to identify the threat.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These raw numbers are just a starting point for more sophisticated and valuable
    measurements, which are generally given as rates and linked together using statistical
    laws, making them statistically comparable and straightforward to compute provided
    the amounts of right and erroneous predictions are known. These are some instances
    of these metrics:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '**Sensitivity (True Positive Rate):** Calculates the percentage of true +Ves
    that are accurately recognized as such.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![../images/520777_1_En_17_Chapter/520777_1_En_17_Figc_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Figc_HTML.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
- en: '**Specificity (True Negative Rate):** A metric that evaluates the percentage
    of true negatives that are accurately classified as being such.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![../images/520777_1_En_17_Chapter/520777_1_En_17_Figd_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Figd_HTML.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
- en: '***Miss Rate*** **(also known as the False Negative Rate):** The percentage
    of real positives that are projected as negative.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![../images/520777_1_En_17_Chapter/520777_1_En_17_Fige_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fige_HTML.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
- en: '***Fall-Out:*** The fraction of real negatives projected as positives is measured
    by the fall-out (false positive rate).'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![../images/520777_1_En_17_Chapter/520777_1_En_17_Figf_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Figf_HTML.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
- en: These four rates can also be coupled to provide a variety of other metrics that
    indicate the model’s forecast performance.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few of the much more commonly utilized metrics:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '*Accuracy* is a metric for quantifying systematic mistakes in forecasts. Disparities
    between such a prediction and its “actual” value are caused by inadequate precision.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![../images/520777_1_En_17_Chapter/520777_1_En_17_Figg_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Figg_HTML.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
- en: '*Precision* is a measure of statistical variation in the model used for forecasts
    that is used to describe random mistakes in forecasts.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![../images/520777_1_En_17_Chapter/520777_1_En_17_Figh_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Figh_HTML.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
- en: '*Fβ-score* is a combined accuracy and sensitivities measure of a test’s reliability.
    This runs from 0 (worst value) to 1 (best value), and it is directly related to
    the true positive.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![../images/520777_1_En_17_Chapter/520777_1_En_17_Figi_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Figi_HTML.jpg)Matthew’s
    Correlation Coefficient is an indicator of overall forecast quality that considers
    every cell in the confusion matrix. This measure runs from 1 (worst value) to
    1 (highest value), allowing for a more comprehensive assessment of model correctness.![../images/520777_1_En_17_Chapter/520777_1_En_17_Figj_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Figj_HTML.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
- en: The *ROC5 Curve Plot* is a graphical representation of a binary classifier’s
    effectiveness, with the x-axis indicating false positive rate and the y-axis indicating
    true positive rate, with the plot divided by the y = x line.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Values above this line indicate “excellent” forecasts, while values below this
    line indicate “worse-than-random” forecasts, and values on the line indicate arbitrary
    guesses.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: All of these indicators may be computed and connected to one another if the
    real number of positive and negative expectations is known, making switching points
    of view of the analysis simple. We want to show that by utilizing this technique,
    we can estimate all of the quantities needed to compute complicated extra metrics
    like Threat Score and False Discovery Rate, which are reliant on the assessment’s
    needs.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: This is just a safety-related extension of the asymmetric fault-tolerant architecture
    for computer systems, with a primary component doing the major calculations and
    a primary checker detecting (and correcting) any primary defects. The challenge
    of determining the reliability of these simpler systems is well-studied in the
    publications.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: The chance of a system failing on a given input (or collection of inputs) is
    demonstrated to be tightly dependent on both the coverage of the primary checker
    and the coverage of the secondary checker in a paper released by Popov and Strigini
    in 2010.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: We want the primary to cover as much ground as possible in the case of self-driving
    cars. This is achieved by putting the neural networks that will drive the car
    through extensive training. The control sys must be able to manage the bulk of
    potentially hazardous occurrences if the network is “fully trained.” It’s feasible
    that, at some time, the controller learns to manage the system supervisor’s “alert
    states,” diminishing the supervisor’s total contribution to the software’s safety.
    (See Figure [17-12](#Fig12).)![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig12_HTML.png](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig12_HTML.png)
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Figure 17-12
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: The controller now captures all of the covered states in the past, as well as
    several that were previously only covered by the monitor
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Another scenario is that a part of the failure region covered by the controller
    becomes exposed during the training. This might lead to a scenario where certain
    formerly safe conditions are no longer safe.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Because the system supervisor’s coverage area cannot vary without modifying
    its implementation, a transition to one of these states will invariably end in
    a failure. (See Figure [17-13](#Fig13).)![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig13_HTML.png](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig13_HTML.png)
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Figure 17-13
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Although some of the states covered previously in the training are no longer
    covered, the controller now captures all the states covered in the past by the
    monitor
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to self-driving cars, we want the main to cover as much ground
    as possible. This is accomplished by rigorously training the neural networks that
    will control the vehicle. The management system should be able to handle the bulk
    of potentially harmful occurrences as long as the network is “fully educated”.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: The creation and execution of an experimental approach to examine these elements
    is presented and discussed in the following sections.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: 17.9 System Analysis Method
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 17.9.1 Preliminary Rounds and Introduction
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The objective  of this research is to provide a preliminary testing approach
    for monitoring emergence-related traits that arise in a controlled environment
    when a control system interacts with a system administrator. An antiviral program’s
    software design was reduced to just two components:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '**A controller:** A neural network that has been taught to control the automobile
    using reinforcement learning methods.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A** **safety supervisor** **:** A system supervisor submodule that uses data
    from a Lidar sensor to determine if the vehicle is approaching an object too rapidly
    and applies an emergency brake if necessary.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The goal of this study is to take a fresh look at the problem and assess its
    feasibility in a controlled, simulated setting. Because the system is made up
    of two constituent systems—controlling and monitoring—we believe that a point
    of view based on emerging behavior emerging from the interplay of the systems
    might increase the standard of the evaluation.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: This section explains and explores a strategy for investigating the safety level
    of an autonomous vehicle over time, which includes observing the emergent behavior
    of a neural network operator and evaluating it safely in a virtual environment.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: The suggested framework is focused on investigating the emergence that occurs
    as a result of the interplay of these two constituent networks.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: We are focused on how a monitor’s efficacy changes as the neural network learns
    and the effects of training techniques on a safety monitor’s efficacy.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: The ability to enhance neural networks by training them on datasets is one of
    their most appealing elements. One step of training involves gathering data across
    n stages and revising the weights of the prediction function.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: The weights of the function indicate the network’s status at epoch after the
    training phases. A neural net should produce satisfactory results after “enough”
    epochs. As the number of epochs required grows, the task gets more difficult.
    Driving a car is a difficult task, and saving the weights of every period is impossible.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: As a result, we define a breakpoint for a neural network N as a generic epoch
    of N. Assume N has completed thousand epochs of training. If we save the weights
    of the usually suppose every 100 epochs, we’ll have ten checkpoints:¹
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: 'Checkpoint1 < checkpoint2 < : : : < checkpoint10'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: where checkpoint1 represents the channel’s weights at epoch 100, checkpoint2
    represents the network’s weights at epoch 200, and so on.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Take a look at a self-driving car that is undergoing testing on the road. Its
    objective is to stay in the car as long as possible without crashing. As the automobile
    progresses on its journey, the world around it will alter. It is possible that
    the chance of a subsequent accident increases dramatically in specific system
    states, such as when a person unexpectedly crosses the road. If and only if the
    controller’s action results in the pedestrian being struck, will we consider it
    a failure. If the pedestrian is genuinely identified and the automobile strikes
    something else while attempting to avoid it, the same logic applies.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Any action taken by the controller that might cause a crash is deemed a failure.
    When a potentially damaging event occurs, such as when the chances of seeing a
    crash are higher than normal, the controllers is destined to fail if and only
    if its attempts to prevent the coming failure are unsuccessful. In this sense,
    we don’t distinguish between climatic changes that enhance the chance of an accident
    (e.g., a passenger strolling down the street) and the controller’s harmful actions
    at this stage of the project.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: It is the sensor’s job to run security to prevent a system failure if the controllers
    fails.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: 'If the controller fails, the monitoring must not only identify whether it succeeded
    or not, but also run a security routine to keep the entire system from failing.
    We believe the monitor’s actions to always be safe in this initial step of analysis.
    That is to say:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: The network will be in a safe condition if the controller completes all of the
    stages in the safety routine.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One of the following might cause the safety monitoring to fail:'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The obstruction has not been found.
  id: totrans-206
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The barrier is identified, but the routine’s execution is not completed. If
    both the administrator and the safety monitor crash, resulting in a failure, we
    evaluate the system to have failed.
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We may separate the system states into three groups based on this concept:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '**Safe States:** States in which the controller does not require the monitor’s
    assistance.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alert States:** Situations that necessitate the monitor’s intervention. The
    safe state space would be reentered if the impending mishap was correctly detected
    (and prevented).'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Failure States:** Areas where an accident has occurred. It’s vital to keep
    in mind that the monitor can’t identify every circumstance. There are some incidents
    that cannot be avoided and for which no monitoring can save the system, resulting
    in a straight shift from a safe to a failure state. (See Figure [17-14](#Fig14).)'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig14_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig14_HTML.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
- en: Figure 17-14
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: The phase space of the system is shown
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: What’s important is discovering the likelihood of a system failure and figuring
    out how to reduce it. Simultaneously, we want to see how the efficacy of the safety
    monitor evolves over time as the controller learns.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: This is beneficial not just for ensuring that the network improves during the
    learning, but also for the controller to get a better knowledge of the monitor’s
    use as they gain experience. Because several checkpoints of the very same system
    are evaluated under the same exact circumstances to discover how the operator’s
    behavior changes over time, this is necessary for the experimental activity.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Multiple checkpoints are required not just to ensure that the connection is
    developing, but also to track how the efficacy of the monitor changes over time.
    Furthermore, as you’ll see in the following section, if multiple checkpoints from
    the same system are tested in the same situations, it can obtain relevant metrics
    and compare the behavior of two checkpoints in the same circumstance.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: 'Several scenarios must be established before the analysis can begin. A scenario
    is a collection of beginning conditions under which the automobile is to be tested
    (for example, the car’s spawn position, seeds used in random number generators:
    : :). The difficulty level for the given example is represented by the pedix h.
    The rationale for this is that we want to test the car in the same beginning settings
    as previously, with the exception of one aspect, so that we may learn more about
    what causes the system to fail more frequently. The h variations should become
    more complicated as time goes on while remaining realistic. Scenario S might be
    modified by increasing the number of cars in the scenario or simulating climate
    change.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: A tougher version of scenario1 should arise from combining these two versions.
    It’s crucial to remember that these scenarios should not be modified after they’ve
    been established because they’ll be utilized to test all of the checkpoints. The
    information gathered here will aid in the process of determining what makes a
    scenario “harder” for some systems than others.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: 17.10 The Experimental Method
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The method for this exploratory study is broken into three stages:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '**Stage 1:** Given c checkpoints of a neural network and nh circumstances,
    the operator is assessed in all situations and its runs are logged.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stage 2:** The security monitor is verified once it has been connected to
    the system by repeating the tests that were performed in Stage 1.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stage 3:** The network is retrained using various techniques to enhance its
    efficiency from the previous checkpoint. After that, the updated controllers and
    the safety monitor are evaluated in all of the specified situations.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’re interested in determining the neural network and monitor’s quality in
    the first phase. This is accomplished in two phases. The controller’s m checkpoints
    are tested in all circumstances in the first stage. We’re primarily interested
    in seeing how the controller’s reliability varies in relation to these checkpoints
    in this phase.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: The issue of repeatability is one of the most difficult aspects of evaluating
    a neural network. It’s quite improbable that the same neural network would act
    in the same way in numerous runs if the beginning circumstances were the same.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Because of this network characteristic, it’s feasible that the mode of failure
    indicated in one of the scenario runs may never happen again, or that the time
    necessary to do so would be unreasonably long. Because it is hard to foresee all
    conceivable failure scenarios, we believe that this type of situation approach
    may help in resolving this issue by creating more challenging operating conditions
    in which the variables that cause a crash may be examined.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: To address the issue of repeatability, a black box was built for each test scenario
    that was run. This method keeps track of the operator’s actions so that the particular
    run may be looked at further to discover whatever went wrong with the controller.
    These data may then be utilized to find out which dangerous circumstances the
    controller safeguards at checkpoint j, and whether or not these scenarios are
    still protected when the network is reviewed at checkpoints --:j + x.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: 17.10.1 Controller Test
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The controllers are assessed in solitude in each situation, at each difficulty
    level, until a crash occurs. It’s still conceivable that there won’t be any failures
    recorded. Acceptable acting criteria are outside the scope of this study, although
    they remain a source of debate in academia; nevertheless, as mentioned in the
    previous section, this issue may be resolved.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Some of the difficulties that occurred during the method development phase prompted
    the decision to isolate the controller in order to test it. The primary challenges
    are consistency and non-intrusiveness. As previously mentioned, the neural network’s
    repeatability problem is handled by creating a black box that saves information
    about the car’s condition in every frame. Because a safety-brake enforced by the
    monitor would almost certainly modify the ambient circumstances for the duration
    of the simulator, we wouldn’t be able to calculate controller performance metrics,
    we can’t test the entire system (controller and monitor) at the same time.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: Testing the controller in isolation aids in the resolution of these difficulties
    and serves as a warmup for the second step. In all cases when the controller has
    been tested for each complexity, the following must be computed at a minimum:![../images/520777_1_En_17_Chapter/520777_1_En_17_Figk_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Figk_HTML.jpg)
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: One of the most important metrics for assessing a system’s dependability function
    R(t) is the Median Time to Failure, which is simple to compute under simulated
    conditions and is used to determine the rate of the exponential function. Statistics
    in the automobile sector, on the other hand, are frequently expressed in terms
    of traveled distance, such as average distance to failure, collision incidence
    per kilometer, and so on. If the parameters and simulation hardware are powerful
    enough to conduct the computations at a defined time-step, it’s very simple to
    flip the point of view on the data using this approach.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: 'We expect the following inequation to continue as long as the neural network
    is fully trained: Ri(t) 6 Rj(t), where I and j are two checkpoints, and I j. This
    may be easily confirmed using the data collection method described previously.![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig15_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig15_HTML.jpg)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Figure 17-15
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: The reliable function determines the likelihood that the system will continue
    to work at time t. We anticipate that more experienced drivers will be able to
    complete longer runs than less trained networks
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: 'Other information should be recorded as well, if the simulator used for testing
    permits it, in order to improve knowledge of the controller’s behavior, such as
    :'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The car’s instantaneous velocity and acceleration vector.
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: What the automobile collided with (another car, a walker).
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Set one or more destination goals and track whether the vehicle meets them.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a crash happened at time t, determine environmental conditions at time t-x.
    These figures are crucial for distinguishing between “safe” and “catastrophic”
    failures. If a fence is struck at less than 10 km/h, for example, it may be deemed
    a less harmful accident than striking a person at the same speed.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because a trained driver causes fewer accidents than a newbie, we anticipate
    the reliable function to increase as the controller learns, boosting the MTBF.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: If the black box utilizes better data, it’s also possible to track changes in
    the car’s behavior in connection to the situation and difficulty level. If we
    double the number of automobiles in the situation, for example, the number of
    crashes with other barriers will almost certainly increase. If this is the case,
    the simulation should be looked into more in order to focus the training strategy
    in a specific direction, since this might result in the controllers colliding
    with walls while attempting to avoid other automobiles.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: 17.10.2 Monitor or Observation Testing
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After the operator’s runs have been documented, the monitor testing  may commence.
    Not only are we evaluating how good the security monitor is at preventing crashes
    during this phase, but we’re also searching for evidence of which situations are
    “difficult” for the monitoring and which are “easy” for the controller.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: Because the controller now encompasses all of the failures previously disclosed
    by the screen, and the risks posed by its novel behavior are too great for the
    watch to detect, its behavior may evolve to the point where the monitor is no
    longer capable of detecting impending failures as the internet backbone matures.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the opposite is a viable option. In the early epochs, the
    controller, for example, would drive “crazy,” making a lot of abrupt, high angle
    steering and ride at high speeds. Because the controller’s behavior is unexpected,
    the monitor will have a harder difficulty anticipating the future state. The network
    will move more smoothly as it learns, making it simpler for the monitor to see
    potential accidents.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: 'The main issue is that the monitor’s effectiveness may diminish as the network
    learns, resulting in a completely pointless component that may even be harmful
    to the system’s performance: the operator may grow sufficient to cover all of
    the damage covered by the screen at a previous checkpoint, resulting in a useless
    component. The system’s overall safety may not be jeopardized if we believe the
    monitor’s activities to be completely safe, but the safety monitor’s security
    will result in fewer smooth trips.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: The monitor is put to the test by repeating the runs that were produced during
    the controllers testing step. The beginning conditions must also be the same,
    and they must be kept in the black box from the previous stage. The controller’s
    prior runs are now repeated, with the monitors linked to the systems and the warnings
    raised throughout the run recorded, as well as whether it was able to avoid the
    previous crash.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: The main issue at this point in the investigation was non-intrusiveness. We
    cannot consider rerunning the simulations just by adding the safety monitor and
    watching how things proceed for the reasons stated above. If an alarm is triggered,
    the safety monitor overwrites the controller’s action, altering the next section
    of the run. This isn’t an issue in theory if you can tell the difference between
    false and real positives. However, without developing software sensors monitor
    and mapping the environment, we won’t be able to predict what a technical error
    will be.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: Because this is a safety monitor, there will be false +ves, even if they are
    extremely low, thus this method will not solve the problem.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: The goal is to maintain track of the warnings that occur during the operation
    while also avoiding the safety procedure from being initiated. Because we’ll be
    repeating the runs from Phase 1, we’ll be able to pinpoint the exact time t when
    the switch to the alert state happened before the crash. Because we know t, all
    prior alerts to t are false +ves or false reports, based on this information.
    Coverage can be approximated by allowing the Monitors to start the safety procedure
    after this point in time.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned  in the previous chapter, we use the confusion matrix to show the
    predicted values of a model in comparison to real values to see how good it is
    at classifying tasks. However, measuring all of them for real-time critical systems
    is difficult, if not impossible. It’s especially difficult to comprehend when
    the operator averted a collision, but the monitor did not sound an alarm.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: This makes calculating the number of real negatives exceedingly difficult since,
    in most cases, such instances can only be recognized when an operator reviews
    each individual run, presenting a degree of arbitrary nature into metrics like
    true negatives.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: For example, a safety monitor input is made up of a series of timed input that
    may be thought of as the development of the environment while the system is running.
    As a result, it’s impossible to predict whether another state will be alerted
    or secure since we don’t know when the collection of inputs that would ultimately
    lead to a crash will begin.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: Because the monitor requires a certain number of true negatives, the metrics
    and rates that may be calculated are limited. Simultaneously, the security monitor
    classifies the condition of the system in each frame, collecting Lidar data, assessing
    it, and deciding whether or not a safety brake is required. Due to the system’s
    real-time nature, we may regard any frame in which the monitors does not raise
    an alarm as a true negative. We can compute all of the widely used metrics in
    statistical classification models using this method.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: We must combine genuine and false pluses and minuses, such as precision and
    accuracy, to achieve large benefits since the vast quantity of real negatives
    is likely to be far greater than the other metrics for the reasons previously
    stated. Because the false positive rate is stated as FP/FP+TN, numbers with numerous
    zeroes before the first significant digit result. Furthermore, in order to give
    an intelligible rate measure for false positives, the quantity of false positives
    was computed over the distance traveled in a session  .
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: 'The rates of correct and wrong operator predictions were determined as previously
    mentioned and may be used to compare checkpoints:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: Miss rate and awareness
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specificity and consequences
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Correctness
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Precise
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matthew’s Factor of Connection
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Percentage of false positives per meter
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Precision recall curves reduced
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An ISO standard was used to choose accuracy and reliability. The notion of accuracy
    has been superseded by the concept of prediction trueness, with accuracy being
    explained as a representation of a mix of random mistakes needing large precision
    and accuracy. The most helpful metric for assessing a confusion matrix is Matthew’s
    Correlation Coefficient, which is calculated as the total of all forecasts and
    has been found to offer more accurate overall data than the F-score.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: We chose not to use Fi since it does not function well with imbalanced datasets
    in general, resulting in conclusions that are either overly optimistic, depending
    on the size. We opted to utilize MCC as a measurement of the monitor’s performance
    because of the large number of True Negatives and our interest in the monitor’s
    overall utility.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: The False +Ves per Meter is used to predict how the system would behave if the
    controllers and the security were both turned on and operating together, as well
    as to quantify the impact of the latter’s faulty safety-brakes. The ROC2 curve,
    a graphical representation of a classifier tool’s diagnostic abilities, might
    have offered a fast visual representation of the sensor’s efficacy, however this
    method was not possible. The x-axis is determined by PR, whereas the y-axis is
    determined by TPR.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: The figure would be flattened on the left side due to the significant imbalance
    of our dataset, where the number of false is likely to be lower than 10-2, based
    on how genuine negatives were classified. As a result, based on data obtained
    for each checkpoint in each difficulty, we used highly precise cropped to produce
    a graphical mean, a curve generated by defining the x-axis by recall and the y-axis
    by accuracy.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: We couldn’t construct a test-set to evaluate the monitor while altering the
    cutoff for choosing whether to brake and presenting the whole curve since the
    monitor only defines states as safe or dangerous in real time depending on data
    provided by the Lidar sensor. As a consequence, past data for each degree of complexity
    was computed, and these values were displayed to explore the link between difficulty
    and monitor efficacy, cropped to the region containing the anticipated value.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: When testing the monitor, it’s a good idea to put it through its paces in order
    to gather additional data and develop links between the data. This element is
    unconnected to the level of difficulty mentioned above, since it is anything linked
    to the environment that may provide proof as to when the monitor is operating
    well and when it is not, and it is more involved with fault injection at a higher
    level.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: The ways by which a security monitors’ settings may be modified are mostly defined
    by how it’s implemented, and the development team is in charge of selecting what
    problems to include and how many to include. Reduce the amount of data read by
    the sensors or add noise into the observations are two easy options. This stage
    will teach you how to change the software’s internal settings to get the “ideal”
    version, which will be utilized throughout the controllers retraining process  .
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: 17.10.3 Controller Retraining
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At this point  , we’ve gathered information on the monitor’s and controller’s
    actions. Whenever the neural network is saved from the latest checkpoint, we will
    investigate how much these values differ depending on the learning technique used.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: We’re looking at a controller constructed up of a neural network that has been
    trained using reinforcement learning techniques, as described at the start of
    this chapter. In these methods, a reward function is utilized to inform the network
    whether it is functioning GOOD or BAD, and it is calculated for each prediction
    step.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: 'The essential parameters are required by the training function and are reevaluated
    at each algorithm’s iteration:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: Response of the network.
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The current state of the system where the action was performed.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A prize given for completing a task in a specific manner.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this phase, we’ll look at how different neural network training techniques
    impact the overall behavior of the system, with a focus on the security monitor’s
    efficacy.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: To begin our investigation into this issue, we identified four techniques as
    well as the expected consequences when the training is done. These results are
    “predicted” in the sense that we don’t know how the network will react to a modification
    in the training method or if the observed behavior will be the same as the one
    predicted.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: 'The strategies created using this technique are mostly dependent on the reward
    function and the channel’s actions:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: S1) When the automobile strikes anything, the reward function is more punitive,
    but braking is somewhat more rewarded, as long as the car does not stop going.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: S2) The security monitor is connected to the system, and if an alarm is raised,
    the monitor’s response takes precedence over the network’s (the safety brake).
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: S3) If the monitor raises an alarm, the network’s activity is substituted by
    the monitor’s. For acting like the monitor, the network receives a good reward.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: S4) If an alarm is triggered, the training phase is terminated and the network
    is given a poor reward.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We estimate the controller’s median time/distance among failures to be reduced
    if we use S1\. Giving a higher negative incentive for crashes and a lower positive
    reward for braking (if the car does not stop driving) should encourage the car
    to choose braking over swerving (which might result in a new dangerous scenario),
    thereby increasing the time between failures and the distance traveled.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: The goal of S2 is to “train” the network to brake if the monitor raises an alert.
    As a result, the warring states formerly covered by the Monitor might become safe
    states.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: S3 resembles S2 in many ways. Providing a positive incentive for behaving like
    the monitors is expected to speed up learning.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: S4 is by far the most promising method, and it has the potential to provide
    the most intriguing outcomes. When the security monitor raises an alert, regardless
    of whether it’s a true or false positive, a negative reward and a change in the
    training step should compel the network to totally avoid instances where the monitor
    intervenes. Essentially, we expect the safety component’s efficacy to be significantly
    decreased.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: The new devices are tested as in Phase 1 when the four controllers have been
    sufficiently educated. For the controllers and monitor, the same measurements
    are estimated, and the results are compared to the actual checkpoints  .
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: 17.11 Method Implementation and Results
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The tools utilized, the software architecture and technique implementation,
    as well as the data gathered throughout the analysis, are reviewed in this chapter.
    A DDPG Agent1 was taught how to drive in a city setting. During the training,
    checkpoints of the network’s status were recorded for comparison. To provide a
    unique view on AV behavior, these network checkpoints were tested with and without
    a simple safety monitor.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 17.12 The Tools and Software
  id: totrans-294
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 17.12.1 CARLA Simulator
  id: totrans-295
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: CARLA^([5](#Fn5)), an open-source simulator created by University of Barcelona
    researchers, was used to construct a realistic environment with accurate physics
    simulation and data sensors. The objective of this simulator was to provide an
    environment in which AI agents could be trained to drive, with a high level of
    control over simulation settings and the simulation of real sensors that could
    be modified to improve or diminish data quality or insert mistakes.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: 'CARLA is designed to work in a client-server environment. The server is essentially
    a game created in C++ using Unreal Engine 4\. C++ speed is unquestionably critical
    to the server’s functionality: not only must the surroundings be simulated (including
    pedestrian/vehicle movements, climate modeling, etc.), but also all of the data
    required from the sensors linked to the system'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: CARLA is now at version 0.9.7, and each release brings significant improvements,
    earning further attention from experts for its realism. Unfortunately, CARLA 0.9
    had just been released when our study began, and the tools we needed were not
    yet available online⁵.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: Version 0.8.4 was utilized at first due to the number of jobs completed for
    the previous stable version of CARLA.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: Version prior to 0.9 have limitations on the amount of control you have over
    the simulation’s parameters and the data it collects. This does not obstruct our
    study, but it does limit the useful information about the surroundings and system
    in some way. Some of these flaws still exist in previous simulator editions, but
    the bulk of them were fixed after the upgrade from version 0.8 to version 0.9².
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: One of the most severe difficulties was revealed to be coordinate systems. Prior
    to version 0.9, developers utilized UE4’s default coordinate system, which is
    left-handed despite the standard being right-handed. This looks to be a minor
    issue, since the problem may be easily solved with the use of a transformation
    matrix. However, due to time constraints, it was decided to stick with the developers’
    method and modify the data mostly at the analysis stage.²
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: 'This version of CARLA includes four sensors, which were all used in the experiments.
    Because of the Python APIs, they’re straightforward to learn:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: Cameras
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A picture of the scene is provided by the final camera.
  id: totrans-304
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: To understand depth in the surroundings, the depth map camera assigns RGB values
    to items.
  id: totrans-305
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: CARLA (see [http://carla.org/](http://carla.org/))
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A semantic segmentation classifies distinct items in the view by presenting
    them in various colors based on their class.
  id: totrans-307
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Lidar based on raycast
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By lighting the object with laser beams and measuring the time it takes for
    the reflected light to return to the sensor, Light Detection & Ranging (LDR) is
    a technique for detecting the environment and estimating the distance between
    objects.
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The three cameras were utilized throughout the network’s training phase. Three
    scene final cameras are mounted on the automobile to allow the driver to observe
    the surroundings.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: The vehicle may acquire a color-map of the distances between objects in the
    scene thanks to the depth map camera. Semantic segmentation provides picture categorization
    features by contacting the server for ground-truth information. This is undeniably
    a simplification of a real system, in which the most powerful photo software is
    essentially other neural networks that have been trained independently. A misclassification
    can also be viewed as a control system error.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: If a possible threat is detected, the safety monitor will not “fix” the misinterpretation;
    instead, it will react promptly and safely to avoid the consequences; hence, this
    simplification will have no influence on the entire approach.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: The other accessible sensor for this version of CARLA is a raycast based Lidar.
    This sensor’s parameters may be readily tweaked to mimic actual Lidars like the
    Velodyne Lidar or flaws like low data quality, noisy data, or data loss. The Point
    Cloud format was used to produce the data.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: 'Because high hardware resources are required to mimic a genuine Lidar in the
    simulations, a significantly modified version of the Velodyne64 Lidar is used
    with the given criteria:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: Number of channels = 64
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The system’s total number of laser beams. These lasers are spaced evenly along
    the y axis. The more lasers there are, the more precise the scanning will be.
  id: totrans-316
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The range is 75 meters.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The range of lasers in meters
  id: totrans-318
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Frequency of rotation = 15 Hz
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These settings define the scanning beams’ rotation rate (in Hz)
  id: totrans-320
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1.000.000 scores per each second
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The quantity of points produced by the sensor for each picture
  id: totrans-322
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: FOV vertical boundaries (high = 24m, lower = -2m). Distances are measured in
    relation to the sensor’s location.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scanning’s min and max heights
  id: totrans-324
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The simulator has Python APIs for modifying sensors as well as a lot of control
    over what’s being emulated, such as seeding places for spawning, pedestrian and
    vehicle behavior, and the status of “actors” in the scene, such as their position
    and velocity.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: All of this information, as well as ground-truth values, is provided by the
    simulator. Simulation-related measures, such as simulation time-steps or frames
    per second, might be used. Metrics connected to actors include vehicle speed,
    collision severity, and the 3D acceleration vector.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: During the testing of this tool, an issue with the Lidar sensor data was discovered,
    which has yet to be rectified. The issue caused the bounding boxes of the cars
    to be warped when they moved, resulting in very poor data. Following considerable
    investigation, an updated version of the simulator was discovered, with the bounding
    boundaries for each vehicle being modified to produce correct data. Developers
    are currently working on this problem, but it cannot be fixed without human involvement
    in the source code.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: 17.12.2 Controller Settings
  id: totrans-328
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The neural network that will select what action to take to move the automobile
    is the most essential element for the controller implementation. We required a
    framework with the following features.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: A code for training.
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are no significant flaws in the codebase.
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create an atmosphere in which the network can communicate with CARLA.
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make a default training approach available.
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We chose Intel AI Lab’s reinforcement-learning platform Coach after analyzing
    all of the device applications for CARLA.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: 'This framework fulfills all of the following criteria: it is distributed as
    a Python package that may be edited. The project’s development team assures us
    that the product will be of high quality. There are also numerous settings to
    choose from as a starting point. Two of these choices include a CARLA simulator
    interface and a preset training strategy, which is precisely what we needed.'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: The Deep Deterministic Policy Gradient method, introduced in 2015, is implemented
    in these settings. As demonstrated in the original work, this method performed
    well in tasks such as vehicle driving.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: 'P1: The first setup perceives the environment using a single front camera as
    well as the additional data enhancement cameras given by CARLA. This preset’s
    agent will very definitely lack any sense of depth provided by the regular camera,
    instead depending only on the depth camera.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'P2: Because the automobile is equipped with three conventional cameras as well
    as all of the data augmentation cameras described in the preceding section, this
    setup employs all of the cameras accessible in CARLA and has a much more fascinating
    design.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The usage of data augmentation cameras allows us to ignore object misclassifications
    as well as other benefits such as estimating distances between objects. This is
    a simplified form of a true architecture, in which object recognition units are
    neural networks that must be educated and assessed differently, as stated in the
    prior section.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: A misclassification, on the other hand, would very definitely cause the controllers
    to act in unexpected ways, which the security monitor would have to be able to
    detect and perhaps correct. Sadly, even if the vehicle is being rewarded positively,
    the initial setting has a flaw that causes it to stop throttling. It would have
    been interesting to test this setup as well, to see how it impacts the safety
    monitor’s efficacy in terms of network data access.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: It’s crucial to note that our objective isn’t to create the “ideal” agent or
    autonomous vehicle. The codebase was examined, but owing to time constraints,
    we were unable to examine all of the specifics of the given implementation. This
    framework served as an illustration of the ideas discussed in this book.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: 17.12.3 Safety Monitor Implementation
  id: totrans-342
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To begin the research, we required software that could read Lidar data and
    map the environment as well as detect impediments. This software must also be
    real-time and capable of communicating with CARLA. The latter is self-evident:
    the CARLA server must receive the “brake” order whenever an alert is triggered.
    The first required some thought: one might envision capturing the Lidar data ahead
    of time and then conducting the simulations using this data. Unfortunately, this
    method will not work since we are concerned not only with having a 100% accurate
    forecast, but also with the quality of monitor’s security measures.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: If the same measurement is made in two separate simulations and the results
    are somewhat different, the monitor may respond in a completely different way
    than it would have if the real-time data provided during the model had been used.
    If the precision of measurements is solely relevant to the research simulator,
    we can’t disregard the impact that a brake has on a particular experiment.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: A survey of the best “non-neural network” approaches, as well as an evaluation
    of the open-source instruments available, were done in order to build an appropriate
    security monitor. To process point cloud data, the Point Cloud library was chosen
    as the open-source library. It was written in C++ to achieve those objectives
    while processing large amounts of data. This library was initially released in
    2011, and each successive version has enhanced it, due in part to the large community
    that has helped with testing and debugging new features.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: 'This package contains a set of methods that implement the most common Point
    Cloud processing techniques. The steps for creating an object-detection module
    are outlined here:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: '**Down sampling:** With a considerable degree of redundancy and noise, a single
    check can produce 100,000 records. As a first step, a down sample is generally
    required to eliminate all of the “useless” data. The Voxel Grid Filter was selected
    for this stage after considerable consideration.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ground segmentation:** The first required step after downsampling (if necessary)
    is to filter out data that is worthless for object recognition, such as points
    relative to the ground. To distinguish the ground from the things we want to identify,
    these points must be filtered. In our implementation, we use the RANSAC2 algorithm,
    which is a mechanism for distinguishing between “inliers” and “outliers.”'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clustering:** This last stage is necessary to properly define what constitutes
    a scene item and which data points are linked to that item. Clustering techniques
    based on point proximity can be used to accomplish this. Because it is a range-finding
    approach calculating the Euclidean distance between points and the premise that
    dense points indicate the same item, the Euclidean Clustering Technique was chosen.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tracking and Avoidance of Objects:** Items identified in the first three
    components must be watched throughout time to determine if two objects observed
    in two sequential stages are the same entity. This is usually done by combining
    a failure safety procedure with physical models, such as the Kalman Filter, that
    anticipate their behavior over time.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, developing a Kalman Filter for such a complex model would have taken
    much too long, forcing us to put our study on hold. As a result, we streamlined
    the object identification and failure avoidance procedure as follows:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: Only data from in front of the automobile is saved. This is a significant improvement
    to the concept, since the monitor can now only identify obstructions in front
    of the vehicle. However, while this will undoubtedly affect the safety monitor’s
    efficacy, the ideas discussed in the preceding section remain valid.
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The failure prevention procedure used is based on Mobileye’s Responsibility-Sensitive
    Safety paradigm, which was proposed by Intel. When an item is detected, the speed
    of the object in relation to the system is calculated. If the system’s distance
    traveled in one second plus the distance is greater than the object’s distance
    traveled plus the space between the systems and the objects, a safety brake is
    engaged.
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because the safety monitor is written in C++, an architecture to communicate
    data with CARLA was created, both to use the Point Cloud library and for performance
    considerations.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: The CARLA client’s point clouds. This data is analyzed in the same way as the
    previous phases, and if necessary, an alarm is given back to the client. If the
    monitor receives an alarm message, the controller’s operations are overridden,
    and a brake is applied. The object identification module was influenced by Engin
    Bozkurt’s open-source project. To adjust the detection algorithm settings to our
    purposes and to interface with CARLA, the software was heavily changed.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: 17.13 Experimental Activity
  id: totrans-356
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This part explains how the approach created in the preceding chapter was put
    into practice, as well as the technical issues that arose during the process.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: Coach’s default technique was used to train the Controllers in an urban context
    in order to produce four checkpoints that were then assessed.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: 'CARLA offered 152 spawn points, which were used to create scenarios. A basic
    configuration and three variants of it were created for each spawn point:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: 'h0-Default Setting: With 30 people and 15 automobiles, the map is produced
    using the same circumstances as when the controllers were trained.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'h1- Setting for Pedestrians: The map is created with the number of pedestrians
    increased from 30 to 60.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'h2- Setting Vehicles: The map is produced with the number of cars in the environment
    increased from 15 to 30.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: h3- The map is made by merging h1 and h2, resulting in a scenario with 60 pedestrians
    and 30 automobiles.
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 152 pairs of unique seeds were produced for consistency and reproducibility
    throughout the variations, each with its own beginning point. You may use the
    same seed for many iterations of the same starting spot this way.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: The automobile is also assigned a destination goal to attain, which is likewise
    documented for repeatability, to supplement the information regarding the system’s
    overall performance. If the goal is met, the achievement is noted, and the sys
    is assigned a new target to pursue.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: In normal cases, a crash might take an extremely long period to occur. As a
    result, a maximum operating duration of 15 min was set to show the principles
    presented in this work, after which the system’s mission was regarded as complete.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: Four checkpoints were developed and evaluated in the first part of the investigation
    using the technique outlined in Section 3\. The coding was publicly available
    because the Coach project is open-source.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: 'We were able to utilize software probes to monitor the controller’s activities
    as a result of this. The source code was changed to include instructions for writing
    all required data into a separate file for every run:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: The situations’ starting position and seeds
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Actions that the controller has taken
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What will happen if there is a collision?
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a target is met, make a note of it as well as the new target coordinates
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In general, altering the source code may result in a reduction in overall performance
    and outcome accuracy. The CARLA simulator, thankfully, allows you to run simulations
    at a specific time step. To guarantee that all data received from the server is
    correct and timely, this was set to the minimum: ten frames per second. Because
    we have no control over the variable time-step, it may introduce unpredictability
    into the data. This also serves as a baseline for testing repeatability. It took
    roughly a month and a half to finish the initial training portion, as well as
    the Controller test.'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: 'In the second step, the security monitors were assessed at each checkpoint.
    The source code was changed once again to establish two autonomous, parallel processes:
    one takes Lidar data from the CARLA server and sends it to the security monitor
    server, while the other waits for the security monitors to decide whether or not
    a brake is required.'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: Each frame, the CARLA system creates Lidar data. Because the burden for data
    creation is completely dependent on the CPU, execution times are significantly
    slower. Unfortunately, if FPSs are less than ten, CARLA has a problem that causes
    data to be incorrect. To guarantee the lowest constraint of ten frames per second,
    a powerful machine was necessary. Software probes were added to the codebase to
    gather information regarding the monitor’s alarms, and the source code was modified
    once more. While the safety-behavior monitor is being watched, the first step’s
    runs are now repeated. During the test, all of the alerts that were generated
    were false positives.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: To assess the quantity of true positives, the emergency brake is activated two
    seconds before the accident. This method allows us to assess the safety-performance
    monitor in its operating context.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: Following the completion of the first phase, the data obtained is processed
    to computerize the measurements stated in the preceding chapter.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: 'Checkpoints for the controller:'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Average time among failures
  id: totrans-379
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Interval between failures (MTBF)
  id: totrans-380
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Rate of failure
  id: totrans-381
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Stability
  id: totrans-382
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Security Inspector:'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrix of predictions confusing
  id: totrans-384
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Positives/negatives rates (true/false)
  id: totrans-385
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Perfection details
  id: totrans-386
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Matthew’s Correlation of Coefficient
  id: totrans-387
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Percentage of false positives
  id: totrans-388
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Training is continued from the previous checkpoints using the previously mentioned
    techniques, and the measuring procedure is performed in the same manner.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: Some of the approaches mentioned need security monitor training, leading in
    exceptionally fast execution times. Because of the high processing load required
    to create Lidar data, this stage took roughly three months, after which the training
    was stopped. The data collected may be compared to evaluate if the network is
    learning correctly as well as how the security-efficacy monitor evolves over time.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: Data was gathered and analyzed using Python scripts to aggregate data and provide
    metrics for the controller and the safety-overall monitor’s functionality. For
    this type of work, data aggregation is essential. However, due to the complexity
    of these systems and the infrequency of many detrimental occurrences, individual
    runs must be evaluated and compared before data can be aggregated.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: Due to the large quantity of data obtained, we offer the collected results primarily
    in aggregated form in the following part. Other issues about “raw” data, which
    were not included in this research but were provided separately for evaluation,
    exist.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: 17.14 Results
  id: totrans-393
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 17.14.1 Testing the Controller (Phase 1)
  id: totrans-394
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The collected data is kept in different files for each run, and the measures
    specified in this chapter are computed using Python code. The obtained data is
    compared to determine the controller’s goodness and modifications in the safety-efficacy
    monitor’s across the neural network’s stages.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: The distances traveled for each circumstance were plotted to determine whether
    the number of meters walked was increasing and if there were any scenarios that
    were particularly “positive” or “challenging” for the system.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the first step, which aids testers in distinguishing between significant
    and minor scenarios. If the distance covered by the controller in scenario x is
    less than the usual distance traveled in all checkpoints, there are two options:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: There may be a danger that the controller has not learned to handle if the controller
    always goes the same distances in all checkpoints before exploding.
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the distance traveled varies in a brief interval, the likelihood of a collision
    may be determined by the initial conditions. In any event, using this method,
    it’s easy to figure out which situations lead the controllers to crash rapidly,
    and each one may be investigated further.
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s important to remember that if a pattern arises when testing various checkpoints,
    such as when the controller regularly works exceptionally well or exceptionally
    poorly, in both cases, a study of the particular instance is necessary.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: For these reasons, the rationale for “poor” runs is self-evident. It may sound
    counterintuitive but doing many “good” runs in the same circumstance necessitates
    more care. An examination of the relationship between performance and beginning
    conditions is required, and it may be shown or refuted using this method.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: When the sys recognizes a “good pattern,” like a run in which the car just repeats
    the very same sequence without encountering any other cars on the road, a more
    complex problem arises.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: 'The order of magnitude differs significantly between Checkpoints 1 and 4 at
    normal difficulty, and in a few situations, the maximum length set for these tests
    has been achieved. Another fascinating feature of this method is that the bottom
    constraint on distance traveled for C2 : : 4 remains constant throughout the challenges,
    remaining at 22 meters.'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: A closer look at the travel distances and running times indicates that there
    are runs in which the controller makes no progress, implying that the event that
    triggered the crash was of a sort that the controller couldn’t handle. These types
    of results are undoubtedly intriguing in terms of determining whether the shortest
    runs share any environmental variables that might cause the controller to perform
    poorly. (See Figure [17-16](#Fig16).)![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig16_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig16_HTML.jpg)
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: Figure 17-16
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: At normal difficulty, controller C1 moves in meters at every situation
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: 'The time gap between two consecutive activities is known because the simulation
    time that has elapsed between two stages of the simulation is specified and understood:
    the true total length of a single run may be estimated by counting how many actions
    the controller has performed. (See Figure [17-17](#Fig17).)![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig17_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig17_HTML.jpg)'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: Figure 17-17
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: Controller C4’s distance traveled at every scenario at normal troubles
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: We can simply approximate the dependability function of every checkpoint in
    this way, using the mean MTTF in each degree of difficulty.![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig18_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig18_HTML.jpg)
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: Figure 17-18
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: After x min of reaction, the chance y of the systems being operational is shown
    graphically
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: The MTTF of the initial checkpoint is relatively low (20 sec), as predicted,
    and grows as the number of checkpoints rises. Interestingly, the second checkpoint
    appears to perform better than the third and fourth checkpoints. Despite this,
    analysis of a portion of the runs in which the second checkpoint accomplished
    extremely good results in terms of time to collapse and distance traveled revealed
    that its driving is far more dangerous than the other two and is likely to result
    in a poor driving style in which the car prevented a crash almost every time by
    steering at the last possible moment. Another indication that C2 isn’t always
    superior to C3 and C4\. C3/C4 indicates that the apparent increased safety is
    most likely due to “fortunate patterns” in the sense indicated above.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, as the findings from Phase 3 will demonstrate, the controller was
    able to overcome this issue.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: 'Checkpoint distances follow a similar pattern: longer runs are really trips
    in which the automobile travels more meters. This guarantees that the system isn’t
    “cheating”: if the car isn’t moving at all, the execution time will be greater.
    We may estimate the durability function in terms of km traveled prior to crashing
    by computing the average distance traveled by each checkpoint in each level of
    danger.'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the observed advances in the distance to failure tend to coincide
    with the progress for a while to failure, implying that the two metrics are linked.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: 'Because CARLA permits the kind of item with which a collision happened to be
    recorded, rates of the type of object collided in relation to total collisions
    are calculated for every checkpoint, for each risk category. This method is beneficial
    for a number of reasons: (See Figure [17-19](#Fig19).)'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: To see whether the automobile slams into walls, lamp poles, or fences, indicating
    that it is going off-road.
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To see how the automobile reacts to different levels of difficulty; for example,
    if the number of people is raised and there are fewer pedestrian collisions, the
    system may be capable of preventing human accidents.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To recognize the system’s capacity to prevent failures when interacting with
    certain things.
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig19_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig19_HTML.jpg)'
  id: totrans-421
  prefs: []
  type: TYPE_IMG
- en: Figure 17-19
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: After x km, the chance y of the system becoming operational is shown graphically
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
- en: '![../images/520777_1_En_17_Chapter/520777_1_En_17_Figl_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Figl_HTML.jpg)Those
    diagrams may be used to see how the system performs as the scenario’s complexity
    is increased while it is being trained, as well as to see whether there are any
    correlations between the types of collision and the security checks. The first
    checkpoint, as expected, collides with off-road objects, showing the controller’s
    weak driving abilities. (See Figure [17-20](#Fig20).)![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig20_HTML.png](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig20_HTML.png)'
  id: totrans-424
  prefs: []
  type: TYPE_IMG
- en: Figure 17-20
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: Charts
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: It also appears that the ratio of collisions with generic barriers has a tendency
    to follow the total checkpoint achievement. When comparing this graph to the contributing,
    it can be seen that C1 has the largest ratio of collisions against barriers, whereas
    C2 has the lowest ratio. C3 increased the frequency of these impacts, which was
    accompanied by a decrease in the MTTF/ MDTF, which was later decreased by C4.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: Even though the four degrees of difficulty described were fairly simple, they
    proved to be an effective means of evaluating the system’s performance in situations
    other than the training environment. In problems three and four MTTFs and MDTFs
    are significantly lower, indicating that situations with high traffic are more
    difficult to manage. At the similar time, the elements of the difficulty chosen
    influence the increase/decrease in hit percentages with a certain type of object.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: This means that the reported collisions are dependent on the surroundings. Increasing
    the population, as well as the number of automobiles, leads to more collisions
    with these “objects.” As the number of people and automobiles grows, it becomes
    clear that collisions with other vehicles remain the major cause of crashes, showing
    that crowded traffic puts the controller in more hazardous positions.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: These characteristics are important in defining more difficult problems. These
    metrics also allow for the detection of connections between the rise and fall
    of different types of collisions.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: By using the technique provided for the first step, which includes the development
    of situations, issue levels, and metrics selected, many features of the controller
    may be seen without actively watching its executions. Furthermore, by combining
    the few measures specified, potential connections between ambient circumstances,
    starting conditions, and checkpoints might be overlooked.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
- en: 17.14.2 Monitor Assessment (Phase 2)
  id: totrans-432
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The security may be assessed after the controller has been verified and its
    runs have been logged in order to measure its prediction accuracy and how it affects
    the overall system’s safety.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: 'As previously indicated, Lidar data is collected at every frame and transmitted
    to the security monitor. These data are then evaluated using the algorithm outlined
    in the Sensor Development sections, and a message with specifics on whether the
    vehicle is braking is sent back to the control system. There is no coordination
    between these two components, as there is in real-world systems of this type:
    Because this would result in choppy runs, the controller would be unable to wait
    for the security monitor at every frame.'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: 'The following technique is used to calculate the quantities of real positives,
    real negatives, fake positives, and false negatives:'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: The control system runs recorded in the initiation section are replicated after
    attaching the Safe operation to the automobile.
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Safe operation is permitted to issue alerts, but the safety brake is not
    applied until the period t has passed since the system entered an alert state,
    as described in Chapter [3](520777_1_En_3_Chapter.xhtml).
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because a choice of a “early” t may induce a brake for an activity that the
    processor managed, and a choice of a “late” t may cause the safety monitor to
    fail merely because the safe stop was activated too late, t is an important parameter
    for the observation’s dependability. When a vehicle transitions from a secure
    to an alert condition, the safety brake should be activated as quickly as possible.
    Unfortunately, understanding when this transition occurred is not always feasible
    (if not impossible in complicated runs).
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All warnings produced before t are considered false positives, based on the
    average speed of the automobile in relation to the velocity limit and the time
    required to analyze Lidar data and obtain an answer from the security monitor,
    which was set at two seconds in this study.
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: True negatives are any frames for which the monitor reaches a prediction but
    does not issue an alarm.
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the system lives for the maximum duration set for a single mission, but the
    safety issues an alarm after time t, a false positive warning is raised.
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An effective avoidance of an accident (if one occurs) as a result of the Safety-brake
    Monitor’s is regarded as a real positive.
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regardless of whether the Safe operation triggered an alert or not, if a collision
    occurs, it is classed as a false negative.
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After determining the amounts of genuine, fake, affirmative, and negatives,
    they can be combined in more exact measures.
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The technique proposed in this study looks to be a good strategy to understand
    and verify the controller’s behavioral assumption as well as monitor the monitor’s
    behavior. The monitor’s efficacy appears to be impacted by the controller’s dependability.
    While the True Positive Rate remains steady around 0.75, we can observe how the
    monitor’s precision decreases after C2, raising some questions about the safety
    monitor’s long-term efficacy.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: The decrease in precision indicates an increase in false positives, which leads
    us to believe that the monitor is unable to accurately identify the system’s states
    owing to the controller’s new behavior. The MCC of every checkpoint supports this
    notion, exhibiting the same accuracy behavior that the controller is taught. We’re
    interested in seeing if the MCC lowers in phase 3 once the controller is restrained
    because it’s a measure of the monitor’s performance overall.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
- en: As expected, this monitor creates a large number of false positives. This has
    no effect on the efficacy of the surveillance approach outlined, but it does assist
    to understand how the system would behave if both parts functioned together, i.e.
    with a lot of “false” security produced by the safety-false monitor’s alerts.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: Viewing the accuracy-recall curves offers a fast visual representation of the
    safety-performance monitor’s decline, which works well with a “dumb” controller
    but becomes nearly disruptive with better trained controllers.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
- en: Figure [17-21](#Fig21) demonstrates that, despite its low efficiency, the monitors
    perform best at the highest difficulty setting, i.e. when the number of people
    and automobiles in the scenarios is doubled. The controller’s second-best performances
    are shown with the second-most difficult difficulty, i.e. the level when the number
    of vehicles is increased, after C1\. Although the link between something “hard”
    for the controllers and something “hard” for the observer cannot be completely
    examined in this study, charting these pictures revealed unexpected behavior,
    leading us to look into this more in future studies.![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig21_HTML.png](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig21_HTML.png)
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: Figure 17-21
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
- en: The safety monitor forecast rates for control points 1 to 4
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
- en: These findings are in line with the data collected and analyzed, as the security
    performs well with C1, while C2 to C4 produce almost identical outcomes, with
    C2 producing somewhat superior results.![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig22_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig22_HTML.jpg)
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: Figure 17-22
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy recall curve for checkpoints C1–4 based on observed values at every
    level of complexity
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: '![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig23_HTML.jpg](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig23_HTML.jpg)'
  id: totrans-455
  prefs: []
  type: TYPE_IMG
- en: Figure 17-23
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
- en: Comparing of PRC for C1 through C4
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
- en: To comprehend the results of the safety monitor’s predictions, we had to personally
    perform and watch some of the best runs for Checkpoints 2 in phase 1\. High speed
    is the major reason for monitor failures for C2.7, according to the percentage
    of false-positive causes shown in the table. Another intriguing aspect of this
    type of data collection is that it appears that as the network learns to handle
    new situations, the security produces more false alarms, and, more importantly,
    the scenarios that will eventually result in a crash are of a new type that the
    watch is unable to detect.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
- en: The table in Figure [17-24](#Fig24) shows how this approach works and how a
    great quantity of information and proof about the system’s behavior can be gathered
    using only a few observations. Depending on the real hardware available and the
    simulation model, further measurements can be acquired and combined to supplement
    this information.![../images/520777_1_En_17_Chapter/520777_1_En_17_Fig24_HTML.png](../images/520777_1_En_17_Chapter/520777_1_En_17_Fig24_HTML.png)
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: Figure 17-24
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
- en: 'C1 generates a high percentage of false - negative: : : C4'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
- en: The monitor’s effectiveness appears to be impacted by how the controller acts,
    as we anticipated at the start of this project. Most significantly, evidence shows
    that the monitor’s prediction accuracy is unrelated to the length of time the
    controller has been taught. Retraining the network with various techniques and
    using the same monitoring approach for the operators may confirm or refute this
    finding.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: 17.14.3 Retraining and Rechecking (Phase 3)
  id: totrans-463
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If Phase 2 suggested that the efficiency of the same security varies when applied
    to different checkpoints, restructuring with different strategies and comparing
    the performance of controllers trained in these methods to the one we used as
    the default approach will be critical in confirming or refuting this theory. In
    this phase, we retrained C4 using the five techniques listed here:'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: S0) The Coach framework’s basic technique, which was used to train C1... 4,
    with the optimization method calculated depending on the total neural network
    quality.
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: S1) When the automobile strikes anything, the functional form is now more severe,
    but braking is somewhat more rewarding, as long as the car does not stop going.
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: S2) The security monitor is connected to the system, and if an alarm is raised,
    the sensor’s response takes precedence over the network’s.
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: S3) If the monitoring raises an alarm, the network’s activity is substituted
    by the monitor’s. For acting like the monitors, the network receives a good incentive.
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: S4) If an alarm is triggered, the training phase is terminated and the system
    is given a poor incentive.
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The result is {C5S0, C5S1, C5S2, C5S3, C5S4}.
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the failure of the S2, S3, and S4 techniques, regrettably, the safety monitor-based
    methods did not yield the expected results. S3 and S4 stop the controller from
    moving, while S2 causes it to stop after a few meters if there is something in
    front of the vehicle, even if it is a considerable distance away. Because not
    moving is a poor reward, none of these checkpoints receive an unintentionally
    large reward for their behavior. As a consequence, the scenario in which the neural
    net becomes stuck between a local minimum and maximum may remain a theory, but
    we feel the training time was too short.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
- en: The monitor’s extremely large false positive rate is probably certainly to blame.
    Extended training in this manner taught the vehicle not to move in order to avoid
    the safety alarms and monitors. Even though these techniques account for the possibility
    of the car not moving by penalizing it with a -ve benefit, it was not sufficient
    to keep the automobile from remaining still.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
- en: We think that the DDPG algorithm’s reward function is well-defined, in the sense
    that it accounts for all good and bad behaviors, and that immediate rewards are
    well-balanced, as there are no inadvertently huge payments. However, adjusting
    all of the reward factors to prevent results like the one we witnessed is exceedingly
    tough owing to the difficulty and diversity of circumstances that a network should
    be allowed to drive a vehicle. Most important, we have no way of knowing if this
    behavior is a product of the reward function’s design or if it requires more training
    to observe intriguing behaviors.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
- en: The most important issue with training is the time commitment; it is difficult
    to teach n agents using n techniques and then wait for them to be taught before
    determining which approach produced the best results.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
- en: The tuning of the network’s parameters is primarily dependent on regulations
    and heuristic approaches, as demonstrated by many publications. These methods,
    on the other hand, have shown to be time-consuming and error-prone.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, at this time, trial-and-error appears to be the sole way to measure
    the reward function’s efficiency. Because training data is still being investigated
    and there are no defined laws for self-driving vehicles, this problem, which is
    unique to these algorithms, remains unresolved. In academia, the design of the
    reward function for these relatively new algorithms is a hot issue, with academics
    trying to find out how to offer an appropriate learning model.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
- en: Simultaneously, as previously said, AV training needs a huge amount of data,
    which is frequently inaccessible or insufficient as compared to traditional training
    methods. There are several frameworks for designing decision-making rules for
    relevance feedback, but most of them seem to focus on how to speed up the learning
    process rather than how to add learning factors to these networks.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
- en: Creating probabilistic models to aid in the calibration of reward system parameters
    prior to the controller’s retraining phase would be a fascinating approach. Because
    the protection performance measures were effectively approximated, the technique
    presented in this book would have a substantial impact on the construction of
    these models.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
- en: In reality, the reward function has no means of knowing ahead of time what value
    each state should be assigned. Keep in mind that we are in a full spatial condition,
    which is difficult to depict and makes it hard to evaluate all potential events
    and transitions, making our task much more difficult.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, because of the complexity and uniqueness of these systems and
    techniques, more research is required to address these issues, and the development
    of a simulation process to aid fine-tuning will be critical in future work.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
- en: 17.15 Summary
  id: totrans-481
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This chapter looked at how to do a checking activity on self-driving automobiles
    managed by a controller and a sys admin.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
- en: Such systems demand special attention due to their complexity and the main problems
    of the ecosystem in which they function. This research is meant to be a first
    step in defining how such systems should be monitored. Because they are regularly
    employed in military activities, automatic vehicles are not a novel sort of equipment.
    However, because self-driving cars will be operating in close proximity to humans
    and in an urban environment, greater caution will be necessary in coping with
    the wide variety of events that may occur.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
- en: 'We also questioned if there were any links between the efficacy of the relative
    safety and that of the control element when the latter was taught for long periods
    of time using various approaches. We covered the basic principles of these activities
    in the initial parts, such as:'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
- en: The definitions of reliability and safety, which are both critical components
    of safety. In the context of self-driving automobiles, critical systems were examined.
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Problems that prohibit us from deploying self-driving automobiles in metropolitan
    areas at this point in time.
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How an incorrect/poor/optimistic evaluation of these systems’ reliability might
    have catastrophic repercussions when they are implemented.
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Problems in analyzing observed emerging behavior as a result of the interaction
    of two main constituent components.
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the efficacy of the safety monitor impacted by the controller’s behavior,
    and if so, how? By the duration of the training and the strategies used throughout
    the training.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
- en: The instruments accessible for this type of activity were considered in the
    creation of this initial technique. We have to seek open-source alternatives because
    most solutions in this sector are private and proprietary, indicating that performing
    these studies in non-professional contexts is difficult.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: The Lidar sensor issue would have rendered our study unfeasible, and it could
    have been impossible if it hadn’t been for Zhuang’s effort, because our only alternative
    would have been to rely on ground observations, which would have been useless
    for our research.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
- en: While the Coach framework was created by Intel AI Labs, it has the usual problems
    that plague open-source projects, the most notable of which being the failure
    of one of the two CARLA agents to move after a few rounds of training in Phase
    1\. This problem makes us question if there were other flaws in the training algorithm’s
    architecture that contributed to the C5S2:::4 behaviors.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: Another issue that obstructs the framework’s use is that the memory is not properly
    released, leading it to overflow and crash the running processes. As a result,
    we had to maintain a close check on the training process and redo it after each
    mishap.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
- en: 'The monitoring activity was created with the following major characteristics
    in mind:'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: '**Consistency:** By saving the controller’s activity in each frame, as well
    as the RNGs1 seeds, goal objectives, and the environment variable of every circumstance
    in files.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The ability to be unobtrusive:** Because of the client-server design, code
    instrumentation may provide non-real-time data or incorrect measurements. This
    difficulty is solved by CARLA, which allows users to conduct simulations at a
    set time step. But the h/w should be capable of achieving the specified time step.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adequate representation:** One of the main issues with monitoring self-driving
    cars is the representativeness of test cases, because dangerous occurrences might
    be so complicated and numerous that it is difficult to evaluate them all. In this
    regard, defining scenarios and difficulty levels helps provide a variety of scenarios
    based on the same situation. Concerns regarding the dataset’s nature arose from
    the predictive value of the metrics generated for the security monitor. The selection
    of the metrics to be utilized in the confusion matrix, as well as the exclusion
    of the others, were explained and justified.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Availability:** The search for the appropriate tools to employ for this task
    was difficult owing to the large number of options presented, many of which had
    significant practical constraints. However, the technologies we utilized in this
    project allowed us to complete this task.'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the same time, we cannot overlook the problems that these initiatives have.
    This approach has shown to be a helpful tool for analyzing the performance of
    the entire system, with a focus on well-known metrics for evaluating a system’s
    reliability and the security monitor’s effectiveness.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
- en: The creation of situations and problems is essential for establishing whether
    external factors impair performance of the system and for creating and evaluating
    “uncommon” circumstances that cannot always be covered when building ad hoc safety
    cases.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
- en: The main hypothesis that inspired us to start this study was to examine if the
    performance of “static” error-checkers was impacted by neuronal network performance,
    and if ad hoc training approaches had an impact as well.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
- en: 'According to the data gathered, the monitor’s efficacy with expert agents is
    expected to alter, encouraging us to further investigate this hypothesis. The
    failure of those methods (S2, S3, S4) that employed the safety monitor to direct
    the training did not provide us with proof of this reality, and this issue was
    highlighted at the beginning of the chapter. There are two possible causes for
    this failure:'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
- en: A reward function that isn’t defined.
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The training duration was insufficient.
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We believe the neural net required more time to comprehend what the security
    was attempting to educate since the trained agents did not receive an accidentally
    huge reward for keeping motionless. A bigger simulation time step would have allowed
    us to run simulation time faster than real time, which would have helped us save
    time.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
- en: We were unable to train the models for extended periods of time or retrain the
    networks by altering the reward parameters since this required hyper hardware.
    Around the same time, the security proved to be less effective when used in conjunction
    with the checkpoint that produced the best results, which was obtained from Checkpoint
    C4 by modifying the training method, whereas and it has the same TPR (0.75) when
    used in conjunction with the security checks trained with method S0, except perhaps
    Checkpoint C2.
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
- en: While Checkpoint C2 was unquestionably a unique instance for the reasons outlined
    in earlier chapters, the same theory cannot be ruled out for C5S1\. We want to
    continue training C5S1 in the future to validate this reality. This study demonstrated
    the benefit of analyzing self-driving automobiles in a simulated environment,
    taking into account and overcoming many of the difficulties that emerge when calculating
    relevant metrics for such systems, as well as usual monitoring concerns.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter wraps up the book and gives a broad overview of blockchain
    technology and distributed system environment.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
