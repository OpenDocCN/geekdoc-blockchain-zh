- en: Chapter 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Task Offloading Using Deep Reinforcement Learning for Edge IoT Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pradeep Bedi
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[![Orcid Image](i/orcid.svg) https://orcid.org/0000-0003-1708-6237](https://orcid.org/0000-0003-1708-6237)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Galgotias University, India
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: S. B. Goyal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[![Orcid Image](i/orcid.svg) https://orcid.org/0000-0002-8411-7630](https://orcid.org/0000-0002-8411-7630)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: City University, Malaysia
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Jugnesh Kumar
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: St. Andrews Institute of Technology and Management, India
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ABSTRACT
  prefs: []
  type: TYPE_NORMAL
- en: Edge computing is a type of distributed computing that was designed especially
    for internet of things (IoT) users to provide computational resources and data
    management nearby to users' devices. By introducing edge computing for IoT, networks
    have reduced the bandwidth and latency issue while handling real-time applications.
    The major benefit of edge computing is that it reduces the communication overhead
    between IoT user and server. With integration of IoT in our daily lives, it has
    attracted researchers towards its performance management such as complexity minimization,
    latency minimization, memory management, energy consumption minimization, etc.
    In this chapter, deep reinforcement learning is focused to minimize the computational
    complexity at IoT user end. The task offloading decision process is designed using
    Q-Learning, which minimizes the system cost and curse of high dimensional data.
    In addition, the proposed methodology will perform better as compared to existing
    algorithms with respect to system costs.
  prefs: []
  type: TYPE_NORMAL
- en: INTRODUCTION
  prefs: []
  type: TYPE_NORMAL
- en: The term Internet of Things (IoT), clearly refers to the objects, things and
    things in an Internet structure which can be easily identified, was first proposed
    in 1998 (Liu et al., 2020). In recent years, due to some representative application
    (for example, intelligent monitoring of greenhouses, while reading electricity
    meters, monitoring of telemedicine and intelligent transport) the IoT concept
    has become popular. Typically, the IoT has four main components- sensors, data
    processing, applications and services. The new era applications such as smart
    city, smart educational system, smart industries, etc are integrated with Internet
    of Things (IoT) (Anand et al, 2021). The IoT architecture is composed of IoT devices
    such as sensors, actuators and gateways that are used to collect and perform computation
    over these generated and collected data (Liu et al. 2020).
  prefs: []
  type: TYPE_NORMAL
- en: With advancement of technologies, every day new innovations in hardware as well
    as software are being made which had contributed in increase of IoT networks and
    their applications. With usage of IoT devices on large scale, there is increase
    in data processing and storage requirements (Alfakih et al., 2020). For instance,
    for adopting smart farming, there is requirement of many sensors, computational
    devices to monitor temperature, humidity, pH, light, nutrition level, etc required
    for proper growth and developments of plants. In IoT network scenario, these data
    are generated by deployed sensors and collected the gateway devices and further
    sent to the cloud server end where processing over collected data is performed
    (Wang et al., 2019).
  prefs: []
  type: TYPE_NORMAL
- en: While processing such large amount of data in dynamic and real channel environment,
    there arise some challenges that are needed to be addressed. In case of smart
    farming, first issue is that where to locate sensors so that they can cover maximum
    area. Another issue is that most of the farms are located mostly outside the city
    where internet services are limited and are not capable to connect to the remote
    servers all the time. This issue can be addressed by integrating IoT-cloud architecture
    with edge computing that can provide promising solution to such issues (Wang et
    al., 2019) (Alelaiwi, 2019). Another issue that arise in IoT network is that there
    is requirement of large processing services to edge server by these deployed IoT
    sensors that burdens on the radio services and the storage services. So, the IoT
    devices required to be developed such that they can process some simple data processing
    tasks locally. Therefore, for fast and optimal processing of large amount of data
    in Edge-IoT network, there is requirement to design an optimal computation task
    offloading scheme (Chen et al., 2020).
  prefs: []
  type: TYPE_NORMAL
- en: User equipment processing some computationally expensive programmes and uploading
    the data processing these applications to the edge server through wireless transmission
    on the condition of weighing continuous or other indicators is referred to as
    task offloading. The processing programme assigns certain computational resources
    to the edge server for these uploads in order to receive ongoing or progressive
    replacements, leading to a positive user engagement. A fundamental aspect of selecting
    whether to offload, that is, the offloading choice, is usually an initial part
    of computer offloading and resource allocation. End devices are viewed as agents
    in this article, making judgments on whether or not the network should offload
    compute chores to edge devices. The computing resource allocation problems were
    framed as a sum cost delay of this framework to address resource allocation and
    task offloading. In this paper, an optimal computational offloading choice is
    presented, and reinforcement learning is used to fix the issues.
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning is a branch of artificial intelligence. The main distinction
    between unsupervised and supervised learning is that unsupervised learning does
    not involve artificial labelling. The exploration of an unknown area and the application
    of previously acquired knowledge are at the heart of the game. Reinforcement learning
    is achieved through constant trial and error, continual interaction with the environment,
    and receiving rewards or punishment from the environment, followed by the acquisition
    of acquiring knowledge to upgrade its very own paradigm. It picks up a new behavior
    strategy. It may make judgments to maximise long-term profits based on environmental
    variables after a specific period of training. Reinforcement learning can now
    handle high-dimensional actions and states, learning efficiency has increased
    dramatically, and the constraints of reinforcement learning have been broken to
    some extent. Deep reinforcement learning techniques will be utilized to solve
    the task offloading problem in edge computing in order to make the model adaptively
    learn to offload decisions.
  prefs: []
  type: TYPE_NORMAL
- en: 'But still there are some issues that has been identified in existing deep learning
    models are such as:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Compatibility with IoT/Edge: A new edge paradigm has emerged as a result of
    the spread of edge computing and IoT, with artificial intelligence being integrated
    into edge. Three-tier design for IoT-edge AI integration uses a DNN with numerous
    levels utilized on both the edge server and cloud servers. The DNN’s front layers
    are located on the edge server, while its backend layers are located on the cloud.
    How to deploy a deep neural network (DNN) on an IoT-edge is an important consideration
    when it comes to offloading the AI-integrated IoT-output edges into the cloud.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Offloading Compatibility with heterogeneity: For the most part, earlier research
    on the topic of offloading models has assumed that the computations are all of
    a similar type. Because of this, offloading modelling is made easier. Modeling
    becomes more difficult due to the wide range of responsibilities. The computing
    units themselves may be a source of variability (hardware).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Offloading Compatibility with Mobility: To ensure service continuity and quality
    of service (QoS) criteria, nodes must undertake a handover to another edge/fog
    domain. If the jobs are being offloaded to a VM container, the question is whether
    this VM should be moved to the new server. This problem derives from the fact
    that migration costs are offset by the benefits of reduced delays and communication
    costs. Furthermore, dynamic VM migration and optimal offloading decisions necessitate
    a prediction technology. In a mobility context, offloading modelling is more difficult
    because of these features.'
  prefs: []
  type: TYPE_NORMAL
- en: EDGE COMPUTING
  prefs: []
  type: TYPE_NORMAL
- en: Edge computing is a distributed approach that was designed for task processing
    and data management of IoT networks’ tasks. These computing resources are deployed
    nearby to IoT devices with an aim to reduce response time and to reduce overall
    bandwidth requirements to handle real-time applications over internet. Its main
    benefit is that it reduces the communication gaps between the IoT users and cloud
    server (Wei et al., 2018). Task offloading by using edge servers have attracted
    researchers to explore new scope for performance enhancement IoT network to handle
    computational complexities. For this there is requirement of latency minimization,
    task offloading, storage management, power consumption and so on. With implementation
    of Edge computing these objectives can be achieved. But still there is requirement
    of more advancement as everyday size of data is increasing which require more
    processing speed. As local computing is not possible all the time because IoT
    devices have limited battery power and computation resources (Higuchi et al.,
    2019).
  prefs: []
  type: TYPE_NORMAL
- en: So, to support real time high latency consuming IoT applications, it is needed
    to reduce the offloading complexities at edge servers. Offloading algorithm are
    concerned to meet Quality-of-Service (QoS) requirements for different resource-demanding
    applications (Khayyat et al., 2020). Due to limited spectrum allocated to gateway
    devices, they cannot handle large set of computation tasks (Li et al., 2020).
    Hence, some researchers implemented the clustering concept to group the IoT devices
    to handle their demand according to their clusters. These clusters are made according
    to their computational demand (Guo et al., 2019).
  prefs: []
  type: TYPE_NORMAL
- en: Subsequently, there is need of optimal offloading of task that can handle the
    major issues and challenge of the IoT edge computing networks. Traditional offloading
    schemes are not much efficient to give optimal decisions for dynamic environment
    (Zhang et al., 2018) (Wang et al., 2019). Many researchers proposed dynamic task
    offloading algorithms, such as Markov decision process (MDP), by interaction with
    environment parameters. But MDP can handle single task at same time. Further,
    reinforcement learning showed its effectiveness to resolve the issues of MDP but
    still it needs to be make the learning process more adaptable to channel environment
    (Zhang et al., 2019) (Chen et al., 2019).
  prefs: []
  type: TYPE_NORMAL
- en: COMPUTATIONAL OFFLOADING USING REINFORCEMENT LEARNING
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning is an optimal learning process that learns the channel
    state by interacting with environment. In Edge-IoT network, each IoT user is considered
    to be as agent and their requirements are considered as environment. As shown
    in Figure 1, three-layer architecture is given for designing Cloud-Edge-IoT computing
    network. There are many IoT networks connected with Edge server. Each IoT network
    composed of large number of IoT users, gateway devices (or edge devices) that
    can collect data from IoT users. These gateway devices collect data from IoT users
    in particular coverage area and process them at edge server equipped with finite
    storage capacity and computational resources. So, these devices, either gateway
    or edge server can allow limited processing simultaneously as each IoT user have
    different type of task of different size. These computing resources are equipped
    with limited resources and battery power as well, so, there is need of optimal
    task offloading to improve the performance and lifetime of the entire network.
  prefs: []
  type: TYPE_NORMAL
- en: In Figure 2, Edge-IoT task offloading scheme is illustrated with reinforcement
    learning. In this architecture, each agent, IoT user (u[i]), having state (S[k]),
    at time instance (k) with action (A[k]) to determine the computing mode based
    on the decision policy given by environmental parameters. Therefore, if there
    is change in environment new state (S[k+1]) is observed with new reward R[k].
  prefs: []
  type: TYPE_NORMAL
- en: 'A reinforcement learning consists of following elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '• Agent: These are the end users, IoT devices, that can perform some actions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '• Environment: These are the determining parameters that decides the reward
    of agents.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '• State: The states explores the environment status such as channel gain, queue
    status, computation capacity, etc.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '• Policy: A policy defines the way the agent behaves in a given time or it
    can be said that a policy is a mapping from the states of the environment to actions
    to the actions the agent takes in the environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '• Reward: A reward can determine whether an agent can offload the task or not.
    For this, reinforcement learning is implemented. For task offloading each agent
    maximizes the rewards during learning. In Edge computing, to minimize the system
    computation cost with respect to power, time and space, negative reward is adopted
    make right decisions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '• Action: The action is performed by each IoT users for choosing local computing
    or offloading.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Figure 1\. IoT network with edge computing with offloading scheme |'
  prefs: []
  type: TYPE_TB
- en: '| ![Figure978-1-6684-3733-9.ch003.f01](i/ch003.f01.png) |'
  prefs: []
  type: TYPE_TB
- en: '| Figure 2\. Reinforcement learning for IoT users |'
  prefs: []
  type: TYPE_TB
- en: '| ![Figure978-1-6684-3733-9.ch003.f02](i/ch003.f02.png) |'
  prefs: []
  type: TYPE_TB
- en: RELATED WORK
  prefs: []
  type: TYPE_NORMAL
- en: Liu et al. (2020) investigated the machine learning approach for resource allocation
    with edge computing in Internet-of-Things (IoT) networks. In this work, centralized
    clustering of IoT users is proposed is by assigning user’s priorities. The highest
    priority cluster is selected and assigned to offload their task at the edge server
    whereas the task having lowest priority is can compute their task locally. The
    distributed task offloading is performed by Markov decision process which consider
    all the IoT user as agent and makes a series of task offloading decision. This
    policy is designed with respect to cost effectiveness based on channel dynamics.
    In this approach, deep Q-network was used for high dimensional tasks to learn
    the optimal policy.
  prefs: []
  type: TYPE_NORMAL
- en: Alfakih et al. (2020) proposed an algorithm using deep reinforcement learning
    approach for designing state-action-reward policy for task offloading from IoT
    users to edge server. The optimal offloading decision was performed to minimize
    system cost in respect to time delay and energy.
  prefs: []
  type: TYPE_NORMAL
- en: Wang et al. (2019) proposed task offloading algorithm for fog-cloud network
    design of Internet of Vehicles (IoV). The objective was to minimize the power
    consumption and computational resources of the vehicles.NP-hard problem was formulated
    as optimization of offloading issues.
  prefs: []
  type: TYPE_NORMAL
- en: Alelaiwi et al. (2019) proposed a structure for forecast of reaction time utilizing
    deep learning and studying how to off the utilization of a deep learning-based
    reaction time-prediction system to make the decision of whether to offload in
    the cloud hub, to close by haze/edge hub or neighbor haze/edge hub, nearby fog/edge
    node or neighbor fog/edge node. Besides, a limited Boltzmann machines learning
    is applied to handle the irregularity in the accessibility of assets.
  prefs: []
  type: TYPE_NORMAL
- en: Chen et al. (2020) proposed an algorithm for offloading task between IoT and
    edge server and termed it as intelligent Task Offloading Algorithm (iTOA). As
    compared to existing algorithms, iTOA decides the offloading activities on current
    state of network by using Monte Carlo Tree Search (MCTS). To provide quick search
    facilities, the MCTS algorithm was merged with Deep Neural Network (DNN).
  prefs: []
  type: TYPE_NORMAL
- en: Wei et al. (2018) analyzed a system comprising of multiple mobiles which are
    intended to carry out uploading tasks to a MEC server and in a single cell, hence
    the proper allocation to limited server with wireless channels emerge out as a
    problem. The author has hence designed an optimization problem for energy and
    tasks on the mobile so that they are efficiently divided. A Select Maximum Saved
    Energy First (SMSEF) algorithm being the key algorithm utilized.
  prefs: []
  type: TYPE_NORMAL
- en: Higuchi et al. (2019) investigated a type of virtual edge server and its compatibility
    of dealing it with the multiple vehicles, however he concluded that the during
    its early development stage, its feasibility requires more concern. The concluding
    simulations of the paper suggested that for vehicles the horizontal form of offloading
    can bring about reduction in the peak load on edge computing structure nearly
    by 53%. The penetration rate of V2V communication technology was kept low during
    this study.
  prefs: []
  type: TYPE_NORMAL
- en: Khayyat et al. (2020) focused on multilevel vehicular edge cloud networks and
    presented an advanced deep learning-based algorithm for it. The main focus is
    on achieving energy conservation and an effective utilization of the resources
    shared by the vehicles which is achieve by achieving an integration model for
    computational constrained offloading. The reduction in the time and energy consumption
    is attained by achieving the binary formulation for the resource allocation. However,
    it was found that due to problem of dimensionality, this type of solution is NP
    difficult and is thus very complex/prohibited to solve them. Thus, the authors
    have developed a similar reinforcement learning method and proposed a distributed
    deep learning algorithm along with neural network-based learning so as to finally
    achieve an optimum solution for taking offloading decision.
  prefs: []
  type: TYPE_NORMAL
- en: Li et al. (2020) proposed a deep reinforcement learning calculation to take
    care of the intricate calculation offloading issue for the Edge Computing Server
    (ECS) that is heterogeneous in nature with combined computing resources. The main
    concern in this work that was focused are such as network condition as well as
    task characteristics. The actor gradient policy was designed to settle on enhanced
    choices of offloading of tasks. Considering performing multiple tasks, the heterogeneity
    of edge subnet and versatility of edge tasks, the proposed calculation can get
    familiar with the network and create the calculation offloading choice to limit
    the allotment delay.
  prefs: []
  type: TYPE_NORMAL
- en: Guo et al. (2019) & Bedi et al (2021) focused on improving the operation earning
    by dropping the charge of the MDs. As the computation demands vary according to
    regions and there is difference in the availability of the computational edge
    servers, the traditional method to achieve the objective cannot be chosen. To
    solve this, the paper concluded that we can develop an efficient computing resource
    strategy and offloading task profile in UDN scenarios with time variation. The
    author concluded a deep Q-network based scheme for solving the problem.
  prefs: []
  type: TYPE_NORMAL
- en: In IoT networks, with the emergence of edge computing has resulted in many challenges
    for the researchers and developers, which include dynamic computation offloading
    scheme designing, resources such as computing resource, spectrum useful resource
    and their allocation, and transmit electricity controlling. It has been found
    that these are very difficult to solve independent as the designing of and computational
    offloading scheme for the edge server has to learn about the resource of the gateway
    as well as the transmit power capability of the end user. There has been focused
    study on computational offloading schemes that are capable of handling multiple
    resources in the edge servers, more specifically in the MEC frameworks. Power
    consumption and latency are the two main area of concern while working in IoT
    network with offloading scheme of task. So, many researchers have proposed an
    optimized task offloading scheme that can handle energy requirement as well as
    latency such as MEC system. But MEC based task offloading can handle single user
    at a time. Then, multi-user framework was implanted using deep reinforcement learning
    using MEC framework. However, these algorithms are not much efficient to handle
    multi-user multi-task at same time optimally.
  prefs: []
  type: TYPE_NORMAL
- en: Along with this in order to achieve threshold structure of the system, an optimal
    task offloading policy is validated. The clustering of the IOT users into various
    groups has been proposed by making use of clustering optimizing algorithm which
    is framed as initial step for the task offloading scheme designing. The reduction
    in the power utilization, time and system cost along with considerable decrement
    in the execution latency is achieved by making use of distribution computation
    task offloading algorithm. Diverse contributions from various authors towards
    the work have been described in the table I.
  prefs: []
  type: TYPE_NORMAL
- en: 'In view of the previous studies, following main issues were being listed:'
  prefs: []
  type: TYPE_NORMAL
- en: • One of the main issues of Markov Decision Problem (MDP) is that it can be
    only utilized with single user with task scheduling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: • MDP can lead to most effective values however creates time-constraint troubles.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: • Q-learning is a method that can be utilized for resolving the MDP issue however
    it may face huddles such as overestimated function. For some stochastic environments
    the famous reinforcement studying algorithm Q-getting is known to perform very
    poorly. This poor performance is resulting from massive overestimations of action
    values. These overestimations due to a positive bias that is added due to the
    fact Q-learning uses the maximum action value as an approximation for the most
    predicted action value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Table 1\. Gives the comparative study of various methods for task offloading
    in iot network
  prefs: []
  type: TYPE_NORMAL
- en: '| Author | Description | Results | Drawbacks |'
  prefs: []
  type: TYPE_TB
- en: '| Liu et al. (2020) | Deep reinforcement learning approach with markov decision
    process | Optimal clustering of IoT users and results in optimal energy cost.
    | Not adaptable to multiple users processing simultaneously. |'
  prefs: []
  type: TYPE_TB
- en: '| Li et al. (2020) | Deep Deterministic Policy Gradient | minimize the task
    delay | Energy cost consumption was not considered. |'
  prefs: []
  type: TYPE_TB
- en: '| Alelaiwi et al. (2019) | Deep learning for prediction of response time |
    Improves the offloading computational performance | Time-constraint issues |'
  prefs: []
  type: TYPE_TB
- en: '| Xiaolan et al. (2019) | Greedy Q learning algorithm for optimal offloading
    t=of task | Achieved better performance of task offloading with respect to energy
    consumption and latency requirement of the entire network. | Not adaptable to
    multiple users processing simultaneously. |'
  prefs: []
  type: TYPE_TB
- en: '| Chen et al. (2019) | Deep Reinforcement Learning Approach | Improved service
    latency performance | There is no predictive model as well not adaptable to massive
    IoT scenario |'
  prefs: []
  type: TYPE_TB
- en: '| Min et al. (2019) | Fast deep Q-network (DQN) based offloading scheme | Optimal
    offloading policy after sufficiently long learning time | Local power control
    and offloading decision-making problem |'
  prefs: []
  type: TYPE_TB
- en: '| Zhang et al. (2018) | Cost as well as energy aware offloading task is proposed
    using deep reinforcement learning. | Energy and cost were estimated | Multiple
    users cannot be served optimally |'
  prefs: []
  type: TYPE_TB
- en: PROPOSED WORK
  prefs: []
  type: TYPE_NORMAL
- en: 'In the world moving towards digitalization the small all mobile devices are
    able to perform small and medium level computation problems with no ability to
    deal with high computation processes. However, offloading the computation processes
    at the Gateway can emerge as one of the key solutions for this problem. While
    it is considered that x IoT devices are capable of performing T[x] task while
    they offload the task at the edge, the entire computational model can be summarized
    in the following three steps (figure 3):'
  prefs: []
  type: TYPE_NORMAL
- en: • All the x IoT devices around to carry and deliver sufficient input information
    at the gateway by making use of various sensors and accomplish the task at the
    edge.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: • Edge shall allocate some portion from its computational resource to enable
    the computation of task for the x IoT devices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: • Results are then sent to IoT, end device, after the computation via edge server.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Figure 3\. IoT task offloading |'
  prefs: []
  type: TYPE_TB
- en: '| ![Figure978-1-6684-3733-9.ch003.f03](i/ch003.f03.png) |'
  prefs: []
  type: TYPE_TB
- en: '| Figure 4\. Proposed task offloading flow chart |'
  prefs: []
  type: TYPE_TB
- en: '| ![Figure978-1-6684-3733-9.ch003.f04](i/ch003.f04.png) |'
  prefs: []
  type: TYPE_TB
- en: To deal with the sequential learning and achieving the decision making, machine
    learning such as Reinforcement learning (RL) can serve as an agent in making decisions
    and help in attaining the objective of cumulative rewards (Liu et al., 2019).
    The process has many key advantages such as energy sparing, quick offloading,
    low inertness, and ideal load distribution, so it is a critical contender for
    the future of the digitalization that is yet to come of remote correspondence.
    The ongoing research and examination depend on proper and effective offloading
    and task allocation for MEC frameworks. The resource allocation scheme is considered
    as partial offloading schemes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The proposed work is performed in following steps (figure 4):'
  prefs: []
  type: TYPE_NORMAL
- en: '• Step 1: Proving input as tasks and with respective IOT user.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '• Step 2: IOT user cluster generation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '• Step 3: Priority level determination of IOT users (multiple) in each cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '• Step 4: Q learning algorithm utilization for training deep reinforcement
    network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '• Step 5: Following above steps, next step is to offload tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '• Step 6: Performance parameters valuation and determination.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DISCUSSIONS
  prefs: []
  type: TYPE_NORMAL
- en: In this section, the paper presents some comparative analysis of existing research
    works are presented which shows efficiency of deep reinforcement learning for
    task offloading in edge computing. Table II to shows the comparative analysis
    of existing techniques and average miili second. Ali et al. (2021) proposes deep
    learning techniques and have maximum average delay i.e.100 millisecond. Liet al.
    (2020) proposes ddpg technique having average delay of 6 ms. Another techniques
    proposed in Chen etl al. (2019) has minimum average delay of 3ms. Chen et al.
    (2019) with iRAF has average delay of 20sec. Liu et al. (2019) proses DRL based
    method with an average delay of 25sec. Hussain and Mausa (2020) Also proposes
    Deep learning techniqus having and average dealt of 85 and 90ms. Several fundamental
    concerns connected with fog computing, including structure, interface, and programming,
    offloading processing, efficient resource provisioning, and security aspects are
    discussed in this paper. Various optimization approaches have been developed in
    previous publications to solve such processing and transmission latency constraints.
    With delay as a limitation, a Q-learning priority-based task offloading strategy
    is presented to minimize the energy consumption in communications systems and
    computing.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2\. Comparative analysis
  prefs: []
  type: TYPE_NORMAL
- en: '| Ref | Techniques | Optimization | Average Delay (in ms) |'
  prefs: []
  type: TYPE_TB
- en: '| Ali et al. (2021) | DL | MCC | 100 |'
  prefs: []
  type: TYPE_TB
- en: '| Li et al. (2020) | DDPG | DRL | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| Chen et al. (2019) | Deep-SARL | DRL | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| Chen et al. (2019) | iRAF | DRL | 20 |'
  prefs: []
  type: TYPE_TB
- en: '| Liu et al. (2019) | DRL | DRL | 25 |'
  prefs: []
  type: TYPE_TB
- en: '| Hussain and Mausa (2020) | DL | ACO | 85 |'
  prefs: []
  type: TYPE_TB
- en: '| Hussain and Mausa (2020) | DL | PSO | 90 |'
  prefs: []
  type: TYPE_TB
- en: '| Figure 5\. Comparative analysis |'
  prefs: []
  type: TYPE_TB
- en: '| ![Figure978-1-6684-3733-9.ch003.f05](i/ch003.f05.png) |'
  prefs: []
  type: TYPE_TB
- en: CONCLUSION
  prefs: []
  type: TYPE_NORMAL
- en: Edge computing is well known for providing computational capabilities to IoT
    consumers, as IoT computing necessitates a vast resource spectrum. Furthermore,
    sending computational activities to an edge server uses more energy. As a result,
    conserving energy locally at the IoT user end is a difficult challenge. This can
    be accomplished through the optimization of network design or routing policies.
    The purpose of this paper is to summaries the research that has been done in the
    subject of edge computing for job offloading. To overcome the issue of offloading
    and to deploy an intelligent decision-making system that can accomplish the aforementioned
    duty while reducing human efforts, a variety of algorithms, frameworks, and predictive
    models have been proposed so far. A brief examination of several task offloading
    schemes is covered in this paper, along with their limitations. Based on a review
    of the literature, it has been determined that deep reinforcement techniques outperform
    standard approaches in terms of lowering computational effort. Furthermore, a
    method based on a modified Q-learning-based deep reinforcement technique is proposed
    to manage multiple users and tasks at the same time with little computing cost.
    The proposed methodology, which may be used with most types of offloading, such
    as vehicular and mobile offloading, will be implemented in the future. It can
    also be enhanced by using it in multi-agent networks.
  prefs: []
  type: TYPE_NORMAL
- en: REFERENCES
  prefs: []
  type: TYPE_NORMAL
- en: Alelaiwi, A. (2019). An efficient method of computation offloading in an edge
    cloud platform. Journal of Parallel and Distributed Computing , 127, 58–64\. doi:10.1016/j.jpdc.2019.01.003
  prefs: []
  type: TYPE_NORMAL
- en: 'Alfakih, T., Hassan, M. M., Gumaei, A., Savaglio, C., & Fortino, G. (2020).
    Task offloading and resource allocation for mobile edge computing by deep reinforcement
    learning based on SARSA. IEEE Access: Practical Innovations, Open Solutions ,
    8, 54074–54084\. doi:10.1109/ACCESS.2020.2981434'
  prefs: []
  type: TYPE_NORMAL
- en: Ali, A., Iqbal, M. M., Jamil, H., Qayyum, F., Jabbar, S., Cheikhrouhou, O.,
    Baz, M., & Jamil, F. (2021). An Efficient Dynamic-Decision Based Task Scheduler
    for Task Offloading Optimization and Energy Management in Mobile Cloud Computing.
    Sensors, 21(13), 4527\. 10.3390/s21134527
  prefs: []
  type: TYPE_NORMAL
- en: Bedi, P., Goyal, S. B., Sharma, R., Yadav, D. K., & Sharma, M. (2021). Smart
    Model for Big Data Classification Using Deep Learning in Wireless Body Area Networks
    . In Sharma, D. K., Son, L. H., Sharma, R., & Cengiz, K. (Eds.), Micro-Electronics
    and Telecommunication Engineering. Lecture Notes in Networks and Systems (Vol.
    179). Springer. doi:10.1007/978-981-33-4687-1_21
  prefs: []
  type: TYPE_NORMAL
- en: Chen, J., Chen, S., Luo, S., Wang, Q., Cao, B., & Li, X. (2020). An intelligent
    task offloading algorithm (iTOA) for UAV edge computing network. Digital Communications
    and Networks , 6(4), 433–443\. doi:10.1016/j.dcan.2020.04.008
  prefs: []
  type: TYPE_NORMAL
- en: 'Chen, J., Chen, S., Wang, Q., Cao, B., Feng, G., & Hu, J. (2019). IRAF: A Deep
    Reinforcement Learning Approach for Collaborative Mobile Edge Computing IoT Networks.
    IEEE Internet of Things Journal , 6(4), 7011–7024\. doi:10.1109/JIOT.2019.2913162'
  prefs: []
  type: TYPE_NORMAL
- en: Chen, X., Zhang, H., Wu, C., Mao, S., Ji, Y., & Bennis, M. (2019). Optimized
    computation offloading performance in virtual edge computing systems via deep
    reinforcement learning. IEEE Internet of Things Journal , 6(3), 4005–4018\. doi:10.1109/JIOT.2018.2876279
  prefs: []
  type: TYPE_NORMAL
- en: GuoH.LvJ.LiuJ. (2019). Smart Resource Configuration and Task Offloading with
    Ultra-Dense Edge Computing. International Conference on Wireless and Mobile Computing,
    Networking and Communications. 10.1109/WiMOB.2019.8923227
  prefs: []
  type: TYPE_NORMAL
- en: Higuchi, T., Ucar, S., & Altintas, O. (2019). Offloading Tasks to Vehicular
    Virtual Edge Servers. Proceedings - 2019 IEEE 16th International Conference on
    Mobile Ad Hoc and Smart Systems Workshops, MASSW 2019, 162–163\. 10.1109/MASSW.2019.00040
  prefs: []
  type: TYPE_NORMAL
- en: 'Hussein, M. K., & Mousa, M. H. (2020). Efficient task offloading for IoT-Based
    applications in fog computing using ant colony optimization. IEEE Access: Practical
    Innovations, Open Solutions , 8, 37191–37201\. doi:10.1109/ACCESS.2020.2975741'
  prefs: []
  type: TYPE_NORMAL
- en: 'Khayyat, M., Elgendy, I. A., Muthanna, A., Alshahrani, A. S., Alharbi, S.,
    & Koucheryavy, A. (2020). Advanced Deep Learning-Based Computational Offloading
    for Multilevel Vehicular Edge-Cloud Computing Networks. IEEE Access: Practical
    Innovations, Open Solutions , 8, 137052–137062\. doi:10.1109/ACCESS.2020.3011705'
  prefs: []
  type: TYPE_NORMAL
- en: 'Li, Y., Qi, F., Wang, Z., Yu, X., & Shao, S. (2020). Distributed Edge Computing
    Offloading Algorithm Based on Deep Reinforcement Learning. IEEE Access: Practical
    Innovations, Open Solutions , 8, 85204–85215\. doi:10.1109/ACCESS.2020.2991773'
  prefs: []
  type: TYPE_NORMAL
- en: LiuX.QinZ.GaoY. (2019). Resource Allocation for Edge Computing in IoT Networks
    via Reinforcement Learning. IEEE International Conference on Communications, 1-6\.
    10.1109/ICC.2019.8761385
  prefs: []
  type: TYPE_NORMAL
- en: Liu, X., Yu, J., Wang, J., & Gao, Y. (2020). Resource Allocation With Edge Computing
    in IoT Networks via Machine Learning. IEEE Internet of Things Journal , 7(4),
    3415–3426\. doi:10.1109/JIOT.2020.2970110
  prefs: []
  type: TYPE_NORMAL
- en: Min, M., Xiao, L., Chen, Y., Cheng, P., Wu, D., & Zhuang, W. (2019). Learning-Based
    Computation Offloading for IoT Devices with Energy Harvesting. IEEE Transactions
    on Vehicular Technology , 68(2), 1930–1941\. doi:10.1109/TVT.2018.2890685
  prefs: []
  type: TYPE_NORMAL
- en: Rajawat, Bedi, Goyal, Alharbi, Aljaedi, Jamal, & Shukla. (2021). Fog Big Data
    Analysis for IoT Sensor Application Using Fusion Deep Learning. Mathematical Problems
    in Engineering. doi:10.1155/2021/6876688
  prefs: []
  type: TYPE_NORMAL
- en: 'Wang, X., Han, Y., Wang, C., Zhao, Q., Chen, X., & Chen, M. (2019). In-edge
    AI: Intelligentizing mobile edge computing, caching and communication by federated
    learning. IEEE Network , 33(5), 156–165\. doi:10.1109/MNET.2019.1800286'
  prefs: []
  type: TYPE_NORMAL
- en: Wang, X., Wei, X., & Wang, L. (2019). A deep learning based energy-efficient
    computational offloading method in Internet of vehicles. China Communications
    , 16(3), 81–91\. doi:10.12676/J.CC.2019.03.008
  prefs: []
  type: TYPE_NORMAL
- en: Wei, F., Chen, S., & Zou, W. (2018). A greedy algorithm for task offloading
    in mobile edge computing system. China Communications , 15(11), 158–170\. doi:10.1109/CC.2018.8543056
  prefs: []
  type: TYPE_NORMAL
- en: Zhang, C., Liu, Z., Gu, B., Yamori, K., & Tanaka, Y. (2018). A Deep Reinforcement
    Learning Based Approach for Cost-and Energy-Aware Multi-Flow Mobile Data Offloading.
    IEICE Transactions on Communications , 101(7), 1625–1634\. doi:10.1587/transcom.2017CQP0014
  prefs: []
  type: TYPE_NORMAL
