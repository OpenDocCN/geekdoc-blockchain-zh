- en: Chapter 3
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章
- en: Task Offloading Using Deep Reinforcement Learning for Edge IoT Networks
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用深度强化学习对边缘物联网网络进行任务卸载
- en: Pradeep Bedi
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 普拉迪普·贝迪
- en: '[![Orcid Image](i/orcid.svg) https://orcid.org/0000-0003-1708-6237](https://orcid.org/0000-0003-1708-6237)'
  id: totrans-3
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[![Orcid Image](i/orcid.svg) https://orcid.org/0000-0003-1708-6237](https://orcid.org/0000-0003-1708-6237)'
- en: Galgotias University, India
  id: totrans-4
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 加尔各答大学，印度
- en: S. B. Goyal
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 苏博特·古奥尔
- en: '[![Orcid Image](i/orcid.svg) https://orcid.org/0000-0002-8411-7630](https://orcid.org/0000-0002-8411-7630)'
  id: totrans-6
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[![Orcid Image](i/orcid.svg) https://orcid.org/0000-0002-8411-7630](https://orcid.org/0000-0002-8411-7630)'
- en: City University, Malaysia
  id: totrans-7
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 马来西亚城市大学
- en: Jugnesh Kumar
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贾格内什·库马尔
- en: St. Andrews Institute of Technology and Management, India
  id: totrans-9
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 圣安德鲁斯理工学院和管理学院，印度
- en: ABSTRACT
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要
- en: Edge computing is a type of distributed computing that was designed especially
    for internet of things (IoT) users to provide computational resources and data
    management nearby to users' devices. By introducing edge computing for IoT, networks
    have reduced the bandwidth and latency issue while handling real-time applications.
    The major benefit of edge computing is that it reduces the communication overhead
    between IoT user and server. With integration of IoT in our daily lives, it has
    attracted researchers towards its performance management such as complexity minimization,
    latency minimization, memory management, energy consumption minimization, etc.
    In this chapter, deep reinforcement learning is focused to minimize the computational
    complexity at IoT user end. The task offloading decision process is designed using
    Q-Learning, which minimizes the system cost and curse of high dimensional data.
    In addition, the proposed methodology will perform better as compared to existing
    algorithms with respect to system costs.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘计算是一种分布式计算，专为物联网（IoT）用户设计，以在用户设备附近提供计算资源和数据管理。通过为物联网引入边缘计算，网络在处理实时应用时减少了带宽和延迟问题。边缘计算的主要好处是减少了物联网用户和服务器之间的通信开销。随着物联网融入我们的日常生活，它吸引研究人员关注其性能管理，如复杂性最小化、延迟最小化、内存管理、能量消耗最小化等。在本章中，我们重点关注使用深度强化学习最小化物联网用户端的计算复杂性。任务卸载决策过程是使用Q学习设计的，这可以最小化系统成本和高维数据的诅咒。此外，与现有算法相比，所提出的方法在系统成本方面表现更佳。
- en: INTRODUCTION
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 引言
- en: The term Internet of Things (IoT), clearly refers to the objects, things and
    things in an Internet structure which can be easily identified, was first proposed
    in 1998 (Liu et al., 2020). In recent years, due to some representative application
    (for example, intelligent monitoring of greenhouses, while reading electricity
    meters, monitoring of telemedicine and intelligent transport) the IoT concept
    has become popular. Typically, the IoT has four main components- sensors, data
    processing, applications and services. The new era applications such as smart
    city, smart educational system, smart industries, etc are integrated with Internet
    of Things (IoT) (Anand et al, 2021). The IoT architecture is composed of IoT devices
    such as sensors, actuators and gateways that are used to collect and perform computation
    over these generated and collected data (Liu et al. 2020).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: “物联网”（IoT）这个术语明确地指的是那些可以轻松识别的、在互联网结构中的对象、物品和事物，它最早是在1998年被提出的（刘等人，2020年）。近年来，由于一些具有代表性的应用（例如，温室智能监控、读取电表、远程医疗和智能交通监控等），物联网的概念变得流行起来。通常，物联网有四个主要组成部分——传感器、数据处理、应用和服务。新时代的应用，如智慧城市、智能教育系统和智能产业等，都是与物联网（IoT）集成在一起的（Anand等人，2021年）。物联网架构由传感器、执行器和网关等物联网设备组成，这些设备用于收集数据并进行计算（刘等人，2020年）。
- en: With advancement of technologies, every day new innovations in hardware as well
    as software are being made which had contributed in increase of IoT networks and
    their applications. With usage of IoT devices on large scale, there is increase
    in data processing and storage requirements (Alfakih et al., 2020). For instance,
    for adopting smart farming, there is requirement of many sensors, computational
    devices to monitor temperature, humidity, pH, light, nutrition level, etc required
    for proper growth and developments of plants. In IoT network scenario, these data
    are generated by deployed sensors and collected the gateway devices and further
    sent to the cloud server end where processing over collected data is performed
    (Wang et al., 2019).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 随着技术的进步，每天在硬件和软件方面都有新的创新，这有助于物联网网络和它们的应用增加。大规模使用物联网设备导致数据处理和存储需求增加（Alfakih 等人，2020）。例如，采用智能农业需要许多传感器、计算设备来监测温度、湿度、pH、光照、营养水平等，这些都是植物正常生长和发育所必需的。在物联网网络场景中，这些数据由部署的传感器生成，并通过网关设备收集，然后发送到云服务器端进行数据处理（Wang
    等人，2019）。
- en: While processing such large amount of data in dynamic and real channel environment,
    there arise some challenges that are needed to be addressed. In case of smart
    farming, first issue is that where to locate sensors so that they can cover maximum
    area. Another issue is that most of the farms are located mostly outside the city
    where internet services are limited and are not capable to connect to the remote
    servers all the time. This issue can be addressed by integrating IoT-cloud architecture
    with edge computing that can provide promising solution to such issues (Wang et
    al., 2019) (Alelaiwi, 2019). Another issue that arise in IoT network is that there
    is requirement of large processing services to edge server by these deployed IoT
    sensors that burdens on the radio services and the storage services. So, the IoT
    devices required to be developed such that they can process some simple data processing
    tasks locally. Therefore, for fast and optimal processing of large amount of data
    in Edge-IoT network, there is requirement to design an optimal computation task
    offloading scheme (Chen et al., 2020).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在动态和实时的信道环境中处理如此大量的数据时，会出现一些需要解决的问题。在智能农业的情况下，首先需要解决的问题是如何定位传感器，以便它们可以覆盖最大面积。另一个问题是，大多数农场位于城市外部，那里互联网服务有限，且无法始终连接到远程服务器。这个问题可以通过将物联网云架构与边缘计算集成来解决，这种集成可以提供解决此类问题的有希望的方法（Wang
    等人，2019）（Alelaiwi，2019）。在物联网网络中出现的另一个问题是，这些部署的物联网传感器需要向边缘服务器提供大量的处理服务，这给无线电服务和存储服务带来了负担。因此，需要开发物联网设备，使它们能够在本地处理一些简单的数据处理任务。因此，为了在边缘-物联网网络中快速和最优地处理大量数据，需要设计一个最优的计算任务卸载方案（Chen
    等人，2020）。
- en: User equipment processing some computationally expensive programmes and uploading
    the data processing these applications to the edge server through wireless transmission
    on the condition of weighing continuous or other indicators is referred to as
    task offloading. The processing programme assigns certain computational resources
    to the edge server for these uploads in order to receive ongoing or progressive
    replacements, leading to a positive user engagement. A fundamental aspect of selecting
    whether to offload, that is, the offloading choice, is usually an initial part
    of computer offloading and resource allocation. End devices are viewed as agents
    in this article, making judgments on whether or not the network should offload
    compute chores to edge devices. The computing resource allocation problems were
    framed as a sum cost delay of this framework to address resource allocation and
    task offloading. In this paper, an optimal computational offloading choice is
    presented, and reinforcement learning is used to fix the issues.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 用户设备在权衡连续或其他指标的情况下处理一些计算密集型程序，并通过无线传输将这些数据处理任务上传到边缘服务器，这一过程被称为任务卸载。处理程序为这些上传分配一定的计算资源给边缘服务器，以获取持续或渐进的替换，从而提高用户参与度。选择是否卸载的根本方面，即卸载选择，通常是计算机卸载和资源分配的初始部分。本文中将终端设备视为代理，对这些设备是否应将计算任务卸载到边缘设备进行判断。计算资源分配问题被构造成此框架的总成本延迟，以解决资源分配和任务卸载。在本文中，提出了一个最优的计算卸载选择，并使用强化学习来解决这些问题。
- en: Reinforcement learning is a branch of artificial intelligence. The main distinction
    between unsupervised and supervised learning is that unsupervised learning does
    not involve artificial labelling. The exploration of an unknown area and the application
    of previously acquired knowledge are at the heart of the game. Reinforcement learning
    is achieved through constant trial and error, continual interaction with the environment,
    and receiving rewards or punishment from the environment, followed by the acquisition
    of acquiring knowledge to upgrade its very own paradigm. It picks up a new behavior
    strategy. It may make judgments to maximise long-term profits based on environmental
    variables after a specific period of training. Reinforcement learning can now
    handle high-dimensional actions and states, learning efficiency has increased
    dramatically, and the constraints of reinforcement learning have been broken to
    some extent. Deep reinforcement learning techniques will be utilized to solve
    the task offloading problem in edge computing in order to make the model adaptively
    learn to offload decisions.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习是人工智能的一个分支。无监督学习和监督学习的主要区别在于，无监督学习不涉及人工标签。探索未知领域和应用之前获得的知识是游戏的核心。强化学习通过不断的尝试和错误，与环境的持续互动，以及从环境中接收奖励或惩罚，然后获取知识以升级其自身的范式。它学会了新的行为策略。在特定时期的训练后，它可能会根据环境变量做出判断，以最大化长期利润。强化学习现在可以处理高维动作和状态，学习效率大幅提高，并在一定程度上打破了强化学习的限制。深度强化学习技术将用于解决边缘计算中的任务卸载问题，使模型适应性地学习卸载决策。
- en: 'But still there are some issues that has been identified in existing deep learning
    models are such as:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 但在现有深度学习模型中仍然存在一些问题，例如：
- en: 'Compatibility with IoT/Edge: A new edge paradigm has emerged as a result of
    the spread of edge computing and IoT, with artificial intelligence being integrated
    into edge. Three-tier design for IoT-edge AI integration uses a DNN with numerous
    levels utilized on both the edge server and cloud servers. The DNN’s front layers
    are located on the edge server, while its backend layers are located on the cloud.
    How to deploy a deep neural network (DNN) on an IoT-edge is an important consideration
    when it comes to offloading the AI-integrated IoT-output edges into the cloud.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: IoT/边缘兼容性：随着边缘计算和物联网的普及，一个新的边缘范式已经出现，人工智能被集成到边缘。三层设计的物联网-边缘AI集成使用多个级别在边缘服务器和云服务器上进行DNN处理。DNN的前层位于边缘服务器上，后层位于云上。当将AI集成的物联网输出边缘卸载到云时，如何在物联网边缘部署深度神经网络（DNN）是一个重要考虑。
- en: 'Offloading Compatibility with heterogeneity: For the most part, earlier research
    on the topic of offloading models has assumed that the computations are all of
    a similar type. Because of this, offloading modelling is made easier. Modeling
    becomes more difficult due to the wide range of responsibilities. The computing
    units themselves may be a source of variability (hardware).'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 异构性兼容的卸载：在关于卸载模型的早期研究中，大部分假设计算都是相同类型的。由于这一点，卸载建模变得容易。建模因责任范围广泛而变得更加困难。计算单元本身可能是变异性（硬件）的来源。
- en: 'Offloading Compatibility with Mobility: To ensure service continuity and quality
    of service (QoS) criteria, nodes must undertake a handover to another edge/fog
    domain. If the jobs are being offloaded to a VM container, the question is whether
    this VM should be moved to the new server. This problem derives from the fact
    that migration costs are offset by the benefits of reduced delays and communication
    costs. Furthermore, dynamic VM migration and optimal offloading decisions necessitate
    a prediction technology. In a mobility context, offloading modelling is more difficult
    because of these features.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 移动性兼容的卸载：为确保服务连续性和服务质量（QoS）标准，节点必须向另一个边缘/雾域进行切换。如果任务正在卸载到虚拟机容器，那么问题就是这个虚拟机是否应该移动到新服务器上。这个问题源于迁移成本与减少延迟和通信成本的好处之间的权衡。此外，动态虚拟机迁移和最优卸载决策需要预测技术。在移动性背景下，由于这些特性，卸载建模更加困难。
- en: EDGE COMPUTING
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘计算
- en: Edge computing is a distributed approach that was designed for task processing
    and data management of IoT networks’ tasks. These computing resources are deployed
    nearby to IoT devices with an aim to reduce response time and to reduce overall
    bandwidth requirements to handle real-time applications over internet. Its main
    benefit is that it reduces the communication gaps between the IoT users and cloud
    server (Wei et al., 2018). Task offloading by using edge servers have attracted
    researchers to explore new scope for performance enhancement IoT network to handle
    computational complexities. For this there is requirement of latency minimization,
    task offloading, storage management, power consumption and so on. With implementation
    of Edge computing these objectives can be achieved. But still there is requirement
    of more advancement as everyday size of data is increasing which require more
    processing speed. As local computing is not possible all the time because IoT
    devices have limited battery power and computation resources (Higuchi et al.,
    2019).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘计算是一种分布式方法，旨在处理物联网网络的任务处理和数据管理。这些计算资源部署在物联网设备附近，旨在减少响应时间，并减少处理互联网上的实时应用所需的整体带宽要求。其主要好处是减少了物联网用户与云服务器之间的通信差距（Wei等人，2018年）。利用边缘服务器进行任务卸载已吸引研究人员探索提高物联网网络性能的新前景，以处理计算复杂性。为此，需要减少延迟、任务卸载、存储管理、功耗等。通过实施边缘计算可以实现这些目标。但是，随着每天数据量的增加，仍然需要更多的进步，这需要更快的处理速度。由于本地计算不可能始终进行，因为物联网设备具有有限的电池电量和计算资源（Higuchi等人，2019年）。
- en: So, to support real time high latency consuming IoT applications, it is needed
    to reduce the offloading complexities at edge servers. Offloading algorithm are
    concerned to meet Quality-of-Service (QoS) requirements for different resource-demanding
    applications (Khayyat et al., 2020). Due to limited spectrum allocated to gateway
    devices, they cannot handle large set of computation tasks (Li et al., 2020).
    Hence, some researchers implemented the clustering concept to group the IoT devices
    to handle their demand according to their clusters. These clusters are made according
    to their computational demand (Guo et al., 2019).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了支持实时高延迟消耗的物联网应用程序，需要减少边缘服务器的卸载复杂性。卸载算法关注满足不同资源需求应用程序的服务质量（QoS）要求（Khayyat等人，2020年）。由于仅分配给网关设备的频谱有限，它们无法处理大量的计算任务（Li等人，2020年）。因此，一些研究人员实现了聚类概念，将物联网设备分组以根据其集群处理需求。这些集群是根据其计算需求制定的（Guo等人，2019年）。
- en: Subsequently, there is need of optimal offloading of task that can handle the
    major issues and challenge of the IoT edge computing networks. Traditional offloading
    schemes are not much efficient to give optimal decisions for dynamic environment
    (Zhang et al., 2018) (Wang et al., 2019). Many researchers proposed dynamic task
    offloading algorithms, such as Markov decision process (MDP), by interaction with
    environment parameters. But MDP can handle single task at same time. Further,
    reinforcement learning showed its effectiveness to resolve the issues of MDP but
    still it needs to be make the learning process more adaptable to channel environment
    (Zhang et al., 2019) (Chen et al., 2019).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，需要优化任务卸载，以处理物联网边缘计算网络的主要问题和挑战。传统的卸载方案不能为动态环境提供最优决策（Zhang等人，2018年）（Wang等人，2019年）。许多研究人员提出了动态任务卸载算法，如马尔可夫决策过程（MDP），通过与环境参数互动。但是MDP一次只能处理一个任务。此外，强化学习显示了其解决MDP问题的有效性，但仍然需要使学习过程更加适应信道环境（Zhang等人，2019年）（Chen等人，2019年）。
- en: COMPUTATIONAL OFFLOADING USING REINFORCEMENT LEARNING
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用强化学习进行计算卸载
- en: Reinforcement learning is an optimal learning process that learns the channel
    state by interacting with environment. In Edge-IoT network, each IoT user is considered
    to be as agent and their requirements are considered as environment. As shown
    in Figure 1, three-layer architecture is given for designing Cloud-Edge-IoT computing
    network. There are many IoT networks connected with Edge server. Each IoT network
    composed of large number of IoT users, gateway devices (or edge devices) that
    can collect data from IoT users. These gateway devices collect data from IoT users
    in particular coverage area and process them at edge server equipped with finite
    storage capacity and computational resources. So, these devices, either gateway
    or edge server can allow limited processing simultaneously as each IoT user have
    different type of task of different size. These computing resources are equipped
    with limited resources and battery power as well, so, there is need of optimal
    task offloading to improve the performance and lifetime of the entire network.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习是一种最优的学习过程，通过与环境的交互来学习通道状态。在边缘-物联网网络中，每个物联网用户被视为代理，他们的需求被视为环境。如图1所示，为设计云-边缘-物联网计算网络给出了三层架构。有许多物联网网络与边缘服务器相连。每个物联网网络由大量物联网用户、网关设备（或边缘设备）组成，可以从物联网用户那里收集数据。这些网关设备在特定的覆盖区域内从物联网用户那里收集数据，并在配备有限存储容量和计算资源的边缘服务器上处理它们。因此，这些设备，无论是网关还是边缘服务器，都可以同时允许有限的处理，因为每个物联网用户都有不同类型和大小的任务。这些计算资源配备了有限的资源和电池电量，所以，需要最优的任务卸载来提高整个网络的性能和寿命。
- en: In Figure 2, Edge-IoT task offloading scheme is illustrated with reinforcement
    learning. In this architecture, each agent, IoT user (u[i]), having state (S[k]),
    at time instance (k) with action (A[k]) to determine the computing mode based
    on the decision policy given by environmental parameters. Therefore, if there
    is change in environment new state (S[k+1]) is observed with new reward R[k].
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在图2中，通过强化学习说明了边缘-物联网任务卸载方案。在这个架构中，每个代理，物联网用户（u[i]），在时间实例（k）具有状态（S[k]）和行为（A[k]）来根据环境参数给出的决策策略确定计算模式。因此，如果环境发生变化，观察到新的状态（S[k+1]）和新的奖励R[k]。
- en: 'A reinforcement learning consists of following elements:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习包括以下元素：
- en: '• Agent: These are the end users, IoT devices, that can perform some actions.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: • 代理：这些都是终端用户，物联网设备，可以执行某些操作。
- en: '• Environment: These are the determining parameters that decides the reward
    of agents.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: • 环境：这些是决定代理奖励的确定性参数。
- en: '• State: The states explores the environment status such as channel gain, queue
    status, computation capacity, etc.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: • 状态：状态探索环境状态，如通道增益、队列状态、计算能力等。
- en: '• Policy: A policy defines the way the agent behaves in a given time or it
    can be said that a policy is a mapping from the states of the environment to actions
    to the actions the agent takes in the environment.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: • 策略：策略定义了代理在给定时间的行为方式，或者可以说策略是从环境的态到代理在环境中采取的动作的映射。
- en: '• Reward: A reward can determine whether an agent can offload the task or not.
    For this, reinforcement learning is implemented. For task offloading each agent
    maximizes the rewards during learning. In Edge computing, to minimize the system
    computation cost with respect to power, time and space, negative reward is adopted
    make right decisions.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: • 奖励：奖励可以决定一个代理是否可以卸载任务。为此，实施了强化学习。对于任务卸载，每个代理在学习过程中最大化奖励。在边缘计算中，为了根据电力、时间和空间最小化系统计算成本，采用了负奖励来做出正确的决策。
- en: '• Action: The action is performed by each IoT users for choosing local computing
    or offloading.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: • 动作：每个物联网用户执行的动作是为了选择本地计算还是卸载。
- en: '| Figure 1\. IoT network with edge computing with offloading scheme |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 图1. 带有边缘计算和卸载方案的物联网网络 |'
- en: '| ![Figure978-1-6684-3733-9.ch003.f01](i/ch003.f01.png) |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| ![Figure978-1-6684-3733-9.ch003.f01](i/ch003.f01.png) |'
- en: '| Figure 2\. Reinforcement learning for IoT users |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 图2. 物联网用户的强化学习 |'
- en: '| ![Figure978-1-6684-3733-9.ch003.f02](i/ch003.f02.png) |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| ![Figure978-1-6684-3733-9.ch003.f02](i/ch003.f02.png) |'
- en: RELATED WORK
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 相关研究
- en: Liu et al. (2020) investigated the machine learning approach for resource allocation
    with edge computing in Internet-of-Things (IoT) networks. In this work, centralized
    clustering of IoT users is proposed is by assigning user’s priorities. The highest
    priority cluster is selected and assigned to offload their task at the edge server
    whereas the task having lowest priority is can compute their task locally. The
    distributed task offloading is performed by Markov decision process which consider
    all the IoT user as agent and makes a series of task offloading decision. This
    policy is designed with respect to cost effectiveness based on channel dynamics.
    In this approach, deep Q-network was used for high dimensional tasks to learn
    the optimal policy.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Liu等人（2020年）研究了物联网（IoT）网络中边缘计算的资源分配机器学习方法。在这项工作中，通过分配用户优先级提出了一种面向物联网用户的集中聚类方法。选择最高优先级的集群并将其分配给边缘服务器卸载其任务，而优先级最低的任务可以在本地计算其任务。通过考虑所有IoT用户为代理的马尔可夫决策过程进行分布式任务卸载，并做出一系列任务卸载决策。根据通道动态基于成本效益设计的策略。在此方法中，使用深度Q网络对高维任务学习最优策略。
- en: Alfakih et al. (2020) proposed an algorithm using deep reinforcement learning
    approach for designing state-action-reward policy for task offloading from IoT
    users to edge server. The optimal offloading decision was performed to minimize
    system cost in respect to time delay and energy.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Alfakih等人（2020年）提出了一个使用深度强化学习方法设计的算法，用于从物联网用户到边缘服务器的任务卸载状态-动作-奖励策略。通过最小化与时间延迟和能量相关的系统成本执行最优卸载决策。
- en: Wang et al. (2019) proposed task offloading algorithm for fog-cloud network
    design of Internet of Vehicles (IoV). The objective was to minimize the power
    consumption and computational resources of the vehicles.NP-hard problem was formulated
    as optimization of offloading issues.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Wang等人（2019年）提出了一个面向车联网雾-云网络设计的任务卸载算法。目标是最小化车辆的能耗和计算资源。将NP难题表述为卸载问题的优化。
- en: Alelaiwi et al. (2019) proposed a structure for forecast of reaction time utilizing
    deep learning and studying how to off the utilization of a deep learning-based
    reaction time-prediction system to make the decision of whether to offload in
    the cloud hub, to close by haze/edge hub or neighbor haze/edge hub, nearby fog/edge
    node or neighbor fog/edge node. Besides, a limited Boltzmann machines learning
    is applied to handle the irregularity in the accessibility of assets.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Alelaiwi等人（2019年）提出了一种利用深度学习预测反应时间的结构，并研究如何将基于深度学习的反应时间预测系统的利用情况卸载到决策中，以决定是否在云枢纽、附近的雾/边缘枢纽或附近的邻居雾/边缘枢纽、附近的雾/边缘节点或邻居雾/边缘节点卸载。此外，还应用了有限玻尔兹曼机学习来处理资产访问的不规则性。
- en: Chen et al. (2020) proposed an algorithm for offloading task between IoT and
    edge server and termed it as intelligent Task Offloading Algorithm (iTOA). As
    compared to existing algorithms, iTOA decides the offloading activities on current
    state of network by using Monte Carlo Tree Search (MCTS). To provide quick search
    facilities, the MCTS algorithm was merged with Deep Neural Network (DNN).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Chen等人（2020年）提出了一种物联网与边缘服务器之间卸载任务的算法，并将其命名为智能任务卸载算法（iTOA）。与现有算法相比，iTOA通过使用蒙特卡洛树搜索（MCTS）来决定网络当前状态下的卸载活动。为了提供快速的搜索设施，将MCTS算法与深度神经网络（DNN）合并。
- en: Wei et al. (2018) analyzed a system comprising of multiple mobiles which are
    intended to carry out uploading tasks to a MEC server and in a single cell, hence
    the proper allocation to limited server with wireless channels emerge out as a
    problem. The author has hence designed an optimization problem for energy and
    tasks on the mobile so that they are efficiently divided. A Select Maximum Saved
    Energy First (SMSEF) algorithm being the key algorithm utilized.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Wei等人（2018年）分析了一个由多个移动设备组成的系统，这些设备旨在将上传任务执行到MEC服务器，并且在一个单细胞中，因此将有限的服务器与无线信道适当的分配成为一个问题。作者因此为移动设备上的能量和任务设计了一个优化问题，以便它们能够有效划分。选择最大节省能量优先（SMSEF）算法作为关键算法使用。
- en: Higuchi et al. (2019) investigated a type of virtual edge server and its compatibility
    of dealing it with the multiple vehicles, however he concluded that the during
    its early development stage, its feasibility requires more concern. The concluding
    simulations of the paper suggested that for vehicles the horizontal form of offloading
    can bring about reduction in the peak load on edge computing structure nearly
    by 53%. The penetration rate of V2V communication technology was kept low during
    this study.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 樋口等人（2019年）研究了一种虚拟边缘服务器及其与多车辆的兼容性，但他得出结论称，在其早期开发阶段，其可行性需要更多关注。该论文的最终模拟结果显示，对于车辆，水平卸载形式可以将近边缘计算结构上的峰值负载减少近53%。在研究期间，V2V通信技术的渗透率保持在较低水平。
- en: Khayyat et al. (2020) focused on multilevel vehicular edge cloud networks and
    presented an advanced deep learning-based algorithm for it. The main focus is
    on achieving energy conservation and an effective utilization of the resources
    shared by the vehicles which is achieve by achieving an integration model for
    computational constrained offloading. The reduction in the time and energy consumption
    is attained by achieving the binary formulation for the resource allocation. However,
    it was found that due to problem of dimensionality, this type of solution is NP
    difficult and is thus very complex/prohibited to solve them. Thus, the authors
    have developed a similar reinforcement learning method and proposed a distributed
    deep learning algorithm along with neural network-based learning so as to finally
    achieve an optimum solution for taking offloading decision.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 哈亚特等人（2020年）专注于多层次的车载边缘云网络，并为此提出了一个先进的基于深度学习的算法。主要关注点是实现能量节约和有效利用车辆共享的资源，这是通过实现计算约束卸载的集成模型来实现的。通过实现资源分配的二进制公式，减少了时间和能量消耗。然而，由于问题的维度问题，这种解决方案是NP难的，因此非常复杂/难以解决。因此，作者开发了一种类似的强化学习方法，并提出了基于神经网络的分布式深度学习算法，以最终实现卸载决策的最优解决方案。
- en: Li et al. (2020) proposed a deep reinforcement learning calculation to take
    care of the intricate calculation offloading issue for the Edge Computing Server
    (ECS) that is heterogeneous in nature with combined computing resources. The main
    concern in this work that was focused are such as network condition as well as
    task characteristics. The actor gradient policy was designed to settle on enhanced
    choices of offloading of tasks. Considering performing multiple tasks, the heterogeneity
    of edge subnet and versatility of edge tasks, the proposed calculation can get
    familiar with the network and create the calculation offloading choice to limit
    the allotment delay.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 李等人（2020年）提出了一种深度强化学习计算方法，以解决边缘计算服务器（ECS）在混合计算资源方面的复杂计算卸载问题。该研究的主要关注点包括网络状况和任务特性等。设计了演员梯度策略，以选择任务卸载的改进选项。考虑到执行多个任务、边缘子网的异质性以及边缘任务的多样性，所提出的计算方法能够熟悉网络并创建计算卸载选择以限制分配延迟。
- en: Guo et al. (2019) & Bedi et al (2021) focused on improving the operation earning
    by dropping the charge of the MDs. As the computation demands vary according to
    regions and there is difference in the availability of the computational edge
    servers, the traditional method to achieve the objective cannot be chosen. To
    solve this, the paper concluded that we can develop an efficient computing resource
    strategy and offloading task profile in UDN scenarios with time variation. The
    author concluded a deep Q-network based scheme for solving the problem.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 郭等人（2019年）和贝迪等人（2021年）专注于通过降低MDs的费用来提高运营收益。由于计算需求根据地区而变化，且计算边缘服务器的可用性存在差异，因此无法选择传统的方法来实现目标。为了解决这个问题，论文得出结论，我们可以在时间变化的UDN场景中开发有效的计算资源策略和卸载任务配置文件。作者得出了一种基于深度Q网络的解决方案。
- en: In IoT networks, with the emergence of edge computing has resulted in many challenges
    for the researchers and developers, which include dynamic computation offloading
    scheme designing, resources such as computing resource, spectrum useful resource
    and their allocation, and transmit electricity controlling. It has been found
    that these are very difficult to solve independent as the designing of and computational
    offloading scheme for the edge server has to learn about the resource of the gateway
    as well as the transmit power capability of the end user. There has been focused
    study on computational offloading schemes that are capable of handling multiple
    resources in the edge servers, more specifically in the MEC frameworks. Power
    consumption and latency are the two main area of concern while working in IoT
    network with offloading scheme of task. So, many researchers have proposed an
    optimized task offloading scheme that can handle energy requirement as well as
    latency such as MEC system. But MEC based task offloading can handle single user
    at a time. Then, multi-user framework was implanted using deep reinforcement learning
    using MEC framework. However, these algorithms are not much efficient to handle
    multi-user multi-task at same time optimally.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在物联网网络中，随着边缘计算的出现，给研究人员和开发者带来了许多挑战，包括动态计算卸载方案设计、计算资源、频谱资源及其分配，以及传输电力控制。研究发现，这些挑战很难独立解决，因为边缘服务器的计算卸载方案设计需要了解网关的资源以及终端用户的传输功率能力。已有研究集中于能够在边缘服务器处理多个资源的计算卸载方案，特别是在
    MEC 框架中。在物联网网络中使用任务卸载方案时，功耗和延迟是两个主要关注的问题。因此，许多研究者提出了能够处理能量需求和延迟的优化任务卸载方案，如 MEC
    系统。但是，基于 MEC 的任务卸载一次只能处理一个用户。随后，通过使用深度强化学习在 MEC 框架中实现了多用户框架。然而，这些算法在同时优化处理多用户多任务方面并不高效。
- en: Along with this in order to achieve threshold structure of the system, an optimal
    task offloading policy is validated. The clustering of the IOT users into various
    groups has been proposed by making use of clustering optimizing algorithm which
    is framed as initial step for the task offloading scheme designing. The reduction
    in the power utilization, time and system cost along with considerable decrement
    in the execution latency is achieved by making use of distribution computation
    task offloading algorithm. Diverse contributions from various authors towards
    the work have been described in the table I.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了达到系统的阈值结构，本研究验证了最优的任务卸载策略。通过利用聚类优化算法将物联网用户划分为不同组别，这作为任务卸载方案设计的第一步。通过使用分布式计算任务卸载算法，实现了功耗、时间和系统成本的降低，以及执行延迟的显著减少。表
    I 中描述了不同作者对工作的各种贡献。
- en: 'In view of the previous studies, following main issues were being listed:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于之前的研究，以下主要问题被列出：
- en: • One of the main issues of Markov Decision Problem (MDP) is that it can be
    only utilized with single user with task scheduling.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: • 马尔可夫决策问题（MDP）的一个主要问题是，它只能与单个用户和任务调度一起使用。
- en: • MDP can lead to most effective values however creates time-constraint troubles.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MDP 虽然能带来最有效的价值，但同时也可能产生时间上的约束问题。
- en: • Q-learning is a method that can be utilized for resolving the MDP issue however
    it may face huddles such as overestimated function. For some stochastic environments
    the famous reinforcement studying algorithm Q-getting is known to perform very
    poorly. This poor performance is resulting from massive overestimations of action
    values. These overestimations due to a positive bias that is added due to the
    fact Q-learning uses the maximum action value as an approximation for the most
    predicted action value.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: • Q 学习是一种可以用于解决 MDP 问题的方法，但它可能会遇到诸如高估函数等问题。在一些随机环境中，著名的强化学习算法 Q 学习表现非常差。这种低效的表现是由于动作价值的巨大高估。这种高估是由于正偏误导致的，因为
    Q 学习使用最大动作值作为最预测动作值的近似。
- en: Table 1\. Gives the comparative study of various methods for task offloading
    in iot network
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1. 提供了物联网网络中任务卸载的各种方法的比较研究
- en: '| Author | Description | Results | Drawbacks |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 作者 | 描述 | 结果 | 缺点 |'
- en: '| Liu et al. (2020) | Deep reinforcement learning approach with markov decision
    process | Optimal clustering of IoT users and results in optimal energy cost.
    | Not adaptable to multiple users processing simultaneously. |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 刘等人（2020 年）| 具有马尔可夫决策过程的深度强化学习方法 | 优化了物联网用户的聚类，从而实现了最优的能源成本。 | 不适用于同时处理多个用户。
    |'
- en: '| Li et al. (2020) | Deep Deterministic Policy Gradient | minimize the task
    delay | Energy cost consumption was not considered. |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 李等人（2020 年）| 深度确定性策略梯度 | 最小化任务延迟 | 未考虑能源成本消耗。 |'
- en: '| Alelaiwi et al. (2019) | Deep learning for prediction of response time |
    Improves the offloading computational performance | Time-constraint issues |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| Alelaiwi 等人（2019 年）| 深度学习用于预测响应时间 | 提高了计算卸载的性能 | 时间约束问题 |'
- en: '| Xiaolan et al. (2019) | Greedy Q learning algorithm for optimal offloading
    t=of task | Achieved better performance of task offloading with respect to energy
    consumption and latency requirement of the entire network. | Not adaptable to
    multiple users processing simultaneously. |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| Xiaolan 等人（2019 年）| 用于优化任务卸载的贪心 Q 学习算法 | 在考虑整个网络的能量消耗和延迟要求的情况下，实现了更好的任务卸载性能。
    | 不适用于同时处理多个用户。 |'
- en: '| Chen et al. (2019) | Deep Reinforcement Learning Approach | Improved service
    latency performance | There is no predictive model as well not adaptable to massive
    IoT scenario |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 陈等人（2019 年）| 深度强化学习方法 | 提高了服务延迟性能 | 没有预测模型，也不适用于大规模物联网场景 |'
- en: '| Min et al. (2019) | Fast deep Q-network (DQN) based offloading scheme | Optimal
    offloading policy after sufficiently long learning time | Local power control
    and offloading decision-making problem |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| Min 等人（2019 年）| 基于快速深度 Q 网络（DQN）的卸载方案 | 在足够长的学习时间后，产生最优的卸载策略 | 本地功率控制和卸载决策问题
    |'
- en: '| Zhang et al. (2018) | Cost as well as energy aware offloading task is proposed
    using deep reinforcement learning. | Energy and cost were estimated | Multiple
    users cannot be served optimally |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 张等人（2018 年）| 提出了考虑成本和能量的计算卸载任务，使用深度强化学习。 | 估计了能源和成本 | 无法为多个用户优化服务 |'
- en: PROPOSED WORK
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: • 提议的工作
- en: 'In the world moving towards digitalization the small all mobile devices are
    able to perform small and medium level computation problems with no ability to
    deal with high computation processes. However, offloading the computation processes
    at the Gateway can emerge as one of the key solutions for this problem. While
    it is considered that x IoT devices are capable of performing T[x] task while
    they offload the task at the edge, the entire computational model can be summarized
    in the following three steps (figure 3):'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在迈向数字化的世界中，小型移动设备能够执行小规模和中等水平的计算问题，但没有能力处理高强度的计算过程。然而，在网关处卸载计算过程可以成为解决这一问题的关键方案之一。考虑到
    x 个物联网设备在边缘卸载 T[x] 任务的同时能够执行这些任务，整个计算模型可以总结为以下三个步骤（图 3）：
- en: • All the x IoT devices around to carry and deliver sufficient input information
    at the gateway by making use of various sensors and accomplish the task at the
    edge.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: • 所有 x 个物联网设备通过利用各种传感器在边缘计算节点处携带和传递足够的输入信息，并将结果发送到物联网、终端设备。
- en: • Edge shall allocate some portion from its computational resource to enable
    the computation of task for the x IoT devices.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: • 边缘计算节点应将其计算资源的一部分分配给 x 个物联网设备任务的计算。
- en: • Results are then sent to IoT, end device, after the computation via edge server.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: • 计算完成后，结果通过边缘服务器发送到物联网、终端设备。
- en: '| Figure 3\. IoT task offloading |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 图 3\. 物联网任务卸载 |'
- en: '| ![Figure978-1-6684-3733-9.ch003.f03](i/ch003.f03.png) |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| ![Figure978-1-6684-3733-9.ch003.f03](i/ch003.f03.png) |'
- en: '| Figure 4\. Proposed task offloading flow chart |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 图 4\. 提出的任务卸载流程图 |'
- en: '| ![Figure978-1-6684-3733-9.ch003.f04](i/ch003.f04.png) |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| ![Figure978-1-6684-3733-9.ch003.f04](i/ch003.f04.png) |'
- en: To deal with the sequential learning and achieving the decision making, machine
    learning such as Reinforcement learning (RL) can serve as an agent in making decisions
    and help in attaining the objective of cumulative rewards (Liu et al., 2019).
    The process has many key advantages such as energy sparing, quick offloading,
    low inertness, and ideal load distribution, so it is a critical contender for
    the future of the digitalization that is yet to come of remote correspondence.
    The ongoing research and examination depend on proper and effective offloading
    and task allocation for MEC frameworks. The resource allocation scheme is considered
    as partial offloading schemes.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理序列学习并实现决策制定，机器学习如强化学习（RL）可以作为决策代理人，帮助获得累积奖励的目标（刘等，2019）。该过程具有许多关键优势，如节能、快速卸载、低惯性和理想的负载分布，因此它是远程通信未来数字化的关键竞争者。正在进行的研究和检查依赖于MEC框架中适当的有效卸载和任务分配。资源分配方案被视为部分卸载方案。
- en: 'The proposed work is performed in following steps (figure 4):'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 'proposed work is performed in following steps (figure 4):'
- en: '• Step 1: Proving input as tasks and with respective IOT user.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: • 步骤1：将输入证明为任务，并与相应的IOT用户相对。
- en: '• Step 2: IOT user cluster generation.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: • 步骤2：生成IOT用户簇。
- en: '• Step 3: Priority level determination of IOT users (multiple) in each cluster.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: • 步骤3：确定每个簇的IOT用户优先级（多个）。
- en: '• Step 4: Q learning algorithm utilization for training deep reinforcement
    network.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: • 步骤4：使用Q学习算法训练深度强化网络。
- en: '• Step 5: Following above steps, next step is to offload tasks.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: • 步骤5：按照上述步骤，下一步是卸载任务。
- en: '• Step 6: Performance parameters valuation and determination.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: • 步骤6：评估和确定性能参数。
- en: DISCUSSIONS
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论
- en: In this section, the paper presents some comparative analysis of existing research
    works are presented which shows efficiency of deep reinforcement learning for
    task offloading in edge computing. Table II to shows the comparative analysis
    of existing techniques and average miili second. Ali et al. (2021) proposes deep
    learning techniques and have maximum average delay i.e.100 millisecond. Liet al.
    (2020) proposes ddpg technique having average delay of 6 ms. Another techniques
    proposed in Chen etl al. (2019) has minimum average delay of 3ms. Chen et al.
    (2019) with iRAF has average delay of 20sec. Liu et al. (2019) proses DRL based
    method with an average delay of 25sec. Hussain and Mausa (2020) Also proposes
    Deep learning techniqus having and average dealt of 85 and 90ms. Several fundamental
    concerns connected with fog computing, including structure, interface, and programming,
    offloading processing, efficient resource provisioning, and security aspects are
    discussed in this paper. Various optimization approaches have been developed in
    previous publications to solve such processing and transmission latency constraints.
    With delay as a limitation, a Q-learning priority-based task offloading strategy
    is presented to minimize the energy consumption in communications systems and
    computing.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，本文提出了一些现有研究的比较分析，展示了深度强化学习在边缘计算中任务卸载的效率。表II显示了现有技术和平均毫秒的比较分析。阿里等（2021）提出了深度学习技术，平均延迟最大，即100毫秒。李等（2020）提出了DDPG技术，平均延迟为6毫秒。陈等（2019）提出的另一种技术具有最小的平均延迟，为3毫秒。陈等（2019）使用iRAF的平均延迟为20秒。刘等（2019）提出了基于DRL的方法，平均延迟为25秒。侯赛因和穆萨（2020）也提出了深度学习技术，平均延迟为85和90毫秒。本文讨论了与雾计算相关的几个基本问题，包括结构、接口和编程、卸载处理、有效资源提供和安全方面。在先前的出版物中已经开发了各种优化方法，以解决此类处理和传输延迟约束。以延迟为限制，提出了基于Q学习优先级的任务卸载策略，以最小化通信系统和计算中的能量消耗。
- en: Table 2\. Comparative analysis
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 表2. 比较分析
- en: '| Ref | Techniques | Optimization | Average Delay (in ms) |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 技术 | 优化 | 平均延迟（毫秒） |'
- en: '| Ali et al. (2021) | DL | MCC | 100 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 阿里等（2021） | DL | MCC | 100 |'
- en: '| Li et al. (2020) | DDPG | DRL | 6 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 李等（2020） | DDPG | DRL | 6 |'
- en: '| Chen et al. (2019) | Deep-SARL | DRL | 3 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 陈等（2019） | Deep-SARL | DRL | 3 |'
- en: '| Chen et al. (2019) | iRAF | DRL | 20 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 陈等（2019） | iRAF | DRL | 20 |'
- en: '| Liu et al. (2019) | DRL | DRL | 25 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 刘等（2019） | DRL | DRL | 25 |'
- en: '| Hussain and Mausa (2020) | DL | ACO | 85 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 侯赛因和穆萨（2020） | DL | ACO | 85 |'
- en: '| Hussain and Mausa (2020) | DL | PSO | 90 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 侯赛因和穆萨（2020） | DL | PSO | 90 |'
- en: '| Figure 5\. Comparative analysis |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 图5. 比较分析 |'
- en: '| ![Figure978-1-6684-3733-9.ch003.f05](i/ch003.f05.png) |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| ![Figure978-1-6684-3733-9.ch003.f05](i/ch003.f05.png) |'
- en: CONCLUSION
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 结论
- en: Edge computing is well known for providing computational capabilities to IoT
    consumers, as IoT computing necessitates a vast resource spectrum. Furthermore,
    sending computational activities to an edge server uses more energy. As a result,
    conserving energy locally at the IoT user end is a difficult challenge. This can
    be accomplished through the optimization of network design or routing policies.
    The purpose of this paper is to summaries the research that has been done in the
    subject of edge computing for job offloading. To overcome the issue of offloading
    and to deploy an intelligent decision-making system that can accomplish the aforementioned
    duty while reducing human efforts, a variety of algorithms, frameworks, and predictive
    models have been proposed so far. A brief examination of several task offloading
    schemes is covered in this paper, along with their limitations. Based on a review
    of the literature, it has been determined that deep reinforcement techniques outperform
    standard approaches in terms of lowering computational effort. Furthermore, a
    method based on a modified Q-learning-based deep reinforcement technique is proposed
    to manage multiple users and tasks at the same time with little computing cost.
    The proposed methodology, which may be used with most types of offloading, such
    as vehicular and mobile offloading, will be implemented in the future. It can
    also be enhanced by using it in multi-agent networks.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘计算因提供物联网消费者所需的计算能力而广为人知，因为物联网计算需要广阔的资源谱。此外，将计算活动发送到边缘服务器会消耗更多能量。因此，在物联网用户端本地节约能量是一个难题。这可以通过优化网络设计或路由策略来实现。本文的目的是总结在作业卸载方面已经完成的研究。为了克服卸载问题并在减少人力投入的同时部署一个智能决策支持系统，到目前为止已经提出了各种各样的算法、框架和预测模型。本文简要介绍了几种作业卸载方案及其局限性。根据文献综述，确定深度强化学习技术在降低计算工作量方面优于传统方法。此外，提出了一种基于改进的基于Q学习的深度强化学习方法，以在少量计算成本的同时管理多个用户和任务。这种可能与大多数类型的卸载（如车辆和移动卸载）一起使用的方法，将在未来得到实施。它还可以通过在多代理网络中使用来增强。
- en: REFERENCES
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献
- en: Alelaiwi, A. (2019). An efficient method of computation offloading in an edge
    cloud platform. Journal of Parallel and Distributed Computing , 127, 58–64\. doi:10.1016/j.jpdc.2019.01.003
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Alelaiwi, A. (2019). 边缘云平台中计算卸载的高效方法。并行与分布式计算杂志，127，58-64。DOI:10.1016/j.jpdc.2019.01.003
- en: 'Alfakih, T., Hassan, M. M., Gumaei, A., Savaglio, C., & Fortino, G. (2020).
    Task offloading and resource allocation for mobile edge computing by deep reinforcement
    learning based on SARSA. IEEE Access: Practical Innovations, Open Solutions ,
    8, 54074–54084\. doi:10.1109/ACCESS.2020.2981434'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Alfakih, T., Hassan, M. M., Gumaei, A., Savaglio, C., & Fortino, G. (2020).
    基于SARSA的深度强化学习方法在移动边缘计算中的作业卸载和资源分配。IEEE Access:实用创新，开放解决方案，8，54074-54084。DOI:10.1109/ACCESS.2020.2981434
- en: Ali, A., Iqbal, M. M., Jamil, H., Qayyum, F., Jabbar, S., Cheikhrouhou, O.,
    Baz, M., & Jamil, F. (2021). An Efficient Dynamic-Decision Based Task Scheduler
    for Task Offloading Optimization and Energy Management in Mobile Cloud Computing.
    Sensors, 21(13), 4527\. 10.3390/s21134527
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Ali, A., Iqbal, M. M., Jamil, H., Qayyum, F., Jabbar, S., Cheikhrouhou, O.,
    Baz, M., & Jamil, F. (2021). 移动云计算中作业卸载优化和能量管理的高效动态决策任务调度器。传感器，21（13），4527。DOI:10.3390/s21134527
- en: Bedi, P., Goyal, S. B., Sharma, R., Yadav, D. K., & Sharma, M. (2021). Smart
    Model for Big Data Classification Using Deep Learning in Wireless Body Area Networks
    . In Sharma, D. K., Son, L. H., Sharma, R., & Cengiz, K. (Eds.), Micro-Electronics
    and Telecommunication Engineering. Lecture Notes in Networks and Systems (Vol.
    179). Springer. doi:10.1007/978-981-33-4687-1_21
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Bedi, P., Goyal, S. B., Sharma, R., Yadav, D. K., & Sharma, M. (2021). 无线体域网络中使用深度学习的大数据分类智能模型。在Sharma,
    D. K., Son, L. H., Sharma, R., & Cengiz, K. (eds.)，《微电子学与电信工程》。网络与系统讲座笔记（第179卷）。Springer。DOI:10.1007/978-981-33-4687-1_21
- en: Chen, J., Chen, S., Luo, S., Wang, Q., Cao, B., & Li, X. (2020). An intelligent
    task offloading algorithm (iTOA) for UAV edge computing network. Digital Communications
    and Networks , 6(4), 433–443\. doi:10.1016/j.dcan.2020.04.008
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Chen, J., Chen, S., Luo, S., Wang, Q., Cao, B., & Li, X. (2020). 无人机边缘计算网络的智能作业卸载算法（iTOA）。数字通信与网络，6（4），433-443。DOI:10.1016/j.dcan.2020.04.008
- en: 'Chen, J., Chen, S., Wang, Q., Cao, B., Feng, G., & Hu, J. (2019). IRAF: A Deep
    Reinforcement Learning Approach for Collaborative Mobile Edge Computing IoT Networks.
    IEEE Internet of Things Journal , 6(4), 7011–7024\. doi:10.1109/JIOT.2019.2913162'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Chen, X., Zhang, H., Wu, C., Mao, S., Ji, Y., & Bennis, M. (2019). Optimized
    computation offloading performance in virtual edge computing systems via deep
    reinforcement learning. IEEE Internet of Things Journal , 6(3), 4005–4018\. doi:10.1109/JIOT.2018.2876279
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: GuoH.LvJ.LiuJ. (2019). Smart Resource Configuration and Task Offloading with
    Ultra-Dense Edge Computing. International Conference on Wireless and Mobile Computing,
    Networking and Communications. 10.1109/WiMOB.2019.8923227
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Higuchi, T., Ucar, S., & Altintas, O. (2019). Offloading Tasks to Vehicular
    Virtual Edge Servers. Proceedings - 2019 IEEE 16th International Conference on
    Mobile Ad Hoc and Smart Systems Workshops, MASSW 2019, 162–163\. 10.1109/MASSW.2019.00040
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'Hussein, M. K., & Mousa, M. H. (2020). Efficient task offloading for IoT-Based
    applications in fog computing using ant colony optimization. IEEE Access: Practical
    Innovations, Open Solutions , 8, 37191–37201\. doi:10.1109/ACCESS.2020.2975741'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: 'Khayyat, M., Elgendy, I. A., Muthanna, A., Alshahrani, A. S., Alharbi, S.,
    & Koucheryavy, A. (2020). Advanced Deep Learning-Based Computational Offloading
    for Multilevel Vehicular Edge-Cloud Computing Networks. IEEE Access: Practical
    Innovations, Open Solutions , 8, 137052–137062\. doi:10.1109/ACCESS.2020.3011705'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: 'Li, Y., Qi, F., Wang, Z., Yu, X., & Shao, S. (2020). Distributed Edge Computing
    Offloading Algorithm Based on Deep Reinforcement Learning. IEEE Access: Practical
    Innovations, Open Solutions , 8, 85204–85215\. doi:10.1109/ACCESS.2020.2991773'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: LiuX.QinZ.GaoY. (2019). Resource Allocation for Edge Computing in IoT Networks
    via Reinforcement Learning. IEEE International Conference on Communications, 1-6\.
    10.1109/ICC.2019.8761385
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Liu, X., Yu, J., Wang, J., & Gao, Y. (2020). Resource Allocation With Edge Computing
    in IoT Networks via Machine Learning. IEEE Internet of Things Journal , 7(4),
    3415–3426\. doi:10.1109/JIOT.2020.2970110
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Min, M., Xiao, L., Chen, Y., Cheng, P., Wu, D., & Zhuang, W. (2019). Learning-Based
    Computation Offloading for IoT Devices with Energy Harvesting. IEEE Transactions
    on Vehicular Technology , 68(2), 1930–1941\. doi:10.1109/TVT.2018.2890685
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Rajawat, Bedi, Goyal, Alharbi, Aljaedi, Jamal, & Shukla. (2021). Fog Big Data
    Analysis for IoT Sensor Application Using Fusion Deep Learning. Mathematical Problems
    in Engineering. doi:10.1155/2021/6876688
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: 'Wang, X., Han, Y., Wang, C., Zhao, Q., Chen, X., & Chen, M. (2019). In-edge
    AI: Intelligentizing mobile edge computing, caching and communication by federated
    learning. IEEE Network , 33(5), 156–165\. doi:10.1109/MNET.2019.1800286'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Wang, X., Wei, X., & Wang, L. (2019). A deep learning based energy-efficient
    computational offloading method in Internet of vehicles. China Communications
    , 16(3), 81–91\. doi:10.12676/J.CC.2019.03.008
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 王**X.**, 魏**X.**, & 王**L.** (2019). 车联网中基于深度学习的能量高效计算卸载方法。中国通信 , 16(3), 81–91。DOI:10.12676/J.CC.2019.03.008
- en: Wei, F., Chen, S., & Zou, W. (2018). A greedy algorithm for task offloading
    in mobile edge computing system. China Communications , 15(11), 158–170\. doi:10.1109/CC.2018.8543056
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 魏**F.**, 陈**S.**, & 邹**W.** (2018). 移动边缘计算系统中任务卸载的贪心算法。中国通信 , 15(11), 158–170。DOI:10.1109/CC.2018.8543056
- en: Zhang, C., Liu, Z., Gu, B., Yamori, K., & Tanaka, Y. (2018). A Deep Reinforcement
    Learning Based Approach for Cost-and Energy-Aware Multi-Flow Mobile Data Offloading.
    IEICE Transactions on Communications , 101(7), 1625–1634\. doi:10.1587/transcom.2017CQP0014
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 张**C.**, 刘**Z.**, 顾**B.**, 矢野**K.**, & 田中**Y.** (2018). 一种基于深度强化学习的成本和能量感知的多流移动数据卸载方法。日本电气通信协会期刊
    on Communications , 101(7), 1625–1634。DOI:10.1587/transcom.2017CQP0014
