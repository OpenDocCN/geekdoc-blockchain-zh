- en: © The Author(s), under exclusive license to Springer Nature Switzerland AG 2021Y.
    Maleh et al. (eds.)Artificial Intelligence and Blockchain for Future Cybersecurity
    ApplicationsStudies in Big Data90[https://doi.org/10.1007/978-3-030-74575-2_14](https://doi.org/10.1007/978-3-030-74575-2_14)
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: © 作者，独家许可给 Springer Nature Switzerland AG 2021 Y. Maleh等人（编）未来网络安全应用的人工智能和区块链大数据研究
- en: Automated Methods for Detection and Classification Pneumonia Based on X-Ray
    Images Using Deep Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于X射线图像的肺炎检测和分类的自动化方法
- en: 'Khalid El Asnaoui^([1](#Aff7)  ), Youness Chawki^([2](#Aff8)) and Ali Idri^([3](#Aff9))(1)National
    School of Applied Sciences (ENSAO), Department of Electronics, Computer Sciences,
    and Telecommunications, Laboratory Smart Information, Communication and Technologies
    “SmarICT Lab”, Mohammed First University, BP: 669, 60000 Oujda, Morocco(2)Faculty
    of Sciences and Techniques, Moulay Ismail University, Errachidia, Morocco(3)Software
    Project Management Research Team, ENSIAS, Mohammed V University, Rabat, Morocco'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'Khalid El Asnaoui^([1](#Aff7)  )，Youness Chawki^([2](#Aff8))和Ali Idri^([3](#Aff9))(1)应用科学国立学校（ENSAO），电子、计算机科学和电信系，智能信息、通信和技术实验室，莫罕默德一世大学，BP:
    669，60000 欧吉达，摩洛哥(2)科学与技术学院，穆拉伊斯梅尔大学，埃拉希迪亚，摩洛哥(3)软件项目管理研究团队，ENSIAS，莫哈比五世大学，拉巴特，摩洛哥'
- en: Abstract
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Recently, researchers, specialists, and companies around the world are rolling
    out deep learning and image processing-based systems that can fastly process hundreds
    of X-Ray and Computed Tomography (CT) images to accelerate the diagnosis of pneumonia
    such as SARS, covid-19, etc., and aid in its containment. Medical image analysis
    is one of the most promising research areas; it provides facilities for diagnosis
    and making decisions of several diseases such as MERS, covid-19, etc. In this
    paper, we present a comparison of recent deep convolutional neural network (CNN)
    architectures for automatic binary classification of pneumonia images based on
    fined tuned versions of (VGG16, VGG19, DenseNet201, Inception_ResNet_V2, Inception_V3,
    Resnet50, MobileNet_V2 and Xception) and a retraining of a baseline CNN. The proposed
    work has been tested using chest X-Ray & CT dataset, which contains 6087 images
    (4504 pneumonia and 1583 normal). As a result, we can conclude that the fine-tuned
    version of Resnet50 shows highly satisfactory performance with rate of increase
    in training and testing accuracy (more than 96% of accuracy).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，全球的研究人员、专家和公司正在推出基于深度学习和图像处理的系统，这些系统可以快速处理数百张X射线和计算机断层摄影（CT）图像，以加速肺炎的诊断，例如SARS、covid-19等，并协助其遏制。医学图像分析是最有前途的研究领域之一；它提供了诊断和决策多种疾病的设施，如MERS、covid-19等。在本文中，我们提出了最近深度卷积神经网络（CNN）架构的比较，用于基于经过微调的版本（VGG16、VGG19、DenseNet201、Inception_ResNet_V2、Inception_V3、Resnet50、MobileNet_V2和Xception）和基线CNN的自动二元分类肺炎图像。所提出的工作已经使用胸部X射线和CT数据集进行了测试，该数据集包含6087张图像（4504张肺炎和1583张正常）。结果表明，经过微调的Resnet50版本显示出非常满意的性能，训练和测试准确率的增长率超过96%。
- en: KeywordsComputer-aided diagnosisPneumonia automatic detectionCT and X-Ray imagesPneumoniaCoronavirusCovid-19Deep
    learning
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 关键词：计算机辅助诊断、肺炎自动检测、CT和X射线图像、肺炎、冠状病毒、Covid-19、深度学习
- en: 1 Introduction
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Epidemics and chronic diseases have killed numerous individuals throughout history
    and caused significant emergencies that have set aside a long effort to survive.
    Two words are utilised epidemic and outbreak to portray a malady inside populaces
    that emerge over a timeframe [[1](#CR1), [2](#CR2)]. Indeed, we can define epidemic
    as the occurrence of more cases of illnesses, injury or other health condition
    than expected in a given area or among a specific group of persons during a specific
    period. For the most part, the cases are pretending to have a common cause [[2](#CR2)].
    The outbreak is distinguished from an epidemic as more localized or less likely
    to evoke public panic.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 流行病和慢性疾病在整个历史上夺走了无数人的生命，并引发了重大紧急情况，这需要长时间的生存。用两个词“流行病”和“爆发”来描述在一段时间内出现在人群中的疾病[[1](#CR1),
    [2](#CR2)]。实际上，我们可以将流行病定义为在特定地区或特定人群中的某一特定期间内出现的疾病、伤害或其他健康状况的病例超过预期的情况。在大多数情况下，这些病例似乎具有共同的原因[[2](#CR2)]。与流行病不同，爆发更为局部化或不太可能引起公众恐慌。
- en: Past epidemics include pneumonia. The pneumonia is an infection of the lungs,
    most often caused by a virus or bacteria. The infection affects the pulmonary
    alveoli, the tiny balloon-shaped sacs at the end of the bronchioles (Fig. [1](#Fig1)).
    It usually affects only one of the lung’s 5 lobes (3 lobes in the right lung and
    2 in the left), hence the term lobar pneumonia. When pneumonia also reaches the
    bronchial tubes, it is called “Bronchopneumonia”. It is the most important cause
    of death in the world for children younger than 5 years (about 12.8% of annual
    deaths) [[3](#CR3), [4](#CR4)]. It is also a leading cause of morbidity and mortality
    in adults worldwide and in particular in China [[5](#CR5)–[7](#CR7)]. Pneumonia
    is the third leading cause of death in Japan with a higher mortality rate for
    the elderly, particularly among individuals ≥80 years old [[8](#CR8)]. Excluding
    lung cancer, in Portugal, Pneumonia is the huge cause of respiratory death [[9](#CR9)].![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig1_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig1_HTML.png)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 过去的流行病包括肺炎。肺炎是肺部感染，最常由病毒或细菌引起。感染影响肺泡，这些是支气管末端的微小气球状囊泡（图1）。它通常只影响肺的5个叶片（右肺3叶，左肺2叶），因此称为大叶肺炎。当肺炎也影响支气管时，称为“支气管肺炎”。对于5岁以下的儿童，肺炎是世界上最重要的死因之一（约占年度死亡人数的12.8%）[[3](#CR3)，[4](#CR4)]。它也是全球成人，特别是在中国[[5](#CR5)–[7](#CR7)]中的主要发病率和死亡率。对于80岁以上的个体，肺炎是日本的第三大死因，老年人死亡率更高[[8](#CR8)]。在葡萄牙，除了肺癌外，肺炎是呼吸系统死亡的主要原因[[9](#CR9)]。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig1_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig1_HTML.png)
- en: Fig. 1
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图1
- en: Pneumonia diagram
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 肺炎图示
- en: 'Several Coronavirus have passed over the species barrier to cause deadly pneumonia
    in humans since the beginning of the 21st century. To know the pathogenesis of
    these deadly epidemics, the specialists need to inspect the structure of the infections
    and its component. This permits them to explain and provide information for the
    development of effective treatment and possibly vaccines [[10](#CR10)]. Based
    on Table [1](#Tab1), that shows the major pandemics that have occurred over time.
    We will summarise the epidemiology and history of the type of Coronavirus in particular:
    SARS, MERS and Covid-19\. SARS-Cov (Severe Acute Respiratory Syndrome Coronavirus)
    [[11](#CR11), [12](#CR12)] is an acute respiratory illness caused by a coronavirus,
    characterized by fever, coughing, breathing difficulty, and usually pneumonia.
    SARS appeared first time in China exactly in the province of Guangdong in 2002
    and spread to the world through air travel routes. Approximately 8098 people were
    affected, causing 774 deaths [[13](#CR13), [14](#CR14)] with a lethal rate of
    about 10% [[15](#CR15)]. It is suggested to originate from bats [[13](#CR13),
    [16](#CR16)]. SARS symptoms are usually the same as flu symptoms: fever, chills,
    muscle aches, headache and occasionally diarrhea. After about one-week, other
    symptoms appear like fever of 38 °C or higher, dry cough, breath shortness [[15](#CR15)].Table
    1'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 自21世纪初以来，有几种冠状病毒跨越物种屏障，在人类中引起致命的肺炎。为了了解这些致命流行病的发病机制，专家需要检查感染的结构及其组分。这使他们能够解释并提供有关有效治疗以及可能的疫苗开发的信息[[10](#CR10)]。根据表格[1](#Tab1)，显示了历史上发生的主要大流行病。我们将总结特定类型冠状病毒的流行病学和历史：SARS，MERS和Covid-19。
    SARS-Cov（严重急性呼吸综合症冠状病毒）[[11](#CR11)，[12](#CR12)]是由冠状病毒引起的一种急性呼吸道疾病，特征是发热，咳嗽，呼吸困难，通常伴有肺炎。
    SARS首次出现在中国的广东省，准确地说是在2002年，并通过航空旅行路线传播到世界各地。大约有8098人受到影响，造成774人死亡[[13](#CR13)，[14](#CR14)]，致死率约为10%[[15](#CR15)]。据推测，它起源于蝙蝠[[13](#CR13)，[16](#CR16)]。
    SARS症状通常与流感症状相同：发热，寒颤，肌肉疼痛，头痛，偶尔还伴有腹泻。大约一周后，会出现其他症状，如38°C或更高的发热，干咳，呼吸急促[[15](#CR15)]。表1
- en: Major pandemics that have occurred over time
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 历史上发生过的主要大流行病
- en: '| Name | Time period | Type/Pre-human host | Death toll |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 时间段 | 类型/前人类宿主 | 死亡人数 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Spanish Flu | 1918–1919 | H1N1 virus/Pigs | 40–50M |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 西班牙流感 | 1918–1919 | H1N1 病毒/猪 | 4000–5000 万 |'
- en: '| Asian Flu | 1957–1958 | H2N2 virus | 1.1M |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 亚洲流感 | 1957–1958 | H2N2 病毒 | 110 万 |'
- en: '| Hong Kong Flu | 1968–1970 | H3N2 virus | 1M |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 香港流感 | 1968–1970 | H3N2 病毒 | 100 万 |'
- en: '| HIV/AIDS | 1981-Present | Virus/Chimpanzees | 25–35M |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 艾滋病 | 1981年至今 | 病毒/黑猩猩 | 2500–3500 万 |'
- en: '| Swine Flu | 2009–2010 | H1N1 virus/Pigs | 200 000 |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 猪流感 | 2009–2010 | H1N1 病毒/猪 | 20 万 |'
- en: '| SARS | 2002–2003 | Coronavirus/Bats, Civets | 774 |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| SARS | 2002–2003 | 冠状病毒/蝙蝠，狸猫 | 774 |'
- en: '| Ebola | 2014–2016 | Ebolavirus/Wild animals | 11 000 |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 埃博拉 | 2014–2016 | 埃博拉病毒/野生动物 | 11 000 |'
- en: '| MERS | 2015-Present | Coronavirus/Bats, Camels | 850 |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| MERS | 2015至今 | 冠状病毒/蝙蝠，骆驼 | 850 |'
- en: '| Covid-19 | 2019-Present | Coronavirus-Unknown (possibly Batsor pangolins)
    | Coronavirus Cases:89.711.341Deaths: 1,936,554Recovered: 64,572,624January 10,
    2021, 11:36 GMT |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| Covid-19 | 2019至今 | 冠状病毒-未知（可能是蝙蝠或穿山甲） | 冠状病毒病例：89,711,341死亡：1,936,554恢复：64,572,6242021年1月10日，格林尼治标准时间11:36
    |'
- en: 'MERS-Cov (Middle East Respiratory Syndrome Coronavirus) is a viral respiratory
    illness caused by a virus [[17](#CR17)]. It appeared first in the Middle East
    and exactly in Saudi Arabia in 2012 [[18](#CR18), [19](#CR19)]. Other cases were
    identified in Jordan [[20](#CR20)], Qatar [[21](#CR21)] then spread to the world.
    MERS is a zoonotic virus that can be transmitted between animals and humans. Indeed,
    the World Health Organization has confirmed that humans are affected by contact
    with affected dromedary camels [[22](#CR22)–[24](#CR24)]. Studies have shown that
    the way the virus is transmitted from animals to humans is not yet understood,
    and the human-to-human transmission is very limited unless there is close contact
    [[17](#CR17), [25](#CR25), [26](#CR26)]. The different MERS symptoms are as follows:
    Fever, Cough (Dry, Productive), Shortness of breath, Diarrhea, Myalgia, Headache,
    Nausea, Vomiting, Abdominal pain, Chest pain, Sore throat, Hemoptysis [[17](#CR17),
    [21](#CR21), [27](#CR27)–[30](#CR30)].'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: MERS-Cov（中东呼吸综合征冠状病毒）是由一种病毒引起的病毒性呼吸道疾病[[17](#CR17)]。它最初出现在中东，确切地说是在2012年的沙特阿拉伯[[18](#CR18)，[19](#CR19)]。其他病例在约旦[[20](#CR20)]、卡塔尔[[21](#CR21)]被发现，然后传播到世界各地。MERS是一种人畜共患病毒，可以在动物和人类之间传播。事实上，世界卫生组织已经确认人类通过与受感染的单峰骆驼接触而受到影响[[22](#CR22)–[24](#CR24)]。研究表明，病毒从动物传播到人类的方式尚不清楚，除非有密切接触，否则人际传播非常有限[[17](#CR17)，[25](#CR25)，[26](#CR26)]。不同的MERS症状如下：发热，咳嗽（干咳，有痰），呼吸急促，腹泻，肌肉疼痛，头痛，恶心，呕吐，腹痛，胸痛，喉咙痛，咳血[[17](#CR17)，[21](#CR21)，[27](#CR27)–[30](#CR30)]。
- en: 'The world is currently experiencing a dangerous viral epidemic caused by a
    virus that has killed tens of thousands of people. This new virus called Covid-19
    was identified in Wuhan [[5](#CR5), [31](#CR31)–[41](#CR41)], China, in December
    2019\. It belongs to the Corona family of viruses, but it is more deadly and dangerous
    than the rest of the coronaviruses [[42](#CR42), [43](#CR43)]. First cases of
    the disease have been related to a live animal seafood market in Wuhan, denoting
    to a zoonotic origin of the epidemic [[36](#CR36), [41](#CR41), [44](#CR44)–[47](#CR47)].
    The routes of transmission, treatments, and results of Covid-19 continually receiving
    much research attention in the world [[31](#CR31)]. Indeed, researchers have identified
    three main modes of virus transmission: close person-to-person contact, aerosol
    transmission and transmission by touch [[10](#CR10), [42](#CR42), [48](#CR48),
    [49](#CR49)]. The Coronavirus is very dangerous because it can have up to two
    weeks of incubation without symptoms. We can cite the symptoms of Covid-19: high
    fever, dry cough, tiredness, shortness of breath, aches and pains, sore throat
    and very few people will report diarrhea, nausea or a runny nose [[10](#CR10),
    [43](#CR43), [50](#CR50)]. As the number of patients infected by this disease
    increases, it becomes increasingly complex for radiologists to finish the diagnostic
    process in the constrained accessible time [[51](#CR51)]. Medical images analysis
    is one of the most promising research areas; it provides facilities for diagnosis
    and making decisions of a number of diseases such as MERS, COVID-19\. Recently,
    many efforts and more attention are paid to imaging modalities and Deep Learning
    (DL) in pneumonia. Therefore, interpretation of these images requires expertise
    and necessitates several algorithms in order to enhance, accelerate and make an
    accurate diagnosis. Following this context, DL algorithms [[52](#CR52)] have obtained
    better performance in detecting pneumonia and demonstrated high accuracy compared
    with the previous state of the art methods. Motivated by the fastest and accurate
    detection rate of pneumonia using DL, our work will present a comparison of recent
    deep convolutional neural network architectures for automatic binary classification
    of X-Ray and CT images between normal and pneumonia in order to answer the following
    research questions: **(1)**. Are there any DL techniques which distinctly outperforms
    other DL techniques? **(2)**. Can DL used to early screen pneumonia from CT and
    X-Ray images? **(3)**. What is the diagnostic accuracy that DL can be attained
    based on CT and X-Ray images?'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当前，全球正在经历一场危险的病毒流行病，由一种已经导致数万人死亡的病毒引起。这种名为Covid-19的新病毒于2019年12月在中国武汉[[5](#CR5),
    [31](#CR31)–[41](#CR41)]被确认。它属于冠状病毒家族，但比其他冠状病毒更致命和危险[[42](#CR42), [43](#CR43)]。该疾病的首例病例与武汉的一家活动动物海鲜市场有关，表明该流行病的动物源性[[36](#CR36),
    [41](#CR41), [44](#CR44)–[47](#CR47)]。Covid-19的传播途径、治疗方法和结果在全球持续受到大量研究关注[[31](#CR31)]。事实上，研究人员已经确定了病毒传播的三种主要方式：密切人与人接触、气溶胶传播和触摸传播[[10](#CR10),
    [42](#CR42), [48](#CR48), [49](#CR49)]。冠状病毒非常危险，因为它可以在没有症状的情况下潜伏长达两周。我们可以列举出Covid-19的症状：高烧、干咳、疲劳、呼吸急促、肌肉酸痛、喉咙痛，很少有人会报告腹泻、恶心或流鼻涕[[10](#CR10),
    [43](#CR43), [50](#CR50)]。随着患这种疾病的患者数量的增加，放射科医生在受限的时间内完成诊断过程变得越来越复杂[[51](#CR51)]。医学图像分析是最有前途的研究领域之一；它为诊断提供便利，并对许多疾病如MERS、COVID-19做出决策。最近，越来越多的努力和关注都集中在肺炎的影像学和深度学习(DL)上。因此，对这些图像的解释需要专业知识，并需要几种算法以增强、加速和进行准确的诊断。在这种背景下，DL算法[[52](#CR52)]在检测肺炎方面表现出更好的性能，并与先前的最先进方法相比显示出高精度。受到使用DL进行肺炎最快和准确的检测率的推动，我们的工作将对近期的深度卷积神经网络架构进行比较，以实现X-Ray和CT图像在正常和肺炎之间的自动二分类。以回答以下研究问题：**(1)**.
    是否有任何DL技术明显优于其他DL技术？**(2)**. DL能否用于早期筛查CT和X射线图像中的肺炎？**(3)**. 基于CT和X射线图像，DL能达到什么样的诊断准确度？
- en: 'Our paper’s contributions are as follows: **(1)** We design fined tuned versions
    of (VGG16, VGG19, DenseNet201, Inception_ResNet_V2, Inception_V3, Xception, Resnet50,
    and MobileNet_V2) and retraining of a baseline CNN. **(2)** To avoid over-fitting
    in different models, we used weight decay and L2-regularizers. **(3)** The various
    models have been tested on chest X-Ray & CT datasets [[53](#CR53), [54](#CR54)]
    for binary classification and outperform state-of-the-art algorithms.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们论文的贡献如下：**(1)** 我们设计了 (VGG16、VGG19、DenseNet201、Inception_ResNet_V2、Inception_V3、Xception、Resnet50
    和 MobileNet_V2) 的优化版本，并对基线 CNN 进行了重新训练。**(2)** 为了避免不同模型中的过拟合，我们使用了权重衰减和 L2 正则化器。**(3)**
    各种模型已在胸部 X 光和 CT 数据集[[53](#CR53)、[54](#CR54)]上进行了二分类测试，并优于最先进的算法。
- en: The remainder of this paper is organized as follows. Section [2](#Sec2) deals
    with some related work. In Sect. [3](#Sec3), we describe our proposed method.
    Section [4](#Sec6) presents some results obtained and interpreting the results.
    The conclusions are given in the last section.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的剩余部分安排如下。第 [2](#Sec2) 节涉及一些相关工作。在第 [3](#Sec3) 节中，我们描述了我们提出的方法。第 [4](#Sec6)
    节呈现了一些获得的结果并解释这些结果。结论在最后一节中给出。
- en: 2 Related Works
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 'Up to this point, there is no compelling method to prevent the occurrence of
    lung abnormalities such as cancer and pneumonia. Therefore, early detection and
    accurate screening methods the most punctual indications of lung abnormalities
    are the initial steps to limit the risk of suffering. In this section, a brief
    review of some important contributions from the existing literature is presented.
    Pneumonia remains one of the diseases that is increasingly becoming research hotspots
    in recent years. Indeed, Toğaçar et al. [[55](#CR55)] employed Convolutional Neural
    Network (CNN) as feature extractor based on lung X-Ray images and used some existing
    CNN models like AlexNet, VGG16 and VGG19 for classification between normal and
    pneumonia. Using the algorithm of minimum redundancy maximum relevance, the authors
    were able to reduce the number of deep features. A step of classification was
    then done using a decision tree, k-NN, linear discriminant analysis, linear regression,
    and SVM. Liang and Zeng [[56](#CR56)] proposed a new deep learning framework to
    classify child pneumonia image by combining residual thought and dilated convolution.
    Thereby, to overcome the over-fitting and the model’s degradation problems, the
    proposed method used a residual structure. The authors used also dilated convolution
    to resolve the issue of loss of feature space information breed by the increment
    in depth of the model. A deep learning method to identify and localize the pneumonia
    in Chest X-Rays images has been suggested by [[57](#CR57)]. The identification
    model is based on Mask-RCNN that can incorporate global and local features for
    pixel-wise segmentation. The investigation of post-stroke pneumonia prediction
    models using advanced machine learning algorithms, specifically deep learning
    approaches has been presented in [[58](#CR58)]. Indeed, the authors have used
    the classical classification methods (logistic regression, support vector machines,
    and extreme gradient boosting). They also implemented methods based on multiple
    layer perceptron neural networks and recurrent neural networks to use the temporal
    sequence information in electronic health record systems. The obtained results
    showed that the deep learning-based predictive model achieved the optimal performance
    compared to many classical machine learning methods. In [[59](#CR59)], the authors
    proposed an automated detection and localization method of pneumonia on chest
    X-Ray images using machine learning solutions. They presented two CNN (RetinaNet
    and Mask R-CNN). The proposed method was validated on a dataset of 26,684 images
    from Kaggle Pneumonia Detection Challenge. Bhandary et al. [[52](#CR52)] have
    reported a deep learning framework for examining lung pneumonia and cancer. Thus,
    they proposed two different deep learning techniques: the first one was a Modified
    AlexNet (MAN). It was intended to classify chest X-Ray images into normal, and
    pneumonia class using Support Vector Machine and its performance was validated
    with pre-trained deep learning (AlexNet, VGG16, VGG19 and ResNet50). Simultaneously,
    the second method implemented a fusion of handcrafted and learned features in
    the MAN to improve classification accuracy during lung cancer assessment. To assist
    radiologists for better diagnosis, [[60](#CR60)] suggested a method for detection
    consolidations in chest X-Ray images using deep learning. Authors have used a
    deep convolutional neural network pre-trained with ImageNet data to improve the
    models’ accuracy. Then, to enhance the models’ generalisation, they proposed a
    three-step pre-processing approach: removing the confounding variables, histogram
    matching and improving the contrast of colorful image.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，还没有一种令人信服的方法来预防肺部异常，如癌症和肺炎的发生。因此，早期检测和准确的筛查方法是限制患病风险的最早迹象。在这一部分中，将简要回顾一些现有文献中的重要贡献。肺炎仍然是近年来越来越成为研究热点的疾病之一。事实上，Toğaçar等人[[55](#CR55)]根据肺部X光图像采用了卷积神经网络（CNN）作为特征提取器，并使用了一些现有的CNN模型，如AlexNet、VGG16和VGG19，用于正常和肺炎之间的分类。作者们采用了最小冗余最大相关性算法，能够减少深度特征的数量。然后，使用了决策树、k-NN、线性判别分析、线性回归和支持向量机进行分类。Liang和Zeng[[56](#CR56)]提出了一个新的深度学习框架，通过结合残差思想和扩张卷积来对儿童肺炎图像进行分类。因此，为了克服过拟合和模型退化问题，所提出的方法使用了残差结构。作者们还使用了扩张卷积来解决模型深度增加引起的特征空间信息丢失问题。一种用于识别和定位胸部X光图像中肺炎的深度学习方法已经由[[57](#CR57)]提出。识别模型基于Mask-RCNN，可以将全局和局部特征合并进行像素级分割。在[[58](#CR58)]中提出了使用先进的机器学习算法，特别是深度学习方法进行中风后肺炎预测模型的研究。事实上，作者们使用了经典的分类方法（逻辑回归、支持向量机和极限梯度提升）。他们还实施了基于多层感知器神经网络和循环神经网络的方法，以利用电子健康记录系统中的时间序列信息。得到的结果显示，基于深度学习的预测模型与许多经典机器学习方法相比达到了最佳性能。在[[59](#CR59)]中，作者提出了一种使用机器学习解决方案在胸部X光图像上自动检测和定位肺炎的方法。他们提出了两种CNN（RetinaNet和Mask
    R-CNN）。所提出的方法在Kaggle肺炎检测挑战的数据集上进行了验证，共有26,684张图像。Bhandary等人[[52](#CR52)]报告了一个用于检测肺炎和癌症的深度学习框架。因此，他们提出了两种不同的深度学习技术：第一种是修改版的AlexNet（MAN）。它旨在使用支持向量机将胸部X光图像分类为正常和肺炎类，并使用预训练的深度学习（AlexNet、VGG16、VGG19和ResNet50）验证了其性能。同时，第二种方法在MAN中实现了手工制作和学习特征的融合，以提高肺癌评估的分类准确性。为了协助放射科医师进行更好的诊断，[[60](#CR60)]提出了一种利用深度学习检测胸部X光图像中浓缩的方法。作者使用了一个在ImageNet数据上预先训练过的深度卷积神经网络来提高模型的准确性。然后，为了增强模型的泛化能力，他们提出了一个三步预处理方法：消除混淆变量、直方图匹配和增强彩色图像的对比度。
- en: 3 Proposed Contribution
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 提议的贡献
- en: 'Deep learning methods have recently demonstrated huge potential with state-of-the-art
    performance on image processing and computer vision [[61](#CR61)]. These techniques
    have been applied in various medical imaging modalities with high performance
    [[62](#CR62)] in segmentation, detection, and classification. Some DL methods
    incorporate skin cancer detection, breast cancer detection, and classification,
    lung cancer detection [[62](#CR62)], etc. Even though these methods have shown
    huge achievement in medical imaging success, they require a large amount of data,
    which is yet not available in this field of applications. Following the context
    of no availability of medical imaging dataset and motivated by the success of
    deep learning and medical image processing, our work is going to deeply compare
    different fine-tuned [[52](#CR52)] architectures: (VGG16, VGG19, DenseNet201,
    Inception_ResNet_V2, Inception_V3, Xception, Resnet50, and MobileNet_V2). The
    following sections detail the proposed models.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，深度学习方法在图像处理和计算机视觉上展示出巨大潜力，具有最先进的性能[[61](#CR61)]。这些技术已应用于各种医学成像模态，在分割、检测和分类方面表现出高性能[[62](#CR62)]。一些深度学习方法包括皮肤癌检测、乳腺癌检测和分类、肺癌检测[[62](#CR62)]等。尽管这些方法在医学成像领域取得了巨大的成就，但它们需要大量的数据，而这些数据在这个应用领域尚不可用。在医学成像数据集不可用的情况下，受到深度学习和医学图像处理成功的启发，我们的工作将深入比较不同的微调[[52](#CR52)]架构：（VGG16、VGG19、DenseNet201、Inception_ResNet_V2、Inception_V3、Xception、Resnet50
    和 MobileNet_V2）。下面的章节详细介绍了提议的模型。
- en: 3.1 Proposed Baseline CNN Architecture
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 提议的基线 CNN 架构
- en: 'Generally, a CNN model consists of five layers: input layer, convolutional
    layers, pooling layers, full-connection layers, and output layer (Fig. [2](#Fig2)).
    Moreover, it is known that a CNN model can be trained end-to-end to allow the
    feature extraction and selection, and finally classification or prediction. Understanding
    how the network interprets an image and processes it is difficult. However, it
    has been shown that features extracted by the layers of a network work better
    than human-built features [[63](#CR63)].![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig2_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig2_HTML.png)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，CNN 模型由五个层组成：输入层、卷积层、池化层、全连接层和输出层（见图[2](#Fig2)）。此外，众所周知，CNN 模型可以端到端地进行训练，以允许特征提取和选择，最终进行分类或预测。理解网络如何解释图像并处理它是困难的。然而，已经证明，网络的各层提取的特征比人工构建的特征效果更好[[63](#CR63)]。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig2_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig2_HTML.png)
- en: Fig. 2
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图2
- en: The main architecture of our baseline CNN
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们基线 CNN 的主要架构
- en: 'The proposed baseline CNN for our experiment has the following architecture:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实验的提议基线 CNN 的架构如下：
- en: 'Input layer: In our experiment, the inputs are X-Ray and CT images. The parameters
    are defining the image dimension (244 × 244).'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入层：在我们的实验中，输入为 X 射线和 CT 图像。参数定义图像尺寸（244 × 244）。
- en: 'Convolutional layers: a convolution is a linear operation consisting of a set
    of weights with the input. It is designed for two-dimensional input; the multiplication
    is performed between a two-dimensional array of weights (filters) and an array
    of input data. In the proposed architecture we have 3 layers with a filter of
    size 3 × 3 and zero padding.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积层：卷积是由一组与输入相乘的权重组成的线性操作。它设计用于二维输入；在权重（滤波器）的二维数组和输入数据的数组之间进行乘法运算。在提议的架构中，我们有
    3 层卷积层，每层滤波器大小为 3 × 3，零填充。
- en: 'Pooling Layers: represent a technique to down-sample feature maps by summarizing
    the presence of features in patches of the feature map. There are two types of
    pooling methods that are average pooling and max pooling. In the proposed architecture,
    we used max-pooling in order to calculate the maximum value in each patch for
    every feature map. The max-pooling is set to 2 × 2 with a stride of 2.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 池化层：代表一种通过总结特征图中各个区域的特征存在来对特征图进行降采样的技术。池化方法有两种类型，即平均池化和最大池化。在提议的架构中，我们使用了最大池化来计算每个特征图中每个区域的最大值。最大池化设置为
    2 × 2，步长为 2。
- en: 'Rectified Linear Unit (ReLU) layers: we have used 4 ReLU layers for each convolutional
    layer.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矫正线性单元（ReLU）层：我们为每个卷积层使用了 4 个 ReLU 层。
- en: 'Fully connected layers: They treat the input data as a simple vector and produce
    an output as a single vector.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全连接层：它们将输入数据视为简单向量，并产生单一向量输出。
- en: 3.2 Deep Learning Architectures
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 深度学习架构
- en: Deep learning architectures are highly used to diagnose pneumonia since 2016
    [[52](#CR52), [53](#CR53)], the most investigated DL techniques are VGG16, VGG19,
    Inception_V3, DenseNet201, Xception, Resnet50, Inception_ResnetV_2, and MobileNet_V2\.
    We have chosen these 8 techniques due to the accuracies they offer.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 自 2016 年以来，深度学习架构被广泛用于诊断肺炎 [[52](#CR52), [53](#CR53)]，最受关注的深度学习技术包括 VGG16、VGG19、Inception_V3、DenseNet201、Xception、Resnet50、Inception_ResnetV_2
    和 MobileNet_V2。我们选择了这 8 种技术是因为它们提供的准确性。
- en: '**VGG16 and VGG19**'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VGG16 和 VGG19**'
- en: Proposed in 2014 by Simonyan and Zisserman, Visual Geometry Group (VGG) is a
    convolutional neural network architecture that won the ILSVR competition in 2014
    [[64](#CR64)]. The major characteristic of this architecture is that instead of
    having a large number of hyper-parameters, they concentrated on simple 3 × 3 size
    kernels in the convolutional layers and 2 × 2 size in the max-pooling layers.
    In the end, it has 2 Fully Connected (FC) layers trailed by a softmax for output.
    The most familiar VGG models are VGG16 and VGG19, which include 16 and 19 layers,
    respectively. The difference between VGG16 and VGG19 is that VGG19 has one more
    layer in each of the three convolutional blocks [[65](#CR65)].
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Visual Geometry Group (VGG) 由 Simonyan 和 Zisserman 在 2014 年提出，是一种卷积神经网络架构，赢得了
    2014 年 ILSVR 竞赛 [[64](#CR64)]。该架构的主要特点是，与其拥有大量的超参数不同，它们专注于卷积层中简单的 3 × 3 大小的核心和最大池化层中的
    2 × 2 大小。最后，它有 2 个全连接 (FC) 层，尾随一个 softmax 输出。最常见的 VGG 模型是 VGG16 和 VGG19，分别包含 16
    层和 19 层。VGG16 和 VGG19 的区别在于 VGG19 在三个卷积块中每个都多了一层 [[65](#CR65)]。
- en: '**Inception_V3**'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Inception_V3**'
- en: Inception models are a type of Convolutional Neural Networks developed by Szegedy
    in 2014 [[66](#CR66)]. The inception models differ from the ordinary CNN in the
    structure where the inception models are inception blocks that mean lapping the
    same input tensor with multiple filters and concatenating their results. Inception_V3
    is a new version of the inception model presented for the first time in 2015 [[67](#CR67)].
    It is an improved version of inception_V1 and inception_V2 with more parameters.
    Indeed, it has a block of parallel convolutional layers with 3 different sizes
    of filters (1 × 1, 3 × 3, 5 × 5).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Inception 模型是由 Szegedy 在 2014 年开发的一种卷积神经网络 [[66](#CR66)]。Inception 模型与普通 CNN
    在结构上不同，其中 Inception 模型是 Inception 块，意味着将相同的输入张量与多个滤波器进行重叠并将它们的结果串联起来。Inception_V3
    是 Inception 模型的新版本，于 2015 年首次提出 [[67](#CR67)]。它是 inception_V1 和 inception_V2 的改进版本，参数更多。事实上，它具有一个并行卷积层块，其中包含
    3 种不同尺寸的滤波器 (1 × 1、3 × 3、5 × 5)。
- en: Additionally, 3 × 3 max pooling is also performed. The outputs are concatenated
    and sent to the next inception module. This model accepts an input image size
    of 299 × 299 pixels.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还进行了 3 × 3 最大池化。输出被串联并发送到下一个 inception 模块。此模型接受 299 × 299 像素的输入图像大小。
- en: '**Resnet50**'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Resnet50**'
- en: Resnet50 is a deep residual network developed by [[68](#CR68)] and is a subclass
    of convolutional neural networks used for image classification. It is the winner
    of ILSVRC 2015\. The principal innovation is the introducing of the new architecture
    network-in-network using residual layers. The Resnet50 consists of five steps,
    each with a convolution and identity block, each convolution block and each identity
    block have 3 convolution layers. Resnet50 has 50 residual networks and accepts
    images size of 224 × 224 pixels.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Resnet50 是由 [[68](#CR68)] 开发的一种深度残差网络，是用于图像分类的卷积神经网络的子类。它是 ILSVRC 2015 的获胜者。其主要创新是引入了新的架构网络内部网络，使用残差层。Resnet50
    由五个步骤组成，每个步骤都有一个卷积块和一个标识块，每个卷积块和每个标识块都有 3 个卷积层。Resnet50 有 50 个残差网络，并接受大小为 224 × 224
    像素的图像。
- en: '**Inception_ResNet_V2**'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Inception_ResNet_V2**'
- en: Inception_ResNet_V2 is a convolutional neural network trained on more than a
    million images from the ImageNet database [[69](#CR69)]. It is a hybrid technique
    combining the inception structure and the residual connection. The model accepts
    images of 299 × 299 image, and its output is a list of estimated class probabilities.
    The advantages of Inception_Resnet_V2 are converting inception modules to Residual
    Inception blocks, adding more Inception modules and adding a new type of Inception
    module (Inception-A) after the Stem module.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Inception_ResNet_V2 是在 ImageNet 数据库中训练的一种卷积神经网络 [[69](#CR69)]。它是一种混合技术，结合了 Inception
    结构和残差连接。该模型接受大小为 299 × 299 的图像，并输出估计的类概率列表。Inception_Resnet_V2 的优点是将 Inception
    模块转换为残差 Inception 块，添加更多 Inception 模块并在 Stem 模块之后添加一种新类型的 Inception 模块 (Inception-A)。
- en: '**DenseNet201**'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DenseNet201**'
- en: Dense Convolutional Network (DenseNet201) is a convolutional neural network
    with 201 layers deep and accepts an input image size of 224 × 224 [[70](#CR70)].
    DenseNet201 is an improvement of ResNet that includes dense connections among
    layers. It connects each layer to every other layer in a feed-forward fashion.
    Unlike traditional convolutional networks with L layers that have L connections,
    DensNet201 has L(L + 1)/2 direct connections. Indeed, compared to traditional
    networks, DenseNet can improve the performance by increasing the computation requirement,
    reducing the number of parameters, encouraging feature reuse and reinforcing feature
    propagation.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Dense Convolutional Network（DenseNet201）是一个深度为201层的卷积神经网络，接受大小为224 × 224的输入图像[[70](#CR70)]。DenseNet201是对ResNet的改进，其中包括层之间的密集连接。它以前馈方式将每一层连接到每一层。与传统的具有L层的卷积网络具有L个连接不同，DenseNet201具有L（L + 1）/2个直接连接。事实上，与传统网络相比，DenseNet可以通过增加计算需求、减少参数数量、鼓励特征重用和加强特征传播来提高性能。
- en: '**MobileNet**_**V2**'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MobileNet_V2**'
- en: 'MobileNet_V2 [[71](#CR71)] is a convolutional neural network being an improved
    version of MobileNet_V1\. It is made of only 54 layers and has an input image
    size of 224 × 224\. Its main characteristic is instead of performing a 2D convolution
    with a single kernel, instead of performing a 2D convolution with a single kernel.
    It uses depthwise separable convolutions that consist of applying two 1D convolutions
    with two kernels. That means, less memory and parameters are required for training
    leading to a small and efficient model. We can distinguish two types of blocks:
    the first one is a residual block with a stride of 1, the second one is block
    with a stride of 2 for downsizing. For each block, there are three layers: the
    first layer is 1 × 1 convolution with ReLU6, the second layer is the depthwise
    convolution, and the third layer is another 1 × 1 convolution but without any
    non-linearity.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: MobileNet_V2 [[71](#CR71)]是MobileNet_V1的改进版本的卷积神经网络。它仅由54层组成，输入图像尺寸为224 × 224。它的主要特点是不是使用单个内核执行2D卷积，而是使用深度可分离卷积，该卷积由应用两个内核的两个1D卷积组成。这意味着，训练时需要更少的内存和参数，从而导致一个小而高效的模型。我们可以区分两种类型的块：第一种是步幅为1的残差块，第二种是步幅为2的用于降维的块。对于每个块，有三个层：第一层是带有ReLU6的1 × 1卷积，第二层是深度卷积，第三层是另一个1 × 1卷积，但没有任何非线性。
- en: '**Xception**'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Xception**'
- en: Xception, presented by Chollet [[72](#CR72)], is a convolutional neural network
    that is 71 layers deep. It is an improved version of Inception architecture and
    involves depthwise separable convolutions. More precisely, Xception replaces the
    standard Inception modules with depthwise separable convolutions. It showed good
    results compared to VGG16, Resnet and Inception in classical classification problems.
    Xception has an input image size of 299 × 299.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Xception，由Chollet [[72](#CR72)] 提出，是一个深度为71层的卷积神经网络。它是Inception架构的改进版本，涉及深度可分离卷积。更准确地说，Xception用深度可分离卷积替换了标准的Inception模块。它在经典分类问题上与VGG16、Resnet和Inception相比表现良好。Xception的输入图像尺寸为299 × 299。
- en: 4 Experimental Results and Analysis
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验结果和分析
- en: 'We compared all mentioned above models once they have been fine-tuned for the
    automatic binary classification on two new publicly available image datasets (chest
    X-Ray & CT dataset [[53](#CR53), [54](#CR54)]). As it can be observed in Fig. [3](#Fig3),
    which shows the diagram of the main steps necessary to compare the different models:
    data acquisition, data pre-processing, training and classification. The following
    sections give out in detail the steps of this comparison.![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig3_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig3_HTML.png)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们比较了所有上述模型，一旦它们被微调用于两个新的公开可用的图像数据集（胸部X射线和CT数据集[[53](#CR53), [54](#CR54)]）的自动二进制分类。如图 [3](#Fig3) 所示，该图显示了比较不同模型所需的主要步骤的图表：数据获取、数据预处理、训练和分类。接下来的章节详细介绍了此比较的步骤。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig3_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig3_HTML.png)
- en: Fig. 3
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图3
- en: Block diagram of the process of X-Ray and CT classification
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: X射线和CT分类过程的块图
- en: 4.1 Dataset
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 数据集
- en: This present work introduces two publicly available image datasets which contain
    X-Ray and computed tomography images. The first dataset [[53](#CR53)] is a chest
    X-Ray & CT dataset composed of 5856 images with two categories (4273 pneumonia
    and 1583 normal) while the second one is named Covid Chest X-ray Dataset [[54](#CR54)]
    containing 231 Covid-19 Chest X-Ray images. We joined the second dataset to the
    first one to form a joint dataset which finally composed of 6087 images (jpeg
    format) and has two classes (4504 pneumonia and 1583 normal). The pneumonia class
    contains images of bacterial pneumonia, viral pneumonia and Covid19\. As can be
    seen from Fig. [4](#Fig4) that illustrates an example of chest X-Rays in patients
    with pneumonia, the normal chest X-Ray (Fig. [4](#Fig4)(a)) shows clear lungs
    with no zones of abnormal opacification. Moreover, Fig. [4](#Fig4)(b) shows a
    focal lobar consolidation (white arrows). Also, Fig. [4](#Fig4)(c) shows a more
    diffuse “interstitial” pattern in both lungs [[53](#CR53)] while Fig. [4](#Fig4)(d)
    presents an image of a patient infected by covid19 [[54](#CR54)].![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig4_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig4_HTML.png)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究介绍了两个公开可用的图像数据集，其中包含X光和计算机断层扫描图像。第一个数据集[[53](#CR53)] 是一个由5856张图像组成的胸部X光和CT数据集，包含两个类别（4273例肺炎和1583例正常），而第二个数据集名为Covid胸部X光数据集[[54](#CR54)]，包含231张Covid-19胸部X光图像。我们将第二个数据集合并到第一个数据集中，形成一个联合数据集，最终由6087张图像（jpeg格式）组成，有两个类别（4504例肺炎和1583例正常）。肺炎类包含细菌性肺炎、病毒性肺炎和Covid19的图像。从图 [4](#Fig4)
    可以看出，图示了肺炎患者胸部X光的示例，正常的胸部X光（图 [4](#Fig4)(a)）显示清晰的肺部，没有异常浸润区域。此外，图 [4](#Fig4)(b)
    显示了局部大叶实变（白色箭头）。此外，图 [4](#Fig4)(c) 显示了两肺的更弥漫的“间质”模式[[53](#CR53)]，而图 [4](#Fig4)(d)
    则展示了一位感染Covid19的患者的图像[[54](#CR54)]。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig4_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig4_HTML.png)
- en: Fig. 4
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4
- en: Examples of Chest X-Rays in patients with pneumonia
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 肺炎患者胸部X光的示例
- en: 4.2 Data Pre-processing and Splitting
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 数据预处理和分割
- en: The next stage is to pre-process input images using different pre-processing
    techniques. The motivation behind image pre-processing is to improve each input
    image’s quality of visual information (to eliminate or decrease noise present
    in the original input image, enhance the quality of image through increased contrast,
    and delete the low or high freqes etc.). In this study, we used intensity normalization
    [[73](#CR73)] and Contrast Limited Adaptive Histogram Equalization (CLAHE) [[74](#CR74),
    [75](#CR75)]. Intensity normalization is a straightforward pre-processing step
    in image processing applications [[73](#CR73)]. In our contribution, we normalize
    the input image (Fig. [5](#Fig5)(b)) to the standard normal distribution using
    min-max normalization (Eq. [1](#Equ1)).![$$X_{norm \, } = \frac{{x - x_{\min }
    }}{{x_{\max } - x_{\min } }}$$](../images/507793_1_En_14_Chapter/507793_1_En_14_Chapter_TeX_Equ1.png)(1)![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig5_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig5_HTML.png)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个阶段是使用不同的预处理技术对输入图像进行预处理。图像预处理背后的动机是改善每个输入图像的视觉信息质量（消除或减少原始输入图像中存在的噪声，通过增加对比度增强图像质量，删除低频或高频等）。在本研究中，我们使用了强度归一化[[73](#CR73)]
    和限制对比度自适应直方图均衡化（CLAHE）[[74](#CR74), [75](#CR75)]。强度归一化是图像处理应用中的一种直接预处理步骤[[73](#CR73)]。在我们的贡献中，我们使用最小-最大归一化将输入图像（图 [5](#Fig5)(b)）归一化到标准正态分布（式 [1](#Equ1)）。![$$X_{norm
    \, } = \frac{{x - x_{\min } }}{{x_{\max } - x_{\min } }}$$](../images/507793_1_En_14_Chapter/507793_1_En_14_Chapter_TeX_Equ1.png)(1)![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig5_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig5_HTML.png)
- en: Fig. 5
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5
- en: X-ray image pre-processing
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: X光图像预处理
- en: Furthermore, before feeding input image into the proposed models, CLAHE is necessary
    to improve the contrast in images [[74](#CR74), [75](#CR75)]. Figure [5](#Fig5)
    illustrates an example of using these techniques.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在将输入图像输入所提出的模型之前，CLAHE 是必要的，以改善图像的对比度[[74](#CR74), [75](#CR75)]。图 [5](#Fig5)
    说明了使用这些技术的示例。
- en: For data splitting, we used in this experiment 60% of the images for training
    and 40% of the images for testing. We ensure that the images chosen for testing
    are not used during training to perform the binary classification task successfully.
    Moreover, we observed that the dataset is imbalanced. Thereby 75% of the images
    represent the pneumonia class. To overcome this issue, we resampled the dataset
    by using data augmentation.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据分割，我们在这个实验中使用了60%的图像进行训练，40%的图像进行测试。我们确保所选用于测试的图像在训练过程中没有被使用，以成功执行二元分类任务。此外，我们观察到数据集存在不平衡的情况。因此，75%的图像代表肺炎类别。为了解决这个问题，我们使用数据增强重新取样了数据集。
- en: 4.3 Data Augmentation
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 数据增强
- en: Data augmentation is used for the training process after dataset pre-processing
    and splitting and aims to avoid the risk of over-fitting. Moreover, the strategies
    we used include geometric transforms such as rescaling, rotations, shifts, shears,
    zooms and flips (Table [2](#Tab2)). We generated from each single input image
    2 new images with different augmentation techniques. Therefore, the total number
    of images in the normal class was increased by 2 times.Table 2
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强在数据集预处理和分割之后用于训练过程，旨在避免过拟合的风险。此外，我们使用的策略包括几何变换，如重新缩放、旋转、平移、剪切、缩放和翻转（表[2](#Tab2)）。我们从每个单一输入图像生成2个具有不同增强技术的新图像。因此，正常类别中的图像总数增加了2倍。表2
- en: Data augmentation used
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 使用的数据增强
- en: '| Argument | Parameter value | Description |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 参数值 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Rescale | 1/255.0 | Scale images from integers 0–255 to floats 0–1 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 重新缩放 | 1/255.0 | 将图像从整数0–255缩放为浮点数0–1 |'
- en: '| Rotation range | 90 | Degree range of the random rotations |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 旋转范围 | 90 | 随机旋转的角度范围 |'
- en: '| Horizontal and Vertical shift range | 0.2 | The parameter value of horizontal
    and vertical shifts (20%) is a fraction of the given dimension |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 水平和垂直移位范围 | 0.2 | 水平和垂直移位（20%）的参数值是给定维度的一部分 |'
- en: '| Shear range | 0.2 | Controls the angle in counterclockwise direction as radians
    in which our image will allow to be sheared |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 剪切范围 | 0.2 | 控制图像允许被剪切的逆时针方向的角度，以弧度表示 |'
- en: '| Zoom range | 0.2 | Allows the image to be “zoomed out” or “zoomed in” |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 缩放范围 | 0.2 | 允许图像“缩小”或“放大” |'
- en: '| Horizontal flip | True | Controls when a given input is allowed to be flipped
    horizontally during the training process |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 水平翻转 | True | 控制在训练过程中何时允许给定输入水平翻转 |'
- en: '| Fill mode | Nearest | This is the default option where the closest pixel
    value is chosen and repeated for all the empty values |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 填充模式 | 最近 | 这是默认选项，选择最接近的像素值并重复所有空值 |'
- en: 4.4 Training and Classification Dataset
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 训练和分类数据集
- en: After data pre-processing, splitting and data augmentation techniques, our training
    dataset size is increased and ready to be passed to the feature extraction step
    with the proposed models to extract the appropriate and pertinent features. The
    extracted features from each proposed model are flattened together to create the
    vectorized feature maps. The generated feature vector is passed to a multilayer
    perceptron to classify each image into corresponding classes. Finally, the performance
    of the proposed method is evaluated on test images using the trained model. We
    repeated each experiment three times and reported their average results.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据预处理、分割和数据增强技术之后，我们的训练数据集大小增加了，并且准备好传递给提议模型的特征提取步骤，以提取适当和相关的特征。从每个提议模型中提取的特征被展平在一起以创建向量化的特征映射。生成的特征向量被传递给多层感知器，以将每个图像分类到相应的类别中。最后，使用训练模型对测试图像评估提出的方法的性能。我们重复每个实验三次，并报告其平均结果。
- en: 4.5 Experimental Setup
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 实验设置
- en: 'Towards an automatic binary classification based on a publicly available image
    dataset (Chest X-Ray dataset [[53](#CR53), [54](#CR54)]), our experimentations
    were carried out based on following experimental parameters: All the images of
    the dataset were resized to 224 × 224 pixels except those of Inception_V3, Inception_Resnet_V2
    and Xception models that were resized to 299 × 299\. To train the models, we set
    the batch size to 32 with the number of epochs set to 300\. The training and testing
    samples are initiated to 159 and 109, respectively. Adam with β1 = 0.9, β2 = 0.999
    is used for optimization, and learning rate initiated to 0.00001 and decreased
    it to 0.000001\. Moreover, we used weight decay and L2-regularizers to reduce
    over-fitting for the different models. A fully connected layer was trained with
    the ReLU, followed by a dropout layer with a probability of 0.5\. We updated the
    last dense layer in all models to output two classes corresponding to normal and
    pneumonia instead of 1000 classes as was utilized for ImageNet. The implementation
    of the proposed models is done using a computer with Processor: Intel (R) core
    (TM) i7-7700 CPU @ 3.60 GHz and 8 GB in RAM running on a Microsoft Windows 10
    Professional (64-bit). For implementation, Keras/Tensorflow is used as deep learning
    backend. Our training and testing steps run using NVIDIA Tesla P40 with 24 GB
    RAM.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 针对基于公开可用图像数据集（胸部 X 光数据集[[53](#CR53), [54](#CR54)]）的自动二元分类，我们的实验基于以下实验参数进行：数据集中的所有图像都被调整大小为
    224 × 224 像素，除了 Inception_V3、Inception_Resnet_V2 和 Xception 模型的图像，它们被调整大小为 299
    × 299。为了训练模型，我们将批量大小设置为 32，将迭代次数设置为 300。训练样本和测试样本的初始化分别为 159 和 109。Adam 优化器的参数为
    β1 = 0.9，β2 = 0.999，并将学习率初始化为 0.00001，然后降低到 0.000001。此外，我们使用权重衰减和 L2 正则化器来减少不同模型的过拟合。一个全连接层使用
    ReLU 进行训练，接着是一个丢失率为 0.5 的丢失层。我们更新了所有模型中的最后一个密集层，将其输出两个类别，分别对应正常和肺炎，而不是像 ImageNet
    那样利用 1000 个类别。所提议模型的实现是使用配置为 Intel (R) Core (TM) i7-7700 CPU @ 3.60 GHz 和 8 GB
    RAM 的计算机运行 Microsoft Windows 10 专业版（64 位）。对于实现，我们使用 Keras/Tensorflow 作为深度学习后端。我们的训练和测试步骤是在配备
    24 GB RAM 的 NVIDIA Tesla P40 上运行的。
- en: 4.6 Evaluation Criteria
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6 评估标准
- en: 'After extracting the appropriate feature, the last step is to classify the
    attained data and assign it to a specific class [[76](#CR76)]. Among the different
    classification performance properties, and since the dataset is now balanced,
    our study uses the following benchmark metrics: accuracy (ACC), sensitivity (SEN),
    specificity (SPE), precision (PRE) and F1 score (F1) [[52](#CR52), [76](#CR76)].
    These metrics are defined as follows:![$$\begin{aligned} ACC &amp; = \frac{TP
    + TN}{{TP + TN + FP + FN}} \times 100\quad \quad PRE = \frac{TP}{{TP + FP}} \times
    100 \\ &amp; SPE = \frac{TN}{{TN + FP}} \times 100\quad \quad SEN = \frac{TP}{{TP
    + FN}} \times 100 \\ &amp; \quad \quad \quad \;F1 = 2 \times \frac{ \, Re call
    \, \times Pr e cision \, }{{ \, Re call \, + \, Pr e cision \, }} \times 100 \\
    \end{aligned}$$](../images/507793_1_En_14_Chapter/507793_1_En_14_Chapter_TeX_Equ2.png)(2)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在提取适当特征之后，最后一步是对获得的数据进行分类并将其分配到特定类别[[76](#CR76)]。在不同的分类性能属性中，由于数据集现在是平衡的，我们的研究使用以下基准度量标准：准确率（ACC）、灵敏度（SEN）、特异性（SPE）、精确度（PRE）和
    F1 分数（F1）[[52](#CR52), [76](#CR76)]。这些度量标准的定义如下:![$$\begin{aligned} ACC &amp;
    = \frac{TP + TN}{{TP + TN + FP + FN}} \times 100\quad \quad PRE = \frac{TP}{{TP
    + FP}} \times 100 \\ &amp; SPE = \frac{TN}{{TN + FP}} \times 100\quad \quad SEN
    = \frac{TP}{{TP + FN}} \times 100 \\ &amp; \quad \quad \quad \;F1 = 2 \times \frac{
    \, Re call \, \times Pr e cision \, }{{ \, Re call \, + \, Pr e cision \, }} \times
    100 \\ \end{aligned}$$](../images/507793_1_En_14_Chapter/507793_1_En_14_Chapter_TeX_Equ2.png)(2)
- en: 'where: TP stands for: True Positive. FP: False Positive.TN: True Negative,
    and FN: False Negative.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '其中：TP 代表：真阳性。FP: 假阳性。TN：真阴性，FN：假阴性。'
- en: 4.7 Results and Discussion
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.7 结果与讨论
- en: This section presents the results for the binary classification for the chest
    X-Ray & CT images [[53](#CR53), [54](#CR54)] with the following architectures
    (Baseline CNN, Fine-tuning the top layers of VGG16, VGG19, Inception_V3, Xception,
    Resnet50, Inception_Resnet_V2, DenseNet201, and MobileNet_V2). Also, to check
    each proposed model’s performance and robustness, several experiments are conducted
    on chest X-Ray dataset [[53](#CR53), [54](#CR54)]. The results are presented separately
    using training and testing curves of accuracy and loss and confusion matrix.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了对胸部 X 光和 CT 图像进行二元分类的结果[[53](#CR53), [54](#CR54)]，使用了以下架构（基线 CNN、微调 VGG16
    的顶层、VGG19、Inception_V3、Xception、Resnet50、Inception_Resnet_V2、DenseNet201 和 MobileNet_V2）。此外，为了检查每个提议模型的性能和稳健性，对胸部
    X 光数据集[[53](#CR53), [54](#CR54)] 进行了几个实验。结果分别使用训练和测试曲线的准确率和损失以及混淆矩阵进行呈现。
- en: 4.7.1 Classification Results of the Different Architectures
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.7.1 不同架构的分类结果
- en: 'This subsection presents and discusses the classification results of chest
    X-Ray & CT images [[53](#CR53), [54](#CR54)]. Before discussing these results,
    let us define some parameters related to the deep learning process: the training
    curve is calculated from the training dataset that provides an idea of how well
    the model is learning. In contrast, the testing curve is calculated from a hold-out
    testing dataset that explains how well the model is generalizing. Simultaneously,
    the training and testing loss are defined as a summation of the errors made for
    each example in testing or training sets. Note that in contrast to accuracy, loss
    is not a percentage. Furthermore, the confusion matrix shows a detailed representation
    of images after classification [[52](#CR52)]. To summarize, a model that generalizes
    well is a model that is neither over-fit nor under-fit.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 本小节介绍并讨论了胸部 X 光和 CT 图像的分类结果[[53](#CR53), [54](#CR54)]。在讨论这些结果之前，让我们定义一些与深度学习过程相关的参数：训练曲线是从提供模型学习情况的训练数据集中计算的，它能够提供模型学习的程度。相反，测试曲线是从一个独立的测试数据集中计算的，用以说明模型的泛化程度。同时，训练和测试损失被定义为在测试或训练集中每个样本中所产生的错误的总和。需要注意的是，与准确率不同，损失不是一个百分比。此外，混淆矩阵显示了分类后图像的详细表示[[52](#CR52)]。总之，一个泛化良好的模型既不过度拟合也不欠拟合。
- en: '**Baseline CNN**'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基线 CNN**'
- en: According to the Fig. [6](#Fig6), it is observed that the accuracy curve of
    training data is rapidly increasing from epoch 0 to epoch 6 where the accuracy
    is equal to 83.17%, after that, it begins to increase slightly until epoch 300
    where the accuracy is equal to 86.28%. The same applies to the accuracy curve
    of testing data with an accuracy of 84.84 for epoch 300\. Concerning the loss
    curve of training data, it is rapidly decreasing from epoch 0 to epoch 6 where
    the loss is 43.77\. At that point, it begins to decrease slightly until the end
    of training (epoch 300) where the loss is equivalent to 36.56\. Same for loss
    curve of testing data with a loss of 37.85 for epoch 300\. From the confusion
    matrix, it is noted that the first images (Normal class), the model recognizes
    1634 images correctly, but 95 were marked as pneumonia. Likewise, for the second
    image’s class (Pneumonia), the model was capable to identify 1277 images correctly,
    unlike 252 images were marked as Normal.![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig6_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig6_HTML.png)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 根据图 [6](#Fig6)，观察到训练数据的准确率曲线从第 0 个时期到第 6 个时期迅速增加，其中准确率为 83.17%，之后开始稍微增加，直到第
    300 个时期，准确率为 86.28%。相同的情况也适用于测试数据的准确率曲线，第 300 个时期的准确率为 84.84。至于训练数据的损失曲线，它从第 0
    个时期到第 6 个时期迅速减小，损失为 43.77。在那一点，它开始稍微减少，直到训练结束（第 300 个时期），损失等于 36.56。对于测试数据的损失曲线也是一样的，在第
    300 个时期的损失为 37.85。从混淆矩阵中可以看出，在第一类图像（正常类）中，模型正确识别了 1634 张图像，但有 95 张被标记为肺炎。同样地，对于第二类图像（肺炎），模型成功识别了
    1277 张图像，但有 252 张被标记为正常。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig6_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig6_HTML.png)
- en: Fig. 6
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6
- en: Accuracy and loss curve and confusion matrix of Baseline CNN
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 基线 CNN 的准确率和损失曲线以及混淆矩阵
- en: '**VGG16**'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VGG16**'
- en: Figure [7](#Fig7) presents the accuracy, loss curve and confusion matrix of
    VGG16\. Indeed, from the epoch 0 to epoch 11, the accuracy curve of training data
    is quickly increasing where it is equal to 81.05%, and then it converges to a
    value of 87.51%. The same applies to the accuracy curve of testing data with an
    accuracy of 86.32% for epoch 300\. A rapid decreasing of loss curve can be noted
    for training data from epoch 0 to epoch 25, where the loss is equivalent to 1.43\.
    At this epoch, a kind of stability can be observed up to the value of 1.15\. The
    same goes for the loss curve of testing data where the loss is equal to 2.21 for
    epoch 300\. The model can predict 1517 images correctly in the normal class from
    the confusion matrix, yet 212 were named pneumonia. For the Pneumonia class, the
    model was capable to identify 1466 images correctly, and 263 images were marked
    as Normal.![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig7_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig7_HTML.png)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [7](#Fig7) 展示了VGG16的准确率、损失曲线和混淆矩阵。确实，从第0轮到第11轮，训练数据的准确率曲线迅速增加，达到81.05%，然后收敛到87.51%。测试数据的准确率曲线也是如此，在第300轮时为86.32%。对于训练数据的损失曲线，从第0轮到第25轮，损失迅速减小，其中损失等于1.43。在这一轮，可以观察到一种稳定性，直到值为1.15。测试数据的损失曲线也是如此，在第300轮时损失为2.21。从混淆矩阵中可以看出，模型可以正确预测正常类中的1517张图像，但有212张被标记为肺炎。对于肺炎类，模型能够正确识别1466张图像，263张被标记为正常。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig7_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig7_HTML.png)
- en: Fig. 7
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7
- en: Accuracy and loss curve and confusion matrix of VGG16
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: VGG16的准确率和损失曲线以及混淆矩阵
- en: '**VGG19**'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VGG19**'
- en: 'As it is shown in Fig. [8](#Fig8), the curve of training data (testing data)
    can be divided into two intervals: the first one starts from epoch 0 to epoch
    13 (from epoch 0 to epoch 10). We can observe a quick increase in accuracy where
    the accuracy is equal to 81.01% (83.05%). In the second interval, the accuracy
    becomes stable and converges toward 87.42% (86.89%). For the loss curve of training
    and testing data, we see a good fit. Indeed, from epoch 0 to 18, the loss is rapidly
    decreasing, where it is equal to 1.27\. Afterwards, it begins to increase slightly
    until the end of the training, equivalent to 1.31\. As observed (see confusion
    matrix) in the normal class, the VGG19 model had the option to predict 1390 images
    correctly and 339 images as pneumonia. The model also was capable to classify
    1582 images as pneumonia and 147 images as Normal for the Pneumonia class.![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig8_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig8_HTML.png)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [8](#Fig8) 所示，训练数据（测试数据）的曲线可以分为两个区间：第一个区间从第0轮到第13轮（从第0轮到第10轮）。我们可以观察到准确率快速增加，其中准确率等于81.01%（83.05%）。在第二个区间，准确率变得稳定，并向87.42%（86.89%）收敛。对于训练和测试数据的损失曲线，我们看到拟合效果良好。确实，从第0轮到第18轮，损失迅速下降，其中等于1.27。然后，它开始略微增加，直到训练结束，相当于1.31。正如在混淆矩阵中观察到的那样，VGG19模型在正常类中有能力正确预测1390张图像和339张肺炎图像。该模型还能够将1582张图像分类为肺炎和147张图像分类为正常。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig8_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig8_HTML.png)
- en: Fig. 8
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8
- en: Accuracy and loss curve and confusion matrix of VGG19
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: VGG19的准确率和损失曲线以及混淆矩阵
- en: '**Inception_V3**'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Inception_V3**'
- en: Figure [9](#Fig9) shows the accuracy, loss curve and confusion matrix of Inception_V3\.
    Thereby, for the training and testing accuracy and from epoch 0 to epoch 7, we
    can see that the accuracy is increasing until the value of 91.03%. After epoch
    7, the accuracy gets started to be stable where it is equal to 97.01% and 95.94%
    for training and testing data respectively. A good fit can be noticed for the
    loss curve of training data in either the quick increasing interval from epoch
    0 to epoch 32 where the loss is 3.98 or in the other interval where the decreasing
    is slow and converges to 1.76\. As shown in the confusion matrix, for the Pneumonia
    class, the model was able to identify 1650 images as pneumonia and 79 images as
    Normal. Concerning class Normal, Inception_V3 model can predict 1621 images as
    Normal and 108 as pneumonia.![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig9_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig9_HTML.png)
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图[9](#Fig9)显示了Inception_V3的准确度、损失曲线和混淆矩阵。因此，对于训练和测试准确度，从第0个时期到第7个时期，我们可以看到准确度在增加，直到达到91.03%的值。第7个时期之后，准确度开始稳定，分别为训练数据和测试数据的97.01%和95.94%。可以注意到对于训练数据的损失曲线拟合良好，无论是从第0个时期到第32个时期的快速增加，损失为3.98，还是在减小缓慢并趋于1.76的另一个区间。如混淆矩阵所示，对于肺炎类别，该模型能够将1650张图像识别为肺炎，79张图像识别为正常。关于正常类别，Inception_V3模型可以预测1621张图像为正常，108张图像为肺炎。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig9_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig9_HTML.png)
- en: Fig. 9
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9
- en: Accuracy and loss curve and confusion matrix of Fine-tuned Inception_V3
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Inception_V3的精调准确度和损失曲线以及混淆矩阵
- en: '**ResNet50**'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ResNet50**'
- en: Figure [10](#Fig10) illustrates the results obtained by Resnet50\. In fact,
    from epoch 0 to 24, the accuracy values are increasing expeditiously either for
    training or testing data where the maximum value is 97.36%. After that, the values
    start to be stables (99.23% and 96.23% for training and testing data respectively).
    We observe a good fit for the loss curve of training and testing data, indeed,
    from epoch 0 to 21, the loss is briskly decreasing where it is equal to 6.89,
    afterwards, it gets started to be stable until the epoch 300 where it is equal
    to 0.85\. The confusion matrix indicates that, for images of Normal class, 1703
    images were predicted correctly as Normal and 26 were marked as pneumonia. Same
    for the second images of Pneumonia class, the model had the option to identify
    1638 images correctly, unlike 91 images were labeled as Normal.![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig10_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig10_HTML.png)
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图[10](#Fig10)展示了Resnet50获得的结果。事实上，从第0个时期到第24个时期，无论是训练数据还是测试数据的准确度值都在迅速增加，其中最大值为97.36%。之后，数值开始稳定（分别为训练数据和测试数据的99.23%和96.23%）。我们观察到训练数据和测试数据的损失曲线拟合良好，实际上，从第0个时期到第21个时期，损失迅速减少，其中等于6.89，之后开始稳定，直到第300个时期，其值为0.85。混淆矩阵表明，对于正常类别的图像，有1703张图像被正确预测为正常，26张标记为肺炎。对于第二类肺炎的图像，模型有1638张图像被正确识别，而91张被标记为正常。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig10_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig10_HTML.png)
- en: Fig. 10
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10
- en: Accuracy and loss curve and confusion matrix of Fine-tuned ResNet50
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ResNet50的精调准确度和损失曲线以及混淆矩阵
- en: '**Inception_ResNet_V2**'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Inception_ResNet_V2**'
- en: Figure [11](#Fig11) shows that from epoch 0 to 18, the training and testing
    accuracy curve are increasing until the value of 95.51%. After epoch 18, the accuracy
    begins to be stable, equivalent to 99.11% and 96.41% for training and testing
    data. We can see an excellent fit for the loss curve for training and testing
    data where the values are 3.99 (epoch 24) and 1.17 (epoch 300). For the Pneumonia
    class, as depicted by the confusion matrix, the Inception_ResNet_V2 model was
    able to identify 1618 images correctly as pneumonia and 111 images as Normal.
    On other hand, for Normal class, 1705 were correctly classified as Normal and
    24 images as pneumonia.![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig11_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig11_HTML.png)
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图[11](#Fig11)显示了从第0个时期到第18个时期，训练和测试准确率曲线都在增加，直到达到95.51%的值。在第18个时期之后，准确度开始稳定，分别为训练数据和测试数据的99.11%和96.41%。我们可以看到训练数据和测试数据的损失曲线拟合良好，其中数值分别为3.99（第24个时期）和1.17（第300个时期）。对于混淆矩阵所示的肺炎类别，Inception_ResNet_V2模型能够正确识别1618张图像为肺炎，111张图像为正常。另一方面，对于正常类别，有1705张被正确分类为正常，24张图像被识别为肺炎。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig11_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig11_HTML.png)
- en: Fig. 11
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11
- en: Accuracy and loss curve and confusion matrix of Fine-tuned Inception_Res-Net_V2
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 经过微调的Inception_Res-Net_V2的准确率和损失曲线以及混淆矩阵
- en: '**DensNet201**'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DensNet201**'
- en: The obtained accuracy curve of training data is speedily increasing until the
    value of 93.49% (Fig. [12](#Fig12)). After epoch 16, the accuracy enters the stability
    stage where it is equivalent to 97.16% and 94.91% for training and testing data
    respectively. A good fit can be seen for the loss curve of training and testing
    data. In fact, from epoch 0 to epoch 17, the loss is quickly decreasing where
    it is equal to 3.99, and then it becomes stable until the epoch 300 where it is
    equal to 1.91\. The confusion matrix depicts that for the first images (Normal
    class) the model can recognize 1712 images correctly in the normal class, yet
    17 were named as pneumonia. The model also was able to identify 1527 images correctly,
    and 202 images were marked as Normal for the second images (Pneumonia class).![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig12_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig12_HTML.png)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据的获得准确率曲线迅速增加，直到 93.49%（图 [12](#Fig12)）。在第 16 个时期之后，准确率进入稳定阶段，在训练数据和测试数据中分别为
    97.16% 和 94.91%。训练和测试数据的损失曲线显示出良好的拟合。事实上，从第 0 个时期到第 17 个时期，损失迅速减小，其中等于 3.99，然后在第
    300 个时期之前变得稳定，其值为 1.91。混淆矩阵显示，对于第一类图像（正常类），模型能够正确识别 1712 个图像为正常类，但有 17 个被标记为肺炎。对于第二类图像（肺炎类），模型也能够正确识别
    1527 个图像，并将 202 个图像标记为正常。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig12_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig12_HTML.png)
- en: Fig. 12
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图12
- en: Accuracy and loss curve and confusion matrix of Fine-tuned DensNet201
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 经过微调的DensNet201的准确率和损失曲线以及混淆矩阵
- en: '**MobileNet_V2**'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MobileNet_V2**'
- en: As illustrated by Fig. [13](#Fig13), we can observe that from epoch 0 to 16,
    the training and testing accuracy are increasing until the value where the accuracy
    is equal to 96.38%. After epoch 16, the accuracy becomes stable and it is equal
    to 98.27% and 96.64% for training and testing data respectively. For the loss
    curve of training data, an excellent fit is noticed. Until the epoch 44, the value
    of loss is expeditiously decreasing where the value is 1.49\. Then it converges
    towards 0.24\. Regarding the confusion matrix, for the first images (Normal class),
    the model was able to identify 1696 images correctly in the normal class, but
    33 were classified as pneumonia. Likewise, in the Pneumonia class, 1634 images
    were labeled correctly as pneumonia and 95 were identified as Normal.![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig13_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig13_HTML.png)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [13](#Fig13) 所示，我们可以观察到从第 0 到第 16 个时期，训练和测试准确率都在增加，直到准确率达到 96.38% 的值。在第 16
    个时期之后，准确率变得稳定，并且分别为训练数据和测试数据的 98.27% 和 96.64%。对于训练数据的损失曲线，可以看到良好的拟合。直到第 44 个时期，损失的值迅速减小，其中值为
    1.49。然后收敛到 0.24。关于混淆矩阵，对于第一类图像（正常类），模型能够正确识别 1696 个图像为正常类，但有 33 个被分类为肺炎。同样，在肺炎类中，有
    1634 个图像被正确标记为肺炎，95 个被识别为正常。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig13_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig13_HTML.png)
- en: Fig. 13
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图13
- en: Accuracy and loss curve and confusion matrix of Fine-tuned MobileNet_V2
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 经过微调的MobileNet_V2的准确率和损失曲线以及混淆矩阵
- en: '**Xception**'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Xception**'
- en: It is noted that the accuracy of training data is fastly increasing from epoch
    0 to 10 where the accuracy is equal to 93.10% (see Fig. [14](#Fig14)). Then it
    gets stable until the end of training where the accuracy is equal to 95.45%. For
    the testing data, a quick increasing can be seen from epoch 0 to 12 where the
    value is 86.87%, after that, it begins to decrease till 69.03% for epoch 300\.
    For the loss curve of training and testing data, the values are rapidly decreasing
    from epoch 0 to epoch 26, where the value is 1.10\. After epoch 26, the value
    converges to 0.44 and 0.69 for training and testing data respectively. When we
    see this confusion matrix, we can say that for the first images (Normal class),
    the model has the option to recognize 1656 images correctly. Moreover, 73 were
    selected as pneumonia. The model also can recognize 1219 images correctly (Pneumonia
    class). Thus 510 images were marked as Normal for the second images (Pneumonia
    class).![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig14_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig14_HTML.png)
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到训练数据的准确率在从 epoch 0 到 10 时迅速增加，其中准确率为 93.10%（见图 [14](#Fig14)）。然后在训练结束时稳定在
    95.45%。对于测试数据，在从 epoch 0 到 12 时可以看到快速增加，其中值为 86.87%，之后开始下降，直到 epoch 300 时为 69.03%。对于训练和测试数据的损失曲线，值在从
    epoch 0 到 epoch 26 时迅速下降，其中值为 1.10。在 epoch 26 之后，值分别收敛到 0.44 和 0.69，用于训练和测试数据。当我们查看这个混淆矩阵时，我们可以说对于第一张图像（正常类），模型有选项正确识别
    1656 张图像。此外，73 张被选为肺炎。该模型还能正确识别 1219 张图像（肺炎类）。因此，对于第二张图像（肺炎类），有 510 张被标记为正常。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig14_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig14_HTML.png)
- en: Fig. 14
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图14
- en: Accuracy and loss curve and confusion matrix of Fine-tuned Xception
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度和损失曲线以及 Fine-tuned Xception 的混淆矩阵
- en: 4.7.2 Discussion
  id: totrans-132
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.7.2 讨论
- en: In this study, we investigated the binary classification (Normal and pneumonia)
    based on X-Ray images using transfer learning of recent deep learning architectures
    to identify the best performing architecture based on the several parameters defined
    in Eq. ([2](#Equ2)). First, we individually compare the deep learning architectures
    by measuring their accuracies. After that, we compare each deep learning architecture’s
    accuracy and loss results to discern the outperforming architecture (Figs. [15](#Fig15),
    [16](#Fig16)). Moreover, Table [3](#Tab3) illustrates a comparison between the
    various deep learning models used in our experiments in terms of parameters defined
    in Eq. ([2](#Equ2)).![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig15_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig15_HTML.png)
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们使用最近的深度学习架构的迁移学习来基于 X-Ray 图像进行二分类（正常和肺炎），以确定根据 Eq. ([2](#Equ2)) 中定义的几个参数的最佳执行架构。首先，我们通过测量它们的准确性来逐个比较深度学习架构。之后，我们比较每个深度学习架构的准确性和损失结果，以识别表现最佳的架构（图 [15](#Fig15)，[16](#Fig16)）。此外，表 [3](#Tab3)
    概述了我们实验中使用的各种深度学习模型在 Eq. ([2](#Equ2)) 中定义的参数方面的比较。![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig15_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig15_HTML.png)
- en: Fig. 15
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图15
- en: Summarization of the previous figures in term of accuracy curve for different
    architectures
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 根据不同架构的准确率曲线总结前面的图表
- en: '![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig16_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig16_HTML.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![../images/507793_1_En_14_Chapter/507793_1_En_14_Fig16_HTML.png](../images/507793_1_En_14_Chapter/507793_1_En_14_Fig16_HTML.png)'
- en: Fig. 16
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图16
- en: Summarization of the previous figures in term of Loss curve for different architectures
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 根据不同架构的损失曲线总结前面的图表
- en: Table 3
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 3
- en: Evaluations metrics in (%)
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 评估指标（%）
- en: '|   | TP | TN | FN | FP | ACC | SEN | SPE | PRE | F1 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '|   | TP | TN | FN | FP | ACC | SEN | SPE | PRE | F1 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Baseline CNN | 1634 | 1277 | 452 | 95 | 84.18 | 78.33 | 93.07 | 94.05 | 85.66
    |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 基线 CNN | 1634 | 1277 | 452 | 95 | 84.18 | 78.33 | 93.07 | 94.05 | 85.66 |'
- en: '| VGG16 | 1517 | 1466 | 263 | 212 | 86.26 | 85.22 | 87.36 | 87.73 | 86.46 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| VGG16 | 1517 | 1466 | 263 | 212 | 86.26 | 85.22 | 87.36 | 87.73 | 86.46 |'
- en: '| VGG19 | 1390 | 1582 | 147 | 339 | 85.94 | 90.43 | 82.35 | 80.39 | 85.11 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| VGG19 | 1390 | 1582 | 147 | 339 | 85.94 | 90.43 | 82.35 | 80.39 | 85.11 |'
- en: '| Xception | 1656 | 1219 | 510 | 73 | 83.14 | 76.45 | 94.34 | 95.77 | 85.03
    |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| Xception | 1656 | 1219 | 510 | 73 | 83.14 | 76.45 | 94.34 | 95.77 | 85.03
    |'
- en: '| DensNet201 | 1712 | 1527 | 202 | 17 | 93.66 | 89.44 | 98.89 | 99.01 | 93.98
    |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| DensNet201 | 1712 | 1527 | 202 | 17 | 93.66 | 89.44 | 98.89 | 99.01 | 93.98
    |'
- en: '| Inception_V3 | 1621 | 1650 | 79 | 108 | 94.59 | 95.35 | 93.85 | 93.75 | 94.54
    |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| Inception_V3 | 1621 | 1650 | 79 | 108 | 94.59 | 95.35 | 93.85 | 93.75 | 94.54
    |'
- en: '| Inception_ Resnet_V2 | 1705 | 1618 | 111 | 24 | 96.09 | 93.88 | 98.53 | 98.61
    | 96.19 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| Inception_ Resnet_V2 | 1705 | 1618 | 111 | 24 | 96.09 | 93.88 | 98.53 | 98.61
    | 96.19 |'
- en: '| MobileNet_V2 | 1696 | 1634 | 95 | 33 | 96.27 | 94.61 | 98.02 | 98.06 | 96.30
    |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| MobileNet_V2 | 1696 | 1634 | 95 | 33 | 96.27 | 94.61 | 98.02 | 98.06 | 96.30
    |'
- en: '| Resnet50 | 1703 | 1638 | 91 | 26 | 96.61 | 94.92 | 98.43 | 98.49 | 96.67
    |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| Resnet50 | 1703 | 1638 | 91 | 26 | 96.61 | 94.92 | 98.43 | 98.49 | 96.67
    |'
- en: For each model in Fig. [15](#Fig15)(a) and (b), which summarize the previous
    training and testing accuracy figures, the plots of training and testing accuracy
    increase to the point of stability. It is observed that fine-tuned version of
    Inception_Resnet_V2, Inception_V3, Resnet50, Densnet201 and Mobilenet_V2 show
    highly satisfactory performance with a rate of increase in training and testing
    accuracy with each epoch. They outperform the baseline CNN, Xception, VGG16 and
    VGG19 that demonstrate low performance. From epoch 20, they start to be stable
    until the end of training where the training and testing accuracy of baseline
    CNN, VGG16 and VGG16 are equal to 85%. However, Xception reaches 83% in testing
    accuracy and 95% in training accuracy. In this case, the predictive model produced
    by Xception algorithm does not adapt well to the training set (Over-fitting).
    Besides, the plots of training and testing loss (Fig. [16](#Fig16)(a) and (b))
    decrease to the point of stability for each proposed model. As can be seen, the
    fine-tuned version of the models shows highly satisfactory performance with the
    rate of decrease in training and testing loss with each epoch.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图 [15](#Fig15)(a)和(b)中每个模型，它们总结了先前的训练和测试准确度数据，训练和测试准确度的图表增长到稳定点。观察到Inception_Resnet_V2、Inception_V3、Resnet50、Densnet201和Mobilenet_V2的微调版本表现出令人满意的性能，随着每个时期的训练和测试准确度的增加而增加。它们优于基线CNN、Xception、VGG16和VGG19，这些模型表现不佳。从第20个时期开始，它们开始稳定直到训练结束，基线CNN、VGG16和VGG16的训练和测试准确度等于85%。然而，Xception在测试准确度达到83%，训练准确度达到95%。在这种情况下，Xception算法产生的预测模型对训练集不适应（过拟合）。此外，每个提出模型的训练和测试损失的图表（图 [16](#Fig16)(a)和(b)）减少到稳定点。可以看出，模型的微调版本表现出每个时期训练和测试损失的下降率非常令人满意。
- en: Results for our multi-experiment classification are tabulated in Table [3](#Tab3)
    based on different fine-tuned versions of recent deep learning architectures.
    The table depicts in detail classification performances across each experiment.
    From the results, it is noted that the accuracy when we use Xception, baseline
    CNN, VGG19 and VGG16 are low compared with other DL architectures, since these
    last models help to obtain respectively 83.14%, 84.18%, 85.94% and 86.26% of accuracy.
    Unlike, the highest accuracies are reported by DensNet201 (93.66%), Inception_V3
    (94.59%), Inception_Resnet_V2 (96.09%), MobileNet_V2 (96.27%) and Resnet50 (96.61%).
    In addition, MobileNet_V2 has been proven to obtain remarkable results in related
    tasks [[77](#CR77)] whereas ResNet50 [[68](#CR68), [78](#CR78)] provides a good
    combination of performance and number of parameters and has proved faster training.
    Therefore, we recommend the MobileNet_V2 (96.27% of accuracy) and Resnet50 (96.61%
    of accuracy) models to be used for the Computer-Aided Diagnosis systems to identify
    the health status of patients against pneumonia in X-ray and CT images, since
    the best scores of training and testing accuracy were obtained. Clinical examinations
    are the following step of this research work.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '我们基于不同的最新深度学习架构的微调版本进行了多实验分类，根据表 [3](#Tab3) 统计了结果。该表详细描述了每个实验的分类性能。从结果中可以看出，当我们使用Xception、基线CNN、VGG19和VGG16时，准确度较低，因为这些模型帮助分别获得了83.14%、84.18%、85.94%和86.26%的准确度。相反，最高的准确度由DensNet201
    (93.66%)、Inception_V3 (94.59%)、Inception_Resnet_V2 (96.09%)、MobileNet_V2 (96.27%)
    和Resnet50 (96.61%) 报告。此外，MobileNet_V2已被证明在相关任务中获得了显着的结果[[77](#CR77)]，而ResNet50[[68](#CR68),
    [78](#CR78)]提供了性能和参数数量的良好组合，并且已证明训练速度更快。因此，我们建议将MobileNet_V2 (96.27%的准确度) 和Resnet50
    (96.61%的准确度) 模型用于计算机辅助诊断系统，以识别X射线和CT图像中肺炎患者的健康状态，因为这些模型获得了最佳的训练和测试准确度分数。临床检查是这项研究工作的下一步。  '
- en: 5 Conclusions and Future Works
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论和未来工作
- en: 'In this work, we presented automated methods used to classify the chest X-Ray
    & CT images into pneumonia and the normal class using eight deep learning architectures
    (VGG16, VGG19, DenseNet201, Inception_ResNet_V2, Inception_V3, Xception, Resnet50,
    and MobileNet_V2) and a baseline CNN. The main goal is to answer the following
    research questions: (1). Are there any DL techniques which distinctly outperforms
    other DL techniques? (2). Can DL use to early screen pneumonia from CT and X-Ray
    images? (3). What is the diagnostic accuracy that DL can be attained based on
    CT and X-Ray images?. The experiments were conducted using chest X-Ray & CT dataset,
    which contains 6087 images (4504 pneumonia and 1583 normal). The pneumonia class
    contains images of bacterial pneumonia, viral pneumonia and Covid19\. Moreover,
    the performances of these experiments were evaluated using various performance
    metrics. Furthermore, the obtained results show that the Resnet50 gave high performance
    (accuracy is more than 96%) against other architectures cited in this work (accuracy
    is lower than 96%). Due to these models’ high performance, we believe that these
    results help doctors make decisions in clinical practice.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们提出了使用八种深度学习架构（VGG16、VGG19、DenseNet201、Inception_ResNet_V2、Inception_V3、Xception、Resnet50
    和 MobileNet_V2）和一个基线 CNN 将胸部 X 射线和 CT 图像分类为肺炎和正常类别的自动方法。主要目标是回答以下研究问题：（1）是否有任何
    DL 技术明显优于其他 DL 技术？（2）DL 可以用于早期筛查 CT 和 X 射线图像中的肺炎吗？（3）DL 可以基于 CT 和 X 射线图像达到的诊断准确度是多少？实验使用包含
    6087 张图像（4504 张肺炎和 1583 张正常）的胸部 X 射线和 CT 数据集进行。肺炎类包含细菌性肺炎、病毒性肺炎和 Covid19 的图像。此外，使用各种性能指标对这些实验的性能进行了评估。此外，所获得的结果显示，Resnet50
    相对于本文中引用的其他架构（准确度低于 96%）表现出较高的性能（准确度超过 96%）。由于这些模型的高性能，我们相信这些结果有助于医生在临床实践中做出决策。
- en: Ongoing work intends to develop a full system for pneumonia via deep learning
    detection, segmentation, and classification. In addition, the performance may
    be improved using more datasets, more sophisticated feature extraction techniques
    such as color [[79](#CR79)], texture [[80](#CR80)], shape [[81](#CR81), [82](#CR82)].
    In addition, the performance may be improved using more datasets, more sophisticated
    feature extraction techniques. Also other fusion approaches would be interesting
    [[83](#CR83)].
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 进行中的工作旨在通过深度学习检测、分割和分类开发肺炎的完整系统。此外，使用更多数据集、更复杂的特征提取技术（如颜色[[79](#CR79)]、纹理[[80](#CR80)]、形状[[81](#CR81)，[82](#CR82)]）可以改善性能。此外，使用更多数据集和更复杂的特征提取技术也可以改善性能。此外，其他融合方法也将是有趣的[[83](#CR83)]。
- en: 'Authors’ Contributions:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 作者贡献：
- en: The experiments and the programming stage were carried out by Khalid El Asnaoui.
    All authors wrote the paper, and all approve this submission.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 实验和编程阶段由 Khalid El Asnaoui 完成。所有作者都参与了论文撰写，并且都批准了本次提交。
